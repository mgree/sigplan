{"article_publication_date": "01-08-2014", "fulltext": "\n Abstract Satisfaction Vijay D Silva Leopold Haller Daniel Kroening Department of Computer Science Department \nof Computer Science Department of Computer Science University of California, Berkeley University of Oxford \nUniversity of Oxford vijayd@eecs.berkeley.edu leopold.haller@cs.ox.ac.uk daniel.kroening@cs.ox.ac.uk \n Abstract This article introduces an abstract interpretation framework that codi.es the operations in \nSAT and SM T solvers in terms of lattices, transformers and .xed points. We develop the idea that a formula \ndenotes a set of models in a universe of structures. This set of mod\u00adels has characterizations as .xed \npoints of deduction, abduction and quanti.cation transformers. A wide range of satis.ability proce\u00addures \ncan be understood as computing and re.ning approximations of such .xed points. These include procedures \nin the DPLL family, those for preprocessing and inprocessing in SAT solvers, decision procedures for \nequality logics, weak arithmetics, and procedures for approximate quanti.cation. Our framework provides \na uni.ed, mathematical basis for studying and combining program analysis and satis.ability procedures. \nA practical bene.t of our work is a new, logic-agnostic architecture for implementing solvers. Categories \nand Subject Descriptors F.4.1 [Mathematical Logic]: Mechanical Theorem Proving; I.2.3 [Deduction and \nTheorem Proving]: Deduction Keywords Abstract interpretation; Logic; Decision Procedures 1. Reasoning \nand Abstraction Static analyzers and satis.ability solvers represent practical tri\u00adumphs of computer \nscience in the face of theoretical hardness re\u00adsults. Static analysis problems are typically undecidable \nyet ana\u00adlyzers compute information that is indispensable in compiler opti\u00admization and program veri.cation. \nThe satis.ability problem for several logics and theories is N P-hard but S AT and SM T solvers handle \nlarge problem instances arising in practice. In this paper, we introduce an abstract interpretation framework \nthat makes ex\u00adplicit some fundamental similarities between the way undecidable and N P-hard problems \nare solved in practice. This framework has several applications including lattice-theoretic characterizations \nof satis.ability algorithms [18, 19], the development of S M T solvers based on abstract interpretation \n[26], and the generalization of sat\u00adis.ability algorithms to static analysis [3, 20]. Abstract interpretation \nis a lattice-theoretic framework for rea\u00adsoning about .xed points [10, 13]. The idiomatic approach to \nap- Permission to make digital or hard copies of part or all of this work for personal or classroom use \nis granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. Copyrights for third-party components \nof this work must be honored. For all other uses, contact the owner/author(s). POPL 14, January 22 24, \n2014, San Diego, CA, USA. Copyright is held by the owner/author(s). ACM 978-1-4503-2544-8/14/01. http://dx.doi.org/10.1145/2535838.2535868 \n plying abstract interpretation to a problem is to characterise solu\u00adtions to the problem by .xed points, \nidentify a space of .xed point approximations, and design an algorithm to compute these approx\u00adimations. \nThe application of abstract interpretation to static anal\u00adysis can be understood in terms of the schema \nbelow. The box on the left is called an abstract domain. It consists of a lattice (A, ., n, U, ., T) \nwith each element a of A representing a set of program states. Each statement s in the programming language \nde.nes four transformers. The predecessor transformer pre s maps a to states the program may have come \nfrom before executing s, while the successor transformer post s maps a to states the program may reach \nafter executing s. The transformers s and post s cap\u00ad pre ture must behaviour. Properties of programs \nare speci.ed as .xed points of such transformers. A r n u . T Fixed point iteration pre s post s pre \ns s Property check post Re.nement vr vt 6r 6t The box on the right represents procedures that use components \nof the abstract domain to reason about .xed points. Iterative pro\u00adcedures are used to compute .xed points. \nThese procedures may use a widening (vr) or dual widening (vt) operator to accelerate convergence. If \nthe result is not precise enough, a narrowing (Lt) or dual narrowing (Lr) operator is used to re.ne the \nresult. The architecture above achieves a valuable separation of concerns by allowing the design and \nimplementation of an abstract domain to be independent of the .xed point approximation procedures. Abstract \nsatisfaction is a framework for applying .xed point approximation to logical reasoning in the same manner \nthat abstract interpretation was .rst applied to static analysis [10]. Consider the satis.ability problem \nfor a logic. An SMT solver typically works in a fragment T of the logic. Elements of T are represented \nusing data structures such as sets, partial functions, graphs, or matrices. These elements are manipulated \nusing techniques called constraint propagation, decisions, learning and subsumption. We show that a solver \ncan be understood in terms of the schema below, which closely resembles the structure of a static analyzer. \nElements of T , ordered by implication, form a lattice of approxima\u00adtions (T , ., n, U, false, true). \nA solver can use deduction to com\u00adpute facts implied by ., or use abduction to compute facts that im\u00adply \n.. These operations de.ne deduction and abduction transform\u00aders (ded . and abd .), and their counterparts \n(cded . and cabd .) for contrapositive reasoning. T . n u false true Theory propagation ded . abd . \ncded . cabd . Con.ict detection extr extt itp sep Decisions and Learning  Propagation and learning in \nsolvers can be viewed as the appli\u00adcation of these transformers. Techniques like decisions, used by a \nsolver to improve precision, correspond to a relaxation of widening called extrapolation (denoted ext \nand ext ), while techniques like r t subsumption and clause minimization correspond to a relaxation of \nnarrowing, which we call interpolation (denoted int and int ). r t Thus, despite external differences, \nthere are fundamental similari\u00adties between the internals of S AT and SM T solvers and static ana\u00adlyzers. \nWe believe that making these similarities explicit has several consequences that we discuss below. Abstract \nInterpretation to S MT One consequence is a transfer of techniques from abstract interpretation to S \nMT solvers. Solvers have been extended with abstractions [4, 30] and joins [1] to im\u00adprove time and memory \nef.ciency, and with widening [33] to aid in guessing loop invariants. We show that the internal data \nstructures of S M T solvers are lattices, which means that these data structures also support joins and \nwidening. Crucially, we show that quanti\u00ad.ers are transformers, which means that abstract quanti.ers \nand best abstract quanti.ers are well de.ned notions. Thus, an abstract interpretation perspective suggests \na new, approximate approach to deduction and quanti.er elimination. S M T to Static Analysis The main \nconclusion of our work is that S M T solvers, like static analyzers, operate on imprecise abstrac\u00adtions. \nHowever, S M T solvers return precise results, which means their algorithms can be understood as techniques \nfor re.ning an imprecise analysis. These techniques are based on properties of lat\u00adtices and can be used \nto re.ne static analyses. SM T solvers for de\u00adcidable logics implement re.nement procedures that are \nguaranteed to terminate (though termination proofs can be non-trivial). The fundamental undecidability \nof static analysis problems precludes the existence of terminating re.nement procedures. An insight we \npresent in Section 4 is that deduction and ab\u00adduction in a logic coincide with reasoning about the postcondi\u00adtions \nand preconditions of conditional statements. Improvements in deduction should lead to an improved handling \nof condition\u00adals in static analyzers. Moreover, preprocessing and inprocessing techniques, which are \nresponsible for recent performance improve\u00adments in solvers can be lifted to static analysis constraints. \nA Grand Uni.cation A lofty goal, towards which this work is an early step, is to achieve a uniform theoretical \nand practical treat\u00adment of static analysis and SMT solving. Speci.cally, if both tech\u00adnologies can be \nunderstood in terms of lattices and transformers, their similarities and differences can be studied using \nlattice theo\u00adretic techniques. The three different problems of combining static analyzers, combining \nS MT solvers, and combining a static analyzer with an SM T solver can be reduced to the single problem \nof com\u00adbining .xed point approximation procedures. Existing procedures such as the reduced product, Nelson-Oppen, \nand D P LL(T), which are now understood to be combination procedures [2, 11, 14], can all be applied \nto the same task. We anticipate practical bene.ts from carrying out a uni.ca\u00adtion programme. Decomposing \na complex piece of software like a static analyzer or an S MT solver into smaller blocks consisting of \nlattice elements, transformers, and an iteration engine leads to a mathematically justi.ed modular design. \nWe expect this modularity to contribute to the development of extensible and programmable solvers and \nanalyzers, and reduce the performance and develop\u00adment overheads involved in integrating different technologies. \n2. Mathematical Preliminaries We denote the complement of a set S as \u00acS, and the set of all subsets of \nS, as the powerset P(S). The function from x to f(g(x)) is denoted f .g, and a function f is treated \nas a set {a . f(a), . . .}when convenient. Sequences We use sequences to simplify presentation. An m\u00adtermed \nA-sequence is a function s\u00af: {0, . . . , m - 1} . A, whose length m is denoted len(\u00afs). We write f(\u00afs) \nfor the application f(s0, . . . , sn-1) and leave implicit that s\u00afhas length n. Given a function g : \nA . C, we write g[a . c] for the function that maps a to c and x distinct from a to g(x). We write a \nsequence of substitutions g[a0 . c0][a1 . c1] \u00b7 \u00b7 \u00b7 with pairwise distinct elements ai as g[\u00afa. c\u00af]. \n Lattices A transformer is a monotone function on a lattice. A lattice is bounded if it has a greatest \nelement, called top and denoted T, and has a least element called bottom and denoted .. A function f \non a lattice is reductive if f(x) x for all x and is extensive if f(x) ; x for all x. A function is idempotent \nif f(f(x)) = f(x) for all x. An upper closure is an idempotent and extensive transformer, and a lower \nclosure is an idempotent and reductive transformer. The pointwise order f g between functions from a \nset to a poset holds if f(x) g(x) holds for all x. The pointwise meet of f and g, denoted f n g, where \nboth functions map into a lattice is de.ned as .x. f (x) ng(x). The pointwise join is similarly de.ned. \nThe set of transformers on a complete lattice form a complete lattice under the pointwise order. A lattice \nis distributive if every x, y and z satisfy x n (y U z) = (x n y) U (x n z), which is equivalent to the \nidentity obtained by interchanging meets and joins. An element y on a bounded lattice is the complement \nof x if x n y = . and x U y = T. Complements may not exist and when they do, may not be unique. We use \nthe notation \u00acx or ~ x for unique complements. Complements in a distributive lattice are unique. A Boolean \nlattice is complemented and distributive. The De Morgan dual of a function f on a Boolean lattice is \nf = \u00ac . f . \u00ac. The powerset lifting of f : A . B is the function f : P(A) . P(B) that maps a set to its \nimage under f. The least and greatest .xed points of a monotone function f on a complete lattice are \ndenoted gfp(f) and lfp(f). Galois Connections Let (L, ) and (M, .) be posets. Two func\u00adtions a : L . \nM and . : M . L form a Galois connection if for all x . L and y . M, a(x) . y if and only if x .(y). \nA Galois . .-- connection is written as L --.M or (L, a, ., M ). The function a a is called the left \nadjoint and . is called the right adjoint of the Galois connection. In a Galois insertion, a is a surjection. \n3. A Collecting Semantics for First-Order Logic The phrase collecting semantics in abstract interpretation \nrefers to associating meaning to an object in terms of its properties. For ex\u00adample, a trace property \nis a set of sequences of states and the col\u00adlecting trace semantics of a program, which is also the strongest \ntrace property the program satis.es, is the set of all program ex\u00adecutions. In this section, we introduce \na compositional, collecting semantics for quanti.ed .rst-order formulae. Our semantics allows us to interpret \na formula as an element of a lattice, so that abstract interpretation of formulae, and of properties \nof formulae, is well de.ned. The collecting semantics of a term is de.ned by lifting the standard evaluation \nsemantics of terms to sets of environments. The collecting semantics of a formula is the set of models \nof the formula. The Boolean operations of conjunction, disjunction and negation have their standard interpretation \nas intersection, union and set complement. Quanti.ers are interpreted as transformers be\u00adtween structures \nover different sets of variables. Of several lattice-theoretic semantics for quanti.ed .rst-order logics \n[38], we use a category-theoretic treatment due to Pitts [40]. A key feature of this treatment is to \nmake the set of free variables part of the syntax of a formula. The structure of the lattices over which \na formula is interpreted are then determined by the syntax of formula. Quanti.ers de.ne transformers \nbetween lattices over different sets of free variables. See [38] for a discussion of the challenges in \ngiving a lattice-theoretic semantics to quanti.ers.  Structural Rules We recall the structural rules \nfor forming terms and formulae. The signature of a .rst-order logic (Sig, ar) consists of disjoint sets \nSig = Pred . Fun of predicate and function symbols whose arity is ar : Sig . N. A nullary function symbol \nis called a constant. We use P, Q, R to range over predicate symbols and F, G, H to range over function \nsymbols. Let Vars be a set of variables and x, y, z range over variables. A .rst-order context G is a \n.nite sequence of variables in which each variable occurs exactly once. We write [] for the empty se\u00adquence, \nG, G' for sequence concatenation, and var(G) for the set of variables in a context. In the case of many-sorted \nlogic, a con\u00adtext is a sequence of pairs, where each pair consists of a variable and a sort. A context \nG' is a subcontext of G if var(G') . var(G). The rules from [40] for forming terms-in-context are given \nbelow. Henceforth, we abbreviate terms-in-context to terms for convenience. In addition to standard rules \nfor variable introduction (VA R) and function composition (F U N), we use a rule (S E Q) for forming \na sequence of terms. The rule for function composition has the side condition that ar(F ) is len(t\u00af). \nWe leave such side conditions implicit in the remaining rules. t\u00af: G t0 : G \u00b7 \u00b7 \u00b7 tn-1 : G VA R F U N \nS E Q x : G, x, G' F (t\u00af) : G t\u00af: G From these rules, we can derive the rules for complete substitu\u00adtion \n(C S U B) and weakening (W E A K) given below. t : \u00afx r0 : G' \u00b7 \u00b7 \u00b7 rn-1 : G' t : G W E A K C S U B t[ \n\u00afx . r\u00af] : G' t : G, G' Terms-in-context are composed with predicate symbols and Boolean operations to \nobtain formulae-in-context. We henceforth abbrevi\u00adate formula-in-context to formula . In the Boolean \noperator rule below, op is one of true, false, ., . or \u00ac applied to the appropriate number of arguments. \nt\u00af: G . : G . : G P R E D O P P (t\u00af) : G . op . : G The weakening rule for formulae is similar to that \nfor terms. Quan\u00adti.cation changes the set of free variables in a formula and causes contraction of a \ncontext. . : G, x, G' . : G, x, G' .-Q .-Q .x.. : G, G' .x.. : G, G' The sets of terms and formulae in \na context G are denoted Term G and Form G, respectively. An atomic predicate is the composition of a \npredicate symbol with terms and a literal is an atomic pred\u00adicate or its negation. A clause is a disjunction \nof literals and a cube is a conjunction of literals. A formula in Conjunctive Nor\u00admal Form (C N F) is \na conjunction of clauses and one in Disjunctive Normal Form (DN F) is a disjunction of cubes. The sets \ncontaining these formulae are denoted LitG, ClauseG, Cube G, CNF G, and DNF G, respectively. If not speci.ed, \nthe formulae we deal with are quanti.er-free. Semantic Structures We now introduce a lattice-theoretic \nstruc\u00adture in which to interpret formulae. This structure consists of a lattice and transformers and \nprovides a template for implementing S M T solvers based on abstract interpretation. Recall that the \nclas\u00adsical semantics of .rst-order logic is given by a Sig-interpretation M = (Val , int), which consists \nof a universe Val and an in\u00adterpretation that maps each function symbol F to a function int(F ) : Val \nar(F ) . Val and each predicate symbol P to a relation int(P ) . Val ar(P ). An environment over G maps \nvariables in G to values. Let EnvG = var(G) . Val be the set of environments over G. The classical semantics \nof .rst-order logic is given by a relation M, e |= . specifying when an environment satis.es a formula. \nCategorical logic does away with environments by observ\u00ading that EnvG . Val is isomorphic to Val len(G). \nFirst-order hyperdoctrines signi.cantly extend this observation to provide a category-theoretic semantics \nfor .rst-order logic [32, 40]. In De.\u00adnition 1 below, we adapt the de.nition of a .rst-order hyperdoctrine \nto powersets of environments. The reader may rightly baulk at the length of the de.nition. One can view \nthe classical and algebraic de.nitions of semantics as making different tradeoffs. In the clas\u00adsical \nsemantics, .rst-order structures have a succinct de.nition but the de.nition of |= is verbose. In algebraic \nsemantics, the de.nition of a structure may appear involved, but (in our opinion) leads to a succinctly \nde.ned semantics. Each item in De.nition 1 is required to provide semantics for some aspect of .rst-order \nlogic. The lattices of tuples P(Val n) rep\u00adresent the domains over which function symbols are interpreted. \nThe lattices of environments P(EnvG) represent the domains over which terms-in-context are interpreted. \nWe use the function v-to-eG that maps values to environments to deal with substitution into a term, and \nthe function e-to-vG to deal with substitution into a predicate. The existential and universal projection \nfunctions (epr and upr ) give a concrete transformer semantics to quanti.ers. De.nition 1. A collecting \nSig-structure de.ned by a .rst-order structure M = (Val , int) consists of the items below. 1. The lattices \nof tuples {(P(Val n), .) | n . N}. 2. The lattices of environments (P(EnvG), .) for every context G. \n 3. For every context G = (x0, . . . , xn-1) of length n, there are two translation functions for mapping \nbetween tuples and environments.  v-to-eG : P(Val n) . P(EnvG) v-to-eG = V . {xi . vi | v\u00af. V } e-to-vG \n: P(EnvG) . P(Val n) e-to-vG = E . {{i . vi | e(xi) = vi} | e . E} 4. There is a weakening function for \nmapping environments from a subcontext G of G' to environments over G'. wkG,G1 : P(EnvG) . P(EnvG1 ) \n wkG,G1 = E .e' | e . E, for all x in G, e(x) = e'(x) 5. For every subcontext G of G' an existential \nprojection eprG1 ,G and a universal projection uprG1 , in P(EnvG1 ) . P(EnvG). ,G eprG1 = E . {e | wkG1,G(e) \nn E = \u00d8} ,G uprG1 = E . {e | wkG1,G(e) . E} ,G 6. A lifting of the interpretation of function symbols \nto sets. cint(F ) : P(Val ar(F )) . P(Val ) cint(F ) = V . {int(F )(\u00afv) | v\u00af. V } 7. The relation int(P \n) for each predicate symbol. The existential and universal projection functions as de.ned above eliminate \narbitrary subcontexts. We only use them to elimi\u00adnate single variables and use the following abbreviations. \nWe write eprx and uprx for projections that extract a single variable by mapping environments over the \ncontext G, x to those over x. Con\u00adversely, we write somex and all x for projections that eliminate a \nsingle variable by mapping environments over G, x to environ\u00adments over G. We also write wkx for the \nweakening function from environments over G to those over G, x.  Collecting Semantics The collecting \nsemantics of terms and se\u00adquences of terms with respect to a classical interpretation M fol\u00adlows. We \ndrop the subscript M when no ambiguity arises. [\u00b7]M : Term n )) G . (P(EnvG) . P(Val n The semantics \nfunction is de.ned inductively below. The semantics of a term t with respect to a set of environments \nE is given by evaluating t in each environment in E. The semantics of a sequence of terms is a set of \nsequences of values. Substitution constructs a sequence of values and lifts it to an environment. [x \n: G] = E . {e(x) | e . E} len(t\u00af) [t\u00af: G] = E . {v\u00af. Val | for some e . E , vi . [ti : G](e) for all \n0 = i < len(t\u00af)} [F (t\u00af) : G] = cint(F ) . [t\u00af: G] [t[ \u00afx . r\u00af] : G] = [t : G ' ] . v-to-eG1 .[r\u00af: G] \nExample 1 below demonstrates how to calculate the semantics of a term in the presence of substitution. \nObserve that the term does not have to be rewritten before being evaluated. Example 1. Consider the term \nt = x + 2y[y . 2x] derived below. VA R x : xW E A K x : x, y F U N VA R y : yW E A K y : x, y VA R F \nU N x : x C S U B x + 2y : x, y 2x : x x + 2y[x . x, y . 2x] : x We interpret variables as natural numbers \nand + as addition. The semantics of the term above is a function in P(Envx) . P(N). [x + 2y[x . x, y \n. 2x] : x] = [x + 2y : x, y] . v-to-ex,y .[(x, 2x) : x] = [x + 2y : x, y] . v-to-ex,y ..E. {(e(x), 2e(x)) \n| e . E)} = [x + 2y : x, y] . .E. {{x . e(x), y . 2e(x)} | e . E} = [x + 2y : x, y] . .E. {e(x) + 4e(x) \n| e . E} = .E. {5e(x) | e . E} In short, a set of environments is mapped to values obtained by multiplying \nthe value of x by 5. < The collecting semantics of terms is the standard evaluation semantics (also called \nforward interpretation ) implemented in program analyzers. The semantics of quanti.er-free formulae given \nnext is a backward interpretation and is known [9] but is less standard. The inverse [t\u00af: G]-1 : P(Val \nlen(t\u00af)) . P(EnvG) is de.ned as follows. [t\u00af: G]-1 = V . {e . EnvG | [t\u00af](e) n V = \u00d8} The semantics of \na formula is given by a function [\u00b7]M : Form G . P(EnvG) de.ned inductively below. Boolean operators \nhave their standard set-theoretic interpretation. [P (t\u00af) : G] = [t\u00af: G]-1(int(P )) [true : G] = EnvG \n[. . . : G] = [. : G] . [. : G] [false : G] = \u00d8 [. . . : G] = [. : G] n [. : G] [\u00ac. : G] = \u00ac[. : G] Quanti.ers \nare interpreted using projection functions. [.x.. : G] = somex([. : G, x]) [.x.. : G] = all x([. : G, \nx]) Example 2. We extend Example 1 to illustrate the semantics of quanti.cation. Consider the formula \n. = .x.x + 2y[y . 2x] = z with = interpreted as equality over the natural numbers. The rela\u00adtion cint(=) \nis {(n, n) | n . N} and the semantics of the formula is a set of environments over z. [.x.x + 2y[x . \nx, y . 2x] = z : z] = somex .[(x + 2y[x . x, y . 2x], z)]-1(cint(=)) = somex .(.E . {(5e(x), e(z)) | \ne . E})-1(cint(=)) = somex({e | e(z) = 5(e(x))}) = {{z . 5n} | n . N} As expected, z maps to multiples \nof 5. This example shows that the semantics of a quanti.ed formula can be calculated mechanically by \napplying the appropriate transformers. If the concrete transform\u00aders are replaced with abstract transformers, \nwe can similarly calcu\u00adlate an abstract semantics. < The collecting semantics we have de.ned is consistent \nwith the classical semantics of .rst-order logic. Theorem 2. For each formula . : G in non-empty context \nG, classical, .rst-order interpretation M and environment e . EnvG, M, e |= . exactly if e . [. : G]M. \nWe also refer to environments as structures. Let G be a non\u00adempty context. A structure e is a model of \n. if e . [. : G]. A formula . is unsatis.able in M if [. : G]M is the empty set and is satis.able in \nM otherwise. We refer to satis.ability in a structure as satis.ability for the rest of the paper. A sentence \nis a formula in an empty context. The set of environ\u00adments over the empty context is the empty set. If \n[. : []]M is {\u00d8}, we say that . is true in M, and otherwise, . is false in M. 4. Concrete Reasoning The \nbasic operations in logical reasoning can be viewed as giving a dynamic interpretation to an implication \n. . .. Deduction is the process of deriving . from .. Abduction is the process of deriving . from .. \nIn classical logic, these processes have contrapositive formulations: we can start with \u00ac. and attempt \nto deduce \u00ac., a process we call contradeduction, or start with \u00ac. and attempt to abduce \u00ac., a process \nwe call contraabduction. In this section, we model these processes using transformers and characterize \nproper\u00adties of formulae as .xed points of these transformers. As with .xed point characterisations of \nprogram correctness, these .xed points are not meant to be computed but will be used to design .xed point \napproximation algorithms. The set of formulae that can be derived from a set of formulae F using a set \nof rules R forms the deductive closure of F with re\u00adspect to R. Deductive closure and automated reasoning \nprocedures have characterizations in terms of Tarski s consequence operator, or as the transitive closure \nof a set of rewrite rules. An important difference between these characterizations and ours is that we \noper\u00adate on sets of structures, so our notions of deduction and abduction are semantic. Existing characterizations \ncan be derived from ours by abstract interpretation but we can also derive abstractions of de\u00adduction \nthat operate on objects other than formulae. 4.1 Structure Transformers A structure transformer for \nformulae in Form G is a function T. : P(EnvG) . P(EnvG). Structure transformers encode reasoning about \nthe models and countermodels of a formula. The deduction transformer ded . which encodes reasoning about \nmodels of .. In the de.nition below, we assume that the set-theoretic operations are lifted pointwise \nto functions.  dedP (t\u00af)(X) = X n [P (t\u00af) : G] ded... = ded. n ded. ded\u00ac. = \u00ac[. : G] ded... = ded. . \nded. The use of negation in de.ning ded\u00ac. is problematic in general because lifting such a de.nition \nto abstractions requires a structure that supports Boolean reasoning. We discuss this issue in greater \ndetail shortly. The contradeduction transformer cded. encodes contrapositive reasoning and manipulates \ncountermodels of .. If ded. is used for satis.ability checking, cded. can be used for validity checking. \ncdedP (t\u00af)(X) = X n \u00ac[P (t\u00af) : G] cded... = cded. . cded. cded\u00ac. = \u00accded. cded... = cded. n cded. The \ntwo transformers above reason forwards in that they start from hypotheses and attempt to derive conclusions. \nThe dual notion to deduction is abduction, where we start from a conclusion and derive the hypotheses \nunder which that conclusion holds. For example if we can abduce true from a formula ., we know that . \nis valid with respect to a set of structures. abdP (t\u00af)(X) = X . \u00ac[P (t\u00af) : G] abd... = abd. . abd. abd\u00ac. \n= cabd. abd... = abd. n abd. Finally, we have a contraabduction transformer which models start\u00ading from \na conclusion and deriving the fallacies: hypotheses from which that conclusion surely does not follow. \nA contraabduction transformer can be used to prune the space of abductions. cabdP (t\u00af)(X) = X . [P (t\u00af) \n: G] cabd... = cabd. n cabd. cabd\u00ac. = abd. cabd... = cabd. . cabd. In addition to deduction and abduction, \nquanti.er elimination is fundamental to logical reasoning. The transformers somex and allx model quanti.er \nelimination and will henceforth be called quanti.cation transformers. There are several symmetries between \ndeduction and abduction, which are preserved in our formulation. We make these properties explicit in \nTheorem 3, below. The set-theoretic identities are not necessarily satis.ed by abstract transformers, \nwhich is why they are not used as a de.nition. The characterizations of deduction and abduction as closures \nextend the existing characterization of log\u00adical consequence as a closure. The characterization of existential \nquanti.cation (wkx . somex) as an upper closure, and of universal quanti.cation (wkx . allx) as a lower \nclosure, when combined with the view of closure operators as abstractions [11], reiterates the connection \nbetween quanti.cation and abstraction used in model checking [5]. The Galois connection between weakening \nand quan\u00adti.cation was .rst observed by Lawvere [32] and indicates that even domains that do not support \nnegation will support both existential and universal quanti.cation. Theorem 3. Structure transformers \nhave the following properties. 1. The transformers satisfy the identities below. ded.(X) = (X n . : G \n) cded.(X) = (X n \u00ac . : G ) cabd.(X) = (X . [ . : G] ) abd.(X) = (X . \u00ac[ . : G] ) 2. The transformers \nded. and cded. are lower closures. 3. The transformers cabd. and abd. are upper closures.  4. The composition \nwkx . somex is an upper closure and wkx . allx is a lower closure. 5. The pairs of transformers (ded., \nabd.), (cded., cabd.) and (allx, somex) are De Morgan duals.  6. The pairs of transformers (ded., abd.) \n(cded., cabd.) form a Galois connection on (P(Env), .).   gfp(ded.) lfp(abd.) gfp(cded\u00ac.) lfp(cabd\u00ac.) \nFigure 1. The vertices represent deduction or abduction proce\u00addures for checking satis.ability of . or \nvalidity of \u00ac.. The edges represent combinations of deduction and abduction procedures. 7. The quanti.cation \ntransformers are related to weakening by the following Galois connections. allx (P(EnvG), .) .---- (P(EnvG,x), \n.), and - --. wkx wkx (P(EnvG,x .----- (P(EnvG), .) ), .) -----. somex The Galois connections are useful \nfor deriving equivalent for\u00admulations of properties of a formula. For example, the mod\u00adels of . are ded.(Env). \nA formula is unsatis.able exactly if ded.(Env) . \u00d8, which by the Galois connection, is equivalent to \nEnv . abd.(\u00d8). In words, we can determine if a formula is unsat\u00adis.able by trying to deduce false from \n. or trying to abduce . from false. Similarly, a formula is valid exactly if cded.(Env) . \u00d8, or equivalently \nEnv . cabd.(\u00d8). Since satis.ability corresponds to existence of a model, we can equivalently de.ne it \nin terms of existential quanti.cation. Treating quanti.ers as transformers allows us to formalise techniques \nthat combine variable elimination and deduction.  4.2 Fixed Points for Satis.ability We now show that \nproperties of a formula can be characterized by .xed points of structure transformers. Consider the process \nof computing consequences of .. We initially know nothing about ., which we can express as . . true. \nA single step of a reasoning algorithm may indicate that . . .1. After k steps, the algorithm may deduce \nthat . . \u00b7 \u00b7 \u00b7 .1 . .k-1 . .k. What we know about the models of . can be represented by the sequence \n[t], [.1], . . . , [.1 . \u00b7 \u00b7 \u00b7 .k]. The process of deduction can thus be viewed as a greatest .xed point \ncomputation, whose limit expresses the maximal information we can derive about models of .. Fixed points \nof structure transformers represent brute force al\u00adgorithms. The greatest .xed point gfp(ded.) represents \nthe se\u00admantics of a solver that initially assumes that every structure is a model of . and then eliminates \ncountermodels of .. The .xed point gfp(cded.) represents a procedure that progresses by eliminating countermodels \nof .. The .xed point lfp(abd.) represents a proce\u00addure that initially assumes . has no countermodels \nand progresses by .nding countermodels of ., while lfp(cabd.) does the same for models of .. The characterisation \nbelow .rst appeared in [18] and is included here to include validity as the dual of satis.ability. Theorem \n4. The following statements are equivalent. 1. The formula . is unsatis.able. 2. The greatest .xed point \ngfp(ded.) is empty. 3. The least .xed point lfp(abd.) has all structures. 4. The formula \u00ac. is valid. \n 5. The least .xed point lfp(cabd\u00ac.) has all structures. 6. The greatest .xed point gfp(cded\u00ac.) is empty. \n In program analysis and model checking, combinations of forward and backward analysis have advantages \nover a single method [9, 28]. In logical reasoning, we can similarly combine the bene.ts of deduction \nand abduction. For instance, as shown in [19], Con.ict Driven Clause Learning (CDCL) combines deduc\u00adtion \nand abduction. The original Davis and Putnam algorithm [16] combined deduction via ordered resolution \nand variable elimina\u00adtion with the pure literal rule. CDCL solvers that use the pure literal rule for \npre-/in-processing combine all three [21].  We de.ne combinations of deduction and abduction transform\u00aders \nbelow. The transformers are de.ned on P(Env) \u00d7 P(Env) with the lattice order shown alongside. For intuition \nabout these com\u00adbinations, consider a greatest .xed point iteration with the trans\u00adformer da., which \ncombines deduction and abduction. The .rst element is (Env, \u00d8), representing that every structure is \na poten\u00adtial model and no structure is a potential countermodel. A single application of da. yields (ded.(Env), \nabd.(\u00d8)), which is a .xed point. If . is unsatis.able, this .xed point is (\u00d8, Env), represent\u00ading that \nthere are no models and every structure is a countermodel. When using abstract transformers, a .xed point \nmay not be reached in a single step so iteration allows information to be transferred be\u00adtween deduction \nand abduction. dcd.(X, Y ) = (ded.(X n Y ), cded\u00ac.(X n Y )) . \u00d7 . da.(X, Y ) = (ded.(X n \u00acY ), abd.(\u00acX \n. Y )) . \u00d7 . dca.(X, Y ) = (ded.(X . Y ), cabd\u00ac.(\u00acX . Y )) . \u00d7 . cda.(X, Y ) = (cded\u00ac.(X n \u00acY ), abd.(\u00acX \n. Y )) . \u00d7 . cdca.(X, Y ) = (cded\u00ac.(X n \u00acY ), cabd\u00ac.(\u00acX . Y )) . \u00d7 . aca.(X, Y ) = (abd.(X . Y ), cabd\u00ac.(X \n. Y )) . \u00d7 . The dcd. transformer is based on Cousot s forward-backward iter\u00adation [9], but the other \ncombinations are, to the best of our knowl\u00adedge, new. An additional possibility for reasoning about satis.a\u00adbility \nis to combine deduction with existential quanti.cation (ds.) and abduction with universal quanti.cation \n(aa.). These are only two of many possible combinations. ds.(X, Y ) = (ded.(X n Y ), wkx . somex(X n \nY )) . \u00d7 . aa.(X, Y ) = (abd.(X . Y ), wkx . allx(X . Y )) . \u00d7 . The application of these transformers \nto satis.ability is below. Theorem 5. The following statements are equivalent. 1. The formula . is unsatis.able. \n 2. The .xed point gfp(da.) is (\u00d8, Env). 3. The .xed point gfp(dcd.) is (\u00d8, \u00d8). 4. The .xed point gfp(dca.) \nis (\u00d8, Env). 5. The .xed point gfp(cda.) is (\u00d8, Env). 6. The .xed point gfp(cdca.) is (\u00d8, Env). 7. \nThe .xed point gfp(aca.) is (Env, Env). 8. The .xed point gfp(ds.) is (\u00d8, \u00d8). 9. The .xed point gfp(aa.) \nis (Env, Env).   4.3 Connection to Programs We now relate deduction and abduction transformers to transform\u00aders \ngenerated by programs. Assume a .rst-order signature Sig and variables Vars as before. We write assume(b), \nabbreviated to [b], for an assumption statement with a quanti.er-free formula b. The operational semantics \nof the statement is below. rel([b]) = {(e, e) | e . [b]} The context for a program is the set of variables \nin the program. The operational semantics de.nes the four transformers below, which are related to deduction \nand abduction in Theorem 6. post[b] = X . X n b post[b] = \u00ac . post[b] . \u00ac pre[b] . \u00ac = X . X n [ b] \npre[b] = \u00ac . pre[b] Theorem 6. For a quanti.er-free test [.] we have that ded. = post[.] and abd. = pre[.]. \nThe consequence of Theorem 6 is that the same transformers can be used for deduction and abduction in \nan SMT solver or for reasoning about conditionals in program analysis. Improvements in solvers lead to \nimproved reasoning about conditionals and vice versa. Moreover, the Galois connection between deduction \nand abduction is a special case of the classic Galois connection between postcondition and precondition \ntransformers [7]. What of assignments? A beautiful result of categorical logic shows that substitution \nde.nes a transformer that has two adjoints, which generalise universal and existential quanti.cation \n[32]. Transformers for assignments are closely related to transformers for quanti.cation. Consequently, \nassignment transformers, which are ubiquitous in program analysis, de.ne approximate quanti.\u00adcation procedures. \nImprovements in quanti.er elimination proce\u00addures should lead to better transformers for assignments. \nDue to space restrictions, we do discuss this connection further. 5. Abstract Reasoning This section \npresents three ideas. The .rst is a standard application of abstract interpretation to the collecting \nsemantics of formulae: if concrete transformers are replaced by abstract transformers, we obtain sound \nbut incomplete conclusions about the properties of a formula. The second is the notion of an abstract \nreasoning do\u00admain, which provides the building blocks for SMT solvers based on abstract interpretation \nin the same way that traditional abstract do\u00admains are building blocks of program analyzers. The third \nidea is that standard logical notions such as de.nability or completeness are properties of a Galois \nconnection between lattices of structures and lattices of formulae. Abstract Interpretation We recall \nessential notions of abstract interpretation. Assume two posets C and A related by a Galois connection \nbetween an abstraction function a : C . A and a concretisation function . : A . C. The fundamental .xed \npoint approximation theorem of abstract interpretation is below, with aF representing the abstract transformer \ncorresponding to F . Theorem 7 ([7]). Let (C, a, ., A) be a Galois connection be\u00adtween two complete lattices \nand F : C . C and aF : A . A be transformers satisfying a . F aF . a. Then, a(lfp(F )) lfp(aF ) and a(gfp(F \n)) gfp(aF). In the case that C is a powerset lattice P(S), we call A overap\u00adproximating if X . .(a(X)) \nfor all X . S and underapproxi\u00admating if .(a(X)) . X for all X . S. An abstract transformer aF : A . \nA is a sound overapproximation of a concrete trans\u00adformer F : P(S) . P(S) if F . . . . . aF and is a \nsound underapproximation if F . . . . . aF . An abstract transformer aF is a-complete for F at c if it \nsatis\u00ad.es a(F (c)) = aF (a(c)) and is a-complete if a.F = aF .a. We say that f is a-.xed point complete \nif a(lfp(F )) = lfp(aF ). An abstract transformer aF is .-complete for F at a if .(aF (a)) = F (.(a)) \nand is .-complete if . . aF = F . .. 5.1 Abstract Interpretation of Formulae We introduce abstract Sig-structures \nwhich are derived from col\u00adlecting Sig-structures by replacing concrete transformers with ab\u00adstract transformers. \nEvaluating a formula with respect to an abstract Sig-structure allows us to approximate the semantics \nof a formula in a predictable manner. De.nition 8. An abstract Sig-structure A consists of the follow\u00ading \ncomplete lattices and transformers. 1. Abstract value lattices (aValn, , n, U) for each n . N. 2. Abstract \nenvironment lattices (aEnvG, , n, U) for each G.   3. Abstract translation functions av-to-eG : aValn \n. aEnvG 4. The projection functions are given below. and ae-to-vG : aEnvG . aValn whenever len(G) = n. \n' aeprG,G1 = e . x . e(x) | x . var(G . .. ) 4. An abstract weakening function awkG,G1 : aEnvG . aEnvG1 \nfor each context G ' and subcontext G. {x . e(x) | x . var(G ' e(y) = T for all y . var(G) \\ var(G ' \n )} if 5. Projection functions aeprG1 ,G, auprG1 ,G : aEnvG1 . aEnvG, auprG,G1 = e . ) .. for every \nsubcontext G of G ' . . otherwise 6. An abstract interpretation aint(F ) : aValar(F ) . aVal1 and its \ninverse ainv(F ) : aVal1 . aValar(F ) for every function symbol F . Sig. 7. An abstract interpretation \naint(P ) . aValar(P ) of every pred\u00adicate symbol P . Sig.  Every abstract lattice above is related to \nthe corresponding con\u00adcrete lattice by a Galois connection (C, a, ., A). We extend the convention for \ncollecting structures and write asomex and aallx for elimination of a single variable. The abstract semantics \nof terms and of formulae with respect to an abstract Sig-structure is given by the functions below. [\u00b7]A \n: Term n [\u00b7]A : FormG . aEnvGG . aEnvG . aValn We obtain these by replacing concrete transformers and \nsemantics by their abstract counterparts in the de.nition []C given earlier. Ex\u00adisting abstract domains \nalready implement several components of De.nition 8. These domains have abstract value and environment \ndomains. The abstract semantics of terms is called forward ab\u00adstract interpretation of expressions and \nthe abstract semantics of a quanti.er-free formula is called backward abstract interpretation of expressions \nin [8]. The abstract semantics of a quanti.er-free . overapproximates the concrete semantics if [. : \nG]C . .([. : G]A). Underapprox\u00adimation is dually de.ned. Abstract domains in program analysis need not \nhave a representation of the empty set. For example, the one-element abstraction is a sound overapproximation \n[10]. When dealing with satis.ability, a representation of the empty set is nec\u00adessary to express that \na formula is unsatis.able. Soundness, as de\u00ad.ned below, includes this condition. The one-element abstraction \nis not necessarily sound in the sense below. De.nition 9. An abstract Sig-structure A soundly overapprox\u00adimates \na collecting Sig-structure C if every lattice in A satis\u00ad.es .(.) = \u00d8 and concrete and abstract transformers \nsatisfy F . . . . . aF . An abstract transformer aF is the best abstract transformer if aF = a . F . \n.. When dealing with underapproximations, these de.nitions are dualised. The soundness of abstraction \nfor negation-free formulae is given below. We discuss negation is more detail shortly. Theorem 10. If \nA is a sound overapproximation of C and . is negation-free [. : G]C . .([. : G]A). The Interval Domain \nWe present an extended example of ab\u00adstractly interpreting quanti.ed formulae over intervals. It is known \nthat interval propagation can be used reason about terms, but the ex\u00adample we present shows that it also \nsupports sound but incomplete reasoning about quanti.ers. The example also exhibits a difference between \nabstract quanti.ers and best abstract quanti.ers. The complete lattice of intervals (Intv, , n, U) is \nde.ned over the set Intv = {[a, b] | a = b, a, b . Z. {-8, 8}}, with . representing the empty interval \nand T being [-8, 8]. The interval structure I contains the items below. 1. The value lattices aValn are \nproduct lattices Intvn . 2. The interval environments aEnvG are var(G) . Intv. 3. The weakening function \nextends an interval with the new vari\u00adable going to T.  awkG,G1 = e . e . y . T | y . var(G) \\ var(G \n' ) Existential projection drops certain variables and universal pro\u00ad jection is not . only if the variables \nbeing dropped are all T. The interpretation of functions and predicates depends on the sig\u00adnature of \nthe theory considered. Example 3. We compute the abstract semantics [.]Intv of the formula . = x = 5 \n. x = 10 . y = 2 using the interval domain. [x = 5] n [x = 10] n [y = 2] = {x . [5, 10], y . [2, 2]} \nThe domain also supports abstract quanti.cation. .y.. = asomey([.]) = {x . [5, 10]} [ .y..] = aally([.]) \n= . Now consider . = . . y = 3 whose semantics is [.]Intv = {x . [5, 10], y . .}. We have that asomey([.]Intv \n) = {x . [5, 10]} , but a(somey(.([.]Intv ))) = a(somey(\u00d8)) = . showing that the existential projection \ntransformer we have de.ned is not the best possible. < Negation Theorem 10 only applies to negation-free \nformulae. Example 4 illustrates the problem of formulae with negation. Example 4. Consider a logic with \nunary predicates of the form x = k interpreted over the integers. Consider the parity lattice Par = ({., \nE, O, T} , ), which represents even and odd numbers. Let [x = k]Par be E if k is even and be O otherwise. \nThe complement ~ in this lattice cannot be used to approximate negation. To see why, consider evaluating \n\u00ac(x = 2) as ~[x = 2]Par , which is ~ E = O but .(O) does not include all models of \u00ac(x = 2). The only \nsound abstraction of negation is to map every element to T. < More generally, in domains that allow for \nstrict overapproxima\u00adtion of the semantics of a formula, the only sound abstract negation will map every \nelement to T. This problem only exists if the syn\u00adtax of formulae have arbitrary negation. If negation \nis limited to atomic predicates, De.nition 8 can be extended to include an ab\u00adstract interpretation aint(\u00acP \n) of the negation of every predicate, De.nition 9 can be extended to require sound overapproximation \nof negation of predicates, and Theorem 10 can be extended to formu\u00adlae in negation normal form. A similar \nrestriction is applied when model checking is combined with abstraction [5].  5.2 Abstract Reasoning \nDomains We now identify the structure of an abstract domain for logical rea\u00adsoning. In addition to a \nlattice that provides approximate seman\u00adtics of formulae and abstract transformers that provide approximate \nsemantics for logical operators, the domain includes operators for inductive reasoning (in the sense \nof philosophical logic). Unlike deductive and abductive reasoning, which are both sound with re\u00adspect \nto implication, inductive reasoning models generalization or specialization which are not necessarily \nsound. Widening and dual-widening operators implement inductive reasoning in program analyzers. Craig \ninterpolation is another tech\u00adnique used for generalisation [34]. Narrowing is a restricted form of interpolation \nin a lattice because it maps a pair satisfying A B to an element I satisfying A I and I B. Narrowing \ndoes not have the syntactic constraints of Craig interpolation because the lattice is not necessarily \nconstructed from formulae. McMillan s notion of interpolation, which we call separation, maps a pair \nsat\u00adisfying A n B . to an I satisfying A I and I n B .. While interpolation and separation are inter-derivable \non Boolean lattices they are not in general, hence have distinct de.nitions.  De.nition 11. A reasoning \ndomain is an extension of an abstract Sig structure with the following operations. 1. Abstract transformers \naded., acded., aabd. and acabd. for deduction and abduction. 2. A unary, extensive function ext : L \n. L called upwards extrapolation and its dual extt r : L . L called downwards extrapolation. 3. A partial, \ninterpolation function itp : L \u00d7 L . L, satisfying x itp(x, y) y whenever x y. The element itp(x, y) \nis called an interpolant. 4. A partial, separation function sep : L \u00d7 L . L, satisfying x sep(x, y) \nand sep(x, y) n y . whenever x n y .. The element sep(x, y) is called a separator.  We use the word \nfunction and not transformers above be\u00ad cause the operations need not be monotone, as with widening [9]. \nExample 5. We apply abstract, interval deduction by computing gfp(aded.) with . = x = 5 . x = 10 . y \n= 2x and E0 = T. E1 = aded.(E0) = [x = 5](T) n [x = 10](T) n [y = 2x](T) = {x . [5, 10], y . [-8, 8]} \nE2 = aded.(E1) = [x = 5](E1) n [x = 10](E1) n [y = 2x](E1) = {x . [5, 10], y . [10, 20]} = gfp(aded.) \nThe .xed point is super.uous in the concrete but yields more information in the abstract than one transformer \napplication. < The overapproximation and underapproximation conditions given earlier provide the following \nabstract satisfaction theorem. Theorem 12. Let O be an overapproximate reasoning domain and U be an underapproximate \none. 1. If .(gfp(aded.)) = \u00d8 in O then . is unsatis.able. 2. If .(lfp(aabd.)) = EnvG in U then . is \nunsatis.able.   5.3 Galois Connection of Syntax and Semantics The .rst abstraction we identify is between \nsyntax and semantics. The Galois connection below has been observed in different set\u00adtings in the literature \n[32, 42]. We are not aware of this connection being identi.ed in the setting that we use. Theories and \nDe.nability A theory is a set of formulae, each called an axiom. A complete theory is a set of formulae \nclosed under implication. The theory of a set of structures S consists of formulae which are true in \nevery structure in S. A set of structures S is de.nable if there exists a formula . such that S = [.]. \nThese notions lead to a Galois connection. th : P(EnvG) . P(FormG) st : P(FormG) . P(EnvG) th = S . \n{. | S . [.]} = F .[.] st ..F st -- Theorem 13. There is a Galois connection (P(Env), .) .- -. th (P(Form), \n.) between structures and formulae. The superset order is chosen because we interpret a set of formulae \nas their conjunction. The Galois connection allows us to view formulae as abstractions of structures \nand is appropriate for our goal of studying satis.ability. In a proof-theoretic investigation, one may \nprefer to accord primacy to formulae and view structures as abstractions. By the Galois connection, a \ncomplete theory F is one satisfying th(st(F)) and a set of structures S is de.nable if st(th(S)) = S. \nProof Systems The Galois connection of syntax and semantics allows us to view proof rules as transformers \non an abstract domain of formulae and logical soundness and completeness as soundness and completeness \nin the sense of abstract interpretation. A proof rule is a relation between formulae. In a rule contain\u00ading \n(.0, . . . , .n-1, .n) the formulae .0, . . . , .n-1 are called an\u00adtecedents and .n is the consequent. \nA proof system is a collection of proof rules of possibly different arities. A unary rule is a set of \nformulae, which are also called the hypotheses. A formula . is derived from a set of formulae F using \na proof system, written F f ., if . occurs in F or if . is derived from .0, . . . , .n-1 by applying \nan n-ary inference rule and the formulae .1, . . . , .n are derived from F. The deductive closure of \na set of axioms F with respect to a proof system f is the set of all formulae that can be derived from \nF with f. A proof system is deductively sound if every . derived from F is in the theory of F. A proof \nsystem is deductively complete if every . in the theory of F can be derived from F. A refutation is a \nderivation of false. A proof system f de.nes a transformer aded. : P(Form) . P(Form) from a set of formulae \nto its immediate consequences. aded. = F . {. | there exist .i . F . {.} (.0, . . . , .n-1, .) is in \na proof rule } The .xed point gfp(aded.) (with respect to the superset order) contains all formulae derivable \nfrom .. Since multiple applications of proof rules are required to derive a conclusion, aded. is not \nusually a closure operator. Properties of proof systems become properties of the abstract transformer. \nLemma 14. A proof system f is deductively sound exactly if ded. . st . aded. . th and is deductively \ncomplete exactly if th . ded. . st = gfp(aded.). While deductive soundness corresponds to soundness in \nab\u00adstract interpretation, deductive completeness is .xed point com\u00adpleteness, which is only one of several \ncompleteness notions [24]. 6. Abstract Satisfaction Procedures The framework in the previous section \nhas already been applied to characterize satis.ability procedures for propositional and .rst\u00adorder logics \nin terms of the lattices and transformers. The method of truth tables, propositional resolution, and \nBoolean Constraint Prop\u00adagation were formalized as greatest .xed points in [18]. The classic DPLL algorithm \nwas shown to be a .xed point re.nement procedure in [18], and CDCL was formalized as a combination of \ndeduction and abduction in [19]. The congruence closure algorithm for the theory of equality with uninterpreted \nfunctions is a .xed point in a lattice of partitions, and the application of the Bellman-Ford al\u00adgorithm \nfor deciding difference logic is a .xed point in a lattice of weighted graphs [2]. The DPLL(T) algorithm \nused in SMT solvers was characterized as an approximate, reduced product construction in [2]. Though \ndifferent frameworks were used to give a lattice\u00adtheoretic characterization of the Nelson-Oppen procedure \n[14] and St\u00b0 almarck s method [44], those procedures can also be formulated in the language of this paper. \nThis section introduces a simple and systematic formulation of the abstractions above. We introduce lattice-theoretic \ngeneraliza\u00adtions of CNF and DNF formulae. A wide range of lattices used in practice, such as partial \nassignments, equality graphs, the intervals, and binary implication graphs, admit such a representation. \nWe exhibit Galois connections showing that C N F and D N F and their generalizations de.ne semantic abstractions. \nMoreover, these lat\u00adtices support logical notions such as resolution, the pure literal rule, and subsumption. \nWe demonstrate that pre-and in-processing tech\u00adniques used in S AT solvers can be understood as abstract \nquanti.ca\u00adtion procedures. Thus, these procedures have a semantic justi.ca\u00adtion, abstract interpretation-based \nsoundness proofs, and generalize to program analysis.  Upwards and Downwards Closure We will use the \nnotions of upward and downward closure to generalise C N F and D N F formulae to logics de.ned over posets. \nA subset Q of a poset A is downwards closed if for every x in Q and y in A, y x implies that y is in \nQ. A downwards-closed set is called a downset. The smallest downset containing Q is de\u00adnoted Ql, and \nthe downset of a singleton set {x} is denoted xl. In examples, we denote a downset as the set of its \nmaximal ele\u00adments. The downset lattice over A, written (D(A), ., n, .), is the set of downsets of A ordered \nby inclusion. Downsets strictly gen\u00aderalise powersets because the downset lattice with respect to the \nidentity relation is isomorphic to P(S). The dual notion to downset is up-sets. The smallest up-set containing \nQ is QI, and (U(A), .) is the up-set lattice with intersection as join and union as meet. Let min(Q) \nand max(Q) denote the minimal and maximal ele\u00adments of a poset Q. These sets form antichains. When convenient, \nwe assume that up-sets are represented by minimal elements and downsets by maximal elements. An abstraction \nA of a powerset lattice is disjunctive if .(a U b) = .(a)..(b). Downset completion is an operation that \nenriches an abstraction with disjunction [12]. The downset completion of A is the lattice D(A) with the \nabstraction and concretisation functions below. Unlike the standard treatment, we use downsets as underap\u00adproximating \nabstractions.  .D(A) : D(A) . P(S) .D(A)(Q) = {.(x) | x . Q} aD(A) : P(S) . D(A) aD(A)(P ) = {x | .(x) \n. P } .U(A) : U(A) . P(S) .U(A)(Q) = {.(x) | x . Q} aU(A) : P(S) . U(A) aU(A)(P ) = {x | .(x) . P } Consult \n[12] for proofs that the pairs of functions above form Galois connections and that the domains are disjunctive. \nWe can dually de.ne the up-set completion of a lattice. If a lattice A overapproximates P(S), the downset \ncompletion overapproximates P(S) and the up-set completion underapproximates P(S). 6.1 Generalised Cube \nAbstract Domains There is some debate about whether the use of C NF representations is bene.cial or detrimental \nto solvers [43]. We believe that C N F is advantageous for solvers because it leads to simple and ef.cient \ndata structures. We also believe there must be deeper, algebraic properties of CNF that are advantageous \nto solvers. One reason is because, as we observed earlier, CN F leads to a simpler treatment of negation. \nAnother is that several domains used in practice have generalized C NF representations. Consider a poset \n(gLit, ) of generalised literals. One may think of gLit as a set of semantically distinct formulae. We \nde.ne generalised cubes, clauses, CNF and D N F formulae by using up-sets to form conjunctions and downsets \nto form disjunctions. gClause = ( D(gLit), .) gCube = (U(gLit), .) gCNF = ( U(gClause), .) gDNF = (D(gCube \n), .) Since up-and downsets become powersets if the identity relation is used as the order, standard \ncubes and clauses are special cases of this de.nition. If gLit contains formulae, the concretisation \nfunction for the poset A is the function st : gLit . P(EnvG) (Cube , .) (Clause, .) (gCNF, .) (gDNF \n, .) (P(EnvG), .) (P(EnvG), .) Figure 2. Re.nement order between the generalised CN F domains. gLit gCube \n({p, \u00acp | p . Prop } , =) Partial assignments ({x = y, x = y | x . Vars } , =) Equality graphs ({x <= \ny, x < y | x . Vars } , =) Difference graphs ({x = k, x = k | k . N} , .) Interval cubes ({m . n | m, \nn . Lit} , =) Binary Implication Graphs Table 1. Domains viewed as generalised clauses, cubes and C NF \nfrom formulae to models. If a is a generalized literal, we write ~ a for a literal that satis.es .(a) \n. .(~ a) = T. The relationship between these domains is depicted in the Hasse diagram in Figure 2, where \nan upward line denotes an abstraction relationship. Cubes constructed by powerset operations are over\u00adapproximations \nof generalised cubes and C N F formulae, which are in turn overapproximations of generalised C N F, which \nare overap\u00adproximations of environments. On the other hand, the dual con\u00adstructions give us underapproximating \ndomains of clauses, gener\u00adalised clauses, D N F and generalised DNF respectively. Another property of \nthis construction is that all domains ob\u00adtained are distributive because up-set and downset lattices \nare dis\u00adtributive [15]. As we show shortly, these domains are distributive lattices but do not express \ndisjunction. Table 1 lists domains that have generalized cube descriptions. Partial Assignments Consider \na set of Boolean variables Prop, a set of literals Lit and the identity relation. The lattice gCube is \niso\u00admorphic to the lattice of partial assignments, the main data structure in solvers based on D P L \nL. This domain was studied in [18]. Equality Graphs Consider generalized clauses over the literals ELit \n= {x = y, x = y} with the identity relation on literals. (Caution! Identity between literals is different \nfrom the equality between variables.) Cubes over equality literals de.ne equality graphs, which are used \nin several solvers [36, 47]. Figure 3 depicts a graph with elements representing literals highlighted \nat the top. Two important operations in equality logic decision procedures are transitive closure and \ncycle detection. We formalize transitive closure by the transformer trans : U(ELit) . U(ELit). trans \n= G . G . {x = y | x = z, z = y . G} Recall that a reduction operator is an abstract transformer . satis\u00adfying \nthat .(a) = .(.(a)) for all a. Observe that transitive closure is a reduction operator and the saturation \nof a graph with transitive edges is a greatest .xed point. A con.icting cycle in an equality graph contains \nonly equalities and exactly one disequality edge [36]. A graph with a con.icting equality edge  disequality \nedge Figure 3. Equality graphs over three variables. The shaded ele\u00adments at the top are literals and \nthe shaded elements at the bottom all concretise to the empty set. cycle satis.es .(G) = \u00d8. The shaded \nelements at the bottom of Figure 3 all contain con.icting cycles and concretise to the empty set. A similar \nabstract domain and reduction operation appear in the logic of order and directed graphs in [31]. Interval \nCubes Consider the set of single variable inequalities (BLit = {x = k, x = k | k . Z} , .). which form \na poset un\u00adder implication. The elements of BLit are light grey in Figure 4. By representing intervals \nas cubes instead of pairs, we obtain a set\u00adbased representation that supports proof rules such as resolution \nand other algorithms in solvers that target clauses and cubes. Ex\u00adample 6 illustrates how intervals can \nbe manipulated using up-sets. Example 6. The interval domain as de.ned in Section 5 is not distributive \nbecause identities such as the one below fail. ([0, 1] U [6, 7]) n [3, 4] = [3, 4] = ([0, 1] n [3, 4]) \nU ([6, 7] n [3, 4]) = . Now consider intervals represented as up-sets. The meet in this lattice is union \nand join is intersection, so it is trivially distributive. We represent up-sets by their minimal elements. \n({x = 0, x = 1} I n {x = 6, x = 7} I) . {x = 3, x = 4} I = {x = 0, x = 7} I . {x = 3, x = 4} I = {x = \n3, x = 4} I A similar calculation yields the expected interval for the other interval expression. The \ncube representation expresses the same concrete elements as the classic pair representation of intervals \nbut contains more redundancy. < Binary Implication Graphs If the set of generalised literals con\u00adtains \nclauses of length 2 (such as {p, \u00acq}) ordered by equality, each generalised literal represents two implications \nq . p and \u00acp . q, which can be viewed as edges in a directed graph. The resulting Binary Implication \nGraph abstract domain is used for preprocess\u00ading in S AT solvers [29]. Though a lattice-based analysis \nhas not been previously applied to Binary Implication Graphs, we need not explicitly de.ne Galois connections \nor their approximation proper\u00adties, as these follow from the cube representation. As with equality graphs, \ntransitive closure is a reduction. The CNF Domains The generalized C NF domains show that C NF formulae \nhave a lattice structure that is usually not recognized. To see the difference between gCNF and CNF , \nconsider BLit. The set {x = 2, x = 5, x = 7} represents a clause but not a generalized clause, while \n{x = 2, x = 5} l is a generalised clause. Solvers use a variety of subsumption techniques to minimize \nformulae without explicitly checking implication. The inclusion (x < 99, y < 99) (x : [1, 98]) (x = \n1, y = 1)  (x : [3, 7], y : [1, 4]) (x : [3, 9], y : [1, 6]) (x : [7, 9], y : [4, 6]) . Figure 4. The \nlattice of interval environments over two variables. The shaded elements at the top represent the poset \nof literals while elements at the bottom represent singleton values. orders in Figure 2 correspond to \nsubsumption notions and also underapproximate implication. For instance, {{p} , {p, q}} and {{p}} are \nlogically equivalent but we can only show {{p}} . {{p} , {p, q}} using the lattice order. From the abstract \ninterpreta\u00adtion perspective, subsumption is not a substitute for implication but is fundamental to the \nlattice structure of C N F and D N F domains.  6.2 Abstract Transformers in Solvers Generalized Unit \nRule The unit rule in SAT solvers asserts that if a cube represents a region of the search space and \nthe cube falsi.es all but one literal in a clause, the remaining literal can be added to the clause. \nThe Abstract Con.ict Driven Learning algorithm (AC DC L) of [19] generalises the unit rule to abstract \ndomains based on the notion of complementable meet irreducibles. The unit rule can be viewed as a technique \nfor re.ning generalized cubes using generalized clauses. gunit : gClause . (gCube . gCube ) gunit. = \np . p . {a} , where a . ., .(p) n .(a) = \u00d8, and for all b . . \\ {a} , .(p) n .(b) = \u00d8 We write gfpx(f) \nfor the function that maps elements a to .xed points gfp(f (a, x)) of a function f(y, x). The main observation \nof [18] was that Boolean Constraint Propagation (B CP) is a .xed point bcp(., x) = gfp(ngunit.) de.ned \npointwise over unit x ... rules. The generalized cubes in Table 1, when combined with the generalized \nclauses, also support the unit rule and B CP. Failed Literal Probing Failed literal probing [21, 22] \nis a prepro\u00adcessing technique in S AT solvers. The technique chooses literal a, computes bcp(a, .) and \nif the result is ., adds the singleton clause {b} to ., where b satis.es that .(a)..(b) = T. No action \nis taken if the result is not bottom. Note that we have not only described failed literal probing, but \nalso its generalization to C N F domains. Clause Dropping Variable elimination is a fundamental opera\u00adtion \nunderlying quanti.er elimination, deduction and syntactic sim\u00adpli.cation of formulae. The simplest form \nof sound variable elim\u00adination is to drop clauses from a C N F formula in which the target variable occurs. \nThis idea lifts directly to generalized C N F domains if we drop constraints based on the literals they \ncontain. drop : gLit \u00d7 gCNF . gCNF drop(.) = {C | {p, ~ p} n C = \u00d8, C . .} p In general, drop p is an \noverapproximation of the deduction trans\u00adformer. If p is a Boolean variable, drop p also overapproximates \nexistential quanti.cation with respect to p.  Resolution The resolution principle asserts that if C \n. p and \u00acp . D are both satis.able, so is C . D. The variable p is the pivot and C . D is the resolvent. \nGeneralised CN F domains support a generalization of resolution res : gLit \u00d7 gCNF . gCNF . res (p, .) \n= {C . D | C . {p} , D . {q} . ., .(p) n .(q) = \u00d8} Generalized C N F domains that apply this transformer \ncan produce resolution-style proofs, which is a .rst step towards combining existing abstract domains \nwith proof-theoretic techniques. Example 7. The generalised C N F element . = {{x = 10, x = 5} l, {x \n= 7, x = 13} l} represents a conjunction of disjunctions of bounds. Standard inter\u00adval propagation will \nlose precision in the clauses, while standard resolution does not apply because no constraint is the \nnegation of another. The result of generalized resolution with respect to the lit\u00aderal x = 7 is res (x \n= 7, .) = {{x = 10, x = 13}}. Though arithmetic techniques methods can deduce the same information, generalised \nresolution is simple and suf.ces in this case. < The Pure Literal Rule Clause dropping is a sound but \nincomplete simpli.cation technique because a formula . that is unsatis.able might become satis.able after \nclause dropping. The pure literal rule, introduced in the original algorithm of Davis and Putnam [16] \ncan be understood as an application of clause dropping only in situations where it does not change the \nsatis.ability of a formula. We formalize the pure literal rule for generalized C N F domains. Recall \nthat gLit is the set of generalized literals. We say that a set of literals A is pure if for each a in \nA, no b satisfying .(a) n .(b) = \u00d8 is also in A. We assume that gLit is the disjoint union of two pure \nsets P and N such that for each a in P , there exists a b in N satisfying that .(a) n .(b) = \u00d8 and vice-versa. \nThe elements of P are positive literals and of N are negative literals. De.ne a set {+, -} of polarities, \na lattice of polarities P({+, -}), and a lattice of polarity maps P . P({+, -}). Polarity analysis of \na generalized C NF formula . computes a polarity map .. such that .(e) is {+} or {-} if the generalized \nliteral e only occurs positively or only negatively in ., and is \u00d8 if e does not occur in ., and is {+, \n-} if e occurs both positively and negatively in .. The polarity of a literal e is {+} if a is in P , \nand is {-} if e is in N. The polarity map for a literal e sends e to its polarity and sends all literals \nb = a to the empty set. The polarity map for a generalized clause is the pointwise join of of polarity \nmaps of its literals. The polarity map of a generalized C N F element is the pointwise join of of polarity \nmaps of its clauses. Note that the join is used in both cases. The pure literal rule for a generalized \nCN F formula, applies drop \u00a3 to a formula . only if the polarity map for . does not send the literal \ne to {+, -}. The pure literal rule is a sound overapprox\u00adimation of the deduction transformer and is \na re.nement of clause dropping. In propositional logic, the pure literal rule applied to a variable p \nis also a sound abstraction of the existential quanti.ca\u00adtion transformer (wkp . somep). 7. Discussion \nand Related Work This paper contributes to a research programme that seeks to close the gap between abstract \ninterpretation techniques and deduction algorithms, both in theory and practice. One direction of this \npro\u00adgram is to use deduction algorithms to re.ne static analyses. Pre\u00adcision loss due to joins was reduced \nby boosting a static analysis with uni.cation [46], D P L L (T) [27], or C D CL [20]. Best abstract transformers \nhave been synthesized using satis.ability solvers [41], and St\u00b0 almarck s method [45], while [37] applied \nsatis.ability tech\u00adniques to reduce precision loss in .xed point iteration. Another direction in this \nprogramme is to characterize satis.\u00adability procedures as abstract interpretations. Boolean constraint \npropagation was shown to be an abstract interpretation in [18], and CD C L was generalized to combine \ndeduction and abduction over lattices in [19]. St \u00b0 almarck s method was characterized as a tech\u00adnique \nfor re.ning abstract transformers in [44]. The Nelson-Oppen method for theory combination implemented \nin S M T solvers was shown to be a special case of the reduced product of abstract do\u00admains [14]. The \nDPL L (T) technique for reasoning about a theory by combining a S AT solver with a theory solver was \nalso shown to be a special case of the reduced product in [2]. In addition to static analysis applications, \nthese characteriza\u00adtions provide a new way for lifting solver algorithms to new logics. For example, \nSt \u00b0 almarck s method was lifted to arithmetic in [45], while CD C L was lifted to .oating point logic \nin [26]. Note that the Nelson-Oppen combination was lifted to abstract domains [25] prior to the reduced \nproduct characterization. Abstract satisfaction is lattice-theoretic in an attempt to align with static \nanalysis. If static analysis is ignored, the D P L L (T) frame\u00adwork provides one generic approach to \nimplementing decision pro\u00adcedures [23]. The separation of Boolean and theory reasoning in D PL L (T) \ncan be detrimental to performance and has driven the search for other frameworks. Abstract D PL L [39], \nnatural domain S MT [6], generalized D P L L [35], and the model construction calcu\u00adlus [17] are attempts \nin this direction. 8. Conclusion Abstraction is fundamental to practical reasoning about computa\u00adtionally \nintractable problems. Abstract interpretation has tradition\u00adally been applied to reason about undecidable \nproblems such as checking semantic properties of programs. This paper introduced a framework for applying \nabstract interpretation to problems that are N P-hard but decidable, such as satis.ability. This framework \nallows for novel perspectives of SM T algo\u00adrithms. Solvers can be viewed as abstract interpretation portfo\u00adlios, \nwhich combine several different, weak abstractions to achieve a conclusive result. Moreover, while solvers \nuse incomplete ab\u00adstractions they produce complete results. This is not due to brute\u00adforce enumerations \nbut clever, semantics-based re.nement tech\u00adniques. Our framework makes some of these techniques explicit, \nbut more importantly provides a general vocabulary for studying a wide range of satis.ability procedures. \nWhile the focus of this paper has been theoretical, our goal is to contribute to the practical state \nof the art. The original abstract interpretation framework provided a simple recipe for constructing \nstatic analyzers. Abstract satisfaction plays a similar role and pro\u00advides a foundation for the development \nof programmable, lattice\u00adbased SM T solvers. There are three different axes for future work. One is to \nap\u00adply abstract interpretation to the implementation of S M T solvers by constructing sound but incomplete \nsolvers and abstract quanti.ca\u00adtion procedures from existing abstract domains. The second axis is to \nlift techniques in S M T solvers to improve the precision and ef.\u00adciency of program analysis. The classic \nDPL L, DPL L (T), C DC L and St\u00b0almarck s method have each been lifted to a single static analy\u00adsis problem, \nbut more applications and evaluation are required to understand their strengths in a static analysis \ncontext. Preprocess\u00ading, subsumption, and sparsity techniques have all been integral to improving the \nperformance of solvers, and the connections in this paper indicate that such techniques should lift to \nprogram analy\u00adsis as well. The .nal axis is to investigate new implementations of abstract domains with \ninterfaces rich enough to support SMT solv\u00ading, static analysis, implication graph construction, and \ndomain and theory combinations. We look forward to these developments.  Acknowledgments This work was \nsupported by the Toyota Motor Corporation, ERC project 280053, EPSRC project EP/H017585/1, and the FP7 \nSTREP PINCETTE. The research reported in this paper was conducted be\u00adtween 2011 and 2013. In 2011, Vijay \nD Silva was supported by a Microsoft Research scholarship. References [1] N. Bj\u00f8rner, B. Duterte, and \nL. de Moura. Accelerating lemma learning using joins DPLL(u). In LPAR, 2008. [2] M. Brain, V. D Silva, \nL. Haller, A. Griggio, and D. Kroening. An abstract interpretation of DPLL(T). In VMCAI, 2012. [3] M. \nBrain, V. D Silva, L. Haller, A. Griggio, and D. Kroening. Interpolation-based veri.cation of .oating-point \nprograms with ab\u00adstract CDCL. In SAS, 2013. [4] R. E. Bryant, D. Kroening, J. Ouaknine, S. A. Seshia, \nO. Strichman, and B. Brady. Deciding bit-vector arithmetic with abstraction. In TACAS, pages 358 372. \nSpringer, 2007. [5] E. M. Clarke, O. Grumberg, and D. E. Long. Model checking and abstraction. ACM TOPLAS, \n16(5):1512 1542, Sept. 1994. [6] S. Cotton. Natural domain SMT: A preliminary assessment. In FORMATS, \npages 77 91, 2010. [7] P. Cousot. Semantic foundations of program analysis. In S. Muchnick and N. Jones, \neditors, Program Flow Analysis: Theory and Applica\u00adtions, chapter 10, pages 303 342. Prentice-Hall, Inc., \n1981. [8] P. Cousot. The calculational design of a generic abstract interpreter. In M. Broy and R. Steinbr \n\u00a8uggen, editors, Calculational System Design. NATO ASI Series F. IOS Press, Amsterdam, 1999. [9] P. Cousot. \nAbstract interpretation. MIT course 16.399, 2005. [10] P. Cousot and R. Cousot. Abstract interpretation: \na uni.ed lattice model for static analysis of programs by construction or approxima\u00adtion of .xpoints. \nIn POPL, pages 238 252. ACM Press, 1977. [11] P. Cousot and R. Cousot. Systematic design of program analysis \nframeworks. In POPL, pages 269 282. ACM Press, 1979. [12] P. Cousot and R. Cousot. Abstract interpretation \nand application to logic programs. Journal of Logic Programming, 13(2 3):103 179, 1992. [13] P. Cousot \nand R. Cousot. Abstract interpretation frameworks. Journal of Logic and Computation, 2(4):511 547, Aug. \n1992. [14] P. Cousot, R. Cousot, and L. Mauborgne. Theories, solvers and static analysis by abstract \ninterpretation. JACM, 59(6):31:1 31:56, Jan. 2013. [15] B. A. Davey and H. A. Priestley. Introduction \nto lattices and order. Cambridge University Press, Cambridge, UK, 1990. [16] M. Davis and H. Putnam. \nA computing procedure for quanti.cation theory. JACM, 7:201 215, July 1960. [17] L. M. de Moura and D. \nJovanovic. A model-constructing satis.ability calculus. In VMCAI, pages 1 12, 2013. [18] V. D Silva, \nL. Haller, and D. Kroening. Satis.ability solvers are static analysers. In SAS, pages 317 333. Springer, \n2012. [19] V. D Silva, L. Haller, and D. Kroening. Abstract con.ict driven learning. In POPL, pages 143 \n154, New York, NY, USA, 2013. ACM Press. [20] V. D Silva, L. Haller, D. Kroening, and M. Tautschnig. \nNumeric bounds analysis with con.ict-driven learning. In TACAS, pages 48 63. Springer, 2012. [21] N. \nE \u00b4en and A. Biere. Effective preprocessing in SAT through variable and clause elimination. In SAT, pages \n61 75, Munich, Germany, 2005. Springer. [22] J. W. Freeman. Failed literals in the Davis-Putnam procedure \nfor SAT. Technical report, Rutgers University, 1993. [23] H. Ganzinger, G. Hagen, R. Nieuwenhuis, A. \nOliveras, and C. Tinelli. DPLL(T): Fast decision procedures. In CAV, pages 175 188, 2004. [24] R. Giacobazzi, \nF. Ranzato, and F. Scozzari. Making abstract interpre\u00adtations complete. JACM, 47(2):361 416, 2000. [25] \nS. Gulwani and A. Tiwari. Combining abstract interpreters. In PLDI, pages 376 386. ACM Press, 2006. [26] \nL. Haller, A. Griggio, M. Brain, and D. Kroening. Deciding .oating\u00adpoint logic with systematic abstraction. \nIn FMCAD, pages 131 140, 2012. [27] W. R. Harris, S. Sankaranarayanan, F. Ivan ci.\u00b4c, and A. Gupta. Program \nanalysis via satis.ability modulo path programs. In POPL, pages 71 82, 2010. [28] T. A. Henzinger, O. \nKupferman, and S. Qadeer. From pre-historic to post-modern symbolic model checking. FMSD, 23(3):303 327, \nNov. 2003. [29] M. J. H. Heule, M. J \u00a8arvisalo, and A. Biere. Ef.cient CNF simpli.\u00adcation based on binary \nimplication graphs. In SAT, pages 201 215, 2011. [30] D. Kroening, J. Ouaknine, S. A. Seshia, and O. \nStrichman. Abstraction-based satis.ability solving of Presburger arithmetic. In CAV, pages 308 320, July \n2004. [31] D. Kroening and G. Weissenbacher. An interpolating decision pro\u00adcedure for transitive relations \nwith uninterpreted functions. In HVC, pages 150 168, 2011. [32] W. Lawvere. Adjointness in foundations. \nDialectica, 23:281 296, 1969. [33] K. R. M. Leino and F. Logozzo. Using widenings to infer loop invariants \ninside an SMT solver, or: A theorem prover as abstract domain. In Workshop on Invariant Generation, pages \n70 84. RISC Report 07-07, 2007. [34] K. L. McMillan. Interpolation and SAT-based model checking. In CAV, \npages 1 13, 2003. [35] K. L. McMillan, A. Kuehlmann, and M. Sagiv. Generalizing DPLL to richer logics. \nIn CAV, pages 462 476, 2009. [36] O. Meir and O. Strichman. Yet another decision procedure for equality \nlogic. In CAV, pages 307 320, 2005. [37] D. Monniaux and L. Gonnord. Using bounded model checking to \nfocus .xpoint iterations. In SAS, pages 369 385, 2011. [38] I. N \u00b4emeti. Algebraization of quanti.er \nlogics, an introductory overview. Studia Logica: An International Journal for Symbolic Logic, 50(3/4):485 \n569, 1991. [39] R. Nieuwenhuis, A. Oliveras, and C. Tinelli. Solving SAT and SAT modulo theories: From \nan abstract Davis Putnam Logemann Loveland procedure to DPLL(T). JACM, 53:937 977, 2006. [40] A. M. Pitts. \nCategorical logic. In S. Abramsky, D. M. Gabbay, and T. S. E. Maibaum, editors, Handbook of Logic in \nComputer Science, Volume 5. Algebraic and Logical Structures, chapter 2, pages 39 128. Oxford University \nPress, 2000. [41] T. W. Reps, S. Sagiv, and G. Yorsh. Symbolic implementation of the best transformer. \nIn VMCAI, pages 252 266, 2004. [42] P. Smith. The Galois connection of syntax and semantics. Technical \nreport, Cambridge University, 2010. [43] P. J. Stuckey. There are no CNF problems. SAT, pages 19 21, \n2013. [44] A. Thakur and T. Reps. A generalization of St\u00b0almarck s method. In SAS. Springer, 2012. [45] \nA. V. Thakur and T. W. Reps. A method for symbolic computation of abstract operations. In CAV, 2012. \n[46] A. Tiwari and S. Gulwani. Logical interpretation: Static program analysis using theorem proving. \nIn CADE, pages 147 166, 2007. [47] O. Tveretina. DPLL-based procedure for equality logic with unin\u00adterpreted \nfunctions. In IJCAR Doctoral Programme, volume 106 of CEUR Workshop Proceedings. CEUR-WS.org, 2004. \n  \n\t\t\t", "proc_id": "2535838", "abstract": "<p>This article introduces an abstract interpretation framework that codifies the operations in SAT and SMT solvers in terms of lattices, transformers and fixed points. We develop the idea that a formula denotes a set of models in a universe of structures. This set of models has characterizations as fixed points of deduction, abduction and quantification transformers. A wide range of satisfiability procedures can be understood as computing and refining approximations of such fixed points. These include procedures in the DPLL family, those for preprocessing and inprocessing in SAT solvers, decision procedures for equality logics, weak arithmetics, and procedures for approximate quantification. Our framework provides a unified, mathematical basis for studying and combining program analysis and satisfiability procedures. A practical benefit of our work is a new, logic-agnostic architecture for implementing solvers.</p>", "authors": [{"name": "Vijay D'Silva", "author_profile_id": "81100215907", "affiliation": "University of California, Berkeley, CA, USA", "person_id": "P4383773", "email_address": "vijay.dsilva@gmail.com", "orcid_id": ""}, {"name": "Leopold Haller", "author_profile_id": "81438596327", "affiliation": "University of Oxford, Oxford, United Kingdom", "person_id": "P4383774", "email_address": "leopold.haller@cs.ox.ac.uk", "orcid_id": ""}, {"name": "Daniel Kroening", "author_profile_id": "81100210974", "affiliation": "University of Oxford, Oxford, United Kingdom", "person_id": "P4383775", "email_address": "daniel.kroening@cs.ox.ac.uk", "orcid_id": ""}], "doi_number": "10.1145/2535838.2535868", "year": "2014", "article_id": "2535868", "conference": "POPL", "title": "Abstract satisfaction", "url": "http://dl.acm.org/citation.cfm?id=2535868"}