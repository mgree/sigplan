{"article_publication_date": "01-08-2014", "fulltext": "\n Proof Search for Propositional Abstract Separation Logics via Labelled Sequents Zh \u00b4e H \u00b4ou Ranald \nClouston Rajeev Gor \u00b4e Research School of Computer Science The Australian National University {zhe.hou,ranald.clouston,rajeev.gore}@anu.edu.au \nAbstract Abstract separation logics are a family of extensions of Hoare logic for reasoning about programs \nthat mutate memory. These logics are abstract because they are independent of any particular concrete \nmemory model. Their assertion languages, called propositional ab\u00adstract separation logics, extend the \nlogic of (Boolean) Bunched Im\u00adplications (BBI) in various ways. We develop a modular proof theory for \nvarious propositional abstract separation logics using cut-free labelled sequent calculi. We .rst extend \nthe cut-fee labelled sequent calculus for BBI of H \u00b4ou et al to handle Calcagno et al s original logic \nof separation algebras by adding sound rules for partial-determinism and cancellativity, while preserving \ncut-elimination. We prove the completeness of our calculus via a sound intermediate calculus that enables \nus to construct counter-models from the failure to .nd a proof. We then capture other propositional abstract \nseparation logics by adding sound rules for indivisible unit and disjointness, while maintaining completeness \nand cut-elimination. We present a theorem prover based on our labelled calculus for these logics. Categories \nand Subject Descriptors F.3.1 [Specifying and Verify\u00ading and Reasoning about Programs]: Logics of programs \nGeneral Terms Languages, Theory, Veri.cation Keywords Abstract separation logics, automated reasoning, \nla\u00adbelled sequents , counter-model construction, bunched implications 1. Introduction Separation logic \n(SL) [29] is an extension of Hoare logic for rea\u00adsoning about programs that explicitly mutate memory. \nThis is achieved via an assertion language that, along with the usual (ad\u00additive) connectives and predicates \nfor .rst-order logic with arith\u00admetic, has the multiplicative connectives separating conjunction *, its \nunit T*, and separating implication, or magic wand, -* , from the logic of Bunched Implications (BI) \n[26], as well as the points-to predicate .. The additive connectives may be either intuitionistic, Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. Copyrights for components of this work owned \nby others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. Request \npermissions from permissions@acm.org. POPL 14, January 22 24, 2014, San Diego, CA, USA. Copyright c &#38;#169; \n2014 ACM 978-1-4503-2544-8/14/01. . . $15.00. http://dx.doi.org/10.1145/2535838.2535864 Alwen Tiu Research \nSchool of Computer Science The Australian National University &#38; School of Computer Engineering Nanyang \nTechnological University atiu@ntu.edu.sg as for BI, or classical, as for the logic of Boolean Bunched \nIm\u00adplications (BBI). Classical additives are more expressive as they support reasoning about non-monotonic \ncommands such as mem\u00adory deallocation, and assertions such as the heap is empty [17]. In this paper we \nconsider classical additives only. The assertion language of SL must provide a notion of inference to \nsupport precondition strengthening and postcondition weaken\u00ading, yet little such proof theory exists, \ndespite its link with the proof-theoretically motivated BI. Instead, inference must proceed via reasoning \ndirectly about the concrete semantics of heaps, or .nite partial functions from addresses to values. \nA heap satis.es P * Q iff it can be partitioned into heaps satisfying P and Q re\u00adspectively; it satis.es \nT* iff it is empty; it satis.es P -* Q iff any extension with a heap that satis.es P must then satisfy \nQ; and it satis.es E . E' iff it is a singleton map sending the address spec\u00adi.ed by the expression E \nto the value speci.ed by the expression E'. Such concrete semantics are appropriate for proving the cor\u00adrectness \nof a speci.c program in a speci.c environment, but mean that if a different notion of memory (or more \ngenerally, resource) is required then a new logic is also required. Calcagno et al s Abstract Separation \nLogic (ASL) [8] intro\u00adduced the abstract semantics of partial cancellative monoids, or separation algebras, \nto unify notions of resources for heaps, heaps with permissions, Petri nets, and other examples. These \nseman\u00adtics allow interpretation of *, T* and -* , although the latter is not considered by Calcagno et \nal. However . has no meaning in separation algebras in general, and is therefore not a .rst class citizen \nof ASL; it may be introduced as a predicate only if an appropriate concrete separation algebra is .xed. \nCalcagno et al do not consider proof theory for their assertion language, whose propositional fragment \nwe call Propositional Abstract Separation Logic (PASL), but separation algebras are a restriction of \nnon\u00addeterministic monoids, which are known to give sound and com\u00adplete semantics for BBI [13]. In this \nsense PASL is a re.nement of BBI, differing only by the addition of the semantic properties of partial-determinism \nand cancellativity. This link between BBI and PASL semantics raises the ques\u00adtion of whether existing \nproof theory for BBI can be extended to give a sound and cut-free complete proof system for PASL; we \nan\u00adswer this question in the af.rmative by extending the labelled se\u00adquent calculus LSBBI of H \u00b4 ou et \nal [16] by adding explicit rules for partial-determinism and cancellativity. The completeness of LSBBI \nwas demonstrated via the Hilbert axiomatisation of BBI, but this avenue is not open to us as partial-determinism \nand can\u00adcellativity are not axiomatisable in BBI [6]; instead completeness follows via a counter-model \nconstruction procedure. A novelty of our counter-model construction is that it can be modularly extended \nto handle extensions and sublogics of PASL.  We have also implemented proof search using our calculus \n(although no decision procedure for PASL is possible [5]). To our knowledge this is the .rst proof to \nbe presented of the cut-free completeness of a calculus for PASL1, and our implementation is the .rst \nautomated theorem prover for PASL. Just as we have a family of separation logics, ranging across different \nconcrete semantics, we now also have a family of abstract separation logics for different abstract semantics. \nThese abstract semantics are often expressed as extensions of the usual notion of separation algebra; \nmost notably Dockins et al [11] suggested the additional properties of positivity (here called indivisible \nunit), disjointness, cross-split, and splittability2. Conversely, the abstract semantics for Fictional \nSeparation Logic [18] generalise separa\u00adtion algebras by dropping cancellativity. Hence there is demand \nfor a modular approach to proof theory and proof search for propo\u00adsitional abstract separation logics. \nLabelled sequent calculi, with their explicitly semantics-based rules, provide good support for this \nmodularity, as rules for the various properties can be added and re\u00admoved as required. We investigate \nwhich properties can be com\u00adbined without sacri.cing our cut-free completeness result. While we work \nwith abstract models of separation logics, the reasoning principles behind our proof-theoretic methods \nshould be applicable to concrete models also, so we investigate as further work how concrete predicates \nsuch as . might be integrated into our approach. Proof search strategies that come out of our proof\u00adtheoretic \nanalysis could also potentially be applied to guide proof search in various encodings of separation logics \n[1, 24, 30] in proof assistants, e.g., they can guide the constructions of proof tactics needed to automate \nthe reasoning tasks in those embeddings. Acknowledgment. This work is partly supported by the Aus\u00adtralian \nResearch Council Discovery Grant DP110103173. 2. The labelled sequent calculus for PASL In this section \nwe de.ne the separation algebra semantics of Calcagno et al [8] for Propositional Abstract Separation \nLogic (PASL), and present the labelled sequent calculus LSP ASL for this logic, adapting the calculus \nLSBBI for BBI of H \u00b4ou et al [16]. Soundness and cut-elimination are then demonstrated for LSP ASL . \n2.1 Propositional abstract separation logic The formulae of PASL are de.ned inductively as follows, where \np ranges over some set V ar of propositional variables: A ::= p | T | . | \u00acA | A . A | A . A | A . A \n| T * | A * A | A-* A PASL-formulae are interpreted according to the semantics below. De.nition 2.1. \nA separation algebra, or partial cancellative com\u00admutative monoid, is a triple (H, ., E) where H is a \nnon-empty set, . is a partial binary function H \u00d7 H -H written in.x, and E . H, satisfying the following \nconditions, where = is inter\u00adpreted as both sides unde.ned, or both sides de.ned and equal : identity: \n.h . H. h . E = h commutativity: .h1, h2 . H. h1 . h2 = h2 . h1 associativity: .h1, h2, h3 . H. h1 . \n(h2 . h3) = (h1 . h2) . h3 1 Larchey-Wendling [20] claims that the tableaux for BBI with partial\u00addeterminism \nin [21] can be extended to cover cancellativity, but the rather involved proof has not appeared yet. \n2 Dockins et al [11] also suggest generalising separation algebras to have a set of units; it is an easy \ncorollary of [6, Lem. 3.11] that single-unit and multiple-unit separation algebras satisfy the same set \nof formulae. cancellativity: .h1, h2, h3, h4 . H. if h1.h2 = h3 and h1.h4 = h3 then h2 = h4 The paradigmatic \nexample of a separation algebra is the set of heaps; here . is the combination of two heaps with disjoint \ndomain, and E is the empty heap. In the paper we prefer to express PASL semantics in the style of ternary \nrelations, to maintain consistency with the earlier work of H\u00b4 ou et al on BBI [16]; it is easy to see \nthat the de.nition below is a trivial notational variant of Def. 2.1. De.nition 2.2. A PASL Kripke relational \nframe is a triple (H, R, E), where H is a non-empty set of worlds, R . H \u00d7 H \u00d7 H, and E . H, satisfying \nthe following conditions for all h1, h2, h3, h4, h5 in H: identity: R(h1, E, h2) iff h1 = h2 commutativity: \nR(h1, h2, h3) iff R(h2, h1, h3) associativity: if R(h1, h5, h4) and R(h2, h3, h5) then there exists h6 \nsuch that R(h6, h3, h4) and R(h1, h2, h6) cancellativity: if R(h1, h2, h3) and R(h1, h4, h3) then h2 \n= h4 partial-determinism: if R(h1, h2, h3) and R(h1, h2, h4) then h3 = h4 A PASL Kripke relational model \nis a tuple (H, R, E, . ) of a PASL Kripke relational frame (H, R, E) and a valuation function . : V ar \n. P (H), where P(H) is the power set of H. The forcing relation I between a model M = (H, R, E, . ) and \na formula is de.ned in Table 1, where we write M, h I A for the negation of M, h I A. Given a model M \n= (H, R, E, . ), a formula is true at (world) h iff M, h I A. The formula A is valid iff it is true at \nall worlds of all models.  2.2 The labelled sequent calculus LSP ASL Let LV ar be an in.nite set of \nlabel variables, and let the set L of labels be LV ar . {E}, where E is a label constant not in LV ar; \nhere we overload the notation for the identity world in the semantics. Labels will be denoted by lower-case \nletters such as a, b, x, y, z. A labelled formula is a pair a : A of a label a and formula A. As usual \nin a labelled sequent calculus one needs to incorporate Kripke relations explicitly into the sequents. \nThis is achieved via the syntactic notion of relational atoms, which have the form (a, b r c), where \na, b, c are labels. A sequent takes the form G; G . where G is a set of relational atoms, and G and . \nare multisets of labelled formulae. Then, G; A is the multiset union of G and {A}. As the interpretation \nof the logical connectives of PASL are the same as those for BBI, we may obtain a labelled sequent calculus \nfor PASL, called LSP ASL , by adding the rules P (partial\u00addeterminism) and C (cancellativity) to LSBBI \n[16]. The rules for LSP ASL are presented in Fig. 1, where p is a propositional variable, A, B are formulae, \nand w, x, y, z . L. Note that some rules use label substitutions. We write G[y/x] (resp. G[y/x]) for \nthe set of labelled formulae (resp. relational atoms) for which the label variable x has been uniformly \nreplaced by the label y. In each rule, the formula (resp. relational atom) shown explicitly in the conclusion \nis called the principal formula (resp. relational atom). A rule with no premise is called a zero-premise \nrule. Note that the . L rule is the classical implication left rule. A function . : L . H from labels \nto worlds is a label mapping iff it satis.es .(E) = E, mapping the label constant E to the identity world \nof H. Thus we de.ne an extended PASL Kripke relational model (H, R, E, ., .) as a model equipped with \na label mapping. De.nition 2.3 (Sequent Falsi.ability). A sequent G; G . is falsi.able in an extended \nmodel M = (H, R, E, ., .) if for every  M, h I p iff p . V ar and h . v(p) M, h I T iff always M, h \nI . iff never M, h I \u00acA iff M, h I A M, h I A . B iff M, h I A and M, h I B M, h I A . B iff M, h I A \nor M, h I B M, h I A . B iff M, h I A or M, h I B M, h I T * iff h = E M, h I A * B iff .h1, h2.(R(h1, \nh2, h) and M, h1 I A and M, h2 I B) M, h I A-* B iff .h1, h2.((R(h, h1, h2) and M, h1 I A) implies M, \nh2 I B) Table 1. Semantics of PASL, where M = (H, R, E, . ). Identity and Cut: id G; G f x : A; . G \n' ; G ' ; x : A f . ' G; G; w : p f w : p; . cut G; G ' ; G; G ' f .; . ' Logical Rules: (E, w t E); \nG; G f . G; G; w : . f . T* L G; G f w : T; . G; G f E : T*; . .L TR T* R G; G; w : T* f . G; G; w : \nA; w : B f . G; G f w : A; . G; G f w : B; . .L .R G; G; w : A . B f . G; G f w : A . B; . G; G f w : \nA; . G; G; w : B f . G; G; w : A f w : B; . . L . R G; G; w : A . B f . G; G f w : A . B; . (x, y t \nz); G; G; x : A; y : B f . (x, z t y); G; G; x : A f y : B; . *L -* R G; G; z : A * B f . G; G f z : \nA-* B; . (x, y t z); G; G f x : A; z : A * B; . (x, y t z); G; G f y : B; z : A * B; . *R (x, y t z); \nG; G f z : A * B; . (x, y t z); G; G; y : A-* B f x : A; . (x, y t z); G; G; y : A-* B; z : B f . -* \nL (x, y t z); G; G; y : A-* B f . Structural Rules: (y, x t z); (x, y t z); G; G f . (u, w t z); (y, \nv t w); (x, y t z); (u, v t x); G; G f . E A (x, y t z); G; G f . (x, y t z); (u, v t x); G; G f . (x, \nE t x); G; G f . (x, w t x); (y, y t w); (x, y t x); G; G f . U AC G; G f . (x, y t x); G; G f . (E, \nw ' t w ' ); G[w ' /w]; G[w ' /w] f .[w ' /w] (E, w ' t w ' ); G[w ' /w]; G[w ' /w] f .[w ' /w] Eq1 Eq2 \n(E, w t w ' ); G; G f . (E, w ' t w); G; G f . (x, y t z); G[z/w]; G[z/w] f .[z/w] (x, y t z); G[y/w]; \nG[y/w] f .[y/w] P C (x, y t z); (x, y t w); G; G f . (x, y t z); (x, w t z); G; G f . Side conditions: \n Only label variables (not E) may be substituted for. In *L and -* R, the labels x and y do not occur \nin the conclusion. In the rule A, AC , the label w does not occur in the conclusion. Figure 1. The labelled \nsequent calculus LSP ASL for Propositional Abstract Separation Logic. x : A . G, (a, b r c) . G, and \nfor every y : B . ., we have (M, .(x) I A), R(.(a), .(b), .(c)) and (M, .(y) I B). It is falsi.able if \nit is falsi.able in some extended model. Theorem 2.1 (Soundness). For any formula A, and for an arbi\u00adtrary \nlabel w, if the labelled sequent w : A is derivable in LSP ASL then A is valid. Proof. We prove that \nthe rules of LSP ASL preserve falsi.ability upwards. The proof is straightforward so we omit the details; \nbut refer the interested reader to a similar proof for LSBBI [16].  2.3 Cut-elimination The only differences \nbetween LSP ASL and LSBBI [16] are the additions of the structural rules P and C, so we may prove cut\u00adelimination \nby the same route, which in turn follows from the usual cut-elimination procedure for labelled sequent \ncalculi for modal logics [25]. We therefore omit full proof details and simply list the necessary lemmas. \nWe use ht(.) to denote the height of the derivation .. Lemma 2.2 (Substitution). If . is an LSP ASL derivation \nfor the sequent G; G . then there is an LSP ASL derivation . ' of the sequent G[y/x]; G[y/x] .[y/x] such \nthat ht(. ' ) = ht(.).  Lemma 2.3 (Admissibility of weakening). If G; G . is deriv\u00adable in LSP ASL , \nthen for all structures G, G ' and . ', the sequent G; G ' ; G; G ' .; . ' is derivable with the same \nheight in LSP ASL . Lemma 2.4 (Invertibility). If . is a cut-free LSP ASL derivation of the conclusion \nof a rule, then there is a cut-free LSP ASL derivation for each premise, with height at most ht(.). Lemma \n2.5 (Admissibility of contraction). If G; G; G; G .; . is derivable in LSP ASL , then G; G . is derivable \nwith the same height in LSP ASL . Theorem 2.6 (Cut-elimination). If G; G . is derivable in LSP ASL then \nit is derivable without using the cut rule. Proof. The proof follows the same structure as that for LSBBI \n, utilising the lemmas above. The additional cases we need to con\u00adsider are those involving the rules \nP and C; their treatment is sim\u00adilar to that for Eq1 in the proof for LSBBI [16]. 3. Completeness of \nLSP AS L We prove the completeness of LSP ASL with respect to the Kripke relational semantics by a counter-model \nconstruction. A standard way to construct a counter-model for an unprovable sequent is to show that it \ncan be saturated by repeatedly applying all applica\u00adble inference rules to reach a limit sequent where \na counter-model can be constructed. In adopting such a counter-model construction strategy to LSP ASL \nwe encounter dif.culty in formulating the sat\u00aduration conditions for rules involving label substitutions. \nWe there\u00adfore adopt the approach of H \u00b4ou et al [16], using an intermediate system without explicit use \nof label substitutions, but where equiv\u00adalences between labels are captured via an entailment E . Let \nr be an instance of a structural rule in which the substitu\u00adtion used is .: this is the identity substitution \nexcept when r is Eq1, E q2, P or C. We can view r (upwards) as a function that takes a set of relational \natoms (in the conclusion of the rule) and outputs an\u00adother set (in the premise). We write r(G, .) for \nthe output relational atoms of an instance of r with substitution . and with conclusion containing G. \nLet s be a sequence of instances of structural rules [r1(G1, .1); \u00b7 \u00b7 \u00b7 ; rn(Gn, .n)]. Given a set of \nrelational atoms G, the result of the (backward) application of s to G, denoted by S(G, s), is de.ned \nas below, where W is used for sequence concatenation: Lemma 3.1. Let G be a set of relational atoms, \nif G E (a = b) by applying s1 and G E (c = d) by applying s2, then .s3 such that S(G, s1) E (c. = d.) \nby s3, where . = subst(s1). Proof. Note that S(G, s1) = G.. So essentially we need to show that if G \nE (c = d), then G. E (c. = d.). This is a consequence of the substitution Lemma 2.2. Lemma 3.2. Given \na set of relational atoms G, the relation =G is an equivalence relation on the set of labels. Proof. \nWe show that E satis.es the following conditions: Re.exivity: for any label a that occurs in G, we have \nG E (a = a) by applying an empty sequence of Eq1, Eq2, P, C rules. Symmetry: if G E (x = y), via a sequence \ns of Eq1, Eq2, P, C applications. Let . = subst(s), then by de.nition x. = y. in G.. Thus y. = x., and \nwe obtain that G E (y = x). Transitivity: if G E (x = y) and G E (y = z), then by Lemma 3.1 we obtain \na sequence s of Eq1, Eq2, P, C applications, and let . = subst(s), then x. = y. = z.. Thus G E (x = z). \nThe intermediate system I LSP ASL is equivalent to LSP ASL , i.e., every sequent provable in I LSP ASL \nis also provable in LSP ASL , and vice versa. This connection is easy to make, as is shown by H \u00b4ou et \nal. [16]. Properties such as contraction admissi\u00adbility, closure under substitution etc. also hold for \nI LSP ASL . Lemma 3.3. The intermediate labelled calculus I LSP ASL is equivalent to LSP ASL . We now \ngive a counter-model construction procedure for I LSP ASL which, by Lemma 3.3, applies to LSP ASL as \nwell. In the construction, we assume that labelled sequents such as G; G . are built from sets G, G, \n. rather than multisets. This is harmless since contraction is admissible in our calculus. As the counter-model \nconstruction involves in.nite sets and sequents, we extend the de.nition of E appropriately as below. \nDe.nition 3.2. A (possibly in.nite) set G of relational atoms satis.es G E (x = y) iff Gf E (x = y) for \nsome .nite Gf . G . Given a set of relational atoms G, the equivalence relation =G partitions L into \nequivalence classes [a]G for each label a . L: S(G, s) = . .. .. [a]G = {a . L | a =G a }. G if s = \n[ ] ' ' S(G. . r(G ' , .), s ' ) if G ' . G and The counter-model procedure is essentially a procedure \nto sat\u00ad Ws ' s = [r(G ' , .)] urate a sequent by applying all applicable rules repeatedly. The unde.ned \notherwise Given s = [r1(G1, .1); \u00b7 \u00b7 \u00b7 ; rn(Gn, .n)], let subst(s) be the com\u00adposite substitution .1 \n. \u00b7 \u00b7 \u00b7 . .n, where t(.1 . .2) means (t.1).2. We write s = t to mean that s and t are syntactically equal. \nDe.nition 3.1 (Equivalence entailment). Let G be a set of rela\u00adtional atoms. The entailment relation \nG E (a = b) holds iff there exists a sequence s of E q1, E q2, P, C applications such that S(G, s) is \nde.ned, and a. = b., where . = subst(s). Since substitution is no longer in the calculus, some inference \nrules that involve matching two equal labels need to be changed. We de.ne the intermediate system I LSP \nASL as LSP ASL minus {Eq1, Eq2, P, C }, with certain rules changed following Fig. 2. Note that the equivalence \nentailment E is not a premise, but rather a condition of the rules. Given a set of relational atoms G, \nwe de.ne the relation =G as follows: a =G b iff G E (a = b). We show next that =G is in fact an equivalence \nrelation. This equivalence relation will be useful in our counter-model construction later. aim is to \nobtain an in.nite saturated sequent from which a counter\u00admodel can be extracted. We .rst de.ne a list \nof desired properties of such an in.nite sequent which would allow the counter-model construction. This \nis given in the following de.nition. De.nition 3.3 (Hintikka sequent). A labelled sequent G; G . is a \nHintikka sequent if it satis.es the following conditions for any formulae A, B and any labels a, a ' \n, b, c, d, e, z: 1. It is not the case that a : A . G, b : A . . and a =G b. 2. If a : A . B . G then \na : A . G and a : B . G. 3. If a : A . B . . then a : A . . or a : B . .. 4. If a : A . B . G then \na : A . . or a : B . G. 5. If a : A . B . . then a : A . G and a : B . .. 6. If a : T * . G then a \n=G E. 7. If a : T * . . then a =G E. 8. If z : A * B . G then .x, y, z ' such that (x, y r z ' ) . \nG , z =G z ' , x : A . G and y : B . G.  '' ' 9. If z : A * B . . then .x, y, z if (x, y r z ) . G and \nz =G z then x : A . . or y : B . ..  G fE (w1 = w2) G fE (w = E) (x, w t x ' ); (y, y t w); (x, y t \nx ' ); G; G f . (x, y t x ' ); G fE (x = x ' ) id T * R AC G; G; w1 : p f w2 : p; . G; G f w : T*; . \n(x, y t x ' ); G; G f . (u, w t z); (y, v t w); (x, y t z); (u, v t x ' ); G; G f . (x, y t z); (u, v \nt x ' ); G fE (x = x ' ) A (x, y t z); (u, v t x ' ); G; G f . (x, y t w ' ); G; G f x : A; w : A * \nB; . (x, y t w ' ); G; G f y : B; w : A * B; . (x, y t w ' ); G fE (w = w ' ) *R (x, y t w ' ); G; \nG f w : A * B; . (x, w ' t z); G; G; w : A-* B f x : A; . (x, w ' t z); G; G; w : A-* B; z : B f . (x, \nw ' t z); G fE (w = w ' ) -* L (x, w ' t z); G; G; w : A-* B f . Side condition: the label w in A, \nAC does not occur in the conclusion. Figure 2. Changed rules in the intermediate system I LSP ASL . 10. \nIf z : A-* B . G then .x, y, z ' if (x, z ' r y) . G and z =G z ' , then x : A . . or y : B . G. 11. \nIf z : A-* B . . then .x, y, z ' such that (x, z ' r y) . G , z =G z ' , x : A . G and y : B . .. 12. \nFor any label m . L, (m, E r m) . G. 13. If (a, b r c) . G then (b, a r c) . G . 14. If (a, b r c) \n. G and (d, e r a ' ) . G and a =G a ', then .f, f ' such that (d, f r c) . G, (b, e r f ' ) . G and \nf =G f ' . 15. a : . . G and a : T . ..  Lemma 3.4. Every Hintikka sequent is falsi.able. Proof. Let \nG; G . be a Hintikka sequent. We construct an extended model M = (H, rG, EG, ., .) as follows: H = {[a]G \n| a . L} '''' ' rG([a]G, [b]G, [c]G) iff .a , b ' , c .(a , b ' r c ) . G, a =G a , b =G b ' , c =G c \n' EG = [E]G  .(p) = {[a]G | a : p . G} for every p . V ar  .(a) = [a]G for every a . L. To reduce \nclutter, we shall drop the subscript G in [a]G and write [a], [b] rG [c] instead of rG([a], [b], [c]). \nWe .rst show that F = (H, rG, EG) is a PASL Kripke relational frame. The identity, commutativity and \nassociativity properties of F follow immediately from De.nition 3.3, clause 12, 13, and 14, respectively. \nWe next show partial-determinism and cancellativity: Partial-determinism: If [a], [b] rG [c] and [a], \n[b] rG [d] hold, ' ' '' then there exists some (a , b ' r c ) . G and (a , b '' r d ' ) . G such ' '' \n[b '' ' that [a] = [a ] = [a ], [b] = [b ' ] = ], [c] = [c ], [d] = [d ' ]. ' d ' ' Then by Lemma 3.1, \nG E (c = ) by using rule P to unify c and d ', thus we obtain that [c] = [c ' ] = [d] = [d ' ]. Cancellativity: \nIf [a], [b] rG [c] and [a], [d] rG [c] hold, then we ' ' '' '' can .nd some (a , b ' r c ) . G and (a \n, d ' r c ) . G such that ' '' ' '' [a] = [a ] = [a ], [c] = [c ] = [c ], [b] = [b ' ], [d] = [d ' ]. \nThen by Lemma 3.1, G E (b ' = c ' ) by using C to unify b ' and c ', thus we obtain that [b] = [b ' ] \n= [c] = [c ' ]. So M is indeed a model based on a PASL Kripke relational frame. We show next that G; \nG . is falsi.able in M. We need to show the following (where .(m) = [m]): (1) If (a, b r c) . G then \n([a], [b] rG [c]). (2) If m : A . G then M, .(m) I A. (3) If m : A . . then M, .(m) I A.  Item (1) \nfollows from the de.nition of rG. We prove (2) and (3) simultaneously by induction on the size of A. \nIn the following, to simplify presentation, we omit the M from the forcing relation. If m : p . G then \n[m] . .(p) by de.nition of ., so [m] I p. ' Suppose m : p . ., but [m] I p. Then m : p . G, for some \nm ' such that m ' =G m. This violates condition 1 in Def. 3.3. Thus [m] I p. Inductive cases: when A \nis a compound formula. We show here the interesting cases involving multiplicative connectives: If m \n: T * . G then [m] = [E] by condition 6 in Def. 3.3. Since [E] I T *, we obtain [m] I T * .  If m : \nT * . ., by condition 7 in Def. 3.3, [m] = [E] and then [m] I T * .  If m : A * B . G, by condition \n8 in Def. 3.3, .a, b, m ' such that (a, b r m ' ) . G and [m] = [m ' ] and a : A . G and b : B . G. By \nthe induction hypothesis, [a] I A and [b] I B. Thus [a], [b] rG [m] holds and [m] I A * B.  If m : \nA * B . ., by condition 9 in Def. 3.3, .a, b, m ' if (a, b r m ' ) . G and [m] = [m ' ], then a : A . \n. or  b : B . .. By the induction hypothesis, if such a, b exist, then [a] I A or [b] I B. For any [a], \n[b] rG [m], there ' '' ' must be some (a , b ' r m ) . G such that [a] = [a ], [b] = [b ' ], [m] = [m \n'' ]. Then [a] = [a ' ] I A or [b] = [b ' ] I B therefore [m] I A * B. If m : A-* B . G, by condition \n10 in Def. 3.3, .a, b, m ' if (a, m ' r b) . G and [m] = [m ' ], then a : A . . or b : B . G. By the \ninduction hypothesis, if such a, b exists, then [a] I A or [b] I B. Consider any [a], [m] rG [b], there \n' '' ' must be some (a , m r b ' ) . G. So [a] = [a ] I A or [b] = [b ' ] I B, thus [m] I A-* B. If m \n: A-* B . ., by condition 11 in Def. 3.3, .a, b, m ' such that (a, m ' r b) . G and [m] = [m ' ] and \na : A . G and b : B . .. By the induction hypothesis, [a] I A and [b] I B and [a], [m] rG [b] holds, \nthus [m] I A-* B. To prove the completeness of I LSP ASL , we have to show that any given unprovable \nsequent can be extended to a Hintikka se\u00adquent. To do so we need a way to enumerate all possible applicable \nrules in a fair way so that every rule will be chosen in.nitely of\u00adten. Traditionally, this is achieved \nvia a fair enumeration strategy of every principal formula of every rule. Since our calculus contains \nstructural rules with no principal formulas, we need to include them in the enumeration strategy as well. \nFor this purpose, we de.ne a notion of extended formulae, given by the grammar: ExF ::= F | U| E| A| \nAC where F is a formula, and U, E, A, AC are constants. The intention is that U, E, A, AC will be as \nused as dummy principal formulae for the structural rules U, E, A, and AC , respectively. A scheduler \n Base cases: when A is an atomic proposition p. then determines the sequence of rule applications to \napply. De.nition 3.4. A schedule is a tuple (O, m, E xF, R), where O is either 0 (left) or 1 (right), \nm is a label, ExF is an extended formula and R is a set of relational atoms such that |R| = 2. Let S \ndenote the set of all schedules. A scheduler is a function from the set of natural numbers N to S. A \nscheduler f is fair if for every schedule S, the set {i | f(i) = S} is in.nite. Lemma 3.5. There exists \na fair scheduler. Proof. Our proof follows a similar proof in [20]. To adapt their proof, we need to \nshow that the set S is countable, which follows from the fact that S is a .nite product of countable \nsets. From now on, we shall .x a fair scheduler, which we call f. We assume that the set of labels L \nis totally ordered, and its elements can be enumerated as a0, a1, a2, . . . where a0 = E. This indexing \nis used to select fresh labels in our construction of Hintikka sequents. We say the formula F is not \ncut-free provable in I LSP ASL if the sequent w : F is not cut-free derivable in I LSP ASL for any label \nw = E. Since we shall be concerned only with cut-free provability, in the following when we mention derivation, \nwe mean cut-free derivation. De.nition 3.5. Let F be a formula which is not cut-free provable in I LSP \nASL . We construct a series of .nite sequents {Gi; Gi .i}i.N from F where G1 = G1 = \u00d8 and .1 = a1 : F \n. Assuming that Gi; Gi .i has been de.ned, we de.ne Gi+1; Gi+1 .i+1 as follows. Suppose we have the schedule \nf(i) = (Oi, mi, ExFi, Ri). If Oi = 0, ExFi is a PASL formula Ci and mi : Ci . Gi: If Ci = F1 . F2, then \nGi+1 = Gi, Gi+1 = Gi . {mi : F1, mi : F2}, .i+1 = .i. If Ci = F1 . F2. If there is no derivation for \nGi; Gi mi : F1; .i then Gi+1 = Gi, .i+1 = .i . {mi : F1}. Otherwise Gi+1 = Gi . {mi : F2}, .i+1 = .i. \nIn both cases, Gi+1 = Gi. If Ci = T *, then Gi+1 = Gi . {(E, mi r E)}, Gi+1 = Gi, .i+1 = .i. If Ci = \nF1 * F2, then Gi+1 = Gi . {(a2i, a2i+1 r mi)}, Gi+1 = Gi . {a2i : F1, a2i+1 : F2}, .i+1 = .i. If Ci = \nF1-* F2 and Ri = {(x, m r y)} . Gi and Gi E (m = mi). If Gi; Gi x : F1; .i has no derivation, then Gi+1 \n= Gi, .i+1 = .i . {x : F1}. Otherwise Gi+1 = Gi . {y : F2}, .i+1 = .i. In both cases, Gi+1 = Gi. If Oi \n= 1, ExFi is a PASL formula Ci, and mi : Ci . .: If Ci = F1 . F2. If there is no derivation for Gi; Gi \nmi : F1; .i then .i+1 = .i . {mi : F1}. Otherwise .i+1 = .i . {mi : F2}. In both cases, Gi+1 = Gi and \nGi+1 = Gi. If Ci = F1 . F2, then Gi+1 = G . {mi : F1}, .i+1 = .i . {mi : F2}, and Gi+1 = Gi. Ci = F1 \n* F2 and Ri = {(x, y r m)} . Gi and Gi E (mi = m). If Gi; Gi x : F1; .i has no derivation, then .i+1 \n= .i . {x : F1}. Otherwise .i+1 = .i . {y : F2}. In both cases, Gi+1 = Gi and Gi+1 = Gi. If Ci = F1-* \nF2, then Gi+1 = Gi . {(a2i, mi r a2i+1)}, Gi+1 = Gi . {a2i : F1}, and .i+1 = .i . {a2i+1 : F2}. If ExFi \n. {U, E, A, AC }, we proceed as follows: If ExFi = U, Ri = {(an, E r an)}, where n = 2i + 1, then Gi+1 \n= Gi . {(an, E r an)}, Gi+1 = Gi, .i+1 = .i. If ExFi = E, Ri = {(x, y r z)} . Gi, then Gi+1 = Gi . {(y, \nx r z)}, Gi+1 = Gi, .i+1 = .i. If E xFi = A, Ri = {(x, yrz); (u, vrx ' )} . Gi and Gi E (x = x ' ), then \nGi+1 = Gi . {(u, a2i r z), (y, v r a2i)}, Gi+1 = Gi, .i+1 = .i. If E xFi = AC , Ri = {(x, y r x ' )} \n. Gi, and Gi E (x = x ' ) then Gi+1 = Gi . {(x, a2i r x), (y, y r a2i)}, Gi+1 = Gi, .i+1 = .i. In all \nother cases, Gi+1 = Gi, Gi+1 = Gi and .i+1 = .i. Intuitively, each tuple (Oi, mi, ExFi, Ri) corresponds \nto a po\u00adtential rule application . If the components of the rule application are in the current sequent, \nwe apply the corresponding rule to these components. The indexing of labels guarantees that the choice \nof a2i and a2i+1 are always fresh for the sequent Gi; Gi .i. The construction in Def. 3.5 non-trivially \nextends a similar construc\u00adtion of Hintikka CSS due to Larchey-Wendling [20], in addition to which we \nhave to consider the cases for structural rules. We say G ' ; G ' . ' . G ; G . iff G ' . G , G ' . G \nand . ' . .. A labelled sequent G; G . is .nite if G, G, . are .nite ' . ' . ' sets. De.ne G ; G ' .f \nG; G . iff G ' ; G ' . G ; G . and G ' ; G ' . ' is .nite. If G; G . is a .nite sequent, it is consistent \niff it does not have a derivation in I LSP ASL . A (possibly in.nite) sequent G; G . is .nitely-consistent \niff every G ' ; G ' . ' .f G; G . is consistent. We write Li for the set of labels occurring in the sequent \nGi; Gi .i. Thus L1 = {a1}. The following lemma states some obvious properties of the construction of \nthe sequents Gi; Gi .i. This can be proved by a simple induction on i. Lemma 3.6. For any i . N , the \nfollowing properties hold: 1. Gi; Gi .i has no derivation 2. Li . {a0, a1, \u00b7 \u00b7 \u00b7 , a2i-1}  3. Gi; Gi \n.i .f Gi+1; Gi+1 .i+1 Given the construction of the series of sequents we have just seen above, we de.ne \na notion of a limit sequent, as the union of every sequent in the series. De.nition 3.6 (Limit sequent). \nLet F be a formula unprovable in I LSP ASL . The limit sequent for F is the sequent G.; G. .. where \nG. = Gi and G. = Gi and .. = .i i.N i.N i.N and where Gi; Gi .i is as de.ned in De.nition 3.5. Lemma \n3.7. If F is a formula unprovable in I LSP ASL , then the limit labelled sequent for F is a Hintikka \nsequent. Proof. Let G.; G. .. be the limit sequent. First we show that G.; G. .. is .nitely-consistent. \nConsider any G; G . .f G.; G. .., we show that G; G . has no derivation. Since G, G, . are .nite sets, \nthere exists i . N s.t. G . Gi, G . Gi, and . . .i. Moreover, Gi; Gi .i is not provable in I LSP ASL \n. Since weakening is admissible in I LSP ASL , G; G . .f Gi; Gi .i cannot be provable either. So condition \n1, 7 and 15 in De.nition 3.3 hold for the limit sequent, for otherwise we would be able to construct \na provable .nite labelled sequent from the limit sequent. We show the proofs that the other conditions \nin De.nition 3.3 involving multiplicative connectives and structural rules are also satis.ed by the limit \nsequent; the cases (1-5) and (15) for the additives are straightforward and are therefore omitted here. \n6. If m : T * . G., then m : T * . Gi for some i . N since each labelled formula from G. must appear \nsomewhere in the sequence. Then there exists j > i such that f(j) = (0, m, T * , R) where this formula \nbecomes principal. By con\u00adstruction (E, m r E) . Gj+1 . G.. Then G. E (m = E) because Gj+1 E (m = E). \nSo m =G. E. 8. If m : F1 * F2 . G., then it is in some Gi, where i . N . Then there exists j > i such \nthat f(j) = (0, m, F1 * F2, R).  By construction Gj+1 = Gj . {(a2j , a2j+1 r m)} . G., and Gj+1 = Gj \n. {a2j : F1, a2j+1 : F2} . G. . 9. If m : F1 * F2 . .., then it is in some .i, where i . N . For any \n(x, y r m ' ) . G. such that G. E (m = m ' ), there exists j > i such that (x, y r m ' ) . Gj and Gj \nE (m = m ' ). Also, there exists k > j such that f(k) = (1, m, F1 * F2, {(x, y r m ' )}) where the labelled \nformula becomes principal. Since (x, y r m ' ) . Gk and Gk (m = m ' ), we have either x : F1 . .k+1 . \n.. or y : F2 . .k+1 . .. . 10. If m : F1-* F2 . G., similar to case 8. 11. If m : F1-* F2 . .., similar \nto case 9. 12. For each an . L, there is a j = n such that f(j) = (O, m, U, {(an, E r an)}) where U \nis applied to an. Then Gj+1 = Gj . {(an, E r an)} . G., because n = 2j + 1. 13. If (x, y r z) . G ., \nthen it is in some Gi, where i . N . Then there is a j > i such that f(j) = (O, m, E, {(x, y r z)}) where \nE is applied. Then Gj+1 = Gj . {(y, x r z)} . G. . 14. If (x, y r z) . G. , (u, v r x ' ) . G ., and \nx =G. x ', then there is some Gi, i . N such that {(x, y r z), (u, v r x ' )} . Gi and Gi E (x = x ' \n). There are two cases to consider, depending on whether (x, y r z) and (u, v r x ' ) are the same relational \natoms. Suppose they are distinct. Then there must be some j > i such that f(j) = (O, m, A, {(x, y r z), \n(u, v r x ' )}). Then {(x, y r z), (u, v r x ' )} . Gj and Gj E (x = x ' ). By construction we obtain \nthat Gj+1 = Gj . {(u, a2j r z), (y, v r a2j )} . G .. If (x, y r z) and (u, v r x ' ) are the same relational \natom, then a similar argument can be applied, but in this case the schedule to choose is one which selects \nAC rather than A.  Theorem 3.8 (Completeness). Every formula F unprovable in I LSP ASL is not valid \n(in PASL relational Kripke models). Proof. We construct a limit sequent G.; G. .. for F following De.nition \n3.6. By the construction of the limit sequent, we have a1 : F . .. . By Lemma 3.7, this limit sequent \nis a Hintikka sequent, and therefore by Lemma 3.4, G.; G. .. is falsi.able. This means there exists a \nmodel (F, ., .) that satis.es G. and G. and falsi.es every element of .., including a1 : F , which means \nthat F is false at world .(a1). Thus F is not valid. 4. Extensions of PASL We now consider some extensions \nof PASL obtained by imposing additional properties on the semantics, as suggested by Dockins et al [11]. \nWe show that sound rules for indivisible unit and the stronger property of disjointness can be added \nto our labelled se\u00adquent calculus without jeopardising our completeness proof, but that the more exotic \nproperties of splittability and cross-split are not fully compatible with our current framework. Indivisible \nunit. The unit E in a commutative monoid (H, ., E) is indivisible iff the following holds for any h1, \nh2 . H: .h1, h2 . H. if h1 . h2 = E then h1 = E. (1) Relationally, this corresponds to the .rst-order \ncondition: .h1, h2 . H. if R(h1, h2, E) then h1 = E (2) Note that this also means that h2 = E whenever \nh1 . h2 = E. Most memory models in the literature have indivisible unit [5], so this property seems appropriate \nfor reasoning about concrete applications of separation logic. Indivisible unit can be axiomatised by \nthe following formula [6]: T * . (A * B) . A We use the following sound rule to capture this property: \n(E, y r E); G[E/x]; G[E/x] .[E/x] I U (x, y r E); G;G . Note that we can then instantiate the label y \nto E by applying Eq1 upwards. Recall that the sequent calculus LSBBI [16] is just the sequent calculus \nLSP ASL minus the rules C and P . Proposition 4.1. The formula T * . (A * B) . A is provable in LSBBI \n+ I U. The proof is as shown in Figure 3 (a). Theorem 4.2. LSP ASL + I U is sound and cut-free complete \nwith respect to the class of PASL Kripke relational frames (and separation algebras) with indivisible \nunit. Proof. Soundness is straightforward as the rule I U essentially just encodes the .rst-order formula \n(2) into the labelled sequent cal\u00adculus. Completeness can be proved via the same counter-model construction \nfor LSP ASL (Theorem 3.8). That is, we .rst de\u00ad.ne an intermediate calculus I LSP ASL + I U that is equiva\u00adlent \nto LSP ASL + I U , and do counter-model construction in I LSP ASL + I U . Since the I U rule contains \nsubstitution, the rule will be localised into the entailment relation E , so the de.nition of E in De.nition \n3.1 is modi.ed to allowed I U in addition to E q1, Eq2, P and C. Thus the rules of I LSP ASL + I U are \nexactly the same as I LSP ASL , and the only change is in the de.nition of E . The equivalence between \nLSP ASL +I U and I LSP ASL +I U can be proved as in Lemma 3.3. We then show that a Hintikka sequent yields \na Kripke relational frame that corresponds to a separation algebra with indivisible unit. No additional \nclauses are needed in the de.nition of Hintikka sequent since it is parametric on the entailment relation \nE . For a Hintikka sequent G; G ., suppose (H, rG, [E]) is the PASL Kripke relational frame generated \nby G. Given any [a], [b] rG [E], we can .nd a (a ' , b ' r c ' ) . G such that [a] = [a ' ], [b] = [b \n' ' ], [E] = [c ]. Also, we can use the rule I U to derive G E (a ' = E). Thus by Lemma 3.1, we obtain \n[a] = [a ' ] = [E]. So the structure (H, rG, [E]) generated by G is indeed a PASL Kripke relational frame \nthat obeys indivisible unit. The saturation with logical and structural rules E, U, A, AC is then the \nsame as in Sec. 3. Disjointness. The separating conjunction * in separation logic requires that the two \ncombined heaps have disjoint domains [29]. In a separation algebra (H, ., E), disjointness is de.ned \nby the following additional requirement: .h1, h2 . H. if h1 . h1 = h2 then h1 = E (3) Relationally, this \ncorresponds to the .rst-order condition: .h1, h2 . H. if R(h1, h1, h2) then h1 = E (4) The disjointness \ncondition is captured in labelled sequent cal\u00adculus by the following rule, where x, y are labels. (E, \nE r y); G[E/x]; G[E/x] .[E/x] D (x, x r y); G;G . In fact disjointness implies indivisible unit (but \nnot vice versa), as shown by Dockins et al. [11]. Thus we can prove the axiom for indivisible unit by \nusing LSBBI + D. Proposition 4.3. The formula T * . (A * B) . A is provable in LSBBI + D. Figure 3(b) \nshows the derivation of the formula; we highlight the principal relational atoms where they are not obvious. \nTheorem 4.4. LSP ASL + D is sound and cut-free complete with respect to the class of Kripke relational \nframes (and separation algebras) with disjointness. Proof. Similar to Theorem 4.2.  id id (E, a2 r E); \nE : A; a2 : B E : A I U (a1, a2 r E); a1 : A; a2 : B E : A (a1, a2 r a0); a0 : T * ; a1 : A; a2 : B a0 \n: A T * L ; a0 : T * ; a0 : A * B a0 : A *L ; a0 : T * . (A * B) a0 : A .L ; a0 : (T * . (A * B)) . A \n. R (a)  (E, E r E); \u00b7 \u00b7 \u00b7 ; E : A; E : B E : A Eq1 (E, a1 r E); \u00b7 \u00b7 \u00b7 ; a1 : A; E : B E : A E (a1, \nw2 r w1);(E, E r w2); (a1, E r E) ;\u00b7 \u00b7 \u00b7 ; a1 : A; E : B E : A D (a1, w2 r w1); (a2, a2 r w2) ; (a1, \na2 r E); \u00b7 \u00b7 \u00b7 ; a1 : A; a2 : B E : A A (a1, w1 r E); (E, a2 r w1); (a1, a2 r E) ; \u00b7 \u00b7 \u00b7 ; a1 : A; a2 \n: B E : A A (E, E r E); (a1, a2 r E); a1 : A; a2 : B E : A U (a1, a2 r E); a1 : A; a2 : B E : A T * \nL (a1, a2 r a0); a0 : T * ; a1 : A; a2 : B a0 : A ; a0 : T * ; a0 : A * B a0 : A *L ; a0 : T * . (A * \nB) a0 : A .L ; a0 : T * . (A * B) . A . R (b) Figure 3. Derivations of the axiom of indivisible unit \nin: (a) LSBBI + I U and (b) LSBBI + D. Splittability and cross-split. The property of in.nite splittability \nis sometimes useful when reasoning about the kinds of resource sharing that occur in divide-and-conquer \nstyle computations [11]. A monoid (H, ., E) has splittability if for every h0 . H \\ {E}, there are h1, \nh2 . H \\ {E} such that h1 . h2 = h0. Relationally, this corresponds to: if h0 = E then there exist h1 \n= E, h2 = E such that R(h1, h2, h0). This property can be axiomatised as the BBI formula \u00acT * . (\u00acT * \n* \u00acT * ) [6]. We give the following rule for splittability, where x, y are fresh: (x, y r z); G; G x \n: T * ; y : T * ; z : T * . G; G z : T * ; . S Proposition 4.5. The rule S for splittability is sound. \nProof. Assume the conclusion of S is falsi.able in an extended relational model (H, R, E, v, .); we show \nthat the premise is also falsi.able. So suppose that everything in G . G is true, and every\u00adthing in \n{z : T * } . . is false in the model. Speci.cally, z : T * is false, meaning .(z) I T *, thus .(z) = \nE. By splittability, there exist some h1, h2 . H \\ {E} such that R(h1, h2, .(z)) holds. Let . ' = .. \n{x . h1, y . h2}. Then (x, y r z) is true under . '. Also, since . ' (x) = E and . ' (y) = E, the labelled \nformulae x : T * and y : T * are false under . '. Thus the model with frame (H, R, E), valuation v, and \nlabel mapping . ' falsi.es the premise. Proposition 4.6. The axiom \u00acT * . (\u00acT * * \u00acT * ) for splittability \nis provable in LSBBI + S. Proof. We start from \u00acT * . (\u00acT * * \u00acT * ), and obtain the following derivation \nbackward: (a1, a2 r a0); a1 : T * ; a2 : T * ; a0 : T * ; a0 : \u00acT * * \u00acT * ; a0 : T * ; a0 : \u00acT * * \u00acT \n* S ; a0 : \u00acT * a0 : \u00acT * * \u00acT * \u00acL ; a0 : \u00acT * . (\u00acT * * \u00acT * ) . R Then we can apply *R (backwards) \non the top sequent using the relational atom (a1, a2 r a0) to obtain the premises SL and SR. The left \npremise SL can be proved as follows: T * R (E, a2 r a0); E : T * ; \u00b7 \u00b7 \u00b7 T * L (a1, a2 r a0); a1 : T \n* a1 : T * ; \u00b7 \u00b7 \u00b7 (a1, a2 r a0); a1 : \u00acT * ; a1 : T * ; \u00b7 \u00b7 \u00b7 \u00acR The right premise SR can be proved \nsimilarly. Note that the rule S creates new labels in the premise, as the rule A does. However, it also \nhas a principal formula, so it is not a structural rule. Unlike the rules I U and D, the rule S cannot \nsimply be localised into the entailment relation E, so we have to extend the notion of a Hintikka sequent \nto add a condition corresponding to splittability. The counter-model construction then has to ensure \nthat this condition is satis.ed by the limit sequent by ensuring that the rule S is applied in a fair \nway. We therefore leave the details of this completeness proof for LSP ASL + S to future work. Cross-split \nis a rather complicated property. It speci.es that if a heap can be split in two different ways, then \nthere should be intersections of these splittings. Formally, in a monoid (H, ., E), if h1 . h2 = h0 and \nh3 . h4 = h0, then there should be four elements h13, h14, h23, h24, informally representing the intersections \nh1 n h3, h1 n h4, h2 n h3 and h2 n h4 respectively, such that h13 . h14 = h1, h23 . h24 = h2, h13 . h23 \n= h3, and h14 . h24 = h4. The corresponding condition on Kripke relational frames is obvious. The following \nsound rule naturally captures cross-split, where p, q, s, t, u, v, x, y, z are labels: R; (x, y r z); \n(u, v r z); G; G (x, y r z); (u, v r z); G; G . . C S where R := (p, q r x); (p, s r u); (s, t r y); \n(q, t r v) and p, q, s, t do not occur in the conclusion We conjecture that this rule can be handled \nin the counter-model construction by treating it similarly to the rule A. We then need to change the \nindexing of labels when constructing the limit se\u00adquent. Let the rule A choose a4i, the rules *L and \n-* R choose a4i, a4i+1, and the rule C S choose a4i, a4i+1, a4i+2, a4i+3 as new labels. Further, let \nthe rule U create the identity relational atom (an, E r an) only when n = 4i + 3. Then each Li is a subset \nof {a1, \u00b7 \u00b7 \u00b7 , a4i-1}. Splittability and cross-split are not as frequently used in sep\u00adaration logic \nas the other conditions, and they require non-trivial modi.cations in our current proofs. We note that \nReynolds heap model [29] falsi.es splittability, as heaps are .nite objects that only non-trivially split \n.nitely often. On the other hand cross-split is true in the heap model; however we are not aware of any \nformu\u00adlae whose proof requires this property. For these reasons we omit these from our modular framework \nof proof systems for PASL.  5. Tailoring the labelled calculus We now consider various labelled calculi \nobtained by extending LSBBI with one or more structural rules that correspond to partial\u00addeterminism \n(P ), cancellativity (C), indivisible unit (IU), and dis\u00adjointness (D). Most of the results in this section \neither directly fol\u00adlow from the proofs in previous sections, or are easy adaptations. As those conditions \nfor monoids are often given in a modular way, e.g., in [6, 11], it is not surprising that our structural \nrules can also be added modularly to LSBBI , since they just simulate those con\u00additions directly and \nindividually in the labelled sequent calculus. Calculi without cancellativity. Some notions of separation \nlogic omit cancellativity [18], so dropping the rule C in LSP ASL gives an interesting system. The proofs \nin Sec. 3 still work if we just insist on a partial commutative monoid, and drop C in E. Theorem 5.1. \nThe labelled sequent calculus LSBBI + P is sound and cut-free complete with respect to the partial commutative \nmonoidal semantics for BBI. As a result, it is easy to obtain the following sound and complete labelled \ncalculi for the corresponding semantics: LSBBI +P +I U and LSBBI +P +D. The proofs are similar to that \nfor Theorem 4.2. Calculi without partial-determinism. Similar to above, dropping partial-determinism \ngives another sound and complete labelled cal\u00adculus LSBBI +C, although we are not aware of any concrete \nmod\u00adels in separation logic that employ this framework. Theorem 5.2. The labelled sequent calculus LSBBI \n+ C is sound and cut-free complete with respect to the cancellative commutative monoidal semantics for \nBBI. Again, using a similar argument as in Theorem. 4.2, we can obtain sound and complete labelled calculi \nLSBBI + C + I U and LSBBI + C + D. Calculi without partial-determinism and cancellativity. The la\u00adbelled \ncalculus LSBBI + I U is sound and complete by Prop. 4.1, and cut-elimination holds. Theorem 5.3. The \nlabelled sequent calculus LSBBI +I U is sound and cut-free complete with respect to the commutative monoidal \nsemantics for BBI with indivisible unit. To prove the completeness of the calculus LSBBI + D, we need \nto go through the counter-model construction proof, since disjointness is not axiomatisable. It is easy \nto check that the proofs in Section 3 do not break when we de.ne E by using Eq1, Eq2, D only, and the \nHintikka sequent then gives the BBI Kripke relational frame that obeys disjointness. The other proofs \nremain the same. Theorem 5.4. The labelled sequent calculus LSBBI + D is sound and cut-free complete \nwith respect to the commutative monoidal semantics for BBI with disjointness. To summarise, our approach \noffers a sound and cut-free calcu\u00adlus for the extension of BBI with every combination of the proper\u00adties \nP, C, I U, D. The case where none of the properties hold, i.e. regular BBI, have already been solved \n[16, 27]. Omitting the cases covered by the implication of I U by D, this provides us with the following \neleven labelled calculi: LSBBI + I U LSBBI + C LSBBI + D LSBBI + P LSP ASL (= LSBBI + P + C) LSBBI + \nP + I U LSBBI + C + I U LSP ASL + I U LSBBI + P + D LSBBI + C + D LSP ASL + D 6. Implementation and experiment \nWe discuss here an implementation of the proof system LSP ASL + D. It turns out that the AC rule is admissible \nin this system; in fact it is admissible in the subsystem LSBBI + C, as shown next, so we do not implement \nthe AC rule. Proposition 6.1. The AC rule is admissible in LSBBI + C. Proof. We show that every derivation \nin LSBBI + C can be trans\u00adformed into one with no applications of AC . It is suf.cient to show that we \ncan eliminate a single application of AC ; then we can elim\u00adinate all AC in a derivation successively \nstarting from the topmost applications in that derivation. So suppose we have a derivation in LSBBI + \nC of the form: . (x, w r x); (y, y r w); (x, y r x); G; G . AC (x, y r x); G;G . where w is a new label \nnot in the root sequent. This is transformed into the following derivation: . ' (x, E r x); (E, E r E); \nG[E/y]; G[E/y] .[E/y] U (x, E r x); G[E/y]; G[E/y] .[E/y] C (x, E r x); (x, y r x); G;G . U (x, y r x); \nG;G . where . ' is obtained by applying the substitutions [E/x] and [E/w] to . (Lemma 2.2). Note that \nsince w does not occur in the root sequent, G[E/x][E/w] = G[E/x], G[E/x][E/w] = G[E/x] and .[E/x][E/w] \n= .[E/x]. These substitutions do not introduce new instances of AC . Our implementation uses the following \nstrategy when applying rules on a sequent: 1. Try to close the branch by rules id, .L, T * R, T * R. \n 2. If (1) not applicable, apply all possible Eq1, Eq2, P, C, I U, D rules to unify labels3 . 3. If \n(1-2) not applicable, apply invertible rules .L, .R, . L, . R, *L, -* R, T * L in all possible ways. \n 4. If (1-3) not applicable, try rules *R or -* L by choosing exist\u00ading relational atoms. 5. If none \nof the existing relational atoms are applicable, or all combinations of *R, -* L formulae and relational \natoms are already applied in (4), apply structural rules on the set G0 of relational atoms in the sequent \nas follows. (a) Use E to generate all commutative variants of existing rela\u00adtional atoms in G0, giving \na set G1. (b) Apply A for each applicable pair in G1, generating a set G2. (c) Use U to generate all \nidentity relational atoms for each label in G2, giving the set G3.  6. If none of above is applicable, \nfail.  Step (2) is terminating, because each substitution eliminates a label, and we only have .nitely \nmany labels. Step (5) is not applicable when G3 = G0. It is also clear that step (5) is terminating. \nWe forbid applications of the rule A to the pair {(x, y r z), (u, v r x)} when {(u, w r z), (y, v r w)}, \nfor some label w, (or any commutative variants of this pair, e.g., {(w, u r z); (v, y r w)}) is already \nin the sequent. This is because the created relational atoms in such an A application can be uni.ed to \nexisting ones by using rules P ,C. We view G, . in a sequent G; G . as lists, and each time a logical \nrule is applied, we place the subformulae in the front of the list. Thus our proof search has a focusing \n.avour , that 3 Although I U is admissible, we keep it because it simpli.es proof search.  Formula BBeye \n(opt) F V LSBBI (heuristic) Separata (1) (a-* b) . (T * (T* . a)) . b 0.076 0.002 0.002 (2) (T*-* \u00ac(\u00aca \n* T*)) . a 0.080 0.004 0.002 (3) \u00ac((a-* \u00ac(a * b)) . ((\u00aca-* \u00acb) . b)) 0.064 0.003 0.002 (4) T* . ((a-* \n(b-* c))-* ((a * b)-* c)) 0.060 0.003 0.002 (5) T* . ((a * (b * c))-* ((a * b) * c)) 0.071 0.002 0.004 \n(6) T* . ((a * ((b-* e) * c))-* ((a * (b-* e)) * c)) 0.107 0.004 0.008 (7) \u00ac((a-* \u00ac(\u00ac(d-* \u00ac(a * (c * \nb))) * a)) . c * (d . (a * b))) 0.058 0.002 0.006 (8) \u00ac((c * (d * e)) . B) where B := ((a-* \u00ac(\u00ac(b-* \u00ac(d \n* (e * c))) * a)) * (b . (a * T))) 0.047 0.002 0.013 (9) \u00ac(C * (d . (a * (b * e)))) where C := ((a-* \n\u00ac(\u00ac(d-* \u00ac((c * e) * (b * a))) * a)) . c) 94.230 0.003 0.053 (10) (a * (b * (c * d))) . (d * (c * (b * \na))) 0.030 0.004 0.002 (11) (a * (b * (c * d))) . (d * (b * (c * a))) 0.173 0.002 0.002 (12) (a * (b \n* (c * (d * e)))) . (e * (d * (a * (b * c)))) 1.810 0.003 0.002 (13) (a * (b * (c * (d * e)))) . (e * \n(b * (a * (c * d)))) 144.802 0.003 0.002 (14) T* . (a * ((b-* e) * (c * d))-* ((a * d) * (c * (b-* e)))) \n6.445 0.003 0.044 (15) \u00ac(T* . (a . (b * \u00ac(c-* (T* . a))))) timeout(1000s) 0.003 0.003 (16) ((D . (E-* \n(D * E))) . (b-* ((D . (E-* ((D * a) * a))) * b))), where D := T* . a and E := a * a 0.039 0.005 8.772 \n(17) ((T* . (a-* (((a * (a-* b)) * \u00acb)-* (a * (a * ((a-* b) * \u00acb)))))) . ((((T* * a) * (a * ((a-* b) \n* \u00acb))) . (((a * a) * (a-* b)) * \u00acb)) * T*)) timeout(1000s) fail 49.584 (18) (F * F ) . F , where F := \n\u00ac(T-* \u00acT*) invalid invalid 0.004 (19) (T* . (a * b)) . a invalid invalid 0.003 Table 2. Experimental \nresults from the prover Separata. always tries to decompose the subformulae of a principal formula if \npossible. To guarantee completeness, each time we apply a *R or -* L rule, the principal formula is moved \nto the end of the list, so that each principal formula for non-determinism rules *R, -* L is considered \nfairly, i.e. applied in turn. We incorporate a number of optimisations in the proof search. (1) Back-jumping \n[2] is used to collect the unsatis.able core along each branch. When one premise of a binary rule has \na deriva\u00adtion, we try to derive the other premise only when the unsatis.able core is not included in \nthat premise. (2) A search strategy discussed by Park et al [27] is also adopted. For *R and -* L applications, \nwe forbid the search to consider applying the rule twice with the same pair of principal formula and \nprincipal relational atom, since the effect is the same as contraction, which is admissible. (3) Previ\u00adous \nwork on theorem proving for BBI has shown that associativity of * is a source of inef.ciency in proof \nsearch [16, 27]. We borrow the idea of the heuristic method presented in [16] to quickly solve certain \nassociativity instances. When we detect z : A * B on the right hand side of a sequent, we try to search \nfor possible worlds (labels) for the subformulae of A, B in the sequent, and construct a binary tree \nusing these labels. For example, if we can .nd x : A and y : B in the sequent, we will take x, y as the \nchildren of z. When we can build such a binary tree of labels, the corresponding relational atoms given \nby the binary tree will be used (if they are in the sequent) as the prioritised ones when decomposing \nz : A * B and its subformulae. Of course, without a free-variable system, our handling of this heuristic \nmethod is just a special case of the origi\u00adnal one, but this approach can speed up the search in certain \ncases. The experiments in this paper are conducted on a Dell Optiplex 790 desktop with Intel CORE i7 \n2600 @ 3.4 GHz CPU and 8GB memory, running Ubuntu 13.04. The theorem provers are written in Ocaml. We \ntest our prover Separata for LSP ASL + D on the formulae listed in Table 2; the times displayed are in \nseconds. We compare the results with provers for BBI, BBeye [27] and the incomplete heuristic-based F \nV LSBBI [16], when the formula is valid in BBI. We run BBeye in an iterative deepening way, and the time \ncounted for BBeye is the total time it spends. Formulae (1-14) are used by Park et al. to test their \nprover BBeye for BBI [27]. We can see that for formulae (1-14) the performance of Separata is comparable \nwith the heuristic based prover for F V LSBBI . Both provers are generally faster than BBeye. Formula \n(15) is one that BBeye had trouble with [16], but Separata handles it trivially. However, there are cases \nwhere BBeye is faster than Separata. We found the exam\u00adple formula (16) from a set of testings on randomly \ngenerated BBI theorems. Formula (17) is a converse example where a randomly generated BBI theorem causes \nBBeye to time out and F V LSBBI with heuristics to terminate within the timeout but without .nding a \nproof due to its incompleteness. Formula (18) is valid only when the monoid is partial [22], and formula \n(19) is the axiom of indi\u00advisible unit. Some interesting cases for disjointness will be shown later. \nWe do not investigate the details in the performances between these provers because they are for different \nlogics. We leave further optimisations for Separata as future work. 7. Future work In this paper we have \nfocused on propositional inference, but the assertion language of separation logic is generally taken \nto include .rst-order logic, usually extended with arithmetic, or at least equal\u00adity. More importantly, \nthis language is interpreted only with respect to some concrete semantics, the most well-known of which \nis the original heap model of Reynolds [29]. We refer readers to that pa\u00adper for a more careful description \nof this model; for the purposes of this section we will remark that values range across the inte\u00adgers, \nand addresses across some speci.ed subset of the integers; that heaps are .nite partial functions from \naddresses to values; and that expressions are built up from variables (evaluated with respect to some \nstore), values, and the usual arithmetic operations. The advantage of this model is that it supports \nthe interpretation of the points-to predicate ., which allows direct reference to the contents of the \nheap: E . E ' is satis.ed by a heap iff it is a singleton map sending the address speci.ed by the expression \nE to the value speci.ed by the expression E ' . The question for future research is whether our labelled \nsequent calculus and implementation could be extended to reason about such concrete predicates; this \nsection presents preliminary work in this direction. While the full power of pointer arithmetic is an \nimportant subject for future work, for the purpose of this work we set arithmetic aside and let expressions \nrange across store variables e, e1, e2, . . . only, as is done for example by Berdine et al [3]. The \nrules for quanti.ers are straightforward, e.g.:  G; G; h : F [e/x] . G; G h : F [e/x]; . .L .R G; G; \nh : .x.F . G; G h : .x.F ; . where e does not appear free in the conclusion of .L. Equality between variables \nsimply requires that they are as\u00adsigned by the store to the same value, giving rise to the rules G; G[e2/e1] \n.[e2/e1] = R = L G; G h : e = e; . G; G; h : e1 = e2 . Points-to poses a more complex problem as it involves \ndirect interaction with the contents of heaps; Fig. 4 presents putative labelled sequent rules for this \npredicate. The semantics of e1 . e2 .rst require that the heap be a singleton, which is a spatial property \nthat can be captured by abstract semantics: a singleton world is not equal to the identity world E, and \ncannot be split into two non-E worlds. This motivates rules . L1 and . L2. The rules . L3 and . L4 address \nthe content of heaps: . L3 says that two heaps with the same address (value of e1) must be the same heap, \nand . L4 says that a singleton heap makes a unique assignment. Our implementation of the calculus de.ned \nby adding these rules to LSP ASL + D is not complete w.r.t. Reynolds semantics: for example it is unable \nto prove the formula below, which is based on a property for septraction due to Vafeiadis and Parkinson \n[32], and is valid in the heap model: T * . \u00ac((e1 . e2)-* \u00ac(e1 . e2)) (5) This formula essentially asserts \nthat a heap satisfying e1 . e2 is possible to construct, but our prover does not support explicit heap \nconstruction. Nevertheless this incomplete calculus does support strikingly elegant proofs of non-trivial \nseparation logic inferences, such as the DISJOINT axiom of Parkinson [28, Cha. 5.3]: . L1 (E, E r a0); \nE : (e1 . e2) a0 : . D (a1, a1 r a0); a1 : (e1 . e2) a0 : . . L3 (a1, a2 r a0); a1 : (e1 . e2); a2 : \n(e1 . e2) a0 : . *L ; a0 : (e1 . e2) * (e1 . e2) a0 : . . R ; a0 : ((e1 . e2) * (e1 . e2)) . . Our experimental \nprover Separata+, extending LSP ASL + D with the rules of this section, has proved a number of tested \nSL formulae very rapidly; see Table 3 for some examples. Formulae (1\u00ad3) are taken from Galmiche and M \n\u00b4ery [14]; in particular, the .rst is the DISJOINT axiom proved above. Formulae (4-6) are taken from \nVafeiadis and Parkinson s study of magic wand s De Morgan dual septraction, \u00ac(A-* \u00acB) [32]. These results \npresent encouraging evidence that the work of this paper may form the basis of practical theorem proving \nfor the assertion language of separation logic. Dealing with splittability and cross-split in our labelled \ncalculi is one of our next goals. We are also interested in extending the techniques of this paper to \nconcrete semantics other than Reynolds heap models, such as those surveyed by Calcagno et al [8] and \nJensen and Birkedal [18]. 8. Related work There are many more automated tools, formalisations, and logical \nembeddings for separation logic than can reasonably be surveyed within the scope of this conference paper. \nAlmost all are not di\u00adrectly comparable to this paper because they deal with separation logic for some \nconcrete semantics. One exception to this concrete approach is Holfoot [31], a HOL mechanisation with \nsupport for automated reasoning about the shape of SL speci.cations exactly those aspects captured by \nabstract separation logic. However, unlike Separata, Holfoot does not support magic wand. This is a common \nrestriction when au\u00adtomating any notion of SL, because -* is a source of undecid\u00adability [4]. Conversely, \nthe mechanisations and embeddings that do incorporate magic wand tend to give little thought to (semi-) \nde\u00adcision procedures. An important exception to this is the tableaux of Galmiche and M\u00b4 ery [14], which \nare designed for the decidable fragment of the assertion language of concrete separation logic with -* \nidenti.ed by Calcagno et al [7], but may also be extendable to the full assertion language. These methods \nhave not been imple\u00admented, and given the dif.culty of the development we expect that practical implementation \nwould be non-trivial. Another partial ex\u00adception to the trend to omit -* is SmallfootRG [9], which supports \nautomation yet includes septraction [32], the De Morgan dual of -* . However SmallfootRG does not support \nadditive negation nor implication, and so -* cannot be recovered; indeed in this setting septraction \nis mere syntactic sugar that can be eliminated. The denigration of magic wand is not without cost, as \nthe con\u00adnective, while surely less useful than *, has found application. A non-exhaustive list follows: \ngenerating weakest preconditions via backwards reasoning [17]; specifying iterators [15, 19, 28]; reason\u00ading \nabout parallelism [12]; and various applications of septraction, such as the speci.cation of iterators \nand buffers [10]. For a par\u00adticularly deeply developed example, see the correctness proof for the Schorr-Waite \nGraph Marking Algorithm of Yang [33], which involves non-trivial inferences involving -* (Lems. 78 and \n79). These examples provide ample motivation to build proof calculi and tool support that include magic \nwand. Undecidability, which in any case is pervasive in program proof, should not deter us from seeking \npractically useful automation. Our work builds upon the labelled sequent calculi for BBI of H \u00b4ou et \nal [16]. Their prover F V LSBBI implements a free-variable calculus for BBI but is incomplete. Our extensions \nto H \u00b4ou et al involves two main advances: .rst, a counter-model construction necessary to prove completeness; \nsecond, our prover deals with labelled sequents directly and (given certain fairness assumptions) is \na complete semi-decision procedure for PASL and its variants. The link between BBI and SL is also emphasised \nas motivation by Park et al [27], whose BBI prover BBeye was used for comparisons in Sec. 6. This work \nwas recently re.ned by Lee and Park [23], in work independent to our own, to a labelled sequent calculus \nfor Reynolds heap model. Their calculus, like ours, cannot prove the formula (5)4 and so is not complete \nfor these semantics. Also related, but so far not implemented, are the tableaux for partial\u00addeterministic \nBBI of Larchey-Wendling and Galmiche [20, 21], which, as mentioned in the introduction to this paper, \nare claimed to be extendable with cancellativity to attain PASL via a rather involved proof. In contrast, \nthe relative ease with which certain properties can be added or removed from labelled sequent calculi \nis an important bene.t of our approach; this advantage comes from structural rules which directly capture \nthe conditions on Kripke relational frames, and handle the equality of worlds by explicit global substitutions. \nFinally we note that the counter-model construction of this pa\u00adper was necessary to prove completeness \nbecause many of the prop\u00aderties we are interested in are not BBI-axiomatisable, as proved by Brotherston \nand Villard [6]; that paper goes on to give a sound and complete Hilbert axiomatisation of these properties \nby extending BBI with techniques from hybrid logic. Sequent calculus and proof search in this setting \nis another promising future direction. 4 Con.rmed by private communications with authors.  (E, h0 r \nh0); G[E/h1][h0/h2]; G[E/h1][h0/h2]; h0 : e1 . e2 .[E/h1][h0/h2] (h0, E r h0); G[E/h2][h0/h1]; G[E/h2][h0/h1]; \nh0 : e1 . e2 .[E/h2][h0/h1] G; G; E : e1 . e2 . . L1 (h1, h2 r h0); G; G; h0 : e1 . e2 . . L2 G[h/h ' \n]; G[h/h ' ]; h : e1 . e2; h : e1 . e3 .[h/h ' ] G; G[e1/e3][e2/e4]; h : e1 . e2 .[e1/e3][e2/e4] . L3 \n. L4 G; G; h : e1 . e2; h ' : e1 . e3 . G; G; h : e1 . e2; h : e3 . e4 . Figure 4. Some rules for the \npredicate . in separation logic. Formula Separata+ (1) (2) (3) (4) (5) (6) ((e1 . e2) * (e1 . e2)) . \n. (((e1 . e2) * (e3 . e4)) . ((e1 . e2) * (e5 . e6))) . ((e3 . e6) * T) (.x3x2x1.(((x3 . x2) * (x1 . \ne)) . (x2 = x1))) . (.x4x5.((x4 . x5) * (x5 . e))) \u00ac((e1 . e2)-* \u00ac(e3 . e4)) . ((e1 = e3) . ((e2 = e4) \n. T*)) \u00ac(((e1 . p) * (e2 . q))-* \u00ac(e3 . r)) . \u00ac(((e1 . p)-* \u00ac(\u00ac((e2 . q)-* \u00ac(e3 . r))))) \u00ac((e1 . p)-* \n\u00ac(e2 . q)) . \u00ac((e1 . p)-* \u00ac((e2 . q) . ((e1 . p) * T))) 0.004 0.002 0.001 0.004 0.002 0.003 Table 3. \nExperimental results from the prover Separata+. References [1] A. W. Appel. Tactics for separation logic. \nUnpublished, 2006. [2] F. Baader. The Description Logic Handbook: Theory, Implementation, and Applications. \nCambridge University Press, 2003. [3] J. Berdine, C. Calcagno, and P. W. OHearn. Symbolic execution with \nseparation logic. In APLAS, volume 3780 of LNCS, pages 52 68, 2005. [4] R. Brochenin, S. Demria, and \nE. Lozes. On the almighty wand. Inform. and Comput., 211:106 137, 2012. [5] J. Brotherston and M. Kanovich. \nUndecidability of propositional separation logic and its neighbours. In LICS, pages 130 139. IEEE, 2010. \n[6] J. Brotherston and J. Villard. Parametric completeness for separation theories. Technical Report \nRN/13/11, UCL, 2013. [7] C. Calcagno, H. Yang, and P. W. OHearn. Computability and com\u00adplexity results \nfor a spatial assertion language for data structures. In FSTTCS, volume 2245 of LNCS, pages 108 119, \n2001. [8] C. Calcagno, P. W. O Hearn, and H. Yang. Local action and abstract separation logic. In LICS, \npages 366 378. IEEE, 2007. [9] C. Calcagno, M. Parkinson, and V. Vafeiadis. Modular safety checking for \n.ne-grained concurrency. In SAS, volume 4634 of LNCS, 2007. [10] R. Cherini and J. O. Blanco. Local reasoning \nfor abstraction and sharing. In SAC, pages 552 557. ACM, 2009. [11] R. Dockins, A. Hobor, and A. W. Appel. \nA fresh look at separation algebras and share accounting. In APLAS, volume 5904 of LNCS, pages 161 177, \n2009. [12] M. Dodds, S. Jagannathan, and M. J. Parkinson. Modular reasoning for deterministic parallelism. \nIn POPL, pages 259 270. ACM, 2011. [13] D. Galmiche and D. Larchey-Wendling. Expressivity properties \nof boolean BI through relational models. In FSTTCS, volume 4337 of LNCS, pages 357 368, 2006. [14] D. \nGalmiche and D. M\u00b4ery. Tableaux and resource graphs for separa\u00adtion logic. J. Logic Comput., 20(1):189 \n231, 2007. [15] C. Haack and C. Hurlin. Resource usage protocols for iterators. J. Object Tech., 8(4):55 \n83, 2009. [16] Z. H \u00b4ou, A. Tiu, and R. Gor \u00b4e. A labelled sequent calculus for BBI: Proof theory and \nproof search. In Tableaux, LNCS, 2013. page 172\u00ad187; extended version at arXiv:1302.4783. [17] S. Ishtiaq \nand P. W. O Hearn. BI as an assertion language for mutable data structures. In POPL, pages 14 26. ACM, \n2001. [18] J. B. Jensen and L. Birkedal. Fictional separation logic. In ESOP, volume 7211 of LNCS, pages \n377 396, 2012. [19] N. R. Krishnaswami. Reasoning about iterators with separation logic. In SAVCBS, pages \n83 86. ACM, 2006. [20] D. Larchey-Wendling. The formal strong completeness of partial monoidal boolean \nBI. To appear in J. Logic. Comput., 2013. [21] D. Larchey-Wendling and D. Galmiche. Exploring the relation \nbe\u00adtween intuitionistic BI and boolean BI: An unexpected embedding. Math. Structures Comput. Sci., 19(3):435 \n500, 2009. [22] D. Larchey-Wendling and D. Galmiche. The undecidability of boolean BI through phase semantics. \nIn LICS, pages 140 149. IEEE, 2010. [23] W. Lee and S. Park. A proof system for separation logic with \nmagic wand. Technical Report CSE-2013-7, POSTECH, 2013. [24] A. McCreight. Practical tactics for separation \nlogic. In TPHOLs, volume 5674 of Lecture Notes in Computer Science, pages 343 358. Springer, 2009. [25] \nS. Negri and J. von Plato. Structural Proof Theory. Cambridge University Press, 2001. [26] P. W. O Hearn \nand D. J. Pym. The logic of bunched implications. Bull. Symbolic Logic, 5(2):215 244, 1999. [27] J. Park, \nJ. Seo, and S. Park. A theorem prover for boolean BI. In POPL, pages 219 232. ACM, 2013. [28] M. Parkinson. \nLocal Reasoning for Java. PhD thesis, Cambridge, 2005. [29] J. C. Reynolds. Separation logic: A logic \nfor shared mutable data structures. In LICS, pages 55 74. IEEE, 2002. [30] H. Tuch, G. Klein, and M. \nNorrish. Types, bytes, and separation logic. In POPL, pages 97 108. ACM, 2007. [31] T. Tuerk. A formalisation \nof smallfoot in HOL. In TPHOLs, volume 5674 of LNCS, 2009. [32] V. Vafeiadis and M. Parkinson. A marriage \nof rely/guarantee and separation logic. In CONCUR, volume 4703 of LNCS, pages 256 271, 2007. [33] H. \nYang. Local Reasoning for Stateful Programs. PhD thesis, Illinois at Urbana-Champaign, 2001.  \n\t\t\t", "proc_id": "2535838", "abstract": "<p>Abstract separation logics are a family of extensions of Hoare logic for reasoning about programs that mutate memory. These logics are \"abstract\" because they are independent of any particular concrete memory model. Their assertion languages, called propositional abstract separation logics, extend the logic of (Boolean) Bunched Implications (BBI) in various ways.</p> <p>We develop a modular proof theory for various propositional abstract separation logics using cut-free labelled sequent calculi. We first extend the cut-fee labelled sequent calculus for BBI of Hou et al to handle Calcagno et al's original logic of separation algebras by adding sound rules for partial-determinism and cancellativity, while preserving cut-elimination. We prove the completeness of our calculus via a sound intermediate calculus that enables us to construct counter-models from the failure to find a proof. We then capture other propositional abstract separation logics by adding sound rules for indivisible unit and disjointness, while maintaining completeness and cut-elimination. We present a theorem prover based on our labelled calculus for these logics.</p>", "authors": [{"name": "Zh&#233; H&#243;u", "author_profile_id": "81502653486", "affiliation": "The Australian National University, Canberra, Australia", "person_id": "P4383882", "email_address": "zhe.hou@anu.edu.au", "orcid_id": ""}, {"name": "Ranald Clouston", "author_profile_id": "81325487911", "affiliation": "The Australian National University, Canberra, Australia", "person_id": "P4383883", "email_address": "ranald.clouston@anu.edu.au", "orcid_id": ""}, {"name": "Rajeev Gor&#233;", "author_profile_id": "81100168471", "affiliation": "The Australian National University, Canberra, Australia", "person_id": "P4383884", "email_address": "rajeev.gore@anu.edu.au", "orcid_id": ""}, {"name": "Alwen Tiu", "author_profile_id": "86159036257", "affiliation": "Nanyang Technological University, Singapore, Singapore", "person_id": "P4383885", "email_address": "atiu@ntu.edu.sg", "orcid_id": ""}], "doi_number": "10.1145/2535838.2535864", "year": "2014", "article_id": "2535864", "conference": "POPL", "title": "Proof search for propositional abstract separation logics via labelled sequents", "url": "http://dl.acm.org/citation.cfm?id=2535864"}