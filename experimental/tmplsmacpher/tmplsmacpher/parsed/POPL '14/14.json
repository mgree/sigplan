{"article_publication_date": "01-08-2014", "fulltext": "\n A Veri.ed Information-Flow Architecture Arthur Azevedo de Amorim1 Nathan Collins2 e DeHon1 Andr\u00b4Delphine \nDemange1 C .at .alin Hrit\u00b8cu1,3 David Pichardie3,4 Benjamin C. Pierce1 Randy Pollack4 Andrew Tolmach2 \n1University of Pennsylvania 2Portland State University 3INRIA 4Harvard University Abstract SAFE is a \nclean-slate design for a highly secure computer sys\u00adtem, with pervasive mechanisms for tracking and limiting \ninfor\u00admation .ows. At the lowest level, the SAFE hardware supports .ne-grained programmable tags, with \nef.cient and .exible prop\u00adagation and combination of tags as instructions are executed. The operating \nsystem virtualizes these generic facilities to present an information-.ow abstract machine that allows \nuser programs to la\u00adbel sensitive data with rich con.dentiality policies. We present a formal, machine-checked \nmodel of the key hardware and software mechanisms used to control information .ow in SAFE and an end\u00adto-end \nproof of noninterference for this model. Categories and Subject Descriptors D.4.6 [Security and Protec\u00adtion]: \nInformation .ow controls; D.2.4 [Software Engineering]: Software/Program Veri.cation Keywords security; \nclean-slate design; tagged architecture; information-.ow control; formal veri.cation; re.nement 1. Introduction \nThe SAFE design is motivated by the conviction that the insecurity of present-day computer systems is \ndue in large part to legacy design decisions left over from an era of scarce hardware resources. The \ntime is ripe for a complete rethink of the entire system stack with security as the central focus. In \nparticular, designers should be willing to spend more of the abundant processing power available on today \ns chips to improve security. A key feature of SAFE is that every piece of data, down to the word level, \nis annotated with a tag representing policies that govern its use. While the tagging mechanism is very \ngeneral, one partic\u00adularly interesting use of tags is for representing information-.ow control (IFC) \npolicies. For example, an individual record might be tagged This information should only be seen by principals \nAlice or Bob, a function pointer might be tagged This code is trusted to work with Carol s secrets, or \na string might be tagged This came from the network and has not been sanitized yet. Such tags repre\u00adsenting \nIFC policies can involve arbitrary sets of principals, and principals themselves can be dynamically allocated \nto represent an unbounded number of entities within and outside the system. At the programming-language \nlevel, rich IFC policies have been extensively explored, with many proposed designs for static [19, Permission \nto make digital or hard copies of part or all of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. Copyrights for third-party components of this \nwork must be honored. For all other uses, contact the owner/author(s). POPL 14, January 22 24, 2014, \nSan Diego, CA, USA. Copyright is held by the owner/author(s). ACM 978-1-4503-2544-8/14/01. http://dx.doi.org/10.1145/2535838.2535839 \n 40, etc.] and dynamic [3, 20, 39, 44, etc.] enforcement mecha\u00ad nisms and a huge literature on their \nformal properties [19, 40, etc.]. Similarly, operating systems with information-.ow tracking have been \na staple of the OS literature for over a decade [28, etc.]. But progress at the hardware level has been \nmore limited, with most proposals concentrating on hardware acceleration for taint-tracking schemes [12, \n15, 45, 47, etc.]. SAFE extends the state of the art in two signi.cant ways. First, the SAFE machine \noffers hardware support for sound and ef.cient purely-dynamic tracking of both ex\u00adplicit and implicit \n.ows (i.e., information leaks through both data and control .ow) for arbitrary machine code programs \nnot just programs accepted by static analysis, or produced by translation or transformation. Moreover, \nrather than using just a few taint bits, SAFE associates a word-sized tag to every word of data in the \nmachine both memory and registers. In particular, SAFE tags can be pointers to arbitrary data structures \nin memory. The inter\u00adpretation of these tags is left entirely to software: the hardware just propagates \ntags from operands to results as each instruction is exe\u00adcuted, following software-de.ned rules. Second, \nthe SAFE design has been informed from the start by an intensive effort to formal\u00adize critical properties \nof its key mechanisms and produce machine\u00adchecked proofs, in parallel with the design and implementation \nof its hardware and system software. Though some prior work (sur\u00adveyed in \u00a712) shares some of these aims, \nto the best of our knowl\u00ad edge no project has attempted this combination of innovations. Abstractly, \nthe tag propagation rules in SAFE can be viewed as a partial function from argument tuples of the form \n(opcode, pc tag, argument1 tag, argument2 tag, . . . ) to result tuples of the form (new pc tag, result \ntag), meaning if the next instruction to be executed is opcode, the current tag of the program counter \n(PC) is pc tag, and the arguments expected by this opcode are tagged argument1 tag, etc., then executing \nthe instruction is allowed and, in the new state of the machine, the PC should be tagged new pc tag and \nany new data created by the instruction should be tagged result tag. (The individual argument-result \npairs in this function s graph are called rule instances, to distinguish them from the symbolic rules \nused at the software level.) In general, the graph of this function in extenso will be huge; so, concretely, \nthe hardware maintains a cache of recently-used rule instances. On each instruction dispatch (in parallel \nwith the logic implementing the usual behavior of the instruction e.g., addition), the hardware forms \nan argument tuple as described above and looks it up in the rule cache. If the lookup is successful, \nthe result tuple includes a new tag for the PC and a tag for the result of the instruction (if any); \nthese are combined with the ordinary results of instruction execution to yield the next machine state. \nOtherwise, if the lookup is unsuccessful, the hardware invokes a cache fault handler a trusted piece \nof system software with the job of checking whether the faulting combination of tags corresponds to a \npolicy violation or whether it should be allowed. In the latter case, an appropriate rule instance specifying \ntags for the instruction s results is added to the cache, and the faulting instruction is restarted. \nThus, the hardware is generic and the interpretation of policies (e.g., IFC, memory safety or control \n.ow integrity) is programmed in software, with the results cached in hardware for common-case ef.ciency. \n The .rst contribution of this paper is to explain and formalize, in Coq, the key ideas in this design \nvia a simpli.ed model of the SAFE machine, embodying its tagging mechanisms in a distilled form and focusing \non enforcing IFC using these general mechanisms. In \u00a72, we outline the features of the full SAFE system \nand enumerate the most signi.cant simpli.cations in our model. To streamline the ex\u00adposition, most of \nthe paper describes a further-simpli.ed version of the system, deferring to \u00a711 the discussion of the \nmore sophis\u00adticated memory model and IFC label representation that we have actually formalized in Coq. \nWe begin by de.ning a very simple abstract IFC machine with a built-in, purely dynamic IFC enforce\u00adment \nmechanism and an abstract lattice of IFC labels (\u00a73). We then show, in three steps, how this abstract \nmachine can be implemented using the low-level mechanisms we propose. The .rst step intro\u00adduces a symbolic \nIFC rule machine that reorganizes the semantics of the abstract machine, splitting out the IFC enforcement \nmech\u00adanism into a separate judgment parameterized by a symbolic IFC rule table (\u00a74). The second step \nde.nes a generic concrete machine (\u00a75) that provides low-level support for ef.ciently implementing many \ndifferent high-level policies (IFC and others) with a combi\u00adnation of a hardware rule cache and a software \nfault handler. The .nal step instantiates the concrete machine with a concrete fault handler enforcing \nIFC. We do this using an IFC fault handler gen\u00aderator (\u00a76), which compiles the symbolic IFC rule table \ninto a se\u00ad quence of machine instructions implementing the IFC enforcement judgment. Our second contribution \nis a machine-checked proof that this simpli.ed SAFE system is correct and secure, in the sense that user \ncode running on the concrete machine equipped with the IFC fault handler behaves the same way as on the \nabstract machine and enjoys the standard noninterference property that high inputs do not in.uence low \noutputs. The interplay of the concrete machine and fault handler is complex, so some proof abstraction \nis essen\u00adtial. In our proof architecture, a .rst abstraction layer is based on re.nement. This allows \nus to reason in terms of a high-level view of memory, ignoring the concrete implementation of IFC labels, \nwhile setting up the intricate indistinguishability relation used in the noninterference proof. A second \nlayer of abstraction is required for reasoning about the correctness of the fault handler. Here, we rely \non a veri.ed custom Hoare logic that abstracts from low-level machine instructions into a reusable set \nof veri.ed structured code generators. In \u00a77 we prove that the IFC fault handler generator correctly \ncompiles a symbolic IFC rule table and a concrete representation of an abstract label lattice into an \nappropriate sequence of machine instructions. We then introduce a standard notion of re.nement (\u00a78) and \nshow that the concrete machine running the generated IFC fault handler re.nes the abstract IFC machine \nand vice-versa, us\u00ading the symbolic IFC rule machine as an intermediate re.nement point in each direction \nof the proof (\u00a79). In our deterministic set\u00ad ting, showing re.nement in both directions guarantees that \nthe con\u00adcrete machine does not diverge or get stuck when handling a fault. We next introduce a standard \ntermination-insensitive noninterfer\u00adence (TINI) property (\u00a710) and show that it holds for the abstract \nmachine. Since deterministic TINI is preserved by re.nement, we conclude that the concrete machine running \nthe generated IFC fault handler also satis.es TINI. Finally, we explain how to accommo\u00addate two important \nfeatures that are handled by our Coq develop\u00adment but elided from the foregoing sections: dynamic memory \nal\u00adlocation and tags representing sets of principals (\u00a711). We close with a survey of related work (\u00a712) \nand a discussion of future di\u00ad rections (\u00a713). We omit proofs and some parts of longer de.nitions; a \nlong version and a Coq script formalizing the entire development are available at http://www.crash-safe.org. \n2. Overview of SAFE To establish context, we begin with a brief overview of the full SAFE system, concentrating \non its OS-and hardware-level fea\u00adtures. More detailed descriptions can be found elsewhere [14, 16, 17, \n21, 22, 29, 34]. SAFE s system software performs process scheduling, stream\u00adbased interprocess communication, \nstorage allocation and garbage collection, and management of the low-level tagging hardware (the focus \nof this paper). The goal is to organize these services as a col\u00adlection of mutually suspicious compartments \nfollowing the princi\u00adple of least privilege (a zero-kernel OS [43]), so that an attacker would need to \ncompromise multiple compartments to gain com\u00adplete control of the machine. It is programmed in a combination \nof assembly and Tempest, a new low-level programming language. The SAFE hardware integrates a number \nof mechanisms for eliminating common vulnerabilities and supporting higher-level se\u00adcurity primitives. \nTo begin with, SAFE is (dynamically) typed at the hardware level: each data word is indelibly marked \nas a num\u00adber, an instruction, a pointer, etc. Next, the hardware is memory safe: every pointer consists \nof a triple of base, bounds, and offset (compactly encoded into 64 bits [17, 29]), and every pointer \noper\u00ad ation includes a hardware bounds check [29]. Finally, the hardware associates each word in the \nregisters and memory, as well as the PC, with a large (59-bit) tag. The hardware rule cache, enabling \nsoftware-speci.ed propagation of tags from operands to result on each machine step, is implemented using \na combination of multiple hash functions to approximate a fully-associative cache [16]. An unusual feature \nof the SAFE design is that formal modeling and veri.cation of its core mechanisms have played a central \nrole in the design process since the beginning. The long-term goal formally specifying and verifying \nthe entire set of critical runtime services is still some ways in the future, but key properties of simpli.ed \nmodels have been veri.ed both at the level of Breeze [21] (a mostly functional, security-oriented, dynamic \nlanguage used for user-level programming on SAFE) and, in the present work, at the hardware and abstract \nmachine level. Experiments are also underway to use random testing of properties like noninterference \nas a means to speed the design process [22]. Our goal in this paper is to develop a clear, precise, and \nmath\u00adematically tractable model of one of the main innovations in the SAFE design: its scheme for ef.ciently \nsupporting high-level data use policies using a combination of hardware and low-level sys\u00adtem software. \nTo make the model easy to work with, we simplify away many important facets of the real SAFE system. \nIn particular, (i) we focus only on IFC and noninterference, although the tag\u00adging facilities of the \nSAFE machine are generic and can be applied to other policies (we return to this point in \u00a713); (ii) \nwe ignore the Breeze and Tempest programming languages and concentrate on the hardware and runtime services; \n(iii) we use a stack instead of registers, and we distill the instruction set to just a handful of opcodes; \n(iv) we drop SAFE s .ne-grained privilege separation in favor of a more conventional user-mode / kernel-mode \ndichotomy; (v) we shrink the rule cache to a single entry (avoiding issues of replacement and eviction) \nand maintain it in kernel memory, ac\u00adcessed by ordinary loads and stores, rather than in specialized \ncache hardware; (vi) we omit a large number of IFC-related concepts (dynamic principals, downgrading, \npublic labels, integrity, clear\u00adance, etc.); (vii) we handle exceptional conditions, including poten\u00adtial \nsecurity violations, by simply halting the whole machine; and  (viii) most importantly, we ignore concurrency, \nprocess scheduling, and interprocess communication, assuming instead that the whole machine has a single, \ndeterministic thread of control. The absence instr ::= Basic instruction set  | Add addition | Output \noutput top of stack | Push n push integer constant | Load indirect load from data memory | Store indirect \nstore to data memory | Jump unconditional indirect jump | Bnz n conditional relative jump | Call indirect \ncall | Ret return Figure 1. Instruction set of concurrency is a particularly signi.cant simpli.cation, \ngiven that we are talking about an operating system that offers IFC as a ser\u00advice. However, we conjecture \nthat it may be possible to add con\u00adcurrency to our formalization, while maintaining a high degree of \ndeterminism, by adapting the approach used in the proof of nonin\u00adterference for the seL4 microkernel \n[35, 36]. We return to this point in \u00a713. 3. Abstract IFC Machine We begin the technical development \nby de.ning a very simple stack\u00adand-pointer machine with hard-wired dynamic IFC. This ma\u00adchine concisely \nembodies the IFC mechanism we want to provide to higher-level software and serves as a speci.cation for \nthe sym\u00adbolic IFC rule machine (\u00a74) and for the concrete machine (\u00a75) run\u00ad ning our IFC fault handler \n(\u00a76). The three machines share a tiny instruction set (Fig. 1) designed to be a convenient target for \ncom\u00ad piling the symbolic IFC rule table (the Coq development formalizes several other instructions). \nAll three machines use a .xed instruc\u00adtion memory ., a partial function from addresses to instructions. \nThe machine manipulates integers (ranged over by n, m, and p); unlike the real SAFE machine, we make \nno distinction between raw integers and pointers (we re-introduce this distinction in \u00a711). Each integer \nis protected by an individual IFC label (ranged over by L). We assume an arbitrary set of labels L equipped \nwith a partial order (=), a least upper bound operation (.), and a bottom element (.). For instance we \nmight take L to be the set of levels {., T}with . = T and . . T = T. We call a pair of an integer n and \nits protecting label L an atom, written n@L and ranged over by a. An abstract machine state (\u00b5 [s] pc) \nconsists of a data memory \u00b5, a stack s, and a program counter pc . (We sometimes drop the outer brackets.) \nThe data memory \u00b5 is a partial function from integer addresses to atoms. We write \u00b5(p) . a for the memory \nthat coincides with \u00b5 everywhere except at p, where its value is a. The stack s is essentially a list \nof atoms, but we distinguish stacks beginning with return addresses (written pc; s) from ones beginning \nwith regular atoms (written a, s). The program counter (PC) pc is an atom whose label is used to track \nimplicit .ows, as explained below. The step relation of the abstract machine, written . f a \u00b51 [s1] pc1 \n-. \u00b52 [s2] pc2, is a partial function taking a machine state to a machine state plus an output action \na, which can be ei\u00adther an atom or the silent action t . We generally omit . from transi\u00adtions because \nit is .xed. Throughout the paper we study other, sim\u00adilar relations, and consistently refer to non-silent \nactions as events (ranged over by e). The stepping rules in Fig. 2 adapt a standard purely dynamic IFC \nenforcement mechanism [3, 39] to a low-level machine, fol\u00ad lowing recent work by Hrit\u00b8cu et al. [22]. \nThe rule for Add joins (.) the labels of the two operands to produce the label of the result, which ensures \nthat the result is at least as classi.ed as each of the operands. The rule for Push labels the integer \nconstant added to the stack as public (.). The rule for Jump uses join to raise the label .(n) = Add \nt \u00b5 [n1@L1, n2@L2, s] n@Lpc -. \u00b5 [(n1+n2)@(L1.L2), s] (n+1)@Lpc .(n) = Output m@(L1.Lpc) \u00b5 [m@L1, s] \nn@Lpc --------. \u00b5 [s] (n+1)@Lpc .(n) = Push m t \u00b5 [s] n@Lpc -. \u00b5 [m@., s] (n+1)@Lpc .(n) = Load \u00b5(p) \n= m@L2 t \u00b5 [p@L1, s] n@Lpc -. \u00b5 [m@(L1.L2), s] (n+1)@Lpc .(n) = Store \u00b5(p) = k@L3 L1.Lpc = L3 ' \u00b5(p) \n. (m@L1.L2.Lpc) = \u00b5 t \u00b5 [p@L1, m@L2, s] n@Lpc -. \u00b5' [s] (n+1)@Lpc .(n) = Jump t \u00b5 [n'@L1, s] n@Lpc -. \n\u00b5 [s] n'@(L1.Lpc) ' .(n) = Bnz k n = n+((m = 0)?1 : k) t' \u00b5 [m@L1, s] n@Lpc -. \u00b5 [s] n @(L1.Lpc) .(n) \n= Call t \u00b5 [n'@L1, a, s] n@Lpc -. \u00b5 [a, (n+1)@Lpc; s] n'@(L1.Lpc) .(n) = Ret t \u00b5 [n'@L1; s] n@Lpc -. \n\u00b5 [s] n'@L1 Figure 2. Semantics of IFC abstract machine of the PC by the label of the target address \nof the jump. Similarly, Bnz raises the label of the PC by the label of the tested integer. In both cases \nthe value of the PC after the instruction depends on data that could be secret, and we use the label \nof the PC to track the label of data that has in.uenced control .ow. In order to prevent implicit .ows \n(leaks exploiting the control .ow of the program), the Store rule joins the PC label with the original \nlabel of the writ\u00adten integer and with the label of the pointer through which the write happens. Additionally, \nsince the labels of memory locations are al\u00adlowed to vary during execution, we prevent leaking information \nvia labels using a no-sensitive-upgrade check [3, 48] (the = precon\u00addition in the rule for Store). This \ncheck prevents memory locations labeled public from being overwritten when either the PC or the pointer \nthrough which the store happens have been in.uenced by secrets. The Output rule labels the emitted integer \nwith the join of its original label and the current PC label.1 Finally, because of the structured control \n.ow imposed by the stack discipline, the rule for Ret can soundly restore the PC label to whatever it \nwas at the time of the Call. (Readers less familiar with the intricacies of dy\u00adnamic IFC may .nd some \nof these side conditions a bit mysterious. A longer explanation can be found in [22], but the details \nare not critical for present purposes.) All data in the machine s initial state are labelled (as in all \nma\u00adchine states), and the simple machine manages labels to ensure non\u00adinterference as de.ned and proved \nin \u00a710. There are no instructions that explicitly raise the label (classi.cation) of an atom. Such an \ninstruction, joinP, is added to the machine in \u00a711. 1 We assume the observer of the events generated \nby Output is constrained by the rules of information .ow i.e., cannot freely look inside bare events. \nIn the real SAFE machine, atoms being sent to the outside world need to be protected cryptographically; \nwe are abstracting this away.  opcode allow erpc er add TRUE LABpc LAB1 U LAB2 output TRUE LABpc LAB1 \nU LABpc push TRUE LABpc BOT load TRUE LABpc LAB1 U LAB2 store LAB1ULABpc r LAB3 LABpc LAB1 U LAB2 U LABpc \njump TRUE LAB1 U LABpc bnz TRUE LAB1 U LABpc call TRUE LAB1 U LABpc LABpc ret TRUE LAB1 Figure 3. Rule \ntable Rabs corresponding to abstract IFC machine 4. Symbolic IFC Rule Machine In the abstract machine \ndescribed above, IFC is tightly integrated into the step relation in the form of side conditions on each \nin\u00adstruction. In contrast, the concrete machine (i.e., the hardware ) described in \u00a75 is generic, designed \nto support a wide range of software-de.ned policies (IFC and other). The machine introduced in this section \nserves as a bridge between these two models. It is closer to the abstract machine indeed, its machine \nstates and the behavior of the step relation are identical. The important difference lies in the de.nition \nof the step relation, where all the IFC-related aspects are factored out into a separate judgment. While \nfactoring out IFC enforcement into a separate reference monitor is common\u00adplace [2, 39, 41], our approach \ngoes further. We de.ne a small DSL for describing symbolic IFC rules and obtain actual monitors by interpreting \nthis DSL (in this section) and by compiling it into ma\u00adchine instructions using veri.ed structured code \ngenerators (in \u00a76 and \u00a77). More formally, each stepping rule of the new machine includes a uniform call \nto an IFC enforcement relation, which itself is pa\u00adrameterized by a symbolic IFC rule table R. Given \nthe labels of the values relevant to an instruction, the IFC enforcement relation (i) checks whether \nthe execution of that instruction is allowed in the current con.guration, and (ii) if so, yields the \nlabels to put on the resulting PC and on any resulting value. This judgment has the form fR (Lpc, i1, \ni2, i3) opcode Lrpc , Lr, where R is the rule table and opcode is the kind of instruction currently executing. \nFor example, the stepping rule for Add .(n) = Add fR (Lpc, L1, L2, ) add Lrpc , Lr t \u00b5 [n1@L1, n2@L2, \ns] n@Lpc -. \u00b5 [(n1+n2)@Lr, s] (n+1)@Lrpc passes three inputs to the IFC enforcement judgment: Lpc, the \nlabel of the current PC, and L1 and L2, the labels of the two operands at the top of the stack. (The \nfourth element of the input tuple is written as because it is not needed for Add.) The IFC enforcement \njudgment produces two labels: Lrpc is used to label the next program counter (n + 1) and Lr is used to \nlabel the result value. All the other stepping rules follow a similar scheme. (The one for Store uses \nall four input labels.) A symbolic IFC rule table R describes a particular IFC enforce\u00adment mechanism. \nFor instance, the rule table Rabs corresponding to the IFC mechanism of the abstract machine is shown \nin Fig. 3. In general, a table R associates a symbolic IFC rule to each instruc\u00adtion opcode (formally, \nR is a total function). Each of these rules is formed of three symbolic expressions: (i) a boolean expression \nin\u00addicating whether the execution of the instruction is allowed or not (i.e., whether it violates the \nIFC enforcement mechanism); (ii) a label-valued expression for Lrpc , the label of the next PC; and (iii) \na label-valued expression for Lr, the label of the result value, if there is one. These symbolic expressions \nare written in a simple domain\u00adspeci.c language (DSL) of operations over an IFC lattice. The grammar \nof this DSL includes label variables LABpc , . . . , LAB3, which correspond to the input labels Lpc, \n. . . , L3; the constant BOT; and the lattice operators U (join) and . (.ows). The IFC enforcement judgment \nlooks up the corresponding symbolic IFC rule in the table and directly evaluates the symbolic expressions \nin terms of the corresponding lattice operations. The de.nition of this interpreter is completely straightforward; \nwe omit it for brevity. In contrast, in \u00a76 we compile this rule table into the IFC fault handler for \nthe concrete machine. 5. Concrete Machine The concrete machine provides low-level support for ef.ciently \nim\u00adplementing many different high-level policies (IFC and others) with a combination of a hardware rule \ncache and a software cache fault handler. In this section we focus on the concrete machine s hard\u00adware, \nwhich is completely generic, while in \u00a76 we describe a spe\u00adci.c fault handler corresponding to the IFC \nrules of the symbolic rule machine. The concrete machine has the same general structure as the more abstract \nones, but differs in several important respects. One is that it annotates data values with integer tags \nT, rather than with labels L from an abstract lattice; thus, the concrete atoms a in the data memories \nand the stack have the form n@T. Similarly, a con\u00adcrete action a is either a concrete atom or the silent \naction t. Using plain integers as tags allows us to delegate their interpretation en\u00adtirely to software. \nIn this paper we focus solely on using tags to implement IFC labels, although they could also be used \nfor enforc\u00ading other policies, such as type and memory safety or control-.ow integrity. For instance, \nto implement the two-point abstract lattice with . = T, we could use 0 to represent . and 1 to represent \nT, making the operations . and = easy to implement (see \u00a76). For richer abstract lattices, a more complex \nconcrete representa\u00adtion might be needed; for example, a label containing an arbitrary set of principals \nmight be represented concretely by a pointer to an array data structure (see \u00a711). In places where a \ntag is needed but its value is irrelevant, the concrete machine uses a speci.c but arbitrary default \ntag value (e.g., -1), which we write TD . A second important difference is that the concrete machine \nhas two modes: user mode (u), for executing the ordinary user program, and kernel mode (k), for handling \nrule cache faults. To support these two modes, the concrete machine s state contains a privilege bit \np, a separate kernel instruction memory f, and a separate kernel data memory ., in addition to the user \ninstruction memory ., the user data memory \u00b5, the stack s, and the PC. When the machine is operating \nin user mode (p = u), instructions are looked up using the PC as an index into ., and loads and stores \nuse \u00b5; when in kernel mode (p = k), the PC is treated as an index into f, and loads and stores use .. \nAs before, since . and f are .xed, we normally leave them implicit. The concrete machine has the same \ninstruction set as the previ\u00adous ones, allowing user programs to be run on all three machines unchanged. \nBut the tag-related semantics of instructions depends on the privilege mode, and in user mode the semantics \nfurther de\u00adpends on the state of the rule cache. In the real SAFE machine, the rule cache may contain \nthousands of entries and is implemented as a separate near-associative memory [16] accessed by special \nin\u00ad structions. Here, for simplicity, we use a cache with just one en\u00adtry, located at the start of kernel \nmemory, and use Load and Store instructions to manipulate it; indeed, until \u00a711, it constitutes the entirety \nof .. The rule cache holds a single rule instance, represented graph\u00adically like this: . Location 0 \nholds an integer representing an opcode. Location 1 holds the PC tag. Locations 2 to 4 hold the tags \nof any other arguments needed by this particular opcode. Location 5 holds the tag that should go on the \nPC after this instruction executes, and location 6 holds the tag for the instruction s result value, \nif needed. For example, sup\u00adpose the cache contains  1 . (Note that we are showing just the payload \npart of these seven atoms; by conven\u00adtion, the tag part is always TD , and we do not display it.) If \n0 is the tag representing the label ., 1 represents T, and -1 is the default tag TD , this can be interpreted \nabstractly as follows: If the next instruction is Add, the PC is labeled ., and the two relevant argu\u00adments \nare both labeled T, then the instruction should be allowed, the label on the new PC should be ., and \nthe label on the result of the operation is T. There are two sets of stepping rules for the concrete \nmachine in user mode; which set applies depends on whether the current machine state matches the current \ncontents of the rule cache. In the cache hit case the instruction executes normally, with the cache s \noutput determining the new PC tag and result tag (if any). In the cache miss case, the relevant parts \nof the current state (opcode, PC tag, argument tags) are stored into the input part of the single cache \nline and the machine simulates a Call to the fault handler. To see how this works in more detail, consider \nthe two user\u00admode stepping rules for the Add instruction. .(n) = Add . = t u . \u00b5 [n1@T1, n2@T2, s] n@Tpc \n-. u . \u00b5 [(n1+n2)@Tr, s] n+1@Trpc .(n) = Add .i= = .j t u [.i, .o] \u00b5 [n1@T1, n2@T2, s] n@Tpc -. k [.j \n, .D ] \u00b5 [(n@Tpc, u); n1@T1, n2@T2, s] 0@TD In the .rst rule (cache hit), the side condition demands \nthat the input part of the current cache contents have form add Tpc T1 T2 TD , where Tpc is the tag \non the current PC, T1 and T2 are the tags on the top two atoms on the stack, and the fourth element is \nthe default tag. In this case, the output part of the rule, , determines the tag Trpc on the PC and \nthe tag Tr on the new atom pushed onto the stack in the next machine state. In the second rule (cache \nmiss), the notation [.i, .o] means let .i be the input part of the current rule cache and .o be the output \npart. The side condition says that the current input part .i does not have the desired form add Tpc T1 \nT2 TD , so the machine needs to enter the fault handler. The next machine state is formed as follows: \n(i) the input part of the cache is set to the desired form .j and the output part is set to .D . ; (ii) \na new return frame is pushed on top of the stack to remember the current PC and privilege bit (u); (iii) \nthe privilege bit is set to k (which will cause the next instruction to be read from the kernel instruction \nmemory); and (iv) the PC is set to 0, the location in the kernel instruction memory where the fault handler \nroutine begins. What happens next is up to the fault handler code. Its job is to examine the contents \nof the .rst .ve kernel memory locations and either (i) write appropriate tags for the result and new \nPC into the sixth and seventh kernel memory locations and then perform a Ret to go back to user mode \nand restart the faulting instruction, or (ii) stop the machine by jumping to an invalid PC (-1) to signal \nthat the attempted combination of opcode and argument tags is illegal. This mechanism is general and \ncan be used to implement many different high-level policies (IFC and others). In kernel mode, the treatment \nof tags is almost completely degenerate: to avoid in.nite regress, the concrete machine does not consult \nthe rule cache while in kernel mode. For most instructions, tags read from the current machine state \nare ignored (indicated by ) and tags written to the new state are set to TD . This can be seen for instance \nin the kernel-mode step rule for addition f(n) = Add t k . \u00b5 [n1@ , n2@ , s] n@ -. k . \u00b5 [(n1+n2)@TD \n, s] n+1@TD The only signi.cant exception to this pattern is Ret, which takes both the privilege bit \nand the new PC (including its tag!) from the return frame at the top of the stack. This is critical, \nsince a Ret instruction is used to return from kernel to user mode when the fault handler has .nished \nexecuting. f(n) = Ret t k . \u00b5 [(n ' @T1, p); s] n@ -. p . \u00b5 [s] n ' @T1 A .nal point is that Output is \nnot permitted in kernel mode, which guarantees that kernel actions are always the silent action t . 6. \nFault Handler for IFC Now we assemble the pieces. A concrete IFC machine implement\u00ading the symbolic rule \nmachine de.ned in \u00a74 can be obtained by installing appropriate fault handler code in the kernel instruction \nmemory of the concrete machine presented in \u00a75. In essence, this handler must emulate how the symbolic \nrule machine looks up and evaluates the DSL expressions in a given IFC rule table. We choose to generate \nthe handler code by compiling the lookup and DSL evaluation relations directly into machine code. (An \nalterna\u00adtive would be to represent the rule table as abstract syntax in the kernel memory and write an \ninterpreter in machine code for the DSL, but the compilation approach seems to lead to simpler code and \nproofs.) The handler compilation scheme is given (in part) in Fig. 4. Each gen* function generates a \nlist of concrete machine instruc\u00adtions; the sequence generated by the top-level genFaultHandler is intended \nto be installed starting at location 0 in the concrete ma\u00adchine s kernel instruction memory. The implicit \naddr* parameters are symbolic names for the locations of the opcode and various tags in the concrete \nmachine s rule cache, as described in \u00a75. The entire generator is parameterized by an arbitrary rule \ntable R. We make heavy use of the (obvious) encoding of booleans where false is represented by 0 and \ntrue by any non-zero value. We omit the straightforward de.nitions of some of the leaf generators. The \ntop-level handler works in three phases. The .rst phase, genComputeResults, does most of the work: it \nconsists of a large nested if-then-else chain, built using genIndexedCases, that com\u00adpares the opcode \nof the faulting instruction against each possible opcode and, on a match, executes the code generated \nfor the corre\u00adsponding symbolic IFC rule. The code generated for each symbolic IFC rule (by genApplyRule) \npushes its results onto the stack: a .ag indicating whether the instruction is allowed and, if so, the \nresult-PC and result-value tags. This .rst phase never writes to memory or transfers control outside \nthe handler; this makes it fairly easy to prove correct. The second phase, genStoreResults, reads the \ncomputed results off the stack and updates the rule cache appropriately. If the result indicates that \nthe instruction is allowed, the result PC and value tags are written to the cache, and true is pushed \non the stack; otherwise, nothing is written to the cache, and false is pushed on the stack. The third \nand .nal phase of the top-level handler tests the boolean just pushed onto the stack and either returns \nto user code (instruction is allowed) or jumps to address -1 (disallowed). The code for symbolic rule \ncompilation is built by straightfor\u00adward recursive traversal of the rule DSL syntax for label-valued \nexpressions (genELab) and boolean-valued expressions (genBool). These functions are (implicitly) parameterized \nby lattice-speci.c generators genBot, genJoin, and genFlows. To implement these  genFaultHandler R = \ngenComputeResults R ++ genStoreResults ++ genIf [Ret] [Push (-1); Jump] genComputeResults R = genIndexedCases \n[] genMatchOp (genApplyRule . RuleR) opcodes genMatchOp op = [Push op] ++ genLoadFrom addrOpLabel ++ \ngenEqual genApplyRule (allow , erpc , er) = genBool allow ++ genIf (genSome (genELab erpc ++ genELab \ner)) genNone genELab BOT = genBot LABi = genLoadFrom addrTagi LE1 U LE2 = genELab LE2 ++ genELab LE1 \n++ genJoin genBool TRUE = genTrue LE1 r LE2 = genELab LE2 ++ genELab LE1 ++ genFlows genStoreResults \n= genIf (genStoreAt addrTag++ genStoreAt addrTag++ genTrue) r rpc genFalse genIndexedCases genDefault \ngenGuard genBody = g where g nil = genDefault g (n :: ns) = genGuard n ++ genIf (genBody n) (g ns) ' \n genIf t f = genSkipIf (length f ' ) ++ f ++ t ' where f = f ++ genSkip(length t) genSkip n = genTrue \n++ genSkipIf n genSkipIf n = [Bnz (n+1)] opcodes = add :: output :: . . . :: ret :: nil Figure 4. Generation \nof fault handler from IFC rule table. generators for a particular lattice, we .rst need to choose how \nto represent abstract labels as integer tags, and then determine a se\u00adquence of instructions that encodes \neach operation. We call such an encoding scheme a concrete lattice. For example, the abstract labels \nin the two-point lattice can be encoded like booleans, rep\u00adresenting . by 0, T by non-0, and instantiating \ngenBot, genJoin, and genFlows with code for computing false, disjunction, and im\u00adplication, respectively. \nA simple concrete lattice like this can be for\u00admalized as a tuple CL = (Tag, Lab, genBot, genJoin, genFlows), \nwhere the encoding and decoding functions Lab and Tag satisfy Lab . Tag = id; to streamline the exposition, \nwe assume this form of concrete lattice for most of the paper. The more realistic encod\u00ading in \u00a711 will \nrequire a more complex treatment. To raise the level of abstraction of the handler code, we make heavy \nuse of structured code generators; this makes it easier both to understand the code and to prove it correct \nusing a custom Hoare logic that follows the structure of the generators (see \u00a77). For example, the genIf \nfunction takes two code sequences, representing the then and else branches of a conditional, and generates \ncode to test the top of the stack and dispatch control appropriately. The higher-order generator genIndexedCases \ntakes a list of integer indices (e.g., opcodes) and functions for generating guards and branch bodies \nfrom an index, and generates code that will run the guards in order until one of them computes true, \nat which point the corresponding branch body is run. 7. Correctness of the Fault Handler Generator We \nnow turn our attention to veri.cation, beginning with the fault handler. We must show that the generated \nfault handler emulates the IFC enforcement judgment fR (Lpc, i1, i2, i3) opcode Lrpc , Lr of the symbolic \nrule machine. The statement and proof of correct\u00adness are parametric over the symbolic IFC rule table \nR and con\u00adcrete lattice, and hence over correctness lemmas for the lattice op\u00aderations. Correctness statement \nLet R be an arbitrary rule table and fR genFaultHandler R be the corresponding generated fault handler. \nWe specify how fR behaves as a whole as a relation between initial state on entry and .nal state on completion \nusing the rela\u00adtion f f cs1 .tk cs2, de.ned as the re.exive transitive closure of the concrete step relation, \nwith the constraints that the fault handler code is f and all intermediate states (i.e., strictly preceding \ncs2) have privilege bit k. The correctness statement is captured by the following two lemmas. Intuitively, \nif the symbolic IFC enforcement judgment allows some given user instruction, then executing fR (stored \nat kernel mode location 0) updates the cache to contain the tag encoding of the appropriate result labels \nand returns to user-mode; otherwise, fR halts the machine (pc = -1). Lemma 7.1 (Fault handler correctness, \nallowed case). Suppose that fR (Lpc, i1, i2, i3) opcode Lrpc , Lr and .i = . opcode Tag(Lpc ) Tag(i1) \nTag(i2) Tag(i3) Then fR f (k [.i, .o] \u00b5 [(pc , u); s] 0@TD ) .t k (u [.i, . ' o] \u00b5 [s] pc)with output \ncache . ' o = (Tag (Lrpc ), Tag (Lr)) . Lemma 7.2 (Fault handler correctness, disallowed case). Suppose \nthat fR (Lpc, i1, i2, i3) opcode, and .i = . opcode Tag(Lpc) Tag(i1) Tag(i2) Tag(i3) Then, for some \n.nal stack s ' , fR f (k [.i, .o] \u00b5 [(pc, u); s] 0@TD ) .t k (k [.i, .o] \u00b5 [s ' ] -1@TD ). Proof methodology \nThe fault handler is compiled by composing generators (Fig. 4); accordingly, the proofs of these two \nlemmas reduce to correctness proofs for the generators. We employ a cus\u00adtom Hoare logic for specifying \nthe generators themselves, which makes the code generation proof simple, reusable, and scalable. This \nis where de.ning a DSL for IFC rules and a structured com\u00adpiler proves to be very useful approach, e.g., \ncompared to symbolic interpretation of hand-written code. Our logic comprises two notions of Hoare triple. \nThe generated code mostly consists of self-contained instruction sequences that terminate by falling \noff the end i.e., that never return or jump outside themselves, although they may contain internal jumps \n(e.g., to implement conditionals). The only exception is the .nal step of the handler (third line of \ngenFaultHandler in Fig. 4). We therefore de.ne a standard Hoare triple {P} c {Q}, suitable for reasoning \nabout self-contained code, and use it for the bulk of the proof. To specify the .nal handler step, we \nde.ne a non-standard triple {P} c {Q}O for reasoning about escaping code. pc Self-contained-code Hoare \ntriples The triple {P} c {Q}, where P and Q are predicates on . \u00d7 s, says that, if the kernel instruction \nmemory f contains the code sequence c starting at the current PC, and if the current memory and stack \nsatisfy P, then the machine will run (in kernel mode) until the PC points to the instruction im\u00admediately \nfollowing the sequence c, with a resulting memory and stack satisfying Q. Note that the instruction memory \nf is uncon\u00adstrained outside of c, so if c is not self-contained, no triple about it will be provable; \nthus, these triples obey the usual composition laws. Also, because the concrete machine is deterministic, \nthese triples express total, rather than partial, correctness, which is essen\u00adtial for proving termination \nin lemmas 7.1 and 7.2. To aid automa\u00ad tion of proofs about code sequences, we give triples in weakest\u00adprecondition \nstyle.  We build proofs by composing atomic speci.cations of individ\u00adual instructions, such as P(., \ns) := . n1 T1 n2 T2 s ' . s = n1@T1, n2@T2, s ' . Q(., ((n1+n2)@TD , s ' )) , {P} [Add] {Q} with speci.cations \nfor structured code generators, such as P(., s) := . n T s ' . s = n@T, s ' . (n = 0 =. P1(., s ' )) \n.(n = 0 =. P2(., s ' )) {P1} c1 {Q} {P2} c2 {Q} . {P} genIf c1 c2 {Q} (We emphasize that all such speci.cations \nare veri.ed, not axiom\u00adatized as the inference rule notation might suggest.) The concrete implementations \nof the lattice operations are also speci.ed using triples in this style. P(., s) := Q(., (Tag (.)@TD \n, s)) {P} genBot {Q} P(., s) := . L L ' s ' . s = Tag (L)@TD , Tag (L ' )@TD , s ' . Q(., Tag (L.L ' \n)@TD , s ' ) {P} genJoin {Q} P(., s) := . L L ' s. s = Tag (L)@TD , Tag (L ' )@TD , s ' . Q(., (if L \n= L ' then 1 else 0)@TD , s ' ) {P} genFlows {Q} For the two-point lattice, it is easy to prove that \nthe implemented operators satisfy these speci.cations; \u00a711 describes an analogous result for a lattice \nof sets of principals. Escaping-code Hoare triples To be able to specify the entire code of the generated \nfault handler, we also de.ne a second form of triple, {P} c {Q}O , which speci.es mostly self-contained, \ntotal pc code c that either makes exactly one jump outside of c or returns out of kernel mode. More precisely, \nif P and Q are predicates on . \u00d7 s and O is a function from . \u00d7 s to outcomes (the constants Success \nand Failure), then {P} c {Q}O holds if, whenever the pc kernel instruction memory f contains the sequence \nc starting at the current PC, the current cache and stack satisfy P, and if O computes Success then \nthe machine runs (in kernel mode) until it returns to user code at pc, and Q is satis.ed.  if O computes \nFailure then the machine runs (in kernel mode) until it halts (pc = -1 in kernel mode), and Q is satis.ed. \n To compose self-contained code with escaping code, we prove two composition laws for these triples, \none for pre-composing with speci.ed self-contained code and another for post-composing with arbitrary \n(unreachable) code: {P} c1 {Q}O {P1} c1 {P2} {P2} c2 {P3}O pc pc {P1} c1++c2 {P3}O {P} c1++c2 {Q}O pc \npc We use these new triples to specify the Ret and Jump instruc\u00adtions, which could not be given useful \nspeci.cations using the self\u00adcontained-code triples, e.g. P(., s) := . s ' . Q(., s ' ) . s = (pc, u); \ns ' O(., s) := Success {P} [Ret] {Q}O pc Everything comes together in verifying the fault handler. We \nuse contained-code triples to specify everything except for [Ret], [Jump], and the .nal genIf, and then \nuse the escaping-code triple composition laws to connect the non-returning part of the fault handler \nto the .nal genIf. 8. Re.nement We have two remaining veri.cation goals. First, we want to show that \nthe concrete machine of \u00a75 (running the fault handler of \u00a76 compiled from Rabs) enjoys TINI. Proving \nthis directly for the con\u00adcrete machine would be dauntingly complex, so instead we show that the concrete \nmachine is an implementation of the abstract ma\u00adchine, for which noninterference will be much easier \nto prove (\u00a710). Second, since a trivial always-diverging machine also has TINI, we want to show that \nthe concrete machine is a faithful implementation of the abstract machine that emulates all its behaviors. \nWe phrase these two results using the notion of machine re.ne\u00adment, which we develop in this section, \nand which we prove in \u00a710 to be TINI preserving. In \u00a79, we prove a two-way re.nement (one direction for \neach goal), between the abstract and concrete machines, via the symbolic rule machine in both directions. \nFrom here on we sometimes mention different machines (ab\u00adstract, symbolic rule, or concrete) in the same \nstatement (e.g., when discussing re.nement), and sometimes talk about machines gener\u00adically (e.g., when \nde.ning TINI for all our machines); for these purposes, it is useful to de.ne a generic notion of machine. \nDe.nition 8.1. A generic machine (or just machine) is a 5-tuple -. M = (S, E, I, \u00b7 . \u00b7, Init), where \nS is a set of states (ranged over by s), E is a set of events (ranged over by e), \u00b7 . \u00b7 -.. S \u00d7 (E + \n{t }) \u00d7 S is a step relation, and I is a set of input data (ranged over by i) that can be used to build \ninitial states of the machine with the function Init . I . S. We call E + {t } the set of actions of \nM (ranged over by a). Conceptually, a machine s program is included in its input data and gets loaded \nby the function Init, which also initializes the machine memory, stack, and PC. The notion of generic \nmachine abstracts all these details, allowing uniform de.nitions of re.ne\u00adment and TINI that apply to \nall three of our IFC machines. To avoid stating it several times below, we stipulate that when we instanti\u00adate \nDe.nition 8.1 to any of our IFC machines, Init must produce an initial stack with no return frames. A \ngeneric step s1 -eor s1 -tproduces event e or is . s2 . s2 silent. The re.exive-transitive closure of \nsuch steps, omitting silent steps (written s1 -ts2) produces traces i.e., lists, t, of events. .t When \nthe end state of a step starting in state s is not relevant we write s -e-t ., and similarly s .t for \ntraces. When relating executions of two different machines through a re.nement, we establish a correspondence \nbetween their traces. This relation is usually derived from an elementary relation on events, C . E1 \n\u00d7 E2, which is lifted to actions and traces: a1 [C] a2 (a1 = t = a2 . a1 = e1 C e2 = a2) x [C] xy length(xx) \n= length(yx) . . i. xi C yi. De.nition 8.2 (Re.nement). Let M1 = (S1, E1, I1, \u00b7 -.\u00b7, Init1) .1 . and \nM2 = (S2, E2, I2, \u00b7 -.2 \u00b7, Init2) be two machines. A re.ne\u00adment of M1 into M2 is a pair of relations \n(Ci, Ce), where Ci . I1 \u00d7 I2 and Ce . E1 \u00d7 E2, such that whenever i1 Ci i2 and t2t1 Init2(i2) -.t , there \nexists a trace t1 such that Init1(i1) -.t and t1 [Ce] t2. We also say that M2 re.nes M1. Graphically: \nt1 i1 Init1(i1) Ci [Ce] i2 Init2(i2) t2 (Plain lines denote premises, dashed ones conclusions.) In order \nto prove re.nement, we need a variant that considers executions starting at arbitrary related states. \n De.nition 8.3 (Re.nement via states). Let M1, M2 be as above. A state re.nement of M1 into M2 is a \npair of relations (Cs, Ce), where Cs . S1 \u00d7 S2 and Ce . E1 \u00d7 E2, such that, whenever s1 Cs s2 t2t1 and \ns2 -.t , there exists t1 such that s1 -.t and t1 [Ce] t2. If the relation on inputs is compatible with \nthe one on states, we can use state re.nement to prove re.nement. Lemma 8.4. Suppose i1 Ci i2 . Init1(i1) \nCs Init2(i2), for all i1 and i2. If (Cs, Ce) is a state re.nement then (Ci, Ce) is a re.nement. concrete \ntags. The relation Cs on stacks is similar, but additionally requires that return frames in the concrete \nstack have their privi\u00adlege bit set to u. The basic idea is to match, in Cc , only concrete s states \nthat are in user mode. We also need to track an extra invari\u00adant, R f ., which means that the cache . \nis consistent with the table R i.e., . never lies. More precisely, the output part of . represents the \nresult of applying the symbolic rule judgment of R to the opcode and labels represented in the input \npart of .. R f [.i, .o] .opcode L1 L2 L3 Lpc, opcode Tag(Lpc ) Tag(L1) Tag(L2) Tag(L3) .i = 9. Re.nements \nBetween Concrete and Abstract .Lrpc . Lr, fR (Lpc, L1, L2, L3) opcode Lrpc, Lr In this section, we show \nthat (1) the concrete machine re.nes the . .o = (Tag (Lrpc), Tag (Lr)) symbolic rule machine, and (2) \nvice versa. Using (1) we will be able to show in \u00a710 that the concrete machine is noninterfering. From \n(2) we know that the concrete machine faithfully implements To prove re.nement via states, we must account \nfor two situa\u00ad tions. First, suppose the concrete machine can take a user step. In this case, we match \nthat step with a single symbolic rule machinethe abstract one, exactly re.ecting its execution traces. \n step. We write cs p to denote a concrete state cs whose privilege bit Abstract and symbolic rule machines \nThe symbolic rule machine is p. u u (with the rule table Rabs) is a simple reformulation of the abstract \nLemma 9.5 (Re.nement, non-faulting concrete step). Let cs1 be a 2. Let qs1 be a symbolic 1. Then there \nexist qs2 2, and aa machine. Their step relations are (extensionally) equal, and started ac - . cs concrete \nstate and suppose that cs u from the same input data they emit the same traces. 1 u such that , with \nc- . Cqsqsqs1 2 2 s aa rule machine state with qs1 Cc s and aa cs De.nition 9.1 (Abstract and symbolic \nrule machines as generic u cs [Cc e ] ac. machines). For both abstract and symbolic rule machines, input \nSince the concrete machine is able to make a user step, the input part of the cache must match the opcode \nand data of the current state. But the invariant R f . says that the corresponding symbolic rule judgment \nholds. Hence the symbolic rule machine can also make a step from qs2, as required. The second case is \nwhen the concrete machine faults into kernel mode and returns to user mode after some number of steps. \nLemma 9.6 (Re.nement, faulting concrete step). Let cs u 0 be a con\u00adcrete state, and suppose that the \nconcrete machine does a faulting data is a 4-tuple (p, args, n, L) where p is a program, args is a list \nof atoms (the initial stack), and n is the size of the memory, initialized with n copies of 0@L. The \ninitial PC is 0@L. Lemma 9.2. The symbolic rule machine instantiated with the rule table Rabs re.nes \nthe abstract machine through (=, =). Concrete machine re.nes symbolic rule machine We prove this re.nement \nusing a .xed but arbitrary rule table, R, an abstract lattice of labels, and a concrete lattice of tags. \nThe proof uses the correctness of the fault handler (\u00a77), so we assume that the fault handler of the \nconcrete machine corresponds to the rule table of the symbolic rule machine (f = fR) and that the encoding \nof abstract u k 1, stays in kernel mode until cs mode by stepping to csn+1. Let qs0 be a state of the \nsymbolic rule k , and then exits kernelstep to cs n labels as integer tags is correct. De.nition 9.3 \n(Concrete machine as generic machine). The input data of the concrete machine is a 4-tuple (p, args, \nn, T) where p is a program, args is a list of concrete atoms (the initial stack), and the initial memory \nis n copies of 0@T. The initial PC is 0@T. The machine starts in user mode, the cache is initialized \nwith an illegal opcode so that the .rst instruction always faults, and the fault handler code parameterizing \nthe machine is installed in the initial privileged instruction memory f. The input data and events of \nthe symbolic rule and concrete machines are of different kinds; they are matched using relations cs \nmachine that matches cs u To prove this lemma, we must consider two cases. If the corre\u00adsponding symbolic \nrule judgment holds, then we apply Lemma 7.1 to conclude directly i.e., the machine exits kernel code \ninto user mode. Otherwise, we apply Lemma 7.2 and derive a contradiction that the fault handler ends \nin a failing state in kernel mode. Lemmas 9.5 and 9.6 can be summarized graphically by: qs0 aa Cc s \ntc qs1 qs2 Cc [Cc ts c ] s s e u 0. Then qs0 Cc s csn+1. u u kk cs uu t 1 2 ac cs cs 0 cs cs 1 n+1 \nk n t t (Cc i and Cc e respectively) stipulating that payload values should be equal and that labels \nshould correspond to tags modulo the function Given two matching states of the concrete and symbolic \nrule ma-Tag of the concrete lattice. ' chines, and a concrete execution starting at that concrete state, \nthese args = map (.(n@L). n@Tag(L)) args (p, args, n, L) Ci c (p, args ' , n, Tag(L)) n@L Ce c n@Tag(L) \nTheorem 9.4. The concrete IFC machine re.nes the symbolic rule machine, through (Cc i , Cc e). We prove \nthis theorem by a re.nement via states (Lemma 9.7); this, in turn, relies on two technical lemmas (9.5 \nand 9.6). The matching relation Cc s between the states of the concrete and symbolic rule machines is \nde.ned as R f . sq Cs sc \u00b5q Cm \u00b5c \u00b5q, [sq], n@L Cc s u, ., \u00b5c, [sc], n@Tag(L) where the new notations \nare de.ned as follows. The relation Cm de\u00admands that the memories be equal up to the conversion of labels \nto two lemmas can be applied repeatedly to build a matching execu\u00adtion of the symbolic rule machine. \nThere is just one last case to consider, namely when the execution ends with a fault into ker\u00adnel mode \nand never returns to user mode. However, no output is produced in this case, guaranteeing that the full \ntrace is matched. We thus derive the following re.nement via states, of which Theo\u00ad rem 9.4 is a corollary. \nLemma 9.7. The pair (Cs c , Ce c) de.nes a re.nement via states between the symbolic rule machine and \nthe concrete machine. Concrete machine re.nes abstract machine By composing the re.nement of Lemma 9.2 \nand the re.nement of Theorem 9.4 in\u00adstantiated to the concrete machine running fRabs , we can conclude \nthat the concrete machine re.nes the abstract one.  Abstract machine re.nes concrete machine The previous \nre.ne\u00adment, (Cc s, Cc e), would also hold if the fault handler never returned when called. So, to ensure \nthe concrete machine re.ects the behav\u00adiors of the abstract machine, we next prove an inverse re.nement: \nTheorem 9.8. The abstract IFC machine re.nes the concrete IFC machine via (Ci -c , Ce -c), where Ci -c \nand Ce -c are the relational inverses of Cc i and Cc e. This guarantees that traces of the abstract machine \nare also emitted by the concrete machine. As above we use the symbolic rule machine as an intermediate \nstep and show a state re.nement of the concrete into the symbolic rule machine. We rely on the following \nlemma, where C-s c is the inverse of Cc s. Lemma 9.9 (Forward re.nement). Let qs0 and cs0 be two states \nwith cs0 C-s c qs0. Suppose that the symbolic rule machine takes a length as the shorter and then demands \nthat the remaining elements be pairwise identical. De.nition 10.2 (TINI). A machine (S, E, I, -. \u00b7 . \n\u00b7, Init) with a notion of observation (O, L\u00b7J\u00b7, \u00b7 \u00b7 \u00b7) satis.es TINI if, for any observer o . O, pair \nof indistinguishable initial data i1 o i2, t1t2 and pair of executions Init(i1) -.t and Init(i2) -.t \n, we have Lt1Jo Lt2Jo. Since a machine s program is part of its input data, this de.ni\u00adtion of TINI, \nquanti.ed over all observers and input data, is concep\u00adtually quanti.ed over all programs too. Because \nof the truncation of traces, the observer cannot detect the absence of output, i.e., it cannot distinguish \nbetween successful termination, failure with an error, or entering an in.nite loop with no observable \noutput. This TINI property is standard for a machine with output [1, 19].2 a- . qs1. Then there exist \nconcrete state cs1 and action TINI for abstract machine such that cs0 a step qs0 a.t cs1, with cs1 C-s \nc qs1 and ac [C-e c lattice, with partial order =. De.ne indistinguishability of atoms, To prove this \nlemma, we consider two cases. If the cache input a1 a a2 by of cs0 matches the opcode and data of cs0, \nthen the concrete o c- ac ] aa. De.nition 10.3 (Observation for abstract machine). Let L be a a cs1. \nMoreover, R f . in cs0 \u00acLa1Jo \u00acLa2Jo- . says the cache output is consistent with the symbolic rule judgment, \na a o a a1 a o a2 c machine can take a step cs0 . (1) so the tags in ac and cs1 are properly related \nto the labels in The notion of observation is (L, L\u00b7Ja \u00b7 , \u00b7 a \u00b7 \u00b7), where aa and qs1. Otherwise, a \ncache fault occurs, loading the cache input and calling the fault handler. By Lemma 7.1 and the fact \nthat Ln@LJa L = o o qs0 a- . qs1, the cache output is computed to be consistent with R, and this allows \nthe concrete step as claimed. Discussion The two top-level re.nement properties (9.4 and 9.8) share the \nsame notion of matching relations but they have been proved independently in our Coq development. In \nthe context of compiler veri.cation [30, 42], another proof methodology has been favored: a backward \nsimulation proof can be obtained from a proof of forward simulation under the assumption that the lower-level \nmachine is deterministic. (CompCertTSO [42] also requires a re\u00adceptiveness hypothesis that trivially \nholds in our context.) Since our concrete machine is deterministic, we could apply a similar tech\u00adnique. \nHowever, unlike in compiler veri.cation where it is common to assume that the source program has a well-de.ned \nsemantics (i.e. it does not get stuck), we would have to consider the possibility that the high-level \nsemantics (the symbolic rule machine) might block and prove that in this case either the IFC enforcement \njudgment is stuck (and Lemma 9.6 applies) or the current symbolic rule ma\u00adchine state and matching concrete \nstate are both ill-formed. 10. Noninterference a In this section we de.ne TINI [1, 19] for generic machines, \nshow that the abstract machine of \u00a73 satis.es TINI (Theorem 10.4), that TINI is preserved by re.nement \n(Theorem 10.5), and .nally, using the fact that the concrete IFC machine re.nes the abstract one (The\u00ad \norem 9.4), that the concrete machine satis.es TINI (Theorem 10.7). Termination-insensitive noninterference \n(TINI) To de.ne non\u00adinterference, we need to talk about what can be observed about the output trace produced \nby a run of a machine. De.nition 10.1 (Observation). A notion of observation for a generic machine is \na 3-tuple (O, L\u00b7J\u00b7, \u00b7 \u00b7 \u00b7). O is a set of observers (i.e., different degrees of power to observe), ranged \nover by o. For each o . O, L\u00b7Jo . E is a predicate of observability of events for ob\u00adserver o, and \u00b7 \no \u00b7 . I \u00d7 I is a relation of indistinguishability of input data for observer o. We write LtJo for the \ntrace in which all unobservable events in t are .ltered out using L\u00b7Jo. We write t1 t2 to say that traces \nt1 and t2 are indistinguishable; this truncates the longer trace to the same (p, args1 , n, L) a o (p, \nargs2 , n, L) args1 [ o a] args2 . (On the right-hand side of the second equation, [ a o ] is indistin\u00adguishability \nof atoms, lifted to lists.) We prove TINI for the abstract machine using a set of stan\u00addard unwinding \nconditions [18, 22]. For this we need to de.ne indistinguishability on states, and thus also indistinguishability \nof stacks; this is where we encounter one subtlety. Indistinguishability of stacks is de.ned pointwise \nwhen the label of the PC is observ\u00adable (Lpc = o). When the PC label is not observable, however, we only \nrequire that the stacks are pointwise related below the most recent Call from an observable state. This \nis necessary because the two machines run in lock step only when their PC labels are observ\u00adable; they \ncan execute completely different instructions otherwise. Theorem 10.4. The abstract IFC machine enjoys \nTINI. TINI preserved by re.nement Theorem 10.5 (TINI preservation). Suppose that generic machine M2 re.nes \nM1 by re.nement (Ci, Ce) and that each machine is equipped with a notion of observation. Suppose that, \nfor all ob\u00adservers o2 of M2, there exists an observer o1 of M1 such that the following compatibility \nconditions hold for all e1, e1 ' . E1, all e2, e ' 2 . E2, and all i2, i2 ' . I2. (i) e1Cee2 . (Le1Jo1 \n. Le2Jo2 ); (ii) i2 o2 i ' 2 . . i1 o1 i ' 1. (i1 Ci i2 . i ' 1 Ci i2 ' ); (iii) (e1 o1 ' ''' e1 . e1 \nCe e2 . e1 Ce e2) . e2 o2 e2. Then, if M1 has TINI, M2 also has TINI. Some formulations of noninterference \nare subject to the re.ne\u00adment paradox [23], in which re.nements of a noninterferent system may violate \nnoninterference. We avoid this issue by employing a strong notion of noninterference that restricts the \namount of non\u00addeterminism in the system and is thus preserved by any re.nement (Theorem 10.5).3 Since \nour abstract machine is deterministic, it is easy to show this strong notion of noninterference for it. \nIn \u00a713 we discuss a possible technique for generalizing to the concurrent setting while preserving a \nhigh degree of determinism. 2 It is called progress-insensitive noninterference in a recent survey [19]. \n3 The recent noninterference proof for the seL4 microkernel [35, 36] works similarly (see \u00a712).  instr \n::= extensions to instruction set | . . . | Alloc allocate a new frame | SizeOf fetch frame size | Eq \nvalue equality | SysCall id system call | GetO. extract pointer offset | Pack atom from payload and tag \n| Unpack atom into payload and tag | PushCachePtr push cache address on stack | Dup n duplicate atom \non stack | Swap n swap two data atoms on stack Figure 5. Additional instructions for extensions .(n) \n= Alloc alloc k (L.Lpc) a \u00b5 = (id, \u00b5 ' ) t \u00b5 [(Int k)@L, a, s] n@Lpc -. \u00b5 ' [(Ptr (id, 0))@L, s] (n+1)@Lpc \n.(n) = SizeOf length (\u00b5(id)) = k t \u00b5 [(Ptr (id, o))@L, s] n@Lpc -. \u00b5 [(Int k)@L, s] (n+1)@Lpc .(n) = \nGetO. t \u00b5 [(Ptr (id, o))@L, s] n@Lpc -. \u00b5 [(Int o)@L, s] (n+1)@Lpc .(n) = Eq t \u00b5 [v1@L1, v2@L2, s] n@Lpc \n-. \u00b5 [(Int (v1 == v2))@(L1.L2), s] (n+1)@Lpc .(n) = SysCall id T (id) = (k, f ) f(s1) = v@L length (s1) \n= k t \u00b5 [s1++s2] n@Lpc -. \u00b5 [v@L, s2] (n+1)@Lpc Figure 6. Semantics of selected new abstract machine \ninstructions TINI for concrete machine with IFC fault handler It remains to de.ne a notion of observation \non the concrete machine, instanti\u00adating the de.nition of TINI for this machine. This de.nition refers \nto a concrete lattice CL, which must be a correct encoding of an ab\u00adstract lattice L: the lattice operators \ngenBot, genJoin, and genFlows must satisfy the speci.cations in \u00a77. De.nition 10.6 (Observation for the \nconcrete machine). Let L be an abstract lattice, and CL be correct with respect to L. The observation \nfor the concrete machine is (L, L\u00b7Jc \u00b7 , \u00b7 c \u00b7 \u00b7), where Ln@TJc o Lab(T) = o, (p, args 1 ' , n, T) o \nc (p, args 2 ' , n, T) args1 [ o a] args2 , and args i ' = map (fun n@L . n@Tag(L)) argsi . Finally, \nwe prove that the backward re.nement proved in \u00a79 sat\u00adis.es the compatibility constraints of Theorem \n10.5, so we derive: Theorem 10.7. The concrete IFC machine running the fault han\u00addler fRabs satis.es \nTINI. 11. An Extended System Thus far we have described our model and proof results only for a simple \nmachine architecture and IFC discipline. Our Coq develop\u00adment actually works with a signi.cantly more \nsophisticated model, extending the basic machine architecture with a frame-based mem\u00adory model supporting \ndynamic allocation and a system call mecha\u00adnism for adding special-purpose primitives. Building on these \nfea\u00adtures, we de.ne an abstract IFC machine that uses sets of principals as its labels and a corresponding \nconcrete machine implementation .(n) = Alloc alloc k u a \u00b5 = (id, \u00b5 ' ) \u00b5(cache) = t u \u00b5 [(Int k)@T1, \na, s] n@Tpc -. u \u00b5 ' [(Ptr (id, 0))@Tr, s] (n+1)@Trpc f(n) = Alloc alloc k k a \u00b5 = (id, \u00b5 ' ) t k \u00b5 [(Int \nk)@ , a, s] n@ -. k \u00b5 ' [(Ptr (id, 0))@TD , s] (n+1)@TD f(n) = PushCachePtr t k \u00b5 [s] n@ -. k \u00b5 [(Ptr \n(cache, 0))@TD , s] (n+1)@TD f(n) = Unpack t k \u00b5 [v1@v2, s] n@ -. k \u00b5 [v2@TD , v1@TD , s] (n+1)@TD f(n) \n= Pack t k \u00b5 [v2@ , v1@ , s] n@ -. k \u00b5 [v1@v2, s] (n+1)@TD .(n) = SysCall id T (id) = (k, n ' ) length \n(s1) = k t ' u \u00b5 [s1++s2] n@T -. k \u00b5 [s1++(n+1@T, u); s2] n @TD Figure 7. Semantics of selected new \nconcrete machine instructions where tags are pointers to dynamically allocated representations of these \nsets. While still much less complex than the real SAFE sys\u00adtem, this extended model shows how our basic \napproach can be incrementally scaled up to more realistic designs. Verifying these extensions requires \nno major changes to the proof architecture of the basic system, serving as evidence of its robustness. \nFig. 5 shows the new instructions supported by the extended model. Instruction PushCachePtr, Unpack, \nand Pack are used only by the concrete machine, for the compiled fault handler (hence they only have \na kernel-mode stepping rule; they simply get stuck if executed outside kernel mode, or on an abstract \nmachine). We also add two stack-manipulation instructions, Dup and Swap, to make programming the kernel \nroutines more convenient. It remains true that any program for the abstract machine makes sense to run \non the abstract rule machine and the concrete machine. For brevity, we detail stepping rules only for \nthe extended abstract IFC machine (Fig. 6) and concrete machine (Fig. 7); corresponding extensions to \nthe symbolic IFC rule machine are straightforward (we also omit rules for Dup and Swap). Individual rules \nare explained below. Dynamic memory allocation High-level programming languages usually assume a structured \nmemory model, in which independently allocated frames are disjoint by construction and programs cannot \ndepend on the relative placement of frames in memory. The SAFE hardware enforces this abstraction by \nattaching explicit runtime types to all values, distinguishing pointers from other data. Only data marked \nas pointers can be used to access memory. To obtain a pointer, one must either call the (privileged) \nmemory manager to allocate a fresh frame or else offset an existing pointer. In partic\u00adular, it is not \npossible to forge a pointer from an integer. Each pointer also carries information about its base and \nbounds, and the hardware prevents it from being used to access memory outside of its frame. Frame-based \nmemory model In our extended system, we model the user-level view of SAFE s memory system by adding a \nframe\u00adstructured memory, distinguished pointers (so values, the payload .eld of atoms and the tag .eld \nof concrete atoms, can now either be an integer (Int n) or a pointer (Ptr p)), and an allocation instruction \nto our basic machines. We do this (nearly) uniformly at all levels of abstraction.4 A pointer is a pair \np = (id, o) of a frame identi.er id and an offset o into that frame. In the machine state, the data mem\u00adory \n\u00b5 is a partial function from pointers to individual storage cells that is unde.ned on out-of-frame pointers. \nBy abuse of notation, \u00b5 is also a partial function from frame identi.ers to frames, which are just lists \nof atoms.  The most important new rule of the extended abstract machine is Alloc (Fig. 6). In this machine \nthere is a separate memory region (assumed in.nite) corresponding to each label. The auxiliary func\u00adtion \nalloc in the rule for Alloc takes a size k, the label (region) at which to allocate, and a default atom \na; it extends \u00b5 with a fresh frame of size k, initializing its contents to a. It returns the id of the \nnew frame and the extended memory \u00b5 ' . IFC and memory allocation We require that the frame identi.ers \nproduced by allocation at one label not be affected by allocations at other labels; e.g., alloc might \nallocate sequentially in each region. Thus, indistinguishability of low atoms is just syntactic equality, \npreserving De.nition 10.3 from the simple abstract machine, which is convenient for proving noninterference, \nas we explain below. We allow a program to observe frame sizes using a new SizeOf instruction, which \nrequires tainting the result of Alloc with L, the label of the size argument. There are also new instructions \nEq, for comparing two values (including pointers) for equality, and GetO., for extracting the offset \n.eld of a pointer into an integer. However, frame ids are intuitively abstract: the concrete representation \nof frame ids is not accessible, and pointers cannot be forged or output. The extended concrete machine \nstepping rules for these new instructions are analogous to the abstract machine rules, with the important \nexception of Alloc, which is discussed below. A few small modi.cations to existing instructions in the \nba\u00adsic machine (Fig. 2) are needed to handle pointers properly. In particular: (i) Load and Store require \npointer arguments and get stuck if the pointer s offset is out of range for its frame. (ii) Add takes \neither two integers or an integer and a pointer, where Int n + Int m = Int (n+m) and Ptr (id, o1) + Int \no2 = Ptr (id, o1+o2). (iii) Output works only on integers, not pointers. Analogous mod\u00adi.cations are \nneeded in the concrete machine semantic rules. Concrete allocator The extended concrete machine s semantics \nfor Alloc differ from those of the abstract machine in one key respect. Using one region per tag would \nnot be a realistic strategy for a concrete implementation; e.g., the number of different tags might be \nextremely large. Instead, we use a single region for all user-mode allocations at the concrete level. \nWe also collapse the separate user and kernel memories from the basic concrete machine into a single \nmemory. Since we still want to be able to distinguish user and kernel frames, we mark each frame with \na privilege mode (i.e., we use two allocation regions). Fig. 7 shows the corresponding concrete stepping \nrule for Alloc for two cases: non-faulting user mode and kernel mode. The concrete Load and Store rules \nprevent dereferencing kernel pointers in user mode. The rule cache is now just a distinguished kernel \nframe cache; to access it, the fault handler uses the (privileged) PushCachePtr instruction. Proof by \nre.nement As before, we prove noninterference for the concrete machine by combining a proof of noninterference \nof the abstract machine with a two-stage proof that the concrete machine re.nes the abstract machine. \nBy using this approach we avoid some well-known dif.culties in proving noninterference directly for the \nconcrete machine. In particular, when frames allocated in low and high contexts share the same region, \nallocations in high contexts can cause variations in the precise pointer values returned for al\u00ad 4 It \nwould be interesting to describe an implementation of the memory manager in a still-lower-level concrete \nmachine with no built-in Alloc instruction, but we leave this as future work. locations in low contexts, \nand these variations must be taken into account when de.ning the indistinguishability relation. For exam\u00adple, \nBanerjee and Naumann [4] prove noninterference by param\u00ad eterizing their indistinguishability relation \nwith a partial bijection that keeps track of indistinguishable memory addresses. Our ap\u00adproach, by contrast, \nde.nes pointer indistinguishability only at the abstract level, where indistinguishable low pointers \nare identical. This proof strategy still requires relating memory addresses when showing re.nement, but \nthis relation does not appear in the non\u00adinterference proof at the abstract level. The re.nement proof \nitself uses a simpli.ed form of memory injections [31]. The differences in the memory region structure \nof both machines are signi.cant, but invisible to programs, since no information about frame ids is revealed \nto programs beyond what can be obtained by comparing pointers for equality. This restriction allows the \nre.nement proof to go through straightforwardly. System calls To support the implementation of policy-speci.c \nprimitives on top of the concrete machine, we provide a new system call instruction. The SysCall id instruction \nis parameterized by a system call identi.er. The step relation of each machine is now parameterized by \na table T that maps system call identi.ers to their implementations. In the abstract and symbolic rule \nmachines, a system call imple\u00admentation is an arbitrary Coq function that removes a list of atoms from \nthe top of the stack and either puts a result on top of the stack or fails, halting the machine. The \nsystem call implementation is re\u00adsponsible for computing the label of the result and performing any checks \nthat are needed to ensure noninterference. In the concrete machine, system calls are implemented by ker\u00adnel \nroutines and the call table contains the entry points of these routines in the kernel instruction memory. \nExecuting a system call involves inserting the return address on the stack (underneath the call arguments) \nand jumping to the corresponding entry point. The kernel code terminates either by returning a result \nto the user pro\u00adgram or by halting the machine. This feature has no major impact on the proofs of noninterfer\u00adence \nand re.nement. For noninterference, we must show that all the abstract system calls preserve indistinguishability \nof abstract machine states; for re.nement, we show that each concrete sys\u00adtem call correctly implements \nthe abstract one using the machinery of \u00a77. Labeling with sets of principals The full SAFE machine supports \ndynamic creation of security principals. In the extended model, we make a .rst step toward dynamic principal \ncreation by taking principals to be integers and instantiating the (parametric) lattice of labels with \nthe lattice of .nite sets of integers.5 In this lattice, . is \u00d8, . is ., and = is .. We enrich our IFC \nmodel by adding a new classi.cation primitive joinP that adds a principal to an atom s label, encoded \nusing the system call mechanism described above. The operation of joinP is given by the following derived \nrule, which is an instance of the SysCall rule from Fig. 6. .(n) = SysCall joinP t \u00b5 [v@L1, (Int m)@L2, \ns] n@Lpc -. \u00b5 [v@(L1.L2.{m}), s] (n+1)@Lpc At the concrete level, a tag is now a pointer to an array \nof prin\u00adcipals (integers) stored in kernel memory. To keep the fault han\u00addler code simple, we do not \nmaintain canonical representations of sets: one set may be represented by different arrays, and a given \narray may have duplicate elements. (As a consequence, the map\u00adping from abstract labels to tags is no \nlonger a function; we return 5 This lattice is statically known, but models dynamic creation by supporting \nunbounded labels and having no top element.  to this point below.) Since the fault handler generator \nin the ba\u00adsic system is parametric in the underlying lattice, it doesn t require any modi.cation. All \nwe must do is provide concrete implementa\u00adtions for the appropriate lattice operations: genJoin just \nallocates a fresh array and concatenates both argument arrays into it; genFlows checks for array inclusion \nby iterating through one array and testing whether each element appears in the other; and genBot allocates \na new empty array. Finally, we provide kernel code to implement joinP, which requires two new privileged \ninstructions, Pack and Unpack (Fig. 7), to manipulate the payload and tag .elds of atoms; otherwise, \nthe implementation is similar to that of genJoin. A more realistic system would keep canonical representations \nof sets and avoid unnecessary allocation in order to improve its memory footprint and tag cache usage. \nBut even with the present simplistic approach, both the code for the lattice operations and their proofs \nof correctness are signi.cantly more elaborate than for the trivial two-point lattice. In particular, \nwe need an additional code generator to build counted loops, e.g., for computing the join of two tags. \ngenFor c = [Dup] ++ genIf (genLoop(c ++ [Push (-1), Add])) [] where genLoop c = c ++ [Dup, Bnz (-(length \nc + 1))] Here, c is a code sequence representing the loop body, which is ex\u00adpected to preserve an index \nvalue on top of the stack; the generator builds code to execute that body repeatedly, decrementing the \nindex each time until it reaches 0. The corresponding speci.cation is Pn(., s) := . T s ' . s = n@T, \ns ' . Inv(., s) Qn(., s) := . T s ' . s = n@T, s ' . . T ' . Inv(., ((n - 1)@T ' , s ' )) . n. 0 < n \n=. {Pn} c {Qn} P(., s) := . n T s ' . 0 = n . s = n@T, s ' . Inv(., s) Q(., s) := . T s ' . s = 0@T, \ns ' . Inv(., s) {P} genFor c {Q} To avoid reasoning about memory updates as far as possible, we code \nin a style where all local context is stored on the stack and manipulated using Dup and Swap. Although \nthe resulting code is lengthy, it is relatively easy to automate the corresponding proofs. Stateful encoding \nof labels Changing the representation of tags from integers to pointers requires modifying one small \npart of the basic system proof. Recall that in \u00a76 we described the encoding of labels into tags as a \npure function Lab. To deal with the memory\u00addependent and non-canonical representation of sets described \nabove, the extended system instead uses a relation between an abstract la\u00adbel, a concrete tag that encodes \nit, and a memory in which this tag should be interpreted. If tags are pointers to data structures, it \nis crucial that these data structures remain intact as long as the tags appear in the machine state. \nWe guarantee this by maintaining the very strong invariant that each execution of the fault handler only \nallocates new frames, and never modi.es the contents of existing ones, except for the cache frame (which \ntags never point into). A more realistic implementation might use mutable kernel memory for other purposes \nand garbage collect unused tags; this would require a more complicated memory invariant. The TINI formulation \nis similar in essence to the one in \u00a710, but some subtleties arise for concrete output events, since \ntags in events cannot be interpreted on their own anymore. We wish to (i) keep the semantics of the concrete \nmachine independent of high-level policies such as IFC and (ii) give a statement of noninterference that \ndoes not refer to pointers. To achieve these seemingly contradictory aims, we model an event of the concrete \nmachine as a pair of a concrete atom plus the whole state of the kernel memory. The resulting trace of \nconcrete events is abstracted (i.e., interpreted in terms of abstract labels) only when stating and proving \nTINI. This is an idealization of what happens in the real SAFE machine, where communication of labeled \ndata with the outside world involves cryptography. Modeling this is left as future work. 12. Related \nWork The SAFE design spans a number of research areas, and a compre\u00adhensive overview of related work \nwould be huge. We focus here on a small set of especially relevant points of comparison. The long version \ndiscusses additional related work. Language-based IFC Static approaches to IFC have generally dominated \nlanguage-based security research [40, etc.]; however, statically enforcing IFC at the lowest level of \na real system is chal\u00adlenging. Soundly analyzing native binaries with reasonable pre\u00adcision is hard, \neven more so without the compiler s cooperation (e.g., for stripped or obfuscated binaries). Proof-carrying \ncode [5, etc.] and typed assembly language [33, etc.] have been used for enforcing IFC on low-level code \nwithout low-level analysis or adding the compiler to the TCB. In SAFE [14, 17] we follow a different \napproach, enforcing noninterference using purely dy\u00adnamic checks, for arbitrary binaries in a custom-designed \ninstruc\u00adtion set. The mechanisms we use for this are similar to those found in recent work on purely \ndynamic IFC for high-level lan\u00adguages [3, 20, 21, 39, 44, etc.]; however, as far as we know, we are the \n.rst to push these ideas to the lowest level. seL4 Murray et al. [35] recently demonstrated a machine\u00adchecked \nnoninterference proof for the implementation of the seL4 microkernel. This proof is carried out by re.nement \nand reuses the speci.cation and most of the existing functional correctness proof of seL4 [27]. Like \nthe TINI property in this paper, the variant of in\u00ad transitive noninterference used by Murray et al. \nis preserved by re\u00ad.nement because it implies a high degree of determinism [36]. This organization of \ntheir proof was responsible for a signi.cant saving in effort, even when factoring in the additional \nwork required to re\u00admove all observable non-determinism from the seL4 speci.cation. Beyond these similarities, \nSAFE and seL4 rely on completely dif\u00adferent mechanisms to achieve different notions of noninterference. \nWhereas, in SAFE, each word of data has an IFC label and labels are propagated on each instruction, the \nseL4 kernel maintains sep\u00adaration between several large partitions (e.g., one partition can run an unmodi.ed \nversion of Linux) and ensures that information is conveyed between such partitions only in accordance \nwith a .xed access control policy. PROSPER In parallel work, Dam et al. [13, 26, etc.] veri.ed in\u00ad formation \n.ow security for a tiny proof-of-concept separation ker\u00adnel running on ARMv7 and using a Memory Management \nUnit for physical protection of memory regions belonging to different par\u00adtitions. The authors argue \nthat noninterference is not well suited for systems in which components are supposed to communicate with \neach other. Instead, they use the bisimulation proof method to show trace equivalence between the real \nsystem and an ideal top\u00adlevel speci.cation that is secure by construction. As in seL4 [35], the proof \nmethodology precludes an abstract treatment of schedul\u00ading, but the authors contend this is to be expected \nwhen information .ow is to be taken into account. TIARA and ARIES The SAFE architecture embodies a number \nof innovations from earlier paper designs. In particular, the TIARA design [43] .rst proposed the idea \nof a zero-kernel operating sys\u00ad tem and sketched a concrete architecture, while the ARIES project proposed \nusing a hardware rule cache to speed up information-.ow tracking [7]. In TIARA and ARIES, tags had a \n.xed set of .elds and were of limited length, whereas, in SAFE, tags are pointers to arbitrary data structures, \nallowing them to represent complex IFC labels encoding sophisticated security policies [34]. Moreover, \nun\u00ad like TIARA and ARIES, which made no formal soundness claims, SAFE proposes a set of IFC rules aimed \nat achieving noninterfer\u00adence; the proof we present in this paper, though for a simpli.ed model, provides \nevidence that this goal is within reach.  RIFLE and other binary-rewriting-based IFC systems RIFLE [46] \nenforces user-speci.ed information-.ow policies for x86 bi\u00adnaries using binary rewriting, static analysis, \nand augmented hard\u00adware. Binary rewriting is used to make implicit .ows explicit; it heavily relies on \nstatic analysis for reconstructing the program s control-.ow graph and performing reaching-de.nitions \nand alias analysis. The augmented hardware architecture associates labels with registers and memory and \nupdates these labels on each in\u00adstruction to track explicit .ows. Additional security registers are used \nby the binary translation mechanism to help track implicit .ows. Beringer [6] recently proved (in Coq) \nthat the main ideas in RIFLE can be used to achieve noninterference for a simple While language. Unlike \nRIFLE, SAFE achieves noninterference purely dynamically and does not rely on binary rewriting or heroic \nstatic analysis of binaries. Moreover, the SAFE hardware is generic, sim\u00adply caching instances of software-managed \nrules. While many other information .ow tracking systems based on binary rewriting have been proposed, \nfew are concerned with soundly handling implicit .ows [11, 32], and even these do so only to the extent \nthey can statically analyze binaries. Since, un\u00adlike RIFLE (and SAFE), these systems use unmodi.ed hardware, \nthe overhead for tracking implicit .ows can be large. To reduce this overhead, recent systems track implicit \n.ows selectively [25] or not at all arguably a reasonable tradeoff in settings such as malware analysis \nor attack detection, where speed and precision are more important than soundness. Hardware taint tracking \nThe last decade has seen signi.cant progress in specialized hardware for accelerating taint tracking \n[12, 15, 45, 47, etc.]. Most commonly, a single tag bit is associated with each word to specify if it \nis tainted or not. Initially aimed at mitigat\u00ading low-level memory corruption attacks by preventing the \nuse of tainted pointers and the execution of tainted instructions [45, etc.], hardware-based taint tracking \nhas also been used to prevent high\u00adlevel attacks such as SQL injection and cross-site scripting [12]. \nIn contrast to SAFE, these systems prioritize ef.ciency and overall helpfulness over the soundness of \nthe analysis, striking a heuris\u00adtic balance between false positives and false negatives (missed at\u00adtacks). \nAs a consequence, these systems ignore implicit .ows and often don t even track all explicit .ows. While \nearly systems sup\u00adported a single hard-coded taint propagation policy, recent ones al\u00adlow the policy \nto be de.ned in software [12, 15, 47] and support monitoring policies that go beyond taint tracking [8, \n15, etc.]. Har\u00ad moni [15], for example, provides a pair of caches that are quite sim\u00ad ilar to the SAFE \nrule cache. Possibly these could even be adapted to enforcing noninterference, in which case we expect \nthe proof methodology introduced here to apply. Veri.cation of low-level code The distinctive challenge \nin verify\u00ading machine code is coping with unstructured control .ow. Our ap\u00adproach using structured generators \nto build the fault handler is sim\u00adilar to the mechanisms used in Chlipala s Bedrock system [9, 10] and \nby Jensen et al. [24], but there are several points of difference. These systems each build macros on \ntop of a powerful low-level program logic for machine code (Ni and Shao s XCAP [38], in the case of Bedrock), \nwhereas we take a simpler, ad-hoc approach, building directly on our stack machine s relatively high-level \nse\u00admantics. Both these systems are based on separation logic, which we can do without since (at least \nin the present simpli.ed model) we have very few memory operations to reason about. We have instead focused \non developing a simple Hoare logic speci.cally suited to verifying structured runtime-system code; e.g., \nwe omit support for arbitrary code pointers, but add support for reasoning about termination. We use \ntotal-correctness Hoare triples (similar to Myreen and Gordon [37]) and weakest preconditions to guaran\u00ad \ntee progress, not just safety, for our handler code. Finally, our level of automation is much more modest \nthan Bedrock s, though still adequate to discharge most veri.cation conditions on straight-line stack \nmanipulation code rapidly and often automatically. 13. Conclusions and Future Work We have presented \na formal model of the key IFC mechanisms of the SAFE system: propagating and checking tags to enforce \nse\u00adcurity, using a hardware cache for common-case ef.ciency and a software fault handler for maximum \n.exibility. To formalize and prove properties at such a low level (including features such as dynamic \nmemory allocation and labels represented by pointers to in-memory data structures), we .rst construct \na high-level abstract speci.cation of the system, then re.ne it in two steps into a realistic concrete \nmachine. A bidirectional re.nement methodology allows us to prove (i) that the concrete machine, loaded \nwith the right fault handler (i.e. correctly implementing the IFC enforcement of the abstract speci.cation) \nsatis.es a traditional notion of termination\u00adinsensitive noninterference, and (ii) that the concrete \nmachine re\u00ad.ects all the behaviours of the abstract speci.cation. Our formal\u00adization re.ects the programmability \nof the fault handling mecha\u00adnism, in that the fault handler code is compiled from a rule table written \nin a small DSL. We set up a custom Hoare logic to specify and verify the corresponding machine code, \nfollowing the structure of a simple compiler for this DSL. The development in this paper concerns three \ndeterministic ma\u00adchines and simpli.es away concurrency. While the lack of concur\u00adrency is a signi.cant \ncurrent limitation that we would like to re\u00admove as soon as possible by moving to a multithreading single-core \nmodel, we still want to maintain the abstraction layers of a proof\u00adby-re.nement architecture. This requires \nsome care so as not to run afoul of the re.nement paradox [23] since some standard notions of noninterference \n(for example possibilistic noninterference) are not preserved by re.nement in the presence of non-determinism. \nOne promising path toward this objective is inspired by the recent non\u00adinterference proof for seL4 [35, \n36]. If we manage to share a com\u00ad mon thread scheduler between the abstract and concrete machines, we \ncould still prove a strong double re.nement property (concrete re.nes abstract and vice versa) and hence \npreserve a strong notion of noninterference (such as the TINI notion from this work) or a possibilistic \nvariation. Although this paper focuses on IFC and noninterference, the tagging facilities of the concrete \nmachine are completely generic. In current follow-on work, we aim to show that the same hardware can \nbe used to ef.ciently support completely different policies targeting memory safety and control-.ow integrity. \nMoreover, although the rule cache / fault handler design arose in the context of SAFE, we believe that \nthis mechanism can also be ported to more traditional architectures. In the future, we plan to reuse \nand extend the formal development in this paper both to a larger set of high-level proper\u00adties and to \nmore conventional architectures. For instance, we expect the infrastructure for compiling DSLs to fault \nhandler software us\u00ading veri.ed structured code generators to extend to runtime-system components (e.g. \ngarbage collectors, device drivers, etc.), beyond IFC and SAFE. Acknowledgments We are grateful to Maxime \nD\u00b4es, Deepak en`Garg, Greg Morrisett, Toby Murray, Jeremy Planul, Alejandro Russo, Howie Shrobe, Jonathan \nM. Smith, Deian Stefan, and Greg Sullivan for useful discussions and helpful feedback on early drafts. \n We also thank the anonymous reviewers for their insightful com\u00adments. This material is based upon work \nsupported by the DARPA CRASH program through the US Air Force Research Laboratory (AFRL) under Contract \nNo. FA8650-10-C-7090. The views ex\u00adpressed are those of the authors and do not re.ect the of.cial policy \nor position of the Department of Defense or the U.S. Government. References [1] A. Askarov, S. Hunt, \nA. Sabelfeld, and D. Sands. Termination\u00ad insensitive noninterference leaks more than just a bit. ESORICS. \n2008. [2] A. Askarov and A. Sabelfeld. Tight enforcement of information-release policies for dynamic \nlanguages. CSF. 2009. [3] T. H. Austin and C. Flanagan. Ef.cient purely-dynamic information .ow analysis. \nPLAS. 2009. [4] A. Banerjee and D. A. Naumann. Stack-based access control and secure information .ow. \nJFP, 15(2):131 177, 2005. [5] G. Barthe, D. Pichardie, and T. Rezk. A certi.ed lightweight non\u00ad interference \nJava bytecode veri.er. ESOP. 2007. [6] L. Beringer. End-to-end multilevel hybrid information .ow control. \nAPLAS. 2012. [7] J. Brown and T. F. Knight, Jr. A minimally trusted computing base for dynamically ensuring \nsecure information .ow. Technical Report 5, MIT CSAIL, 2001. Aries Memo No. 15. [8] S. Chen, M. Kozuch, \nT. Strigkos, B. Falsa., P. B. Gibbons, T. C. Mowry, V. Ramachandran, O. Ruwase, M. P. Ryan, and E. Vlachos. \nFlexible hardware acceleration for instruction-grain program monitoring. ISCA. 2008. [9] A. Chlipala. \nMostly-automated veri.cation of low-level programs in computational separation logic. PLDI, 2011. [10] \nA. Chlipala. The Bedrock structured programming system: Combin\u00ad ing generative metaprogramming and Hoare \nlogic in an extensible pro\u00ad gram veri.er. ICFP. 2013. [11] J. A. Clause, W. Li, and A. Orso. Dytan: a \ngeneric dynamic taint analysis framework. ISSTA. 2007. [12] M. Dalton, H. Kannan, and C. Kozyrakis. Raksha: \na .exible informa\u00ad tion .ow architecture for software security. ISCA, 2007. [13] M. Dam, R. Guanciale, \nN. Khakpour, H. Nemati, and O. Schwarz. Formal veri.cation of information .ow security for a simple ARM\u00ad \nbased separation kernel. CCS, 2013. To appear. [14] A. DeHon, B. Karel, T. F. Knight, Jr., G. Malecha, \nB. Montagu, R. Morisset, G. Morrisett, B. C. Pierce, R. Pollack, S. Ray, O. Shivers, J. M. Smith, and \nG. Sullivan. Preliminary design of the SAFE platform. PLOS, 2011. [15] D. Y. Deng and G. E. Suh. High-performance \nparallel accelerator for .exible and ef.cient run-time monitoring. DSN. 2012. [16] U. Dhawan and A. DeHon. \nArea-ef.cient near-associative memories on FPGAs. In International Symposium on Field-Programmable Gate \nArrays, (FPGA2013), 2013. [17] U. Dhawan, A. Kwon, E. Kadric, C. Hrit\u00b8cu, B. C. Pierce, J. M. Smith, \nA. DeHon, G. Malecha, G. Morrisett, T. F. Knight, Jr., A. Sutherland, T. Hawkins, A. Zyxnfryx, D. Wittenberg, \nP. Trei, S. Ray, and G. Sulli\u00advan. Hardware support for safety interlocks and introspection. AHNS, 2012. \n[18] J. A. Goguen and J. Meseguer. Unwinding and inference control. IEEE S&#38;P. 1984. [19] D. Hedin \nand A. Sabelfeld. A perspective on information-.ow control. Marktoberdorf Summer School. IOS Press, 2011. \n[20] D. Hedin and A. Sabelfeld. Information-.ow security for a core of JavaScript. CSF. 2012. [21] C. \nHrit\u00b8cu, M. Greenberg, B. Karel, B. C. Pierce, and G. Morrisett. All your IFCException are belong to \nus. IEEE S&#38;P. 2013. [22] C. Hrit\u00b8cu, J. Hughes, B. C. Pierce, A. Spector-Zabusky, D. Vytiniotis, \nA. Azevedo de Amorim, and L. Lampropoulos. Testing noninterfer\u00ad ence, quickly. ICFP, 2013. [23] J. Jacob. \nOn the derivation of secure components. IEEE S&#38;P. 1989. [24] J. B. Jensen, N. Benton, and A. Kennedy. \nHigh-level separation logic for low-level code. POPL. 2013. [25] M. G. Kang, S. McCamant, P. Poosankam, \nand D. Song. DTA++: Dynamic taint analysis with targeted control-.ow propagation. NDSS. 2011. [26] N. \nKhakpour, O. Schwarz, and M. Dam. Machine assisted proof of ARMv7 instruction level isolation properties. \nCPP, 2013. To appear. [27] G. Klein, K. Elphinstone, G. Heiser, J. Andronick, D. Cock, P. Der\u00adrin, D. \nElkaduwe, K. Engelhardt, R. Kolanski, M. Norrish, T. Sewell, H. Tuch, and S. Winwood. seL4: Formal veri.cation \nof an OS kernel. SOSP. 2009. [28] M. N. Krohn and E. Tromer. Noninterference for a practical DIFC\u00ad based \noperating system. IEEE S&#38;P. 2009. [29] A. Kwon, U. Dhawan, J. M. Smith, T. F. Knight, Jr., and A. \nDeHon. Low-fat pointers: compact encoding and ef.cient gate-level implemen\u00ad tation of fat pointers for \nspatial safety and capability-based security. CCS. 2013. [30] X. Leroy. A formally veri.ed compiler back-end. \nJournal of Auto\u00admated Reasoning, 43(4):363 446, 2009. [31] X. Leroy and S. Blazy. Formal veri.cation \nof a C-like memory model and its uses for verifying program transformations. JAR, 41(1):1 31, 2008. [32] \nW. Masri, A. Podgurski, and D. Leon. Detecting and debugging insecure information .ows. ISSRE. 2004. \n[33] R. Medel, A. B. Compagnoni, and E. Bonelli. A typed assembly language for non-interference. ICTCS. \n2005. [34] B. Montagu, B. C. Pierce, and R. Pollack. A theory of information\u00ad .ow labels. CSF. 2013. \n[35] T. C. Murray, D. Matichuk, M. Brassil, P. Gammie, T. Bourke, S. Seefried, C. Lewis, X. Gao, and \nG. Klein. seL4: from general pur\u00ad pose to a proof of information .ow enforcement. IEEE S&#38;P. 2013. \n[36] T. C. Murray, D. Matichuk, M. Brassil, P. Gammie, and G. Klein. Noninterference for operating system \nkernels. CPP. 2012. [37] M. O. Myreen and M. J. C. Gordon. Hoare logic for realistically modelled machine \ncode. TACAS. 2007. [38] Z. Ni and Z. Shao. Certi.ed assembly programming with embedded code pointers. \nPOPL. 2006. [39] A. Russo and A. Sabelfeld. Dynamic vs. static .ow-sensitive security analysis. CSF. \n2010. [40] A. Sabelfeld and A. Myers. Language-based information-.ow secu\u00ad rity. JSAC, 21(1):5 19, 2003. \n[41] A. Sabelfeld and A. Russo. From dynamic to static and back: Riding the roller coaster of information-.ow \ncontrol research. In Ershov Memorial Conference. 2009. [42] J. Sevc\u00b4ik, V. Vafeiadis, F. Z. Nardelli, \nS. Jagannathan, and P. Sewell. Relaxed-memory concurrency and veri.ed compilation. POPL. 2011. [43] H. \nShrobe, A. DeHon, and T. F. Knight, Jr. Trust-management, intrusion-tolerance, accountability, and reconstitution \narchitecture (TIARA), 2009. [44] D. Stefan, A. Russo, J. C. Mitchell, and D. Mazi`eres. Flexible dynamic \ninformation .ow control in Haskell. Haskell. 2011. [45] G. E. Suh, J. W. Lee, D. Zhang, and S. Devadas. \nSecure program execution via dynamic information .ow tracking. ASPLOS, 2004. [46] N. Vachharajani, M. \nJ. Bridges, J. Chang, R. Rangan, G. Ottoni, J. A. Blome, G. A. Reis, M. Vachharajani, and D. I. August. \nRIFLE: An architectural framework for user-centric information-.ow security. MICRO, 2004. [47] G. Venkataramani, \nI. Doudalis, Y. Solihin, and M. Prvulovic. Flex\u00ad iTaint: A programmable accelerator for dynamic taint \npropagation. HPCA, 2008. [48] S. A. Zdancewic. Programming Languages for Information Security. PhD thesis, \nCornell University, 2002.  \n\t\t\t", "proc_id": "2535838", "abstract": "<p>SAFE is a clean-slate design for a highly secure computer system, with pervasive mechanisms for tracking and limiting information flows. At the lowest level, the SAFE hardware supports fine-grained programmable tags, with efficient and flexible propagation and combination of tags as instructions are executed. The operating system virtualizes these generic facilities to present an information-flow abstract machine that allows user programs to label sensitive data with rich confidentiality policies. We present a formal, machine-checked model of the key hardware and software mechanisms used to control information flow in SAFE and an end-to-end proof of noninterference for this model.</p>", "authors": [{"name": "Arthur Azevedo de Amorim", "author_profile_id": "83058788457", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P4383780", "email_address": "aarthur@seas.upenn.edu", "orcid_id": ""}, {"name": "Nathan Collins", "author_profile_id": "81496659413", "affiliation": "Portland State University, Portland, OR, USA", "person_id": "P4383781", "email_address": "nathan.collins@gmail.com", "orcid_id": ""}, {"name": "Andr&#233; DeHon", "author_profile_id": "81100203250", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P4383782", "email_address": "andre@acm.org", "orcid_id": ""}, {"name": "Delphine Demange", "author_profile_id": "81418599022", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P4383783", "email_address": "ddemange@seas.upenn.edu", "orcid_id": ""}, {"name": "C&#259;t&#259;lin Hri&#355;cu", "author_profile_id": "81384610090", "affiliation": "University of Pennsylvania and INRIA, Philadelphia, PA, USA", "person_id": "P4383784", "email_address": "catalin.hritcu@gmail.com", "orcid_id": ""}, {"name": "David Pichardie", "author_profile_id": "81321496627", "affiliation": "Harvard University and INRIA, Cambridge, MA, USA", "person_id": "P4383785", "email_address": "David.Pichardie@inria.fr", "orcid_id": ""}, {"name": "Benjamin C. Pierce", "author_profile_id": "81100303310", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P4383786", "email_address": "bcpierce@cis.upenn.edu", "orcid_id": ""}, {"name": "Randy Pollack", "author_profile_id": "81100439862", "affiliation": "Harvard University, Cambridge, MA, USA", "person_id": "P4383787", "email_address": "rpollack@seas.harvard.edu", "orcid_id": ""}, {"name": "Andrew Tolmach", "author_profile_id": "81100247872", "affiliation": "Portland State University, Portland, OR, USA", "person_id": "P4383788", "email_address": "apt@cs.pdx.edu", "orcid_id": ""}], "doi_number": "10.1145/2535838.2535839", "year": "2014", "article_id": "2535839", "conference": "POPL", "title": "A verified information-flow architecture", "url": "http://dl.acm.org/citation.cfm?id=2535839"}