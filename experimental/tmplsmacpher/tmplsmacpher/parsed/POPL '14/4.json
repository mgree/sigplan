{"article_publication_date": "01-08-2014", "fulltext": "\n Combining Proofs and Programs in a Dependently Typed Language Chris Casinghino Vilhelm Sj\u00f6berg Stephanie \nWeirich University of Pennsylvania {ccasin,vilhelm,sweirich}@cis.upenn.edu Abstract Most dependently-typed \nprogramming languages either require that all expressions terminate (e.g. Coq, Agda, and Epigram), or \nal\u00adlow in.nite loops but are inconsistent when viewed as logics (e.g. Haskell, ATS, Omega). Here, we \ncombine these two approaches into a single dependently-typed core language. The language is composed \nof two fragments that share a common syntax and over\u00adlapping semantics: a logic that guarantees total \ncorrectness, and a call-by-value programming language that guarantees type safety but not termination. \nThe two fragments may interact: logical ex\u00adpressions may be used as programs; the logic may soundly reason \nabout potentially nonterminating programs; programs can require logical proofs as arguments; and mobile \nprogram values, includ\u00ading proofs computed at runtime, may be used as evidence by the logic. This language \nallows programmers to work with total and partial functions uniformly, providing a smooth path from func\u00adtional \nprogramming to dependently-typed programming. Categories and Subject Descriptors D.3.1 [Programming Lan\u00adguages]: \nFormal De.nitions and Theory Keywords Dependent types; Termination; General recursion 1. Introduction \nDependently typed languages have developed along two different traditions, distinguished by their attitude \ntowards nonterminating programs. On the one hand, languages like Cayenne [6], ATS [13], Omega [33] and \nHaskell [29] treat dependently-typed program\u00ad ming as an extension of ordinary functional programming. \nThese languages enhance ordinary functional programs, de.ned by gen\u00aderal recursion, with more expressive \ntypes. On the other hand, lan\u00adguages like Coq [40], Agda [28] and Epigram [23] treat depen\u00ad dently typed \nprogramming as a use-case of constructive theorem proving. These systems disallow nontermination because \nan in.\u00adnite loop can be given any type and would therefore make the logic inconsistent. We would like \nbalance between proving and programming, with neither activity given preferential treatment. Although \nwe are sym\u00adpathetic to the ideal that all programs should be proven correct, we Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. Copyrights for components of this work owned by others than the \nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to \npost on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. Request \npermissions from permissions@acm.org. POPL 14, January 22 24, 2014, San Diego, CA, USA. Copyright is \nheld by the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-2544-8/14/01. . . $15.00. \nhttp://dx.doi.org/10.1145/2535838.2535883 understand that there are practical reasons not to do so. \nInstead, we desire a language for heterogeneous veri.cation, allowing pro\u00adgrammers to devote their veri.cation \nbudget to critical sections. Such a language must support general recursion as natively as a functional \nprogramming language, yet at the same time must pro\u00advide the expressive reasoning capabilities of a constructive \nlogic proof assistant. In support of this goal, we propose a novel language that is com\u00adposed of two \nfragments: a logical fragment where every expression is known to terminate, and a programmatic fragment \nthat does not provide this assurance. The key idea of our work is to distinguish between these fragments \nby indexing the typing judgement with a consistency classi.er . that may be L ( logic ) or P ( program \n), thus G f. a : A When . is L, the Curry-Howard Isomorphism applies, and we may consider a a proof of \nthe theorem A. When . is P, the only inter\u00adpretation of a is as a functional program. Making this distinction \nmeans that one language can subsume both functional program\u00adming and constructive logic by embedding \neach in their respective fragments. However, these activities are not too far apart the syn\u00adtax and semantics \nof the two fragments overlap considerably, be\u00adcause the distinction between them is made through typing. \nIn this paper, we explore the consequences of this design in the context of a dependently-typed programming \nlanguage, focusing on the following mechanisms that foster interaction between the two fragments. First, \nwe de.ne the logical language as a sublanguage of the programmatic language, so that all logical expressions \ncan be used as programs. (Of course, the programmatic language in\u00adcludes forms that are not available \nto the logic, including gen\u00aderal recursion and the elimination of iso-recursive types.)  We allow uniform \nreasoning for logical and programmatic ex\u00adpressions through a heterogenous equality type. Two expres\u00adsions \ncan be shown to be equal based on their evaluation, which is the same for both fragments. Equality proofs \ncan be used im\u00adplicitly by the type system.  We internalize the labeled typing judgment as a new type \nform A@.. This type can be used by either fragment to manipulate values belonging to the other.  We \nidentify a set of mobile types those whose values can freely move between the fragments.  To demonstrate \nthe soundness and consistency of these mecha\u00adnisms, we de.ne a core dependently-typed language, called \n.., that supports these interactions (see Sections 2 and 3). In addition to the A@. type, this language \nincludes dependent functions, products, propositional equality, natural numbers, sums, recursive functions \nand iso-recursive types. We prove that this language is type safe and that the L fragment is normalizing \nand logically consistent (Section 4). Our normalization proof uses a combination of traditional and step-indexed \nlogical relations. All of our metatheoretic results have been completely machine-checked using the Coq \nproof assistant and are available online1 .  We also explore how our ideas interact with other programming \nlanguage features. We have implemented a prototype language, Zombie, based on the semantics of .., and \ndiscuss that imple\u00admentation in Section 5. Zombie extends .. with features that are convenient for dependently-typed \nprogramming: parametric poly\u00admorphism, type-level computation, user-de.ned datatypes, and im\u00adplicit arguments. \nWe have developed a number of examples using Zombie; the implementation is available online2 . We are \nnot the .rst to consider the combination of total and par\u00adtial programming in the setting of dependently-typed \nlanguages. Partial types [14] and the coinductive partiality monad [11] em\u00ad bed general recursive programs \ninto constructive logic by mod\u00adeling nontermination. Alternatively, languages such as Idris [10], Aura \n[18], and F* [38] identify a restricted sublanguage of pure to\u00ad tal functions. However, neither of these \napproaches provide equal support for total and partial programming. We compare them to our work in Section \n6. 1.1 Combining Proofs and Programs Before explaining the semantics of .., we conclude this section \nwith a number of examples to demonstrate the key ideas. In Zombie, declarations must indicate whether \nthey belong to the logical or programmatic fragment of the language. For exam\u00adple, a boolean negation \noperation is trivially terminating, so it is checkable in the logical fragment, as indicated by the tag \nlog in its de.nition: log not : Bool . Bool not b = if b then False else True Likewise, addition for \nnatural numbers can be shown terminat\u00ading via natural number induction. In the case expression below, \nplus may be called on any subterm of its argument. The argument n_eq is a proof that n is a subterm of \nn. log plus : Nat . Nat . Nat ind plus n m = case n [n_eq] of Zero . m Succ n . Succ (plus n n_eq m) \nAlternatively, the following natural number division function diverges when m is 0, so it must be tagged \nwith prog. The rec keyword indicates that this function is implemented using general recursion. prog \ndiv : Nat . Nat . Nat rec div n m = if lt n m then 0 else plus 1 (div (minus n m) m) Subsumption. All \nproofs can be used as programs. In the above example, even though the plus operation is logical, we can \nseam\u00adlessly use it (and other logical operations such as lt and minus) directly in a programmatic term, \nand call it on an argument whose termination behavior is unknown. Thus, the fact that we know that plus \nterminates does not restrict how it may be used we do not 1 Proofs available at http://www.cis.upenn.edu/~ccasin/papers/ \ncombining-coq.tgz 2 Implementation available at https://code.google.com/p/trellys in the branch branches/zombie-trellys-POPL14/ \nneed to duplicate its de.nition for it to be available to both frag\u00adments. Proofs containing programs. \nThe @-type allows values to be embedded from one fragment into another. For example, the logical language \ncan safely manipulate programmatic values as long as their types indicate (with @P) that they are programmatic. \nBelow, consider the de.nition of a Maybe datatype that could contain arbitrary programs. data Maybe (A \n: Type) where Nothing Just of (A @ P) As long as the programmatic component is treated carefully, ex\u00adpressions \nin the logical fragment can work with this data structure. This includes constructing values of the Maybe \ntype, and pattern matching on the data structure. log md3 : Maybe (Nat . Nat) md3 = Just (\\x. div 3 x) \nlog foo : Maybe (Nat . Nat) . (Nat . Nat @ P) foo x = case x of Just y . y Nothing . \\x. x However, if \nthe programmatic component is ever used, then the de.nition must be marked as programmatic, as an embedded \nfunction could cause divergence. prog bar : Maybe (Nat . Nat) . Nat . Maybe Nat bar x y = case x of Just \nf . Just (f y) Nothing . Nothing prog boom : Maybe Nat boom = bar md3 0 Proofs about programs. Having \nde.ned the programmatic func\u00adtion div, we might wish to verify facts about it. As a simple exam\u00adple, \nwe prove that div 6 3 evaluates to 2. We can state and prove these facts using the logical language, \neven though the object of study may not terminate. log div63 : div 6 3 = 2 div63 = refl The proof above \n(refl) is valid when both sides of an equality proposition evaluate to the same result. (To avoid in.nite \nloops, the typechecker will give up and signal an error if the expression does not reach a normal form \nwithin 1000 steps. If more evaluation is required the programmer can write e.g. refl 5000). In languages \nlike Aura or F*, this theorem cannot even be stated because non\u00advalue expressions such as div 6 3 cannot \nappear in types. This example illustrates an important property of our language, which we call freedom \nof speech: although proofs cannot themselves use general recursion, they are allowed to refer to arbitrary \nprogram\u00admatic expressions. As a more complicated example, we might wish to prove that if the divisor \nis not zero, then the result is less than the dividend. In other words: log div_le : (n:Nat) . (m:Nat) \n. (eq m 0 = False) . (le (div n m) n = True) Above, eq is an equality function for natural numbers and \nle m n determines whether m = n. We do not show proof of the above theorem here, though it is available \nwith our implementation. The proof itself uses strong natural number induction to simultaneously show \nboth that division terminates and that the property above holds for the result.  Note that we can only \nshow properties that are provable via .\u00adnite reduction sequences. For example, we cannot show that divi\u00adsion \ndiverges when the dividend is 0, because that divergence is not .nitely observable. (The logic does not \nhave a general principle for reasoning about nonterminating programs, such as .xed-point induction. We \nreturn to this issue in Section 6.) Programs that return proofs. An alternative to writing separate proofs \nabout nonterminating programs is to give the programs themselves more speci.c types that express their \ncorrectness. For example, consider writing a SAT solver that we do not want to prove terminating. A SAT \nsolver takes a formula of n variables and, if the formula is satis.able, returns a satisfying assignment \nfor some subset of those variables. We can represent the result of a SAT solver using the following datatype \ndeclaration. The result for a given formula is either an assignment together with a proof that that assignment \nsatis.es the formula, or UNSAT when the formula is unsatis.able. data Ans (n : Nat) (form : Formula n) \n: Type where SAT of (assign : Vector (Maybe Bool) n) (proof : satisfies assign form = (Just True : Maybe \nBool)) UNSAT The main loop of the solver itself takes a formula and the current assignment and returns \nwhether that assignment can be extended to a satisfying one. If the current assignment is known to be \nsatisfying, then that one is returned. Zombie can automatically .ll in the _ below with the proof that \nassign satis.es the formula. If the assignment is known to invalidate the formula, then the result is \nUNSAT. Otherwise the algorithm must search for an extension to the assignment using techniques such as \nunit propagation, pure literal assignment, or merely trying both possibilities for an unassigned variable. \nprog solver : (n:Nat) . (formula : Formula n) . Vector (Maybe Bool) n . Ans n formula @ L solver n formula \nassign = case (satisfies assign formula) of Just True . SAT assign _ Just False . UNSAT Nothing . .... \n Since the solver is written in the programmatic fragment, it may not terminate. It also may fail to \n.nd an assignment even though the formula was satis.able. However, the type of this function is more \ninformative than if it had been written in ML or Haskell. The @L in its type indicates that if it does \nreturn a proof of satis.ability, then that value was type checked in the logical fragment. When a program \ncontains subexpressions from both fragments, values can be handled more freely than expressions. For \nexample, a logical expression cannot call solver directly because of the possibility of divergence. However, \nif the result of that call has already been bound to a variable, then the logic has access to that result. \nlet prog f = (... : Formula n) in let log empty = repeat (Nothing : Maybe Bool) n in let prog isSat = \n(solver n f empty : Ans n f @L) in let log prf = case isSat of SAT assignment pf . --... use proof of \nsatisfiability ... UNSAT . ... . ::= L | P a, b, A, B ::= * | (x : A) . B | a = b | Nat | A + B | Sx \n:A.B | \u00b5x.A | A@. | x | .x.a | rec f x .a | ind f x .a | a b | re. | inl a | inr b | scasez a of {inl \nx . a1; inr y . a2}| (a, b) | pcasea of {(x, y) . b} z | Z | S a | ncasez a of {Z . a1; S x . a2}| roll \na | unroll a v ::= * | (x : A) . B | a = b | Nat | A + B | Sx :A.B | \u00b5x.A | A@. | x | .x.a | rec f x \n.a | ind f x .a | re. | inl v | inr v | (v1, v2) | Z | S v | roll v a b (.x.a) v [v/x]a SLA M SFU N \n(rec f x .a) v [v/x][rec f x .a/f ]a SIN D (ind f x .a) v [v/x][.y..z.(ind f x .a) y/f ]a SCL scasez \ninl v of {inl x . a1; inr x . a2} [re./z ][v/x]a1 SCR scasez inr v of {inl x . a1; inr x . a2} [re./z][v/x]a2 \nSCP pcase(v1, v2) of {(x, y) . a} [re./z][v1/x][v2/y]a z SUNRO L L unroll (roll v) v Figure 1. Expressions, \nvalues, and operational semantics (excerpt) Mobile types Finally, some types have the same meaning in \nboth fragments, so they do not bene.t from being tagged with a consis\u00adtency classi.er. For example, a \nvalue of type Nat can never cause divergence, so it is safe to be used in logical expressions even when \nnot marked as @L. Similarly, the Ans type above is also mobile, so the @L annotation on the type of solver \nis actually unnecessary. This observation simpli.es programming as the only function ar\u00adguments that \nmust be annotated with their fragment are those that are not mobile. 2. The .. language We begin our \ntechnical development with an overview of the for\u00admal language, ... This language is based on a call-by-value \n(CBV) variant of lambda calculus. Its syntax is shown in Figure 1. For uniformity, terms, types and the \nsingle kind * (the type of types) are drawn from the same syntactic category, as in pure type sys\u00adtems \n[7]. The .rst two lines of the .gure list the type forms, the following lines list the terms. By convention, \nwe use lowercase metavariables a, b for expressions that are terms and uppercase metavariables A, B for \nexpressions that are types. The .. values v and key rules of the operational semantics are also shown \nin Figure 1. The reduction relation a b de.nes a small-step call-by-value semantics. The slightly unusual \nbeta rule for natural number induction (SIND) is described in Section 2.1. To save space, most rules \nhave been omitted. The full set of rules can be found in the companion technical report3 .  Values include \nthe standard components of functional program\u00adming: recursive functions rec f x .a, nonrecursive functions \n.x.a, natural numbers (constructed by Z and S a and eliminated by ncase), disjoint unions (constructed \nby inl a and inr a and elim\u00adinated by scase), dependently typed pairs (constructed by (a, b)and eliminated \nby pcase), and recursive data (introduced by roll a and eliminated by unroll a). Values also include \n*, all type forms, a trivial equality proof re., and variables. Including variables is safe because CBV \nevaluation only substitutes values for variables and it is useful because it allows the .. type checker \nto reduce open terms. We chose CBV because of its simple cost model, but this choice also affects the \ninteraction between the logical and programmatic fragments. As shown in Sections 2.2 and 3.3, the type \nsystem takes advantage of the fact that values cannot induce nontermination. As a result, some typing \nrules apply only to values. Note that expressions do not contain type annotations. Types describe terms \nbut do not interfere with equality. We do not want terms with the same runtime behavior to be considered \nunequal just because they have different annotations. Due to the lack of annotations, it is not possible \nto algorithmi\u00adcally compute the type of a .. term. This is not a problem because we do not intend programmers \nto write these terms directly. In\u00adstead, our implementation uses an annotated surface language that the \ntype checker elaborates into typing derivations (see Section 5). The rest of this section describes the \nspeci.c details of .., in\u00adcluding its basic judgements (Section 2.1), and treatment of equal\u00ad ity (Section \n2.2). In the next section, we introduce the novel fea\u00ad tures of our language that permit the interaction \nbetween the logical and programmatic fragments of the language. 2.1 Classifying terminating and nonterminating \nexpressions The starting point for .. is a dependent type theory where the typing judgment G f. a : A \nis indexed by a consistency classi.er .. The judgement is designed so that expressions that type check \nat L always terminate. Figure 2 shows the typing rules for the basic building blocks of the language \nvariables, functions and various data structures and their types. Because we work with a collapsed syntax, \nwe use the type system to identify which expressions are types: A is a well\u00adformed type if G f. A : *. \nContexts are lists of assumptions about the types of variables. G ::= \u00d8 | G, x : . A Each variable in \nthe context is tagged with . to indicate its frag\u00adment, and this tag is checked in the TVA R typing rule. \nA context is valid, written f G, if each type A is valid in the corresponding fragment. The rules TARR, \nTSI G M A, TSUM, and TMU check types for well-kindedness. For example, TARR checks a function type by \nchecking the the domain and range. We discuss the premise Mobile (A), which asserts that A is a mobile \ntype, in Section 3.3. There are three ways to de.ne functions in ... Rule TLA M types non-recursive .-expressions \nin the logical fragment, whereas rule TRE C types general recursive rec-expressions and can only be used \nin the programmatic fragment. Additionally, terminating recursion over natural numbers is pro\u00advided in \nthe logical fragment by rule TIND. When typechecking the body of a terminating recursive function (ind \nf x .b), the recursive 3 Available from http://www.seas.upenn.edu/~ccasin/papers/ combining-TR.pdf and \nas University of Pennsylvania CIS Technical Re\u00adport MS-CIS-13-08. f G f G f G G f. A : * CNI L CSTA R \nCTYP E f\u00b7 f G, x :. * f G, x :. A G f. a : A G f. A : * Mobile (A) (x :. A) . G f G G, x :. A f. B : \n* TVA R TAR R G f. x : A G f. (x :A) . B : * G f. b : (x : A) . B G f. a : A G f. [a/x]B : * TAPP G \nf. b a : [a/x]B G, x :L A fL b : B G fL (x : A) . B : * TLA M G fL .x.b : (x :A) . B G, f :P (x :A) . \nB, x :P A fP b : B G fP (x :A) . B : * TRE C G fP rec f x .b : (x : A) . B G, x :L Nat, f :L (y : Nat) \n. (z :S y = x) . B fL b : B G fL (x : Nat) . B : * TIN D G fL ind f x .b : (x : Nat) . B G f. A : * \nG f. B : * TSUM G f. A + B : * G f. a : A G f. b : B G f. A + B : * G f. A + B : * TIN L TIN R G f. inl \na : A + B G f. inr b : A + B G f. a : A1 + A2 G f. B : * G, x :. A1, z :L inl x = a f. b1 : B G, x :. \nA2, z :L inr x = a f. b2 : B TSCA S E G f. scasez a of {inl x . b1; inr x . b2} : B G f. Sx :A.B : * \nG f. A : * G f. a : A Mobile (A) G f. b : [a/x]B G, x :. A f. B : * G f. [a/x]B : * TSI GM A TPA I R \nG f. Sx :A.B : * G f. (a, b) : Sx :A.B G f. a : Sx :A1.A2 G f. B : * G, x :. A1, y :. A2, z :L (x, y) \n= a f. b : B TPCA S E G f. pcasea of {(x, y) . b} : B z G f. a : [\u00b5x.A/x]A L * fL G f. G, x :A : * \u00b5x.A \n: * TMU TRO L L G fL \u00b5x .A : * G f. roll a : \u00b5x.A G fP a : \u00b5x.A G fP [\u00b5x.A/x]A : * TUN RO L L G fP unroll \na : [\u00b5x.A/x]A Figure 2. Typing: variables, functions, and datatypes (rules for Nat omitted)  call f \ntakes an extra argument proving that it is being applied to the predecessor of the initial argument x. \nThis ensures termination. When beta-reducing such an expression, this argument is ignored by wrapping \nthe function in an extra lambda (rule SIN D from Fig\u00adure 1). The rule for function application, TAPP, \ndiffers from the usual application rule in pure dependently-typed languages in the addi\u00adtional third \npremise G f. [a/x]B : s, which checks that the re\u00adsult type is well-formed. Some rules of the language \n(such as \u00df\u00adreduction) are sensitive to whether terms are values. Because values include variables, substituting \nan expression a for a value x could cause B to no longer type check. Any dependently typed language that \ncombines pure and effect\u00adful code will likely have to restrict the application rule in some way. Previous \nwork [18, 21, 38] uses a more restrictive typing for applications, by splitting it into two rules: one \nwhich permits only value dependency and requires the argument to be a value, and one which allows a non-dependent \nfunction to be applied to an arbitrary argument. Since substituting a value can never violate a value \nre\u00adstriction in B, our application rule subsumes the value-dependent version. Likewise, in the case of \nno dependency, the premise can never fail because the substitution has no effect on B. Being able to \ncall dependent functions with non-value argu\u00adments is useful when writing explicit proofs. For example, \na pro\u00adgrammer may want to .rst prove a lemma about addition log plus_zero : (n:Nat) . plus n 0 = n and \nthen instantiate the lemma to prove a theorem about a particular expression in the logical fragment. \nplus_zero (f x) : plus (f x) 0 = (f x) The rules for sum types (TSUM, TIN L, TIN R, and TSCASE) provide \ndependent case analysis. The term scase binds the logical variable z inside both branches of the case. \nThis variable provides an equality between the scrutinee and the pattern of the branch so that type checking \nis .ow-sensitive. At runtime, this variable is replaced by re. because the scrutinee must match the pattern \nfor the branch to be taken. The rules for dependent products (TSI G M A, TPA I R, TPCASE) allow the type \nof the second component of the pair to depend on the value of the .rst component. As with function application, \nthe premise G f. [a/x]B : * ensures that substituting the expression a does not violate any assumptions \nmade about the value x in the type of the second component. Analogously to sums, the eliminator for pairs \nmakes available a logical proof z that equates the scrutinee to the pattern in the body of the match. \nThe availability of this equality means that the strong elimination forms (projections) for S-types are \nderivable. Finally, the rules TMU, TRO LL and TUN RO LL deal with general recursive types. These are \nthe standard rules for iso\u00adrecursive types (see, e.g., [30]). But recursive types with negative occurrences \nthat is, with the recursive variable appearing to the left of an arrow, such as \u00b5x.(x . Nat) are a potential \nsource of nontermination. To ensure normalization, it suf.ces to restrict the the elimination rule TUN \nRO L L to be in P. The introduction rule TRO LL can be used in both fragments. This re.ects the fact \nthat it is not dangerous to construct negative datatype values; the potential nontermination comes from \ntheir elimination.  2.2 Reasoning about equivalence A big bene.t of combining termination-checking with \ndependent types is that it is possible to write proofs about programs. For ex\u00adample, in the introduction \nwe showed a proof that when the divisor is not zero, natural number division produces a result less than \nthe G fP a : A G fP b : B G f. a : A G fL a = b : * TEQ a .* c b .* c G f.1 a : A G f.2 b : B TRE FL \n G fL re. : a = b G fL b : b1 = b2 G f. a : [b1/x]A G f. [b2/x]A : * TCON V G f. a : [b2/x]A Figure 3. \nTyping: equality dividend. Our rules for propositional equality (Figure 3) are de\u00ad signed to support \nsuch reasoning uniformly, based only on the run\u00adtime behavior of the expressions being equated, and independent \nof the fragment that they are de.ned in. Therefore, the rule TEQ shows that the type a = b is well\u00adformed \nand in the logical fragment even when a and b can be type checked only programmatically. This is freedom \nof speech: proofs can refer to nonterminating programs. The term re. is the primitive proof of equality. \nRule TRE FL says that re. is a proof of a = b just when a and b reduce to a common expression. The notion \nof reduction used in the rule is parallel reduction, denoted a . b. This relation extends the ordinary \nevaluation a b by allowing reduction under binders, e.g. (.x.1 + 1) . (.x.2) even though (.x.1 + 1) is \nalready a value. Having this extra .exibility makes equality more expressive and simpli.es the proof \nof preservation. Proven equalities are used to substitute expressions in types by the elimination rule \nTCONV. The proof term is checked in L to ensure it is a valid proof. We demand that the equality proof \nused in conversion type checks in the logical fragment for type safety. All types are inhabited in the \nprogrammatic fragment, so if we permitted the user to convert using a programmatic proof of, say, Nat \n= Nat . Nat, it would be easy to create a stuck term. Similar to TAP P, we need to check that b2 does \nnot violate any value restrictions, so the last premise checks the well-formedness of the type given \nto the converted term. Rule TCONV is quite general, and may be used to change some small part of A or \nthe entire type by picking x for A. This treatment of equality is a variant of Sj\u00f6berg et al. [34]. However, \nthat setting did not include a logical sublanguage; instead it enforced soundness by requiring the proof \nterm used in conver\u00adsion to be a value. Uses of TCO N V are not marked in the term because they are not \nrelevant at runtime. Again, types should describe terms without in\u00adterfering with equality; we do not \nwant terms with the same runtime behavior to be considered unequal due to uses of conversion. 3. Interactions \nbetween the fragments What is interesting about .. is how its two fragments interact. In the introduction, \nwe discussed ways in which logical and program\u00admatic terms work together. Below, we discuss the technical \nmachin\u00adery of the type system that supports this interaction. 3.1 Subsumption Every logical expression \ncan be safely used programmatically. We re.ect this fact into the type system by the rule TSUB, which \nsays that if a term a type checks logically, then it will also type check programmatically. For example, \na logical term can always be supplied to a function expecting a programmatic argument. This rule is useful \nto avoid code duplication. A function de.ned in the  G f. a : A G fL a : A G f.1 A : * TSU B TAT G fP \na : A G f. A@.' : * G f. v : A@.' G f. a : A G f.1 A : * G f. A : * TUN BOXVA L TBOX P G f.1 v : A G \nfP a : A@. G fL a : A G fP v : A G f. A : * G fP A : * TBOX L TBOXLV G fL a : A@. G fL v : A@P Figure \n4. Typing: subsumption and internalized consistency clas\u00adsi.cation logical fragment can be used without \npenalty in the programmatic fragment. Subsumption also eliminates duplication in the design of the language. \nFor example, we need only one type a = b to talk about when two programmatic or two logical terms are \nequal. In fact, we can also equate logical and programmatic expressions.  3.2 Internalized Consistency \nClassi.cation To provide a general mechanism for logical expressions to appear in programs and programmatic \nvalues to appear in proofs, we in\u00adtroduce a type that internalizes the typing judgment, written A@.. \nNonterminating programs can take logical proofs as preconditions (with functions of type (x : A@L) . \nB), return them as post\u00adconditions (with functions of type (x : A) . (B@L)), and store them in data structures \n(with pairs of type Sx :A.(B@L)). At the same time, logical lemmas can use @ to manipulate values from \nthe programmatic fragment. The rules for the A@. type appear in Figure 4. Intuitively, the judgment G \nf.1 a : A@.2 holds if the fragment .1 may safely observe that G f.2 a : A. This intuition is captured \nby the three introduction rules. The programmatic fragment can internalize any typing judgement (TBOX \nP), but in the logical fragment (TBOX L and TBOX LV) we sometimes need a restriction to ensure termina\u00adtion. \nTherefore, rule TBOX LV only applies when the subject of the typing rule is a value. (The rule TBOX L \ncan introduce A@. for any . since logical terms are also programmatic). Both introduction and elimination \nof @ is unmarked in the syntax, so the reduction behav\u00adior of an expression is unaffected by whether \nthe type system deems it to be provably terminating or not. For example, a recursive function f can require \nan argument to be a proof by marking it @L, e.g., A@L . B, forcing that argument to be checked in fragment \nL. Similarly, a logical lemma g can be applied to a programmatic value by marking it @P: G fL a : A TBOX \nP G fP f : A@L . B G fP a : A@L TAP P G fP f a : B G fP v : A TBOX LV G fL g : A@P . B G fL v : A@P TAP \nP G fL g v : B Of course, g can only be de.ned in the logical fragment if it is careful to not use its \nargument in unsafe ways. For example, using TCO N V we can prove a lemma of type (n: Nat) . (f: (Nat \n. Nat)@P) . (f (plus n 0) = f n) because reasoning about f does not require calling f at runtime. Mobile \n(A) MAT Mobile (A@.) Mobile (A) Mobile (B) MEQ MSI GM A Mobile (a = b) Mobile (Sx :A.B) Mobile (A) Mobile \n(B) MNAT MSU M Mobile (Nat) Mobile (A + B) G f. a : A G fP v : A G fL A : * Mobile (A) TMVA L G fL v \n: A G f. a : (A1 + A2)@.' G f. B : * G, x :.1 A1, z :L inl x = a f. b1 : B G, x :.1 A2, z :L inr x = \na f. b2 : B TSCA SE G f. scasez a of {inl x . b1; inr x . b2} : B G f. a : (Sx :A1.A2)@.' G f. B : * \n.1 .1 G, x :A1, y :A2, z :L (x, y) = a f. b : B TPCA S E G f. pcasea of {(x, y) . b} : B z Figure 5. \nTyping: mobile types and cross-fragment case expres\u00adsions There is no way to apply a logical lemma to \na programmatic non-value expression. If an expression a may diverge then so may f a, so we must not assign \nit a type in the logical fragment.4 How\u00adever, we can work around this restriction by either .rst evaluating \na to a value in the programmatic fragment or by thunking. The @-types are eliminated by the rule TUN \nB OX VAL. To pre\u00adserve termination, the rule is restricted to apply only to values. Recall the function \nsolver of type prog solver : (n:Nat) . (f:Formula n) . Vector (Maybe Bool) n . (Ans n f)@L In the introduction, \nwe asserted that the following code type checks. let prog isSat = (solver n f empty : Ans n f @L) in \nlet log prf = case isSat of SAT a pf . --... here pf is logical ... UNSAT . --... In this example, the \nlogical program prf cannot directly treat solver n f empty as a proof because it may diverge. However, \nonce it has been evaluated to a value, it can be safely used by the logical fragment. Above, the let \nbinding forces evaluation of the expression solver n f empty, introducing a new program\u00admatic variable \nisSat : Ans n f @ L into the context. Because variables are values, any logical context can freely use \nthe vari\u00adable through TUN B OXVA L even though it was computed by the programmatic language.  3.3 Mobile \ntypes The consistency classi.er tracks which expressions are known to come from a normalizing language. \nFor some types of values, how\u00adever, the rules described so far can be unnecessarily conservative. For \nexample, while a programmatic expression of type Nat may diverge, a programmatic value of that type is \njust a number, so we can treat it as if it were logical. On the other hand, we can not treat 4 This is \none drawback of working in a strict rather than a lazy language. If we know that f is nonstrict, then \nthis application is indeed safe.  a programmatic function value as logical, since it might cause non\u00adtermination \nwhen applied. The rule TMVA L (Figure 5) allows values to be moved from the programmatic to the logical \nfragment. It relies on an auxiliary judgment Mobile (A).. Intuitively, a type is mobile if the same set \nof values inhabit the type when . = L and when . = P. In particular, these types do not include functions \n(though any type may be made mobile by tagging its fragment with @). Concretely, the natural number type \nNat is mobile, as is the primitive equality type (which is inhabited by the single constructor re., as \ndiscussed in Section 2.2). Any @-type is mobile, since it .xes a particular . independent of the one \non the typing judgment. Sum and pair types are mobile if their component types are. Even if a sum type \nis not mobile, it is always safe to do one level of pattern matching on one of its values, since such \na value must start with a constructor. We re.ect that in the rule TSCA S E , which generalizes TSCA S \nE from the previous section. This rule allows a scrutinee that type checks in one fragment . ' to be \neliminated in another fragment .. This lets the logical language reason by case analysis on programmatic \nvalues. Similarly, TPCASE is a more general version of the rule TPCA S E. The two rules shown here are \nthe ones actually included in our formalization. The mobile rule lets the programmer write simpler types, \nbe\u00adcause mobile types never need to be tagged with logical classi.ers. For example, without loss of generality \nwe can give a function the type (a = b) . B instead of ((a = b)@L) . B, since when needed, the body of \nthe function can treat the argument as logical through TMVAL. Similarly, multiple @ s have no effect \nbeyond the innermost @ in a type. Values of type A@P@L@P@L@P can be used as if they had type A@P. In \nfact, the arguments to functions must always have mobile types. This restriction, enforced by rule TAR \nR, means that higher\u00adorder functions must use @-types to specify which fragment their arguments belong \nto. For example, the type (Nat . Nat) . A is not well-formed, so the programmer must choose either ((Nat \n. Nat)@L) . A or ((Nat . Nat)@P) . A. In either case, programmers bene.t from implicit unboxing. For \nexample, checking well-formedness of a type like (f : (Nat . Nat)@P) . f (plus n 0) = f n implicitly \nuses TUN BOX VA L. But the equation still talks about the expression f n. If we instead had to use explicit \nunboxing to eliminate the @-type, as in (unbox f) n, there would be no way to write a logical lemma proving \nthe original equation. By contrast, mobile arguments do not need nor bene.t from tagging. The reason \nthat function arguments must be mobile is to ac\u00adcount for contravariance. Through subsumption, we can \nintroduce a function in the logical fragment and use it in the programmatic: G, x :L A fL b : B TLA M \nG fL (.x.b) : (x : A) . B TSU B G fP (.x.b) : (x :A) . B Here, the de.nition of b assumed x was logical, \nyet when the function is called it can be given a programmatic argument. For this derivation to be sound, \nwe need to know that A means the same thing in the two fragments, which is exactly what Mobile (A) checks. \n4. Metatheory We now describe the metatheory of ... We are interested in two properties. First, that \nthe entire language is type safe, including both the L and P fragments. Second, that any closed term \nin the L fragment normalizes, which implies logical consistency. Type safety is proven using standard \nprogress and preservation theorems. Since the rules TCO N V and TCON TR A allow stuck terms to type check \ngiven a contradiction, the progress theorem depends on logical consistency. For this reason, we .rst \nprove preservation, then normalization and consistency, and .nally progress. The theorems in this paper \nhave been checked in Coq. To prove certain facts about our logical relation we needed a standard axiom \nof functional extensionality. This axiom is known to be consistent with Coq s logic [41]. 4.1 Preservation \nAs usual, the preservation proof relies on weakening, substitution and inversion lemmas. The weakening \nlemma is standard. Due to the value restrictions in the type system, the substitution lemma is restricted \nto values: .1 B, G2 f. LEM M A 1 (Substitution). If G1, x :a : A and G1 f.1 v : B, then G1, [v/x]G2 f. \n[v/x]a : [v/x]A. However, our inversion lemmas are more complicated than usual, because one of the design \ngoals of .. is that typing rules without runtime effects should not require annotation. In particular, \nuses of TCONV and TBOX P/L/LV are not marked. For example, consider inversion for .-expressions. Usually, \nit is the case that if G f (.x.b) : A, then A is \u00df-convertible with some arrow type (x : B1) . B2 and \nG, x : B1 f b : B2. In .. this is not true: if there were a hypothesis (x :L (Nat . Nat) = Nat) . G, \nthe expression could also have been given type Nat using TCO N V. (Restricting preservation to empty \ncontexts would not help, since at this point in the proof before proving consistency we cannot rule out \nthat this equality is provable). Alternatively, if the BOX rules were used, A may be an @-type. Taking \nthis into account, our inversion lemma reads: LEM M A 2 (Inversion for .-expressions). If G f. (.x.b) \n: B, then there is some p and (x :B1) . B2 such that either 1. G fL p : B = ((x : B1) . B2) and G, x \n:. B1 f. b : B2, 2. or there are some . ' . . . . '' such that G fL p : B = (((x : B1) . B2)@. ' . . \n. @. '' ) and G, x :.1 B1 f.1 b : B2.  With this and other similar inversion lemmas, we can prove preser\u00advation. \nTH E O R E M 3 (Preservation). If G f. a : A and a a ', then G f. a ' : A. The proof of the preservation \ntheorem requires the addition of type constructor discrimination and injectivity rules (Figure 6) to \nthe type system. The discrimination rule TCO N T RA eliminates contradictory equalities. If we can prove \na contradiction we must be in unreachable code, so we allow giving any typeable expression a any wellformed \ntype B at any . ' . An equation B1 = B2 counts as contradictory if the head forms of both sides are de.ned \nand unequal. The head form of a type is its outermost constructor. For example, the head form of (x :A) \n. B is ., and the head form of Nat is Nat. The complete de.nition of hd(A) appears in the companion technical \nreport. The injectivity rules invert equality proofs between type forms. For example, from a proof G \nfL p : ((x : A1) . A2) = ((x : B1) . B2) we can also derive G fL p : A1 = B1. Similar typing rules are \navailable for @, sum and pair types. These are elided here for space, but included in the technical report. \nThese rules are necessitated by the weak inversion lemmas. Consider, e.g., the case when a function application \nbeta reduces, (.x.b) v [v/x]b. From the premises of the rule TAP P we know that G f. (.x.b) : (x : A1) \n. A2 and G f. v : A1, and from  G f. a : A G f. a : ((x : A1) . A2) = ((x :B1) . B2) G f. A1 = B1 : \n* G f. a : A1 = B1 G f. a : ((x : A1) . A2) = ((x :B1) . B2) G f.1 v : A1 G f. [v/x]A2 = [v/x]B2 : * \nG f. a : [v/x]A2 = [v/x]B2 G fL a1 : B1 = B2 hd(B1) = hd(B2) G f. a : A G f. A : * G f.1 B : * TARRINV1 \nTCONTRA G f.1 a : B TARRINV2 Figure 6. Typing: discrimination and injectivity of type constructors (injectivity \nrules for @-, \u00b5-, pair-and sum-types omitted). inversion we know either G fL p : ((x : A1) . A2) = ((x \n: B1) . B2) and G, x :. B1 f. b : B1, or else (x : A1) . A2 is provably equal to an @-type. In the .rst \ncase we apply the substitution lemma, using TARRINV1 to prove A1 = B1, while in the second case we use \nTCONTRA.  4.2 Normalization and Progress Our proof of normalization builds upon the standard Girard-Tait \nreducibility method [17, 39] in a CBV-style formulation. The crux of this method is to de.ne a type interpretation \n. For each type that check in fragment . (the Intuitively, G |= k . asserts that . maps term variables \nto well\u00adbehaved values. Because of the premise G f. A : * it also asserts that G does not contain any \ntype variables. This is vacuously true for the empty context, and preserved by each case of the type \ninterpretation. In a normalization proof for System F or for CC [16], the type interpretation would take \nan input . which speci.es the interpreta\u00adtion of type variables in A, but not one which speci.es the \nvalues of term variables. Since we do not have polymorphism in our lan\u00adguage, we do not need to account \nfor type variables. But unlike CC, because of the primitive equality type we can not just ignore additional \ninputs . and k are discussed below). The de.nition of .we de.ne a set of values VA [ A] .k term variables \nin types. Our . is similar to normalization proofs for systems that have large elimination of datatypes, \nsuch as CIC [43]. the type interpretation (Figure 7) is a logical relation and follows The soundness \ntheorem relies on a few key lemmas about the the structure of A. interpretation. The .rst is a standard \ndownward closure property Our main theorem is that the interpretation is sound : any for step-indexed \nrelations: it says that requiring values to stay well-behaved for a larger number of steps creates a \nmore precise Lclosed logical expression of type reduces to a value in VA [ A] a .kThe rules TUVand TMVcan \nmove values from toPNBOX AL AL . .L4. For any and , if then= VEMMA A. .j k [ A] , .k interpretation. \nL, so for the proof to go through we must generalize the soundness theorem to also characterize expressions \nin P. For these values we j . V.[ A] . . The next two lemmas are speci.c to .. because they relate the \nL . prove a partial correctness property: if a closed programmatic ex- Ppression of type reduces to a \nvalue, then the value is in VA [ A] a .k These invariants are summarized by a computational type interpre-and \nP interpretations of a type. They are used to handle the TSUB The type interpretation for programmatic \nexpressions must ac\u00ad .tation C[ A] .k , which identi.es sets of (non-value) expressions, and and TMVAL \nrules, respectively. The .rst says that the set of logical .is de.ned mutually with V [ A] .k L PVV[ \nA] [ A] . .k k . values is a subset of the corresponding programmatic sets. LEMMA 5. For any A, k, . \nand ., and . count for recursive functions and recursive types, which means . L PC. C[ A] [ A] . .k k \nThe second says that for mobile types, the reverse containment that it cannot be de.ned by recursion \non A. Instead, we use step\u00adindexing [1, 5]. The interpretation is indexed by a number k. Any Pvalue in \nV [ A] v .k will be well-behaved for at least k steps of also holds. For these types, the interpretations \ncontain the same execution. The interpretation is de.ned by well-founded recursion values in both fragments. \non the lexicographically ordered triple (k, A, I), where I is one of PV[ A] .k LV[ A] .k tation only \nlends itself to proving safety properties it tells us that Finally, for the TCONV rule, we need equal \ntypes to have the same an expression will not do anything bad for the next k steps. By con\u00adinterpretation. \n trast, normalization is a liveness property: every expression will eventually do something good (namely \nreduce to a value). In our LEMMA 7. Suppose . B1 * A and . B2 * A and G f. B1 : * LEMMA 6. For any k \nand ., if Mobile (A) then . C or V with V < C. However, the usual formulation of a step-indexed type \ninterpre\u00ad . and G f. . . . Then iff. I. I.[ B] [ B] a a. 1 . 2k k We can now prove soundness by induction \non G f. a : A. Normal\u00adde.nition, we take a hybrid approach by only counting steps that B2 : * and G |= \nk . happen in the P fragment. The difference can be seen by compar- L Ping the de.nitions of andV. V.[[(A) \nB] [[(A) B] : :x x. .k k which say j = k and j < k respectively. If all .s in a deriva\u00ad, ization is an \nimmediate corollary. We also get a characterization of which terms can be proven equal in the empty context. \nWe needtion are L, then no inequalities are strict, so the step-count k never such a characterization \nto prove progress. f. THEOREM 8 (Soundness). If G a : A and G |= k ., then . a . C.[ A] . needs to decrease. \nThe input . is a substitution mapping free variables of A to values. We use . when interpreting equality \ntypes. The type a1 = . k COROLLARY 9 (Normalization). a2 is interpreted as the singleton set {re.} if \n. a1 and . a2 parallel\u00adreduce to a common expression, and as the empty set otherwise. k We inductively \nde.ne the judgment G |= k ., which asserts that . If \u00b7 fL a : A, then there exists a value v such that \na * v. maps to values in the correct interpretation, by COROLLARY 10 (Soundness of propositional equality). \n v . V.[ A] . * G f. A : * If \u00b7 fL a : A1 = A2, then there exists some A such that A1 G |= k . A ENIL \n ECONS * and A2 A. \u00b7 |= k \u00d8 G, x :. A |= k .[x . v]  V.[ *] . = {v | \u00b7 f. v : *} k V.[ Nat] . k = {v \n| v is of the form Sn Z} V.[ A@. ' ] . k = {v | \u00b7 f.1 . A : * and v . V.[ A] .k 1 } V.[[(x : A) . B] \nL k = {.x.b | \u00b7 fL .x.b : . ((x : A) . B) and .j = k, if v . V.[ A] L j then [v/x]b . C.[x .v][ B] L \nj } . {ind f x.b | \u00b7 fL ind f x.b : . ((x :A) . B) and .j = k, if v . V.[ A] L j then [v/x][.y..z.(ind \nf x.b) y/f ]b . C.[x .v][ B] L j } V.[[(x : A) . B] P = {.x.b | \u00b7 fP .x.b : . ((x : A) . B) k and .j \n< k, if v . V.[ A] P j then [v/x]b . C.[x .v][ B] j P} . {rec f x.b | \u00b7 fP rec f x.b : . ((x :A) . B) \nand .j < k, if v . V.[ A] P j then [v/x][rec f x.b/f ]b . C.[x .v][ B] P j } . {ind f x.b | \u00b7 fP ind \nf x.b : . ((x :A) . B) and .j < k, if v . V.[ A] P j then [v/x][ind f x.b/f ]b . C.[x .v][ B] P j } V.[ \nA + B] . k = {inl v | \u00b7 f. . (A + B) : * and v . V.[ A] . k }. {inr v | \u00b7 f. . (A + B) : * and v . V.[ \nB] . k } V.[[Sx :A.B] . = {(v1, v2) | \u00b7 f. . (Sx :A.B) : * and v1 . V.[ A] . and v2 . V.[x .v1][ B] k \n. } V.[ \u00b5x.A] .1 = {roll v | \u00b7 f.1 roll v : . (\u00b5x.A) and .j < k, v . V.[[[\u00b5x.A/x]A] . j } k k k V.[ \na1 = a2] . = {re. | \u00b7 f. . (a1 = a2) : * and . a1 * a and . a2 * a for some a} V.[ A] . k = \u00d8 otherwise \nk C.[ A] P k = {a | \u00b7 fP a : . A and .j = k, if a j v then v . V.[ A] P } (k-j) C.[ A] L k = {a | \u00b7 \nfL a : . A and a * v . V.[ A] L k } Figure 7. Type interpretation Normalization holds only for closed \nterms. This is a result of the fact that uses of the TCONV rule are unmarked in the syntax. It is possible \nto assume a contradictory equality and use it to typecheck a non-terminating term in the logical fragment. \nFor example, the following statement is derivable: y : L Nat = (Nat . Nat) fL (.x.x x) (.x.x x) : Nat \nThis distinguishes .. from intensional type theories like Coq and Agda. In those systems, our rule TCONV \narises as the pattern\u00admatching elimination form for a de.ned equality datatype. Uses of this eliminator \nwould appear in the term above, and their reduction would get stuck on the variable y, since it does \nnot reduce to the appropriate constructor. The bene.t of giving up normalization of open terms is a more \ngenerous equality. Since uses of conversion appear in terms in Coq and Agda, they often get in the way \nof judging two terms which use such conversions equal. In our system, this can not happen. The drawback \nis that the typechecker can not automatically normalize expressions (since they may diverge), so uses \nof refl must be ex\u00adplicit and annotated with a maximum step count. However, in a lan\u00adguage with general \nrecursion some explicit proofs are unavoidable, since checking a logical term can involve reducing a \nprogrammatic term that appears in its type. Since our language must accommodate such proofs in any case, \nmaking conversion unmarked is appealing. The progress theorem relies on a canonical forms lemma (elided). \nIn the TCONV and TCONTRA cases we need to know that there are no proofs of inconsistent equalities such \nas (Nat . Nat) = Nat. Therefore, this lemma relies on Corollary 10. The progress theorem is then an easy \ninduction on \u00b7 f. a : A. Surface language (Zombie) . (elaboration) Annotated language (ZT derivations) \n. (erasure) Core language (ZT) Figure 8. Implementation THEOREM 11 (Progress). If \u00b7 f. a : A, then either \na is a value, or there exists a ' such that a a ' . 5. Implementation We have implemented a prototype \ndependently-typed language, called Zombie, based on .. . We have used this implementation to gain experience \nwith the features described in this paper. Indeed, all of the example code in this paper can be type-checked \nby our implementation. These, and other examples are available for download. Our language includes several \nfeatures which were left out of .. to keep the normalization proof simple. Instead of a single sort *, \nZombie includes a full predicative hierarchy [22], which al\u00adlows both polymorphism and type-level functions. \nWe also include a general form for parameterized recursive datatypes, which sub\u00adsumes Nat, A + B, Sx \n: A.B and \u00b5x.A. Datatypes are always mobile, and Zombie provides structural induction for all strictly \npositive datatypes (not just Nat) following [20]. Finally, Zombie distinguishes between computationally \nrelevant and irrelevant ar\u00adguments [24], and includes a multiplace conversion operator, called multiconversion \n[34].  Adding these features to .. would complicate the type interpre\u00adtation, increasing the complexity \nof our machine-checked proof far beyond its current state. In particular, to add predicative polymor\u00adphism \nand type-level computation we would have to rede.ne our type interpretation as an induction over typing \nderivations, which is very painful to do in Coq. However, based on work in progress, we are optimistic \nthat the metatheoretic requirements of these ad\u00additional features will have little interaction with the \nfundamental consistency mechanism proposed here. The general structure of our implementation appears \nin Fig\u00adure 8. The part of our implementation that most closely resem\u00ad bles .. is the internal language \nZT. This language de.nes the op\u00aderational behavior of Zombie expressions. However, like .., type checking \nis not decidable for ZT expressions. Therefore, the imple\u00admentation also includes an annotated version \nof ZT that supports syntax-directed type checking, an approach we have explored in previous work [34]. \nAnnotated ZT is a direct representation of ZT typing derivations, marking all uses of conversion, subsumption, \ncumulativity, and coercion to and from A@. types. Furthermore, because reduction may not terminate, annotations \non re. control and limit the search for a common reduct when proving that two terms are equal. Directly \nworking with ZT derivations incurs a considerable an\u00adnotation burden for programmers. Therefore, the \nZombie surface language makes these annotations optional. We are currently exper\u00adimenting with a number \nof elaboration strategies to infer these an\u00adnotations. These include using bidirectional type checking \n[31] to propagate type information through terms, uni.cation to automati\u00adcally infer some dependent arguments, \nand congruence closure [27] to automatically infer equality proofs used in conversions. For example, \nconsider the projection functions (fst and snd) for dependent pairs shown below. These functions pattern \nmatch their argument and return its .rst and second components respec\u00adtively. data Sigma (A:Type) (B:A \n. Type) : Type where Pair of (x:A) (y : B x) log fst : [A:Type] . [B:A . Type] . Sigma A B . A fst [A] \n[B] p = case p of Pair x y . x log snd : [A:Type] . [B:A . Type] . (p:Sigma A B) . B (fst p) snd [A] \n[B] p = case p of Pair x y . unfold (fst p) in y In the implementation of snd, uni.cation can infer the \narguments A and B to fst (which were marked inferable by the fat arrow .in the declaration of fst). Because \nnot all expressions terminate, the pro\u00adgrammer must explicitly ask the type checker to unfold (fst p) \nby \u00df-reduction, which introduces the equation (fst p) = x into the context. That equation is then automatically \nused to convert the type of y from B x to B (fst p). The examples we have implemented fall into two categories. \nThe .rst includes the division and SAT-solving programs described in Section 1. These examples illustrate \nhow one can write proofs about general recursive programs, and how general recursive pro\u00adgrams can return \nproofs. Second, we have implemented functions for length-indexed lists (Vectors), .nite sets represented \nas binary search trees, and data compression using run-length encoding, to\u00adgether with proofs of their \ncorrectness. Since these functions use simple structural recursion, they can be done entirely in the \nlogi\u00adcal fragment. They show that although our core language requires annotations on re. and conv, the \noverhead of these annotations is manageable. 6. Related Work In previous work, we introduced the proof \ntechnique of hybrid step-indexed/traditional logical relations, but for a simply-typed language [12]. \nThis paper extends the normalization proof to a more expressive type system with dependent function types, \nan equality type, and conversion. It also improves the treatment of @\u00adtypes by making them implicit. \nThis change complicates the meta\u00adtheory (see Lemma 2) but makes the language more expressive and simpli.es \nthe application rule. Terminating Sublanguage. There are other dependently-typed languages which allow \ngeneral recursion but identify a sublanguage of terminating expressions. Aura [18] and F* [38] do this \nusing the kind system: expressions whose type has kind Prop are checked for normalization. Types can \ncontain values but not non-value expres\u00adsions, so there is no way to write separate proofs about programs. \nThere also is no facility to treat programmatic values as proofs, e.g. a logical case expression cannot \ndestruct a value from the nonter\u00adminating fragment. ATS [13], GURU [36], and Sep3 [20] are dependently-typed \nlanguages where the logical and programmatic fragments are syn\u00adtactically separate in effect rejecting \nthe rule TSU B. One of the gains of this separation is that the logical language can be made CBN even \nthough the programmatic one is CBV, avoiding the need for thunking (as discussed in Section 3.3). To \ndo inductive reason\u00ad ing, the Sep3 language adds an explicit terminates predicate. Idris [10] is a full-spectrum \ndependently typed programming language that permits non-total de.nitions. Internally, it applies a syntactic \ntest to check if function de.nitions are structurally de\u00adcreasing, and programmers may ask whether particular \nde.nitions have been judged total. The type checker will only reduce expres\u00adsions that have been proved \nterminating, again precluding separate equational reasoning about partial programs. Idris metatheory \nhas not been studied formally. Partiality Monad. Capretta s partiality monad [11] uses coin\u00ad ductive \ntypes to embed general recursion into Type Theory. This approach treats pure functions as the default \nand nontermination less conveniently. Nonterminating programs must be written using monadic combinators \n(and are therefore never syntactically equal to pure programs). The partiality monad provides recursive \nfunc\u00adtion de.nitions but not general recursive types. Furthermore, the coinductive approach requires \na separate no\u00adtion of equivalence to reason about partial programs. In, e.g., Coq, one would compare \npure expressions according to the standard op\u00aderational semantics, but de.ne a coarser equivalence relation \nfor partial terms that ignores the number of steps they take to nor\u00admalize. Equations like ((rec f x \n.b) v) = [v/x][rec f x .b/f ]b do not hold with the usual Coq equality because the step counts differ. \nConveniently programming with equivalence relations like this, which are not directly justi.ed by the \nreduction behavior of expressions, is an active area of research involving topics such as setoids [8], \nquotient types, and the univalence axiom [42]. Non-constructive .xpoint semantics. The work of Bertot \nand Komendantsky [9] describes a way to embed general recursive functions into Coq that does not use \ncoinduction. They de.ne a datatype partial A that is isomorphic to the usual Maybe A but is understood \nas representing a lifted CPO A., and use classical logic axioms to provide a .xpoint combinator .xp. \nWhen de.ning a recursive function the user must prove continuity side-conditions.  Since recursive functions \nare de.ned nonconstructively they can not be reduced directly, so instead one must reason about them \nusing the .x-point equation. Partial Types. Nuprl has at its core an untyped lambda calculus, capable \nof de.ning a general .xed point combinator for de.ning re\u00adcursive computations. In the core type theory, \nall expressions must be proven terminating when used. Constable and Smith [14] inte\u00ad grated potentially \nnonterminating computations through the addi\u00adtion of a type A of partial terms of type A. The .xpoint \nopera\u00adtor then has type (A . A) . A. However, to preserve the con\u00adsistency of the logic, the type A must \nbe restricted to admissible. types. Crary [15] provides an expressive axiomatization of admissi\u00ad ble \ntypes, but these conditions lead to signi.cant proof obligations, especially when using S-types. Smith \n[35] provides an example which shows that Nuprl needs this restriction. Writing a . for a terminates \n, de.ne a S-type T of functions which are not total, and recursively de.ne a p which inhabits T . Total \n(f : N . N) def = (n : N) . (f n) . T def = S(f : N . N).Total f . False (p : T ) g def = def = .x (.p.(g, \n.h. )) .x.if x = 0 then 0 else p1(p)(x - 1) Here the dash is an (elided) proof which sneakily derives \na con\u00adtradiction using p2(p) and the hypothesis h that g is total. On the other hand, a separate induction \nshows that p1(p) is total; it returns 0 for all arguments. This is a contradiction. .. has almost all \nthe ingredients for this paradox. Instead of a recursively de.ned pair we can use a recursive function \nUnit . T , and we can encode a. as S(y : A).a = y. What saves us is that the proof in the second component \nof p uses the following reasoning principle: if p1(p) terminates, then p terminates. In Nuprl a . is \na primitive predicate and this inversion principle is built in. But using our encoding, a function (p1(p) \n.) . (p .) would have to magically guess the second component of a pair knowing only the .rst component. \nIf we assume this function as an axiom we can encode the paradox and derive inconsistency , so our consistency \nproof shows that there is no way to write such a function. Hoare Type Theory. HTT [26, 37] is another \nembedding of gen\u00ad eral programs into a type theory like Coq, which goes beyond non\u00adtermination to also \nhandle memory effects. Instead of a unary type constructor A, it adds the indexed type {P }x : A{Q} representing \nan effectful computation returning A and with pre-and postcondi\u00adtions P and Q. The assertions P and Q \ncan use all of Coq, so the type of a computation can specify its behavior precisely. However, computations \ncan not be evaluated during type checking (the .x\u00adpoint combinator and memory access primitives are implemented \nas Coq axioms with types but no reduction rules). Fixpoint induction Domain-theory based formalisms provide \ntwo basic reasoning principles for proving properties about re\u00adcursive functions: unfolding a function \nde.nition, and .xpoint in\u00adduction. The latter principle (see e.g. [44]) states that to prove a property \nabout a function, one may assume it as an induction hy\u00adpothesis for the recursive calls of the function. \nFor this to be valid, the property must be admissible , and it most hold for in.nite loops. An equivalent \nvariant [9] is to allow induction on the num\u00ad ber of recursive steps an expression takes to normalize. \n.. currently provides no such principle. If a theorem can not be proved just from unfolding, there are \ntwo ways to proceed. In order to prove div_le in Section 1 we used (strong) natural-number induction. \nFor this strategy to work the programmer has to .nd a termination metric for the function in question, \nso it only works for functions that are in fact terminating. However, it can still be convenient to give \na direct recursive de.nition of the function. For functions that genuinely do not terminate, one can \ninstead change them to return a S-type asserting the property, so that the property is automatically \navailable for recursive calls. This is what we did for solver in Section 1, and it is the only option \nin Hoare Type Theory. Modal types for distributed computation. Modal logic reasons about statements whose \ntruth varies in different possible worlds . Our type system is formally similar, with the possible worlds \nbeing L and P. Modal logic has previously been used to design type systems for distributed computation \n[19, 25]. In particular, .. was inspired by ML5 [25], in which the typing judgment is indexed by what \nworld (computer in a distributed system) a program is running on, and which includes a type A@. internalizing \nthat judgment. Our rule TMVA L is similar to the GET rule in ML5, and our Mobile (A) is similar to the \njudgment A mobile in ML5. On the other hand, unlike .., ML5 does not require that the domain of an arrow \ntype be mobile. As we explained in Section 3.1 we make that restriction to accommodate our rule TSU B, \na rule which does not make sense in the context of distributed computation. 7. Future work In future \nwork, we hope to extend the metatheory of .. to include more of ZT. We plan to allow polymorphic types \nand type-level functions in both the L and P fragments, extending our proof us\u00ading ideas from normalization \nproofs for the Calculus of Construc\u00adtions [16]. Following the ideas of Ahn and Sheard [2] and their language \nNax [3], we also hope to add combinators to de.ne re\u00ad cursive functions over recursive data to the logical \nlanguage. Nax places no restriction on what sorts of datatypes can be de.ned or how they can be constructed. \nInstead, it limits the analysis of data structures to ensure the soundness of the logic. More generally, \nwe would like to extend our proofs to a general theory of datatype def\u00adinitions, maybe encoded via recursion, \nsums, and products as in .S [4]. One potential worry is that we assume injectivity for all type constructors, \nwhich can be used to encode Cantor-like para\u00addoxes. We hope to avoid inconsistency by forbidding impredicative \npolymorphism and datatypes with large indices. Adding these features will require substantial additional \nwork in the normalization proof, but we do not anticipate any changes to the novel typing rules that \nconnect the L and P fragments. Reasoning about general recursive functions Currently .. em\u00adphasizes lightweight \nveri.cation. In order to turn it into a tool for full veri.cation of potentially nonterminating programs, \nwe would add stronger reasoning principles. First, the value restrictions in can get in the way of equational \nreasoning. If a is an expression in P there is no way to prove an equation like (let x = a in f x) = \n(f a), even though the two sides are in fact contextually equivalent. To make it provable we could add \ntermination-case a case analysis on whether a programmatic expression evaluates to a value or diverges \n[20]. Unfortunately, this operator is unimplementable, so we would not want to allow proofs that use \nthis reasoning to be used as programs. One solution is to introduce a new consistency classi.er O, for \noracular, in addition to L and P. By not allowing O expressions to be used as programs, we could control \nand track the use of termination case. Second, we would like to investigate whether some (perhaps weakened) \nform of .xpoint induction can be consistently added. The experience with partial types in Nuprl suggests \nthat this may require a notion of admissible predicates.  8. Conclusion This paper presents a framework \nfor interacting logics and pro\u00adgramming languages. The consistency classi.ers, ., describe the set of \ntyping rules that determine the properties of each well-typed expression. At the same time, many standard \ntyping rules are poly\u00admorphic in this classi.er, leading to uniformity between the sys\u00adtems. Internalizing \nthis judgment as a type and observing that some values can move freely allows the fragments to interact \nin nontriv\u00adial ways, leading to an expressive foundation for dependently-typed programming. Acknowledgments \nThis material is based upon work supported by the National Science Foundation under Grant Nos. 0910500 \nand 1116620. The Zombie implementation was developed with the assistance of the Trellys team, and the \nideas in this paper bene.tted greatly from that col\u00adlaboration. This paper was written with the help \nof the excellent Ott tool [32]. The authors would also like to thank the anonymous reviewers for their \nconsidered and helpful comments. References [1] Ahmed, A.: Step-indexed syntactic logical relations for \nrecursive and quanti.ed types. In: ESOP 06: European Symposium on Program\u00adming. LNCS, vol. 3924. Springer \n(2006) [2] Ahn, K.Y., Sheard, T.: A hierarchy of mendler style recursion com\u00adbinators: taming inductive \ndatatypes with negative occurrences. In: ICFP 11: International Conference on Functional programming. \npp. 234 246. ACM (2011) [3] Ahn, K.Y., Sheard, T., Fiore, M., Pitts, A.M.: The Nax programming language \n(work in progress) (2012), talk presented at IFL 2012: the 24th Symposium on Implementation and Application \nof Functional Languages [4] Altenkirch, T., Danielsson, N.A., L\u00f6h, A., Oury, N.: .S: Dependent types \nwithout the sugar. Functional and Logic Programming pp. 40 55 (2010) [5] Appel, A.W., McAllester, D.: \nAn indexed model of recursive types for foundational proof-carrying code. ACM Trans. Program. Lang. Syst. \n23(5), 657 683 (2001) [6] Augustsson, L.: Cayenne a language with dependent types. In: ICFP 98: International \nConference on Functional Programming. pp. 239 250. ACM (1998) [7] Barendregt, H.P.: Lambda calculi with \ntypes. In: Abramsky, S., Gab\u00adbay, D.M., Maibaum, T.S.E. (eds.) Handbook of Logic in Computer Science. \npp. 117 309. Oxford University Press (1992) [8] Barthe, G., Capretta, V., Pons, O.: Setoids in type theory. \nJournal of Functional Programming 13(2), 261 293 (2003) [9] Bertot, Y., Komendantsky, V.: Fixed point \nsemantics and partial re\u00adcursion in coq. In: PPDP 08: Principles and practice of declarative programming. \npp. 89 96. ACM (2008) [10] Brady, E.C.: Idris systems programming meets full dependent types. In: PLPV \n11: Programming languages meets program veri.cation. pp. 43 54. ACM (2011) [11] Capretta, V.: General \nrecursion via coinductive types. Logical Meth\u00adods in Computer Science 1(2), 1 18 (2005) [12] Casinghino, \nC., Sj\u00f6berg, V., Weirich, S.: Step-indexed normalization for a language with general recursion. In: MSFP \n12: Mathemati\u00adcally Structured Functional Programming. EPTCS, vol. 76, pp. 25 39 (2012) [13] Chen, C., \nXi, H.: Combining programming with theorem proving. In: Proceedings of the tenth ACM SIGPLAN international \ncon\u00adference on Functional programming. pp. 66 77. ICFP 05, ACM, New York, NY, USA (2005), http://doi.acm.org/10.1145/ \n1086365.1086375 [14] Constable, R.L., Smith, S.F.: Partial objects in constructive type the\u00adory. In: \nLogic in Computer Science (LICS 87). pp. 183 193. IEEE (1987) [15] Crary, K.: Type Theoretic Methodology \nfor Practical Programming Languages. Ph.D. thesis, Cornell University (1998) [16] Geuvers, H.: A short \nand .exible proof of Strong Normalization for the Calculus of Constructions. In: TYPES 94. LNCS, vol. \n996, pp. 14 38 (1995) [17] Girard, J.Y.: Interpr\u00e9tation fonctionelle et \u00e9limination des coupures de l \narithm\u00e9tique d ordre sup\u00e9rieur. Ph.D. thesis, Universit\u00e9 Paris VII (1972) [18] Jia, L., Vaughan, J.A., \nMazurak, K., Zhao, J., Zarko, L., Schorr, J., Zdancewic, S.: AURA: A programming language for authorization \nand audit. In: ICFP 08: International Conference on Functional Programming). pp. 27 38. ACM (2008) [19] \nJia, L., Walker, D.: Modal proofs as distributed programs (extended abstract). In: ESOP 04: European \nSymposium on Programming. LNCS, vol. 2986, pp. 219 233. Springer (2004) [20] Kimmell, G., Stump, A., \nEades III, H.D., Fu, P., Sheard, T., Weirich, S., Casinghino, C., Sj\u00f6berg, V., Collins, N., Ahn, K.Y.: \nEquational reasoning about programs with general recursion and call-by-value semantics. In: PLPV 12: \nProgramming languages meets program veri.cation. ACM (2012) [21] Licata, D.R., Harper, R.: Positively \ndependent types. In: PLPV 09: Programming languages meets program veri.cation. pp. 3 14. ACM (2008) [22] \nLuo, Z.: Computation and Reasoning: A Type Theory for Computer Science. Oxford University Press, USA \n(1994) [23] McBride, C., McKinna, J.: The view from the left. J. Funct. Program. 14(1), 69 111 (2004) \n[24] Miquel, A.: The implicit calculus of constructions -extending pure type systems with an intersection \ntype binder and subtyping. In: TLCA 01: Proceeding of 5th international conference on Typed Lambda Calculi \nand Applications. LNCS, vol. 2044, pp. 344 359. Springer (2001) [25] Murphy, VII, T., Crary, K., Harper, \nR.: Type-safe distributed program\u00adming with ML5. In: Trustworthy Global Computing 2007 (2007) [26] Nanevski, \nA., Morrisett, G., Shinnar, A., Govereau, P., Birkedal, L.: Ynot: dependent types for imperative programs. \nIn: ICFP 08: Inter\u00adnational Conference on Functional Programming. pp. 229 240. ACM (2008) [27] Nieuwenhuis, \nR., Oliveras, A.: Fast congruence closure and exten\u00adsions. Inf. Comput. 205(4), 557 580 (2007) [28] Norell, \nU.: Towards a practical programming language based on de\u00adpendent type theory. Ph.D. thesis, Chalmers \nUniversity of Technology (2007) [29] Peyton-Jones, S., Vytiniotis, D., Weirich, S., Washburn, G.: Simple \nuni.cation-based type inference for GADTs. In: ICFP 06: Inter\u00adnational Conference on Functional Programming. \npp. 50 61. ACM (2006) [30] Pierce, B.C.: Types and Programming Languages. MIT Press (2002) [31] Pierce, \nB.C., Turner, D.N.: Local type inference. In: ACM SIGPLAN SIGACT Symposium on Principles of Programming \nLanguages (POPL), San Diego, California (1998) [32] Sewell, P., Nardelli, F., Owens, S., Peskine, G., \nRidge, T., Sarkar, S., Strnisa, R.: Ott: Effective tool support for the working semanticist. J. Funct. \nProgram. 20(1), 71 122 (2010) [33] Sheard, T., Linger, N.: Programming in .mega. In: Horv\u00e1th, Z., Plasmeijer, \nR., So\u00f3s, A., Zs\u00f3k, V. (eds.) 2nd Central European Func\u00adtional Programming School (CEFP). LNCS, vol. \n5161, pp. 158 227. Springer (2007) [34] Sj\u00f6berg, V., Casinghino, C., Ahn, K.Y., Collins, N., Eades III, \nH.D., Fu, P., Kimmell, G., Sheard, T., Stump, A., Weirich, S.: Irrelevance, heterogeneous equality, and \ncall-by-value dependent type systems. In: MSFP 12: Mathematically Structured Functional Programming. \nEPTCS, vol. 76, pp. 112 162 (2012)  [35] Smith, S.F.: Partial Objects in Type Theory. Ph.D. thesis, \nCornell University (1988) [36] Stump, A., Deters, M., Petcher, A., Schiller, T., Simpson, T.W.: Ver\u00adi.ed \nprogramming in guru. In: Altenkirch, T., Millstein, T.D. (eds.) PLPV. pp. 49 58. ACM (2009) [37] Svendsen, \nK., Birkedal, L., Nanevski, A.: Partiality, state and depen\u00addent types. In: Typed lambda calculi and \napplications (TLCA 11). LNCS, vol. 6690, pp. 198 212. Springer (2011) [38] Swamy, N., Chen, J., Fournet, \nC., Strub, P.Y., Bhargavan, K., Yang, J.: Secure Distributed Programming with Value-dependent Types. \nIn: ICFP 11: International Conference on Functional Programming. pp. 285 296. ACM (2011) [39] Tait, W.W.: \nIntensional interpretations of functionals of .nite type i. The Journal of Symbolic Logic 32(2), pp. \n198 212 (1967) [40] The Coq Development Team: The Coq Proof Assistant Reference Manual, Version 8.3. \nINRIA (2010), http://coq.inria.fr/V8. 3/refman/ [41] The Coq Development Team: The Coq Proof Assistant, \nFrequently Asked Questions. INRIA (2011), http://coq.inria.fr/faq/ [42] The Univalent Foundations Program: \nHomotopy Type Theory: Univa\u00adlent Foundations of Mathematics (2013), http://arxiv.org/abs/ 1308.0729 \n[43] Werner, B.: Une Th\u00e9orie des Constructions Inductives. Ph.D. thesis, Universit\u00e9 Paris 7 (1994) [44] \nWinskel, G.: The formal semantics of programming languages: an introduction. MIT Press, Cambridge, MA, \nUSA (1993)    \n\t\t\t", "proc_id": "2535838", "abstract": "<p>Most dependently-typed programming languages either require that all expressions terminate (e.g. Coq, Agda, and Epigram), or allow infinite loops but are inconsistent when viewed as logics (e.g. Haskell, ATS, &#937;mega. Here, we combine these two approaches into a single dependently-typed core language. The language is composed of two fragments that share a common syntax and overlapping semantics: a logic that guarantees total correctness, and a call-by-value programming language that guarantees type safety but not termination. The two fragments may interact: logical expressions may be used as programs; the logic may soundly reason about potentially nonterminating programs; programs can require logical proofs as arguments; and \"mobile\" program values, including proofs computed at runtime, may be used as evidence by the logic. This language allows programmers to work with total and partial functions uniformly, providing a smooth path from functional programming to dependently-typed programming.</p>", "authors": [{"name": "Chris Casinghino", "author_profile_id": "81453658565", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P4383740", "email_address": "ccasin@cis.upenn.edu", "orcid_id": ""}, {"name": "Vilhelm Sj&#246;berg", "author_profile_id": "81447602937", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P4383741", "email_address": "vilhelm@cis.upenn.edu", "orcid_id": ""}, {"name": "Stephanie Weirich", "author_profile_id": "81548019099", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P4383742", "email_address": "sweirich@cis.upenn.edu", "orcid_id": ""}], "doi_number": "10.1145/2535838.2535883", "year": "2014", "article_id": "2535883", "conference": "POPL", "title": "Combining proofs and programs in a dependently typed language", "url": "http://dl.acm.org/citation.cfm?id=2535883"}