{"article_publication_date": "01-08-2014", "fulltext": "\n Replicated Data Types: Speci.cation, Veri.cation, Optimality Sebastian Burckhardt Alexey Gotsman Microsoft \nResearch IMDEA Software Institute Abstract Geographically distributed systems often rely on replicated \neventu\u00adally consistent data stores to achieve availability and performance. To resolve con.icting updates \nat different replicas, researchers and practitioners have proposed specialized consistency protocols, \ncalled replicated data types, that implement objects such as reg\u00adisters, counters, sets or lists. Reasoning \nabout replicated data types has however not been on par with comparable work on abstract data types and \nconcurrent data types, lacking speci.cations, correctness proofs, and optimality results. To .ll in this \ngap, we propose a framework for specifying repli\u00adcated data types using relations over events and verifying \ntheir im\u00adplementations using replication-aware simulations. We apply it to 7 existing implementations \nof 4 data types with nontrivial con.ict\u00adresolution strategies and optimizations (last-writer-wins register, \ncounter, multi-value register and observed-remove set). We also present a novel technique for obtaining \nlower bounds on the worst\u00adcase space overhead of data type implementations and use it to prove optimality \nof 4 implementations. Finally, we show how to specify consistency of replicated stores with multiple \nobjects ax\u00adiomatically, in analogy to prior work on weak memory models. Overall, our work provides foundational \nreasoning tools to support research on replicated eventually consistent stores. Categories and Subject \nDescriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation; F.3.1 [Logics and Meanings of \nPrograms]: Specifying and Verifying and Reasoning about Pro\u00adgrams Keywords Replication; eventual consistency; \nweak memory 1. Introduction To achieve availability and scalability, many networked computing systems \nrely on replicated stores, allowing multiple clients to issue operations on shared data on a number of \nreplicas, which commu\u00adnicate changes to each other using message passing. For example, large-scale Internet \nservices rely on geo-replication, which places data replicas in geographically distinct locations, and \napplications for mobile devices store replicas locally to support of.ine use. One bene.t of such architectures \nis that the replicas remain locally avail\u00adable to clients even when network connections fail. Unfortunately, \nthe famous CAP theorem [19] shows that such high Availability and tolerance to network Partitions are \nincompatible with strong Consistency, i.e., the illusion of a single centralized replica han\u00addling all \noperations. For this reason, modern replicated stores often Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. Copyrights for components of this work owned by others than ACM must \nbe honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. Request permissions from \npermissions@acm.org. POPL 14, January 22 24, 2014, San Diego, CA, USA. Copyright c &#38;#169; 2014 ACM \n978-1-4503-2544-8/14/01. . . $15.00. http://dx.doi.org/10.1145/2535838.2535848 Hongseok Yang Marek Zawirski \nUniversity of Oxford INRIA &#38; UPMC-LIP6 provide weaker forms of consistency, commonly dubbed eventual \nconsistency [36]. Eventual usually refers to the guarantee that if clients stop issuing update requests, \nthen the replicas (1) will eventually reach a consistent state. Eventual consistency is a hot research \narea, and new replicated stores implementing it appear every year [1, 13, 16, 18, 23, 27, 33, 34, 37]. \nUnfortunately, their semantics is poorly understood: the very term eventual consistency is a catch-all \nbuzzword, and different stores claiming to be eventually consistent actually pro\u00advide subtly different \nguarantees. The property (1), which is a form of quiescent consistency, is too weak to capture these. \nAlthough it requires the replicas to converge to the same state eventually, it doesn t say which one \nit will be. Furthermore, (1) does not provide any guarantees in realistic scenarios when updates never \nstop ar\u00adriving. The dif.culty of reasoning about the behavior of eventually consistent stores comes from \na multitude of choices to be made in their design, some of which we now explain. Allowing the replicas \nto be temporarily inconsistent enables eventually consistent stores to satisfy clients requests from \nthe local replica immediately, and broadcast the changes to the other replicas only after the fact, when \nthe network connection permits this. However, this means that clients can concurrently issue con\u00ad.icting \noperations on the same data item at different replicas; fur\u00adthermore, if the replicas are out-of-sync, \nthese operations will be applied to its copies in different states. For example, two users shar\u00ading an \nonline store account can write two different zip codes into the delivery address; the same users connected \nto replicas with dif\u00adferent views of the shopping cart can also add and concurrently remove the same \nproduct. In such situations the store needs to en\u00adsure that, after the replicas exchange updates, the \nchanges by dif\u00adferent clients will be merged and all con.icts will be resolved in a meaningful way. Furthermore, \nto ensure eventual consistency (1), the con.ict resolution has to be uniform across replicas, so that, \nin the end, they converge to the same state. The protocols achieving this are commonly encapsulated within \nreplicated data types [1, 10, 16, 18, 31, 33, 34] that implement ob\u00adjects, such as registers, counters, \nsets or lists, with various con.ict\u00adresolution strategies. The strategies can be as simple as establishing \na total order on all operations using timestamps and letting the last writer win, but can also be much \nmore subtle. Thus, a data type can detect the presence of a con.ict and let the client deal with it: \ne.g., the multi-value register used in Amazon s Dynamo key-value store [18] would return both con.icting \nzip codes in the above ex\u00adample. A data type can also resolve the con.ict in an application\u00adspeci.c way. \nFor example, the observed-remove set [7, 32] pro\u00adcesses concurrent operations trying to add and remove \nthe same element so that an add always wins, an outcome that may be appro\u00adpriate for a shopping cart. \nReplicated data type implementations are often nontrivial, since they have to maintain not only client-observable \nobject state, but also metadata needed to detect and resolve con.icts and to han\u00addle network failures. \nThis makes reasoning about their behavior challenging. The situation gets only worse if we consider multi\u00adple \nreplicated objects: in this case, asynchronous propagation of updates between replicas may lead to counterintuitive \nbehaviors anomalies, in database terminology. The following code illustrates an anomaly happening in \nreal replicated stores [1, 18]:  Replica r1 . x.wr(post) i = y.rd // comment . Replica r2 (2) y.wr(comment) \nj = x.rd // empty We have two clients reading from and writing to register objects x and y at two different \nreplicas; i and j are client-local variables. The .rst client makes a post by writing to x at replica \nr1 and then comments on the post by writing to y. After every write, replica r1 might send a message \nwith the update to replica r2. If the messages carrying the writes of post to x and comment to y arrive \nto replica r2 out of the order they were issued in, the second client can see the comment, but not the \npost. Different replicated stores may allow such an anomaly or not, and this has to be taken into account \nwhen reasoning about them. In this paper, we propose techniques for reasoning about even\u00adtually consistent \nreplicated stores in the following three areas. 1. Speci.cation. We propose a comprehensive framework \nfor specifying the semantics of replicated stores. Its key novel com\u00adponent is replicated data type speci.cations \n(\u00a73), which provide the .rst way of specifying the semantics of replicated objects with advanced con.ict \nresolution declaratively, like abstract data types [25]. We achieve this by de.ning the result of a data \ntype operation not by a function of states, but of operation contexts sets of events affecting the result \nof the operation, together with some relationships between them. We show that our speci.cations are suf.ciently \n.exible to handle data types representing a variety of con.ict-resolution strategies: last-write-wins \nregister, counter, multi-value register and observed-remove set. We then specify the semantics of a \nwhole store with multiple objects, possibly of different types, by consistency axioms (\u00a77), which constrain \nthe way the store processes incoming requests in the style of weak shared-memory models [2] and thus \nde.ne the anomalies allowed. As an illustration, we de.ne consistency mod\u00adels used in existing replicated \nstores, including a weak form of eventual consistency [1, 18] and different kinds of causal consis\u00adtency \n[23, 27, 33, 34]. We .nd that, when specialized to last-writer\u00adwins registers, these speci.cations are \nvery close to fragments of the C/C++ memory model [5]. Thus, our speci.cation framework generalizes axiomatic \nshared-memory models to replicated stores with nontrivial con.ict resolution. 2. Veri.cation. We propose \na method for proving the correctness of replicated data type implementations with respect to our speci\u00ad.cations \nand apply it to seven existing implementations of the four data types mentioned above, including those \nwith nontrivial opti\u00admizations. Reasoning about the implementations is dif.cult due to the highly concurrent \nnature of a replicated store, with multiple replicas simultaneously updating their object copies and \nexchang\u00ading messages. We address this challenge by proposing replication\u00adaware simulations (\u00a75). Like \nclassical simulations from data re.ne\u00adment [21], these associate a concrete state of an implementation \nwith its abstract description structures on events, in our case. To combat the complexity of replication, \nthey consider the state of an object at a single replica or a message in transit separately and as\u00adsociate \nit with abstract descriptions of only those events that led to it. Verifying an implementation then requires \nonly reasoning about an instance of its code running at a single replica.  Here, however, we have to \ndeal with another challenge: code at a single replica can access both the state of an object and a message \nat the same time, e.g., when updating the former upon receiving the latter. To reason about such code, \nwe often need to rely on cer\u00adtain agreement properties correlating the abstract descriptions of the message \nand the object state. Establishing these properties re\u00adquires global reasoning. Fortunately, we .nd that \nagreement prop\u00aderties needed to prove realistic implementations depend only on ba\u00adsic facts about their \nmessaging behavior and can thus be established once for broad classes of data types. Then a particular \nimplementa\u00adtion within such a class can be veri.ed by reasoning purely locally. By carefully structuring \nreasoning in this way, we achieve easy and intuitive proofs of single data type implementations. We then \nlift these results to stores with multiple objects of different types by showing how consistency axioms \ncan be proved given properties of the transport layer and data type implementations (\u00a77). 3. Optimality. \nReplicated data type designers strive to optimize their implementations; knowing that one is optimal \ncan help guide such efforts in the most promising direction. However, proving optimality is challengingly \nbroad as it requires quantifying over all possible implementations satisfying the same speci.cation. \nFor most data types we studied, the primary optimization target is the size of the metadata needed to \nresolve con.icts or handle net\u00adwork failures. To establish optimality of metadata size, we present a \nnovel method for proving lower bounds on the worst-case meta\u00addata overhead of replicated data types the \nproportion of metadata relative to the client-observable content. The main idea is to .nd a large family \nof executions of an arbitrary correct implementation such that, given the results of data type operations \nfrom a certain .xed point in any of the executions, we can recover the previous execution history. This \nimplies that, across executions, the states at this point are distinct and thus must have some minimal \nsize. Using our method, we prove that four of the implementations we veri.ed have an optimal worst-case \nmetadata overhead among all implementations satisfying the same speci.cation. Two of these (counter, \nlast-writer-wins register) are well-known; one (optimized observed-remove set [6]) is a recently proposed \nnontrivial opti\u00admization; and one (optimized multi-value register) is a small im\u00adprovement of a known \nimplementation [33] that we discovered dur\u00ading a failed attempt to prove optimality of the latter. We \nsummarize all the bounds we proved in Fig. 10. We hope that the theoretical foundations we develop will \nhelp in exploring the design space of replicated data types and replicated eventually consistent stores \nin a systematic way. 2. Replicated Data Types We now describe our formal model for replicated stores \nand intro\u00adduce replicated data type implementations, which implement op\u00aderations on a single object at \na replica and the protocol used by replicas to exchange updates to this object. Our formalism follows \nclosely the models used by replicated data type designers [33]. A replicated store is organized as a \ncollection of named ob\u00adjects Obj = {x, y, z, . . .}. Each object is hosted at all replicas r, s . ReplicaID. \nThe sets of objects and replicas may be in.nite, to model their dynamic creation. Clients interact with \nthe store by performing operations on objects at a speci.ed replica. Each ob\u00adject x . Obj has a type \nt = type(x) . Type, whose type signa\u00adture (Opt , Valt ) determines the set of supported operations Opt \n(ranged over by o) and the set of their return values Valt (ranged over by a, b, c, d). We assume that \na special value . . Valt be\u00adlongs to all sets Valt and is used for operations that return no value. For \nexample, we can de.ne a counter data type ctr and an integer register type intreg with operations for \nreading, incre\u00admenting or writing an integer a: Valctr = Valintreg = Z . {.}, Opctr = {rd, inc} and Opintreg \n= {rd} . {wr(a) | a . Z}. We also assume sets Message of messages (ranged over by m) and timestamps Timestamp \n(ranged over by t). For simplicity, we let timestamps be positive integers: Timestamp = N1. DE FINI T \nI ON 1. A replicated data type implementation for a data type t is a tuple Dt = (S, is0, M, do, send, \nreceive), where is0 :  Figure 1. Illustrations of a concrete (a) and two abstract executions (b, c) \n ReplicaID . S, M . Message and do : Opt \u00d7 S \u00d7 Timestamp . S \u00d7 Valt ; send : S . S \u00d7 M; receive : S \u00d7 \nM . S. We denote a component of Dt , such as do, by Dt .do. A tuple Dt de.nes the class of implementations \nof objects with type t , meant to be instantiated for every such object in the store. S is the set of \nstates (ranged over by s) used to represent the current state of the object, including metadata, at a \nsingle replica. The initial state at every replica is given by is0. Dt provides three methods that the \nrest of the store implemen\u00adtation can call at a given replica; we assume that these methods execute atomically. \nWe visualize store executions resulting from re\u00adpeated calls to the methods as in Fig. 1(a), by arranging \nthe calls on several vertical timelines corresponding to replicas at which they occur and denoting the \ndelivery of messages by diagonal arrows. In \u00a74, we formalize them as sequences of transitions called \nconcrete executions and de.ne the store semantics by their sets; the intuition given by Fig. 1(a) should \nsuf.ce for the following discussion. A client request to perform an operation o . Opt triggers the call \ndo(o, s, t) (e.g., event 1 in Fig. 1(a)). This takes the current state s . S of the object at the replica \nwhere the request is issued and a timestamp t . Timestamp provided by the rest of the store implementation \nand produces the updated object state and the return value of the operation. The data type implementation \ncan use the timestamp provided, e.g., to implement the last-writer-wins con.ict-resolution strategy mentioned \nin \u00a71, but is free to ignore it. Nondeterministically, in moments when the network is able to accept \nmessages, a replica calls send. Given the current state of the object at the replica, send produces a \nmessage in M to broadcast to all other replicas (event 2 in Fig. 1(a)); sometimes send also alters the \nstate of the object. Using broadcast rather than point-to-point communication does not limit generality, \nsince we can always tag messages with the intended receiver. Another replica that receives the message \ngenerated by send calls receive to merge the enclosed update into its copy of the object state (event \n3 in Fig. 1(a)). We now reproduce three replicated data type implementations due to Shapiro et al. [33].They \nfall into two categories: in op\u00adbased implementations, each message carries a description of the latest \noperations that the sender has performed, and in state-based implementations, a description of all operations \nit knows about. Op-based counter (ctr). Fig. 2(a) shows an implementation of the ctr data type. A replica \nstores a pair (a, d), where a is the current value of the counter, and d is the number of increments \nperformed since the last broadcast (we use angle brackets for tuples representing states and messages). \nThe send method returns d and resets it; the receive method adds the content of the message to a. This \nimplementation is correct, as long as each message is delivered exactly once (we show how to prove this \nin \u00a75). Since inc operations commute, they never con.ict: applying them in different orders at different \nreplicas yields the same .nal state. State-based counter (ctr). The implementation in Fig. 2(b) summarizes \nthe currently known history by recording the contri- Figure 2. Three replicated data type implementations \n(a) Op-based counter (ctr) S = N0 \u00d7 N0 do(rd, (a, d), t) = ((a, d), a) M = N0 do(inc, (a, d), t) = ((a \n+ 1, d + 1), .) is0 = .r. (0, 0) send((a, d)) = ((a, 0), d) receive((a, d), d') = (a + d', d) (b) State-based \ncounter (ctr) S = ReplicaID \u00d7 (ReplicaID . N0) s0 = .r. (r, .s. 0) M = ReplicaID . N0 do(rd, (r, v), \nt) = ((r, v),{v(s) | s . ReplicaID}) do(inc, (r, v), t) = ((r, v[r . v(r) + 1]), .) send((r, v)) =((r, \nv), v) receive((r, v), v') = (r, (.s. max{v(s), v'(s)})) (c) State-based last-writer-wins register (intreg) \nS = Z\u00d7 (Timestamp 1 {0}) is0 = .r. (0, 0) M = S do(rd, (a, t), t') = ((a, t), a) do(wr(a'), (a, t), t') \n= if t < t' then ((a', t'), .) else ((a, t), .) send((a, t)) = ((a, t), (a, t)) receive((a, t), (a', \nt')) = if t < t' then (a', t') else (a, t) bution of every replica to the counter value separately (reminiscent \nof vector clocks [29]). A replica stores its identi.er r and a vector v such that for each replica s \nthe entry v(s) gives the number of increments made by clients at s that have been received by r. A rd \noperation returns the sum of all entries in the vector. An inc operation increments the entry for the \ncurrent replica. We denote by v[i . j] the function that has the same value as v everywhere, except for \ni, where it has the value j. The send method returns the vector, and the receive method takes the maximum \nof each entry in the vectors v and v' given to it. This is correct because an entry for s in either vector \nre.ects a pre.x of the sequence of increments done at replica s. Hence, we know that min{v(s), v'(s)} \nincrements by ' s are taken into account both in v(s) and in v(s). State-based last-writer-wins (LWW) \nregister (intreg). Un\u00adlike counters, registers have update operations that are not com\u00admutative. To resolve \ncon.icts, the implementation in Fig. 2 uses the last-writer-wins strategy, creating a total order on \nwrites by as\u00adsociating a unique timestamp with each of them. A state contains the current value, returned \nby rd, and the timestamp at which it was ' written (initially, we have 0 instead of a timestamp). A wr(a) \ncom\u00adpares its timestamp t' with the timestamp t of the current value a and sets the value to the one \nwith the highest timestamp. Note that ' here we have to allow for t< t, since we do not make any assump\u00adtions \nabout timestamps apart from uniqueness: e.g., the rest of the store implementation can compute them using \nphysical or Lamport clocks [22]. We show how to state assumptions about timestamps in \u00a74. The send method \njust returns the state, and the receive method chooses the winning value by comparing the timestamps \nin the cur\u00adrent state and the message, like wr. State-based vs. op-based. State-based implementations \ncon\u00adverge to a consistent state faster than op-based implementations be\u00adcause they are transitively delivering, \nmeaning that they can prop\u00adagate updates indirectly. For example, when using the counter in Fig. 2(b), \nin the execution in Fig. 1(a) the read at r3 (event 7) re\u00adturns 2, even though the message from r1 has \nnot arrived yet, be\u00adcause r3 learns about r1 s update via r2. State-based implementa\u00adtions are also resilient \nagainst transport failures like message loss, reordering, or duplication. Op-based implementations require \nthe replicated store using them to mask such failures (e.g., using mes\u00adsage sequence numbers, retransmission \nbuffers, or reorder buffers).  The potential weakness of state-based implementations is the size of \nstates and messages, which motivates our examination of space optimality in \u00a76. For example, we show \nthat the counter in Fig. 2(b) is optimal, meaning that no counter implementation satisfying the same \nrequirements (transitive delivery and resilience against message loss, reordering, and duplication) can \ndo better. 3. Specifying Replicated Data Types and Stores Consider the concrete execution in Fig. 1(a). \nWhat are valid return values for the read in event 7? Intuitively, 1 or 2 can be justi.able, but not \n100. We now present a framework for specifying the ex\u00adpected outcome declaratively, without referring \nto implementation details. For example, we give a speci.cation of a replicated counter that is satis.ed \nby both implementations in Fig. 2(a, b). In presenting the framework, we rely on the intuitive under\u00adstanding \nof the way a replicated store executes given in \u00a72. Later we de.ne the store semantics formally (\u00a74), \nwhich lets us state what it means for a store to satisfy our speci.cations (\u00a74 and \u00a77). 3.1 Abstract \nExecutions and Speci.cation Structure We de.ne our speci.cations on abstract executions, which in\u00adclude \nonly user-visible events (corresponding to do calls) and describe the other information about the store \nprocessing in an implementation-independent form. Informally, we consider a con\u00adcrete execution correct \nif it can be justi.ed by an abstract execution satisfying the speci.cations that is similar to it and, \nin particular, has the same operations and return values. Abstract executions are inspired by axiomatic \nde.nitions of weak shared-memory models [2]. In particular, we use their pre\u00adviously proposed reformulation \nwith visibility and arbitration rela\u00adtions [13], which are similar to the reads-from and coherence rela\u00adtions \nfrom weak shared-memory models. We provide a comparison with shared-memory models in \u00a77 and with [13] \nin \u00a78. DE FI NI TI O N 2. An abstract execution is a tuple A = (E , repl, obj, oper, rval, ro, vis, ar), \nwhere E . Event is a set of events from a countable universe Event;  each event e . E describes a replica \nrepl(e) . ReplicaID performing an operation oper(e) . Opon an object type(obj(e)) obj(e) . Obj, which \nreturns the value rval(e) . Valtype(obj(e));  ro . E \u00d7 E is a replica order, which is a union of transitive, \nirre.exive and total orders on events at each replica;  vis . E \u00d7 E is an acyclic visibility relation \nsuch that  vis .e, f . E . e -. f =. obj(e) = obj(f); ar . E \u00d7 E is an arbitration relation, which is \na union of transitive, irre.exive and total orders on events on each object. We also require that ro, \nvis and ar be well-founded. In the following, we denote components of A and similar structures as in \nA.repl. We also use (e, f ) . r and e -r . f interchangeably. vis Informally, e -. f means that f is \naware of e and thus e s effect can in.uence f s return value. In implementation terms, this may be the \ncase if the update performed by e has been delivered to the replica performing f before f is issued. \nThe exact meaning of delivered , however, depends on how much information messages carry in the implementation. \nFor example, as we explain in \u00a73.2, the return value of a read from a counter is equal to the number \nof inc operations visible to it. Then, as we formalize in \u00a74, the abstract execution illustrated in Fig. \n1(b) justi.es the op-based implementation in Fig. 2(a) reading 1 in the concrete execution in Fig. 1(a). \nThe abstract execution in Fig. 1(c) justi.es the state-based implementation in Fig. 2(b) reading 2 due \nto transitive delivery (\u00a72). There is no abstract execution that would justify reading 100. The ar relation \nrepresents the ordering information provided by the store, e.g., via timestamps. On the right we show \nan ab\u00adstract execution corresponding to a variant of the anomaly (2). The ar edge means that any replica \n that sees both writes to x should assume that post overwrites empty. We give a store speci.cation by \ntwo components, constraining abstract executions: 1. Replicated data type speci.cations determine return \nvalues of operations in an abstract execution in terms of its vis and ar rela\u00adtions, and thus de.ne con.ict-resolution \npolicies for individual objects in the store. The speci.cations are the key novel compo\u00adnent of our framework, \nand we discuss them next. 2. Consistency axioms constrain vis and ar and thereby disallow anomalies \nand extend the semantics of individual objects to that of the entire store. We defer their discussion \nto \u00a77. See Fig. 13 for their .avor; in particular, COCV prohibits the anomaly above.  Each of these \ncomponents can be varied separately, and our spec\u00adi.cations will de.ne the semantics of any possible \ncombination. Given a speci.cation of a store, we can determine whether a set of events can be observed \nby its users by checking if there is an abstract execution with this set of events satisfying the data \ntype speci.cations and consistency axioms.  3.2 Replicated Data Type Speci.cations In a sequential setting, \nthe semantics of a data type t can be speci.ed by a function St : Op+ t . Valt , which, given a non\u00adempty \nsequence of operations performed on an object, speci.es the return value of the last operation. For a \nregister, read operations return the value of the last preceding write, or zero if there is no prior \nwrite. For a counter, read operations return the number of preceding increments. Thus, for any sequence \nof operations .: Sintreg (. rd) = a, if wr(0) . = .1 wr(a) .2 and .2 does not contain wr operations; \nSctr (. rd) = (the number of inc operations in .); Sintreg (. inc) = Sctr (. wr(a)) = .. In a replicated \nstore, the story is more interesting. We specify a data type t by a function Ft , generalizing St . Just \nlike St , this determines the return value of an operation based on prior opera\u00adtions performed on the \nobject. However, Ft takes as a parameter not a sequence, but an operation context, which includes all \nwe need to know about a store execution to determine the return value of a given operation o the set \nE of all events that are visible to o, together with the operations performed by the events and visibility \nand arbitration relations on them. DE FIN I T I ON 3. An operation context for a data type t is a tuple \nL = (o, E, oper, vis, ar), where o . Opt , E is a .nite subset of Event, oper : E . Opt , vis . E \u00d7 E \nis acyclic and ar . E \u00d7 E is transitive, irre.exive and total. We can extract the context of an event \ne . A.E in an abstract execution A by selecting all events visible to it according to A.vis: ctxt(A, \ne) = (A.oper(e), G, (A.oper)|G, (A.vis)|G, (A.ar)|G), where G = (A.vis)-1(e) and \u00b7|G is the restriction \nto events in G. Thus, in the abstract execution in Fig. 1(b), the operation context of the read from \nx includes only one increment event; in the execution in Fig. 1(c) it includes two. DE FIN I T I ON 4. \nA replicated data type speci.cation for a type t is a function Ft that, given an operation context L \nfor t, speci.es a return value Ft (L) . Valt .  Note that Ft (o, \u00d8, . . .) returns the value resulting \nfrom performing o on the initial state for the data type (e.g., 0 for the LWW-register). We specify multiple \ndata types used in a replicated store by a partial function Fmapping them to data type speci.cations. \nDE FI NI TI O N 5. An abstract execution A satis.es F, written A |= F, if the return value of every event \nin A is computed on its context by the speci.cation for the type of the object the event accesses: .e \n. A.E . (A.rval(e) = F(type(A.obj(e)))(ctxt(A, e))). We specify a whole store by Fand a set of consistency \naxioms (\u00a77). This lets us determine if its users can observe a given set of events by checking if there \nis an abstract execution with these events that satis.es Faccording to the above de.nition, as well as \nthe axioms. Note that Ft is deterministic. This does not mean that so is an outcome of an operation on \na store; rather, that all the non\u00addeterminism arising due to its distributed nature is resolved by vis \nand ar in the context passed to Ft . These relations are chosen arbitrarily subject to consistency axioms. \nDue to the determinacy property, two events that perform the same operation and see the same set of events \nproduce the same return values. As we show in \u00a77, this property ensures that our speci.cations can formalize \neventual consistency in the sense of (1). We now give four examples of data type speci.cations, corre\u00adsponding \nto the four con.ict-resolution strategies mentioned in \u00a71 and \u00a72: (1) operations commute, so no con.icts \narise; (2) last writer wins; (3) all con.icting values are returned; and (4) con.icts are resolved in \nan application-speci.c way. We start by specifying the data types whose implementations we presented \nin \u00a72. 1. Counter (ctr) is de.ned by Fctr (inc, E, oper, vis, ar) = .; (3) Fctr (rd, E, oper, vis, ar) \n= {e . E | oper(e) = inc} Thus, according to Def. 5 the executions in Fig. 1(b) and 1(c) satisfy Figure \n3. The set of con.gurations Con.g and the transition relation -.D: Con.g \u00d7 Event \u00d7 Con.g for a data type \nlibrary D. We use e : {h1 = u1, h2 = u2} to abbreviate h1(e) = u1 and h2(e) = u2. We uncurry R . RState \nwhere convenient. Objt = {x . Obj | type(x) = t} RState = (ReplicaID . D(type(x)).S) X.Objx.X TState \n= MessageID . (ReplicaID \u00d7 Objt \u00d7 D(t).M) t.Type Con.g = RState \u00d7 TState D(type(x)).do(o, s, t) = (s \n' , a) e : {act = do, obj = x, repl = r, oper = o, time = t, rval = a} e (R[(x, r) . s], T ) -.D (R[(x, \nr) . s ' ], T ) D(type(x)).send(s) = (s ' , m) mid ./dom(T ) e : {act = send, obj = x, repl = r, msg \n= mid} e (R[(x, r) . s], T ) -.D (R[(x, r) . s ' ], T [mid . (r, x, m)]) ' D(type(x)).receive(s, m) = \ns ' r= r ' e : {act = receive, obj = x, repl = r, srepl = r , msg = mid} e ' (R[(x, r) . s], T [mid . \n(r , x, m)]) -.D ' (R[(x, r) . s ' ], T [mid . (r , x, m)]) 4. Observed-remove set (orset). How do we \nspecify a repli\u00adcated set of integers? The operations of adding and removing differ\u00adent elements commute \nand thus do not con.ict. Con.icts arise from concurrently adding and removing the same element. For example, \nwe need to decide what rd will return as the contents of the set in the context (rd, {e, f }, oper, vis, \nar), where oper(e) = add(42) and oper(f) = remove(42). If we use the generic construction from the LWW-register, \nthe result will depend on the arbitration . ar relation: \u00d8 if e -. f, and {42} otherwise. An application \nmay re\u00adquire a more consistent behavior, e.g., that an add operation always the counter speci.cation: \nboth 1 and 2 are valid return values for the read from x when there are two concurrent increments. 2. \nLWW-register (intreg) is de.ned by Fintreg (o, E , oper, vis, ar) = Sintreg (Ear o), (4) where Ear denotes \nthe sequence obtained by ordering the opera\u00adtions performed by the events in E according to ar. Thus, \nthe return value is determined by establishing a total order of the visible oper\u00adations and applying \nthe regular sequential semantics. For example, by Def. 5 in the example execution from \u00a73.1 the read \nfrom x has to return empty; if we had a vis edge from the write of post to the read from x, then the \nread would have to return post. As we show in \u00a77, weak shared-memory models are obtained by specializing \nour framework to stores with only LWW-registers. We can obtain a concurrent semantics Ft of any data \ntype t based on its sequential semantics St similarly to (4). For example, Fctr de.ned above is equivalent \nto what we obtain using this generic construction. The next two examples go beyond this. 3. Multi-value \nregister (mvr). This register [1, 18] has the same operations as the LWW-register, but its reads return \na set of values: Fmvr (rd, E , oper, vis, ar) = {a | .e . E. oper(e) = wr(a) vis . \u00ac.f . E . oper(f) \n= wr( ) . e -. f}. (We write for an expression whose value is irrelevant.) A read returns the values \nwrit\u00adten by currently con.icting writes, de.ned as those that are not superseded in vis by later writes; \nar is not used. For example, a rd would return {2, 3} in the context on the right. win against concurrent \nremove operations. Observed-remove (OR) set [7, 32] achieves this by mandating that remove operations \ncan\u00adcel only the add operations that are visible to them: Forset (rd, E, oper, vis, ar) = {a | .e . E. \noper(e) = add(a) vis . \u00ac.f . E. oper(f) = remove(a) . e -. f}, (5) vis In the above operation context \nrd will return \u00d8 if e -. f, and {42}otherwise. The rationale is that, in the former case, add(42) and \nremove(42) are not concurrent: the user who issued the remove knew that 42 was in the set and thus meant \nto remove it. In the latter case, the two operations are concurrent and thus add wins. As the above examples \nillustrate, our speci.cations can describe the semantics of data types and their con.ict-resolution policies \ndeclaratively, without referring to the internals of their implemen\u00adtations. In this sense the speci.cations \ngeneralize the concept of an abstract data type [25] to the replicated setting. 4. Store Semantics and \nData Type Correctness A data type library Dis a partial mapping from types t to data type implementations \nD(t) from Def. 1. We now de.ne the semantics of a replicated store with a data type library D as a set \nof its concrete executions, previously introduced informally by Fig. 1(a). We then state what it means \nfor data type implementations of \u00a72 to satisfy their speci.cations of \u00a73.2 by requiring their concrete \nexecutions to be justi.ed by abstract ones. In \u00a77 we generalize this to the correctness of the whole \nstore with multiple object with respect to both data type speci.cations and consistency axioms. Semantics. \nWe de.ne the semantics using the relation -.D: Con.g \u00d7 Event \u00d7 Con.g in Fig. 3, which describes a single \nstep of the store execution. The relation transforms con.gurations (R, T ) . Con.g describing the store \nstate: R gives the object state at each replica, and T the set of messages in transit between them, each \nidenti.ed by a message identi.er mid . MessageID. A mes\u00adsage is annotated by the origin replica and the \nobject to which it pertains. We allow the store to contain only some objects from Obj and thus allow \nR to be partial on them. We use a number of func\u00adtions on events, such as act, obj, etc., to record the \ninformation about the corresponding transitions, so that -.D is implicitly pa\u00adrameterized by them; we \ngive their full list in Def. 6 below.  The .rst rule in Fig. 3 describes a replica r performing an opera\u00adtion \no on an object x using the do method of the corresponding data type implementation. We record the return \nvalue using the function rval. To communicate the change to other replicas, we can at any time perform \na transition de.ned by the second rule, which puts a new message m created by a call to send into the \nset of messages in transit. The third rule describes the delivery of such a message to a replica r other \nthan the origin replica r ' , which triggers a call to receive. Note that the relation -.D does not make \nany assumptions about message delivery: messages can be delivered in any order, multiple times, or not \nat all. These assumptions can be introduced separately, as we show later in this section. A concrete \nexecution can be thought of as a .nite or in.nite sequence of transitions: e1e2en (R0, T0) -. (R1, T1) \n-. . . . -. (Rn, Tn) . . . , where all events ei are distinct. To ease mapping between concrete and abstract \nexecutions in the future, we formalize it as a structure on events, similarly to Def. 2. DEFINITION 6. \nA concrete execution of a store with a data type library Dis a tuple C = (E, eo, pre, post, act, obj, \nrepl, oper, time, rval, msg, srepl). Here E . Event, the execution order eo is a well-founded, transitive, \nirre.exive and total order on E, relating the events according to the order of the transitions they describe, \ntime is injective and pre, post : E . Con.g form a valid sequence of transitions: e (.e . E. pre(e) -.D \npost(e)) . eoeoeo (.e, f . E. e -. f . \u00ac.g. e -. g -. f =. post(e) = pre(f)). We have omitted the types \nof functions on events, which are easily inferred from Fig. 3: e.g., act : E . {do, send, receive}and \ntime : E -Timestamp, de.ned only on e with act(e) = do. We denote the initial con.guration of C by init(C) \n= C.pre(e0), where e0 is the minimal event in C.eo. If C.E is .nite, we denote the .nal con.guration \nof C by .nal(C) = C.post(ef ), where ef is the maximal event in C.eo. The semantics [D] of D is the set \nof all its concrete executions C that start in a con.guration with an empty set of messages and all objects \nin initial states, i.e., .X . Obj. init(C) = ((.x . X. D(type(x)).is0), [ ]), where [ ] is the everywhere-unde.ned \nfunction. Transport layer speci.cations. Data type implementations such as the op-based counter in Fig. \n2(a) can rely on some guarantees concerning the delivery of messages ensured by the rest of the store \nimplementation. They may similarly assume certain properties of timestamps other than uniqueness (guaranteed \nby the injectivity of time in Def. 6). We take such assumptions into account by admit\u00adting only a subset \nof executions from [D] that satisfy a transport layer speci.cation T , which is a predicate on concrete \nexecutions. Thus, we consider a replicated store to be de.ned by a pair (D, T ) and the set of its executions \nbe [D] n T . Even though our de.nition of T lets it potentially restrict data type implementation internals, \nthe particular instantiations we use only restrict message delivery and timestamps. For technical rea\u00adsons, \nwe assume that T always satis.es certain closure properties: for every C . T , the projection of C onto \nevents on a given object or a subset of events forming a pre.x in the eo order is also in T . As an example, \nwe de.ne a transport layer speci.cation ensur\u00ading that a message is delivered to any single replica at \nmost once, as required by the implementation in Fig. 2(a). Let the delivery re\u00adlation del(C) . C.E \u00d7 \nC.E pair events sending and receiving the same message: del(C)C.eo e - --. f .. e - -. f . C.act(e) = \nsend . C.act(f) = receive . C.msg(e) = C.msg(f). Then the desired condition on concrete executions C \nis del(C)del(C) .e, f, g . C.E. e - --. f . e - --. g . C.repl(f ) = C.repl(g) =. f = g. (T-Unique) Data \ntype implementation correctness. We now state what it means for an implementation Dt of type t from Def. \n1 to satisfy a speci.cation Ft from Def. 4. To this end, we consider the behavior of Dt under the most \ngeneral client and transport layer, perform\u00ading all possible operations and message deliveries. Formally, \nlet [Dt ] be the set of executions C . [[t . Dt ]] of a store contain\u00ading a single object x of a type \nt with the implementation Dt , i.e., init(C) = (R, [ ]) for some R such that dom(R) = {x}. Then Dt should \nsatisfy Ft under a transport speci.cation T if for every concrete execution C . [Dt ] n T we can .nd \na simi\u00adlar abstract execution satisfying Ft and, in particular, having the same operations and return \nvalues. As it happens, all components of the abstract execution except visibility are straightforwardly \nde\u00adtermined by C; as explained in \u00a73.1, we have some freedom in choosing visibility. We de.ne the choice \nusing a visibility witness V, which maps a concrete execution C . [Dt ] to an acyclic re\u00adlation on (C.E)|do \nde.ning visibility (here \u00b7|do is the restriction to events e with C.act(e) = do). Let ro(C) C.eo e ---. \nf .. e - -. f . C.repl(e) = C.repl(f ); ar(C) e ---. f .. e, f . (C.E)|do . C.obj(e) = C.obj(f) . C.time(e) \n< C.time(f). Then the abstract execution justifying C . [Dt ] is de.ned by abs(C, V) = (C.E|do, E.repl|do, \nE.obj|do, E.oper|do, E.rval|do, ro(C)|do, V(C), ar(C)). DEFINITION 7. A data type implementation Dt satis.es \na speci\u00ad.cation Ft with respect to V and T , written Dt sat[V, T ] Ft , if .C . [Dt ] n T . (abs(C, V) \n|= [t . Ft ]), where |= is de.ned in Def. 5. As we explained informally in \u00a73.1, the visibility witness \nde\u00adpends on how much information the implementation puts into messages. Since state-based implementations, \nsuch as the ones in Fig. 2(b, c), are transitively delivering (\u00a72), for them we use the witness Vstate(C) \n= (ro(C) . del(C))+|do. By the de.nition of ro(C) and del(C), (ro(C) . del(C)) is acyclic, so Vstate \nis well\u00adde.ned. State-based implementations do not make any assumptions about the transport layer: in \nthis case we write T = T-Any. In contrast, op-based implementations, such as the one in Fig. 2(a), require \nT = T-Unique. Since such implementations are not tran\u00adsitively delivering, the witness Vstate is not \nappropriate for them. We could attempt to de.ne a witness for them by straightforwardly lifting the delivery \nrelation: Vop(C) = ro(C)|do . {(e, f) | e, f . (C.E)|do . ro(C) del(C)ro(C) '' '' .e , f . e ---. e - \n--. f ---. f}.  However, we need to be more careful, since for op-based imple\u00ad ro(C) del(C)ro(C) mentations \ne ---. e ' - --. f ' ---. f does not ensure that the update of e is taken into account by f: if there \nis another send event '' '' ' e in between e and e ' , then e will capture the update of e and e will \nnot. Hence, we de.ne the witness as: Vop(C) = ro(C)|do . {(e, f ) | e, f . (C.E)|do ro(C) del(C)ro(C) \n'' '' . .e , f . e ---. e - --. f ---. f ro(C) ro(C) '' '' '' . \u00ac.e . e ---. e ---. e ' . C.act(e ) = \nsend}. We next present a method for proving data type implementation correctness in the sense of Def. \n7. In \u00a77 we lift this to stores with multiple objects and take into account consistency axioms. 5. Proving \nData Type Implementations Correct The straightforward approach to proving correctness in the sense of \nDef. 7 would require us to consider global store con.gurations in executions C, including object states \nat all replicas and all mes\u00adsages in transit, making the reasoning non-modular and unintuitive. To deal \nwith this challenge, we focus on a single component of a store con.guration using replication-aware simulation \nrelations Rr and M, analogous to simulation (aka coupling) relations used in data re.nement [21]. The \nRr relation associates the object state at a replica r with an abstract execution that describes only \nthose events that led to this state; M does the same for a message. For example, when proving Dctr in \nFig. 2(b) with respect to Fctr in (3), M associates a message carrying a vector v with executions in \nwhich each replica s makes v(s) increments. As part of a proof of Dt , we require checking that the effect \nof its methods, such as Dt .do, can be simulated by appropriately transforming related ab\u00adstract executions \nwhile preserving the relations. We de.ne these transformations using abstract methods do., send. and \nreceive. as illustrated in Fig. 4(a, b). For example, if a replica r executes Dt .do from a state s related \nby Rr to an abstract execution I (we explain the use of I instead of A later), we need to .nd an I ' \nrelated by Rr to the resulting state s ' . We also need to check that the value returned by Dt .do on \ns is equal to that returned by Ft on I. These conditions consider the behavior of an implementation method \non a single state and/or message and its effect on only the relevant part of the abstract execution. \nHowever, by localizing the reasoning in this way, we lose some global information that is actually required \nto verify realistic implementations. In particular, this occurs when discharging the obligation for receive \nin Fig. 4(b). Taking a global view, s and m there are meant to come from the same con.guration in a concrete \nexecution C; correspondingly, I and J are meant to be fragments of the same abstract execution abs(C, \nV). In this context we may know certain agreement prop\u00aderties correlating I and J, e.g., that the union \nof their visibility re\u00adlations is itself a well-formed visibility relation and is thus acyclic. Establishing \nthem requires global reasoning about whole execu\u00adtions C and abs(C, V). Fortunately, we .nd that this \ncan be done knowing only the abstract methods, not the implementation Dt . Furthermore, these methods \nstate basic facts about the messaging behavior of implementations and are thus common to broad classes \nof them, such as state-based or op-based. This allows us to estab\u00adlish agreement properties using global \nreasoning once for a given class of implementations; at this stage we can also bene.t from the transport \nlayer speci.cation T and check that the abstract methods construct visibility according to the given \nwitness V. Then a par\u00adticular implementation within the class can be veri.ed by discharg\u00ading local obligations, \nsuch as those in Fig. 4(a, b), while assuming agreement properties. This yields easy and intuitive proofs. \nTo summarize, we deal with the challenge posed by a distributed data type implementation by decomposing \nreasoning about it into Figure 4. Diagrams illustrating replication-aware simulations (a) (b) (c) do \nreceive -step(C1,e,D)\u00ad -' I I (I, J) ID'D DD' DD D D Rr Rr\u00d7M t G t  Rr t t Rr G t t - s ' - C ' s \n-s ' C (s, m) Dt .do e Dt .receive global reasoning done once for a broad class of implementations and \nlocal implementation-speci.c reasoning. We start by present\u00ading the general form of obligations to be \ndischarged for a single implementation within a certain class (\u00a75.1) and the particular form they take \nfor the class of state-based implementations (\u00a75.2), to\u00adgether with some examples (\u00a75.3). We then formulate \nthe obliga\u00adtions to be discharged for a class of implementations (\u00a75.4), which in particular, establish \nthe agreement properties assumed in the per\u00adimplementation obligations. In [12, \u00a7B], we give the obligations \nfor op-based implementations, together with a proof of the counter in Fig. 2(a). An impatient reader \ncan move on to \u00a76 after .nishing \u00a75.3, and come back to \u00a75.4 later. Since Def. 7 considers only single-object \nexecutions, we .x an object x of type t and consider only concrete and abstract executions over x, whose \nsets we denote by CEx[x] and AEx[x]. 5.1 Replication-Aware Simulations As is typical for simulation-based \nproofs, we need to use auxiliary state to record information about the computation history. For this \nreason, actually our simulation relations associate a state or a mes\u00adsage with an instrumented execution \na pair (A, info) . IEx of an abstract execution A . AEx[x] and a function info : A.E . AInfo, tagging \nevents with auxiliary information from a set AInfo. As we show below, AInfo can be chosen once for a \nclass of data type implementations: e.g., AInfo = Timestamp for state-based ones (\u00a75.2). We use I and \nJ to range over instrumented executions and shorten, e.g., I.A.E to I.E. For a partial function h we \nwrite h(x). for x . dom(h), and adopt the convention that h(x) = y implies h(x).. DEFINITION 8. A replication-aware \nsimulation between Dt and Ft with respect to info and abstract methods do., send. and receive. is a collection \nof relations {Rr, M | r . ReplicaID}satisfying the conditions in Fig. 5. Here info and abstract methods \nare meant to be .xed for a given class of implementations, such as state or op-based. To prove a par\u00adticular \nimplementation within this class, one needs to .nd simula\u00adtion relations satisfying the conditions in \nFig. 5. For example, as we show in \u00a75.3, the following relation lets us prove the correctness of the \ncounter in Fig. 2(b) with respect to info and abstract methods appropriate for state-based implementations: \n(s, v) [Rr] I .. (r = s) . (v [M] I); v [M] ((E, repl, obj, oper, rval, ro, vis, ar), info) .. (6) .s. \nv(s) = {e . E | oper(e) = inc . repl(e) = s} . INIT in Fig. 5 associates the initial state at a replica \nr with the execution having an empty set of events. DO, SEND and RECEIVE formalize the obligations illustrated \nin Fig. 4(a, b). Note that do. is parameterized by an event e (required to be fresh in instantiations) \nand the information about the operation performed. The abstract methods are partial and the obligations \nin Fig. 5 assume that their applications are de.ned. When instantiating receive. for a given class of \nimplementations, we let it be de.ned only when its arguments satisfy the agreement property for this \nclass, which we establish separately (\u00a75.4). While doing this, we can also establish some execution invariants, \nholding of single ex\u00ad  Figure 5. De.nition of a replication-aware simulation {Rr, M} between Dt and \nFt . All free variables in each condition are implicitly universally quanti.ed and have the following \ntypes: s, s ' . S, m . M, I , I ' , J . IEx, e . Event, r . ReplicaID, o . Opt , a . Valt , t . Timestamp. \nRr . S \u00d7 IEx, r . ReplicaID; M . M \u00d7 IEx do : IEx \u00d7 Event \u00d7 ReplicaID \u00d7 Opt \u00d7 Valt \u00d7 Timestamp IEx send \n: IEx IEx \u00d7 IEx; receive : IEx \u00d7 IEx IEx IN I T: Dt .is0(r) [Rr] I\u00d8, where I\u00d8.E = \u00d8 ' DO: (do (I , e, \nr, o, a, t) = I . Dt .do(o, s, t) = (s ' , a) . s [Rr] I) ' =. (s ' [Rr] I . a = Ft (ctxt(I ' .A, e))) \nSE N D: (send (I) = (I ' , J ) . Dt .send(s) = (s ' , m) . s [Rr] I) ' =. (s ' [Rr] I . m [M] J) RE C \nE I V E: (receive (I , J ). . s [Rr] I . m [M] J) =. (Dt .receive(s, m) [Rr] receive (I , J )) ecutions \nsupplied as parameters to do and send . We similarly as\u00adsume them in Fig. 5 via the de.nedness of these \nabstract methods.  5.2 Instantiation for State-Based Implementations Fig. 6 de.nes the domain AInfo \nand abstract methods appropriate for state-based implementations. In \u00a75.4 we show that the existence \nof a simulation of Def. 8 with respect to these parameters implies sat[Vstate Dt , T-Any] Ft (Theorems \n9 and 10). The do method adds a fresh event e with the given attributes to I; its timestamp t is recorded \nin info. In the resulting execution I ', the event e is the last one by its replica, observes all events \nin I and occupies the place in arbitration consistent with t. The send method just returns I, which formalizes \nthe intuition that, in state-based implementa\u00adtions, send returns a message capturing all the information \nabout the object available at the replica. The receive method takes the component-wise union I U J of \nexecutions I related to the current state and J related to the message, applied recursively to the com\u00adponents \nof I .A and J.A. We also assume that I U J recomputes the arbitration relation in the resulting execution \nfrom the timestamps. This is the reason for recording them in info: we would not be able to construct \nreceive (I , J ).ar solely from I .ar and J.ar. The agreement property agree(I , J ) guarantees that \nI U J is well-formed (e.g., its visibility relation is acyclic) and that, for each replica, I describes \na computation extending J or vice versa. The latter follows from the observation we made when explaining \nthe state-based counter in \u00a72: a message or a state in a state-based im\u00adplementation re.ects a pre.x \nof the sequence of events performed at a given replica. The .rst conjunct of the execution invariant \ninv requires arbitration to be consistent with event timestamps; the sec\u00adond conjunct follows from the \nde.nition of Vstate (\u00a74). When dis\u00adcharging the obligations in Fig. 5 with respect to the parameters \nin Fig. 6 for a particular implementation, we can rely on the agree\u00adment property and the execution invariant. \n 5.3 Examples We illustrate the use of the instantiation from \u00a75.2 on the state\u00adbased counter, LWW-register \nand OR-set. In [12, \u00a7A] we also give proofs of two multi-value register implementations. Counter: Dctr \nin Fig. 2(b) and Fctr in (3). Discharging the obligations in Fig. 5 for the simulation (6) is easy. The \nkey case is RE CEI V E, where the .rst conjunct of agree in Fig. 6 ensures that min{v(s), v ' (s)} increments \nby a replica s are taken into account both in v(s) and in v ' (s): ((r, v) [Rr] I) . (v ' [M] J) =. (.s. \nmin{v(s), v ' (s)} = |{e . I .E n J.E | I .oper(e) = inc . I .repl(e) = s}|). Figure 6. Instantiation \nfor state-based data type implementations. In do we omit the straightforward de.nition of ar ' in terms \nof I .info and t. AInfo = Timestamp agree(I , J ) .. .r. (({e . I .E | I .repl(e) = r}, I .ro) is a pre.x \nof ({e . J.E | J.repl(e) = r}, J.ro) or vice versa) . (I U J . IEx) inv(I) .. (.e, f . I .E . (e, f ) \n. I .ar .. I .info(e) < I .info(f)) . ((I .vis . I .ro)+ . I .vis) ' ' do (I , e, r, o, a, t) = I , if \ninv(I) . e . I .E . I . IEx ' where I = ((I .E . {e}, I .repl[e . r], I .obj[e . x], I .oper[e . o], \nI .rval[e . a], I .ro . {(f, e) | f . I .E . I .repl(f) = r}, I .vis . {(f , e) | f . I .E}, ar ' ), \nI .info[e . t]) send (I) = (I , I ), if inv(I) receive (I , J ) = I U J, if inv(I) . inv(J) . agree(I \n, J ) This allows establishing receive((r, v), v ' ) [Rr] (I U J), thus formalizing the informal justi.cation \nof correctness we gave in \u00a72. LWW-register: Dintreg in Fig. 2(c) and Fintreg in (4). We asso\u00adciate a \nstate or a message (a, t) with any execution that contains a wr(a) event with the timestamp t maximal \namong all other wr events (as per info). By inv in Fig. 6, this event is maximal in ar\u00adbitration, which \nimplies that rd returns the correct value; the other obligations are also discharged easily. Formally, \n.r. Rr = M and (a, t) [M] ((E, repl, obj, oper, rval, ro, vis, ar), info) .. (t = 0 . a = 0 . (\u00ac.e . \nE. oper(e) = wr( ))) . (t > 0 . (.e . E. oper(e) = wr(a) . info(e) = t) . (.f . E. oper(f) = wr( ) =. \ninfo(f) = t)). Optimized OR-set: Dorset in Fig. 7 and Forset in (5). A problem with implementing a replicated \nset is that we often cannot discard the information about an element from a replica state after it has \nbeen removed: if another replica unaware of the removal sends us a snapshot of its state containing this \nelement, the semantics of the set may require our receive to keep the element out of the set. As we prove \nin \u00a76, for the OR-set keeping track of information about removed elements cannot be fully avoided, which \nmakes its space-ef.cient implementation very challenging. Here we consider a recently-proposed OR-set \nimplementation [6] that, as we show in \u00a76, has an optimal space complexity. It improves on the original \nimplementation [32], whose complexity was suboptimal (we have proved the correctness of the latter as \nwell; see [12, \u00a7A]). An additional challenge posed by the OR-set is that, according to Forset , a remove \noperation may behave differently with respect to different events adding the same element to the set, \ndepending on whether it sees them or not. This causes the implementation to treat internally each add \noperation as generating a unique instance of the element being added, further increasing the space required. \nTo combat this, the implementation concisely summarizes information about instances. An instance is represented \nby a unique instance identi.er that is generated when a replica performs an add and consists of the replica \nidenti.er and the number of adds (of any elements) performed at the replica until then. In a state (r, \nV , w), the vector w determines the identi.ers of all instances that the current replica r has ever observed: \nfor any replica s, the replica r has seen w(s) successive identi.ers (s, 1), (s, 2), . . . , (s, w(s)) \ngenerated at s. To generate a new identi.er in do(add(a ' )), the replica r increments w(r). The connection \nbetween the vector w in a state or a message and add events es,k in corresponding executions is formalized \nin lines 1-3 of the simulation relation, also shown in Fig. 7. In receive we take the pointwise maximum \nof the two vectors w and w '. Like for the counter, the .rst conjunct of agree implies that this preserves \nthe clauses in lines 1-3.  Figure 7. Optimized OR-set implementation [6] and its simulation S = ReplicaID \n\u00d7 ((Z\u00d7 ReplicaID) . N0) \u00d7 (ReplicaID . N0) is0 = .r. (r, (.a, s. 0), (.s. 0)) M = ((Z\u00d7 ReplicaID) . N0) \n\u00d7 (ReplicaID . N0) do(add(a ' ), (r, V , w), t) = ((r, (.a, s. if a = a ' . s = r then w(r) + 1 else \nV (a, s)), w[r . w(r) + 1]), .) do(remove(a ' ), (r, V , w), t) = ((r, (.a, s. if a = a ' then 0 else \nV (a, s)), w), .) do(rd, (r, V , w), t) = ((r, V , w), {a | .s. V (a, s) > 0}) send((r, V, w)) = ((r, \nV , w), (V , w)) receive((r, V , w), (V ' , w ' )) = (r, (.a, s. if (V (a, s) = 0 . w(s) = V ' (a, s)) \n. ' (V ' (a, s) = 0 . w (s) = V (a, s)) then 0 else max{V (a, s), V ' (a, s)}), ' (.s. max{w(s), w (s)})) \n(s, V, w) [Rr] I .. (r = s) . ((V, w) [M] I) (V, w) [M] ((E, repl, obj, oper, rval, ro, vis, ar), info) \n.. 1: . distinct es,k. ({es,k | s . ReplicaID . 1 = k = w(s)} = 2: {e . E | oper(e) = add( )}) . ro 3: \n(.s, k, j. (repl(es,k) = s) . (es,j -. es,k .. j < k)) . 4: (.a, s. (V (a, s) = w(s)) . (V (a, s) = 0 \n=. 5: (oper(es,V (a,s)) = add(a)) . 6: (\u00ac.k. V (a, s) < k = w(s) . oper(es,k) = add(a)) . vis 7: (\u00ac.f \n. E . oper(f) = remove(a) . es,V (a,s) -. f))) . 8: (.a, s, k. es,k . E . oper(es,k) = add(a) =. vis \n9: (k = V (a, s) . .f . E. oper(f) = remove(a) . es,k -. f)) The component w in (r, V, w) records identi.ers \nof both of those instances that have been removed and those that are still in the set (are active). The \ncomponent V serves to distinguish the latter. As it happens, we do not need to store all active instances \nof an element a: for every replica s, it is enough to keep the last active instance identi.er generated \nby an add(a) at this replica. If V (a, s) 0, this identi.er is (s, V (a, s)); if V (a, s) = 0, all = \ninstances of a generated at s that the current replica knows about are inactive. The meaning of V is \nformalized in the simulation: each instance identi.er given by V is covered by w (line 4) and, if V (a, \ns) 0, then the event es,V (a,s) performs add(a) (line 5), is = the last add(a) by replica s (line 6) \nand has not been observed by a remove(a) (line 7). Finally, the add(a) events that are not seen by a \nremove(a) in the execution are either the events es,V (a,s) or those superseded by them (lines 8-9). \nThis ensures that returning all elements with an active instance in rd matches Forset . When a replica \nr performs do(add(a ' )), we update V (a ' , r) to correspond to the new instance identi.er. Conversely, \nin do(remove(a ' )), we clear all entries in V (a ' ), thereby deactivat\u00ading all instances of a '. However, \nafter this their identi.ers are still recorded in w, and so we know that they have been previously re\u00admoved. \nThis allows us to address the problem with implementing receive we mentioned above: if we receive a message \nwith an active instance (s, V ' (a, s)) of an element a that is not in the set at our replica (V (a, \ns) = 0), but previously existed (w(s) = V ' (a, s)), this means that the instance has been removed and \nshould not be active in the resulting state (the entry for (a, s) should be 0). We also do the same check \nwith the state and the message swapped. As the above explanation shows, our simulation relations are \nuseful not only for proving correctness of data type implementa\u00adtions, but also for explaining their \ndesigns. Discharging obligations in Fig. 5 requires some work for the OR-set; due to space con\u00adstraints, \nwe defer this to [12, \u00a7A]. Figure 8. Function step that mirrors the effect of an event e . C ' .E from \n' C . CEx[x] in D . DEx, de.ned when so is the abstract method used step(C ' , e, D) = ' D[r . do (D(r), \ne, r, C ' .oper(e), C ' .rval(e), C .time(e))], ' if C ' .act(e) = do . C .repl(e) = r ' step(C ' , e, \nD) = D[r . I , C .msg(e) . J], ' if C ' .act(e) = send . C ' .repl(e) = r . C .msg(e) . dom(D) . send \n(D(r)) = (I , J ) ' step(C ' , e, D) = D[r . receive (D(r), D(C .msg(e)))], ' if C ' .act(e) = receive \n. C .repl(e) = r  5.4 Soundness and Establishing Agreement Properties We present conditions on AInfo \nand abstract methods ensuring the soundness of replication-aware simulations over them and, in par\u00adticular, \nestablishing the agreement property and execution invari\u00adants assumed via the de.nedness of abstract \noperations in Fig. 5. TH E O R E M 9 (Soundness). Assume AInfo, do , send , receive , V and T that satisfy \nthe conditions in Fig. 9 for some G. If there exists a replication-aware simulation between Dt and Ft \nwith respect to these parameters, then Dt sat[V, T ] Ft . Conditions in Fig. 9 require global reasoning, \nbut can be discharged once for a class of data types. For example, they hold of the instantiation for \nstate-based implementations from \u00a75.2, as well as one for op-based implementations presented in [12, \n\u00a7B]. TH E O R E M 10. There exists G such that, for all Dt , the parameters in Fig. 6 satisfy the conditions \nin Fig. 9 with respect to this G, = Vstate V , T = T-Any. The proofs of Theorems 9 and 10 are given in \n[12, \u00a7B]. To explain the conditions in Fig. 9, here we consider the proof strategy for Theorem 9. To \nestablish Dt sat[V, T ] Ft , for any C . [Dt ] n T we need to show abs(C, V) |= [t . Ft ]. We prove this \nby induction on the length of C. To use the localized conditions in Fig. 5, we require a relation G associating \nC with a decomposed execution a partial function D : (ReplicaID . MessageID) -IEx that gives fragments \nof abs(C, V) corresponding to replica states and messages in the .nal con.guration of C. We write DEx \nfor the set of all decomposed executions, so that G . CEx[x] \u00d7 DEx. The existence of a decomposed execution \nD such that C [G] D forms the core of our induction hypothesis. G-CT X T in Fig. 9 checks that the abstract \nmethods construct visibility according to V: it requires the context of any event e by a replica r to \nbe the same in D(r) and abs(C, V). Together with DO in Fig. 5, this ensures abs(C, V) |= [t . Ft ]. We \nwrite C ' ~ (C . (R, T )) when C ' -eis an extension of C in the following sense: C ' .E = C.E l {e}, \nthe other compo\u00adnents of C are those of C ' restricted to C.E, e is last in C ' .eo and C ' .post(e) \n= (R, T ). For the induction step, assume C [G] D and -e C ' ~ (C . (R, T )); see Fig. 4(c). Then the \ndecomposed execu\u00adtion D ' corresponding to C ' is given by step(C ' , e, D), where the function step \nin Fig. 8 mirrors the effect of the event e from C ' in D using the abstract methods. G-ST E P ensures \nthat it preserves the relation G. Crucially, G-ST E P also requires us to establish the de\u00ad.nedness of \nstep and thus the corresponding abstract method. This justi.es the agreement property and execution invariants \nencoded by the de.nedness and allows us to use the conditions in Fig. 5 to complete the induction. We \nalso require G-IN IT, which establishes the base case, and G-VIS, which formulates a technical restriction \non V. Finally, the conditions in Fig. 9 allow us to use the transport speci.cation T by considering only \nexecutions C satisfying it. 6. Space Bounds and Implementation Optimality Object states in replicated \ndata type implementations include not only the current client-observable content, but also metadata \n Figure 9. Proof obligations for abstract methods. Free variables are implic\u00ad ' itly universally quanti.ed \nand have the following types: C, C . CEx[x] n T , D . DEx, r . ReplicaID, e . Event, (R, T ) . Con.g. \nG-CTXT: (C [G] D . e . abs(C, V).E . abs(C, V).repl(e) = r) =. ctxt(D(r).A, e) = ctxt(abs(C, V), e) e \nG-STEP: (C ' ~ (C -. (R, T )) . (C [G] D)) ' ' =. (step(C , e, D). . C [G] step(C ' , e, D)) G-INIT: \n(C.E = {e} . C.pre(e) = ( , [ ])) =. (step(C, e, D\u00d8). . C [G] step(C, e, D\u00d8)), where D\u00d8 is such that \ndom(D\u00d8) = ReplicaID . .r . ReplicaID. D\u00d8(r).E = \u00d8 ' G-VIS: (e . abs(C, V).E . (C is a pre.x of C ' under \nC .eo)) ' =. ctxt(abs(C, V), e) = ctxt(abs(C , V), e) needed for con.ict resolution or masking network \nfailures. Space taken by this metadata is a major factor determining their ef.ciency and feasibility. \nAs illustrated by the OR-set in \u00a75.3, this is espe\u00adcially so for state-based implementations, i.e., those \nthat satisfy their data type speci.cations with respect to the visibility witness Vstate and the transport \nlayer speci.cation T-Any. We now present a general technique for proving lower bounds on this space over\u00adhead, \nwhich we use to prove optimality of four state-based imple\u00admentations (we leave other implementation \nclasses for future work; see \u00a79). As in \u00a75, we only consider executions over a .xed object x of type \nt . 6.1 Metadata Overhead To measure space, we need to consider how data are represented. An encoding \nof a set S is an injective function enc : S . .+ , where . is some suitably chosen .xed .nite set of \ncharacters (left unspeci.ed). Sometimes, we clarify the domain being encoded using a subscript: e.g., \nencN0 (1). For s . S, we let lenS(s) be the length of encS (s). The length can vary: e.g., for an integer \nk, lenN0 (k) . T(lg k). We use standard encodings (listed in [12, \u00a7C]) for return values encValt of the \ndata types t we consider and assume an arbitrary but .xed encoding of object states encDt .S. To distinguish \nmetadata from the client-observable content of the object, we assume that each data type has a special \nrd operation that returns the latter, as is the case in the examples considered so far. For a concrete \nexecution C . [Dt ] over the object x and a read event e . (C.E)|rd , we de.ne state(e) to be the state \nof the object accessed at e: state(e) = R(x, C.repl(e)) for (R, ) = C.pre(e). We now de.ne the metadata \noverhead as a ratio, by dividing the size of the object state by the size of the observable state. We \nthen quantify the worst-case overhead by taking the maximum of this ratio over all read operations in \nall executions with given numbers of replicas n and update operations m. To de.ne the latter, we assume \nthat each data type t speci.es a set Updt . Opt of update operations; for all examples in this paper \nUpdt = Opt \\ {rd}. DEFINITION 11. The maximum metadata overhead of an execu\u00ad tion C . [Dt ] of an implementation \nDt is lenDt .S(state(e)) mmo(Dt , C) = max| e . (C.E)|rd. lenValt (C.rval(e)) The worst-case metadata \noverhead of an implementation Dt over all executions with n replicas and m updates (2 = n = m) is wcmo(Dt \n, n, m) = max{mmo(Dt , C) | C . [Dt ] . n = |{C.repl(e) | e . C.E}| . m = |{e . C.E | C.oper(e) . Updt \n}|}. We consider only executions with m = n, since we are inter\u00adested in the asymptotic overhead of executions \nwhere all replicas are mutated (i.e., perform at least one update operation). Figure 10. Summary of bounds \non metadata overhead for stated-based implementations, as functions of the number of replicas n and updates \nm Type Existing implementation Any implementation overhead algorithm ref. overhead ctr Fig. 2(b) [32] \neT(n) eO(n) orset Fig. 7 [6] eT(n lg m) eO(n lg m) Fig. 15, [12, \u00a7A] [32] eT(m lg m) intreg Fig. 2(c) \n[32] eT(lg m) eO(lg m) mvr Fig. 17, [12, \u00a7A] new eT(n lg m) eO(n lg m) Fig. 16, [12, \u00a7A] [32] eT(n2 \nlg m) Assuming timestamp encoding is O(lg m), satis.ed by Lamport clocks. An optimization of [32] discovered \nduring the optimality proof. DEFINITION 12. Assume Dt and a positive function f (n, m). f is an asymptotic \nupper bound (Dt . O (f(n, m))) if supn,m.8(wcmo(Dt , n, m)/f(n, m)) < 8, i.e., .K > 0. .m = n = 2. wcmo(Dt \n, n, m) < Kf(n, m); . O f is an asymptotic lower bound (Dt O(f(n, m))) if limn,m.8(wcmo(Dt , n, m)/f(n, \nm)) = 0, i.e., .K > 0. .m0 = n0 = 2. .n = n0, m = n0. wcmo(Dt , n, m) > Kf(n, m); f is an asymptotically \ntight bound (Dt . O T(f (n, m))) if it is both an upper and a lower asymptotic bound. Fig. 10 summarizes \nour results; as described in \u00a75, we have proved all the implementations correct. Matching lower and upper \nbounds indicate worst-case optimality of an implementation (note that this is different from optimality \nin all cases). The derivation of upper bounds relies on standard techniques and is deferred to [12, \u00a7C]. \nWe now proceed to the main challenge: how to derive lower bounds that apply to any implementation of \nt. We present proofs for ctr and orset; intreg and mvr are covered in [12, \u00a7C].  6.2 Experiment Families \nThe goal is to show that for any correct implementation Dt (i.e., sat[Vstate such that Dt , T-Any] Ft \n), the object state must store some minimum amount of information. We achieve this by con\u00adstructing an \nexperiment family, which is a collection of executions Ca, where a . Q for some index set Q. Each experiment \ncontains a distinguished read event ea. The experiments are designed in such a way that the object states \nstate(ea) must be distinct, which then implies a lower bound lg|.| |Q| on the size of their encoding. \nTo prove that they are distinct, we construct black-box tests that execute the methods of Dt on the states \nand show that the tests must produce different results for each state(ea) provided Dt is correct. Formally, \nthe tests induce a read-back function rb that sat\u00adis.es rb(state(ea)) = a. We encapsulate the core argument \nin the following lemma. DEFINITION 13. An experiment family for an implementation Dt is a tuple (Q, n, \nm, C, e, rb) where Q is a .nite set, 2 = n = m, and for each a . Q, Ca . [Dt ] is an execution with n \nreplicas and m updates, ea . (Ca.E)|rd and rb : Dt .S . Q is a function satisfying rb(state(ea)) = a. \nLEMMA 14. If (Q, n, m, C, e, rb) is an experiment family, then wcmo(Dt , n, m) = Llg|.| |Q|J / (maxa.Q \nlen(Ca.rval(ea))). PROOF. Since rb(state(ea)) = a, the states state(ea) are pair\u00adwise distinct and so \nare their encodings enc(state(ea)). Since there are fewer than |Q| strings of length strictly less than \nLlg|.| |Q|J, for some a . Q we have len(enc(state(ea))) = Llg|.| |Q|J. Then  wcmo(Dt , n, m) = mmo(Dt \n, Ca) = len(state(ea)) Llg|.| |Q|J = . UD len(Ca.rval(ea)) maxa1.Q len(Ca1 .rval(ea1 )) To apply this \nlemma to the best effect, we need to .nd experi\u00adment families with |Q| as large as possible and len(Ca1 \n.rval(ea1 )) as small as possible. Finding such families is challenging, as there is no systematic way \nto derive them. We relied on intuitions about which situations force replicas to store a lot of information \nwhen searching for experiment families. Driver programs. We de.ne experiment families using driver programs \n(e.g., see Fig. 11). These are written in imperative pseu\u00addocode and use traditional constructs like \nloops and conditionals. As they execute, they construct concrete executions of the data type library \n[t . Dt ] by means of the following instructions, each of which triggers a uniquely-determined transition \nfrom Fig. 3: dor o t do operation o on x at replica r with timestamp t u . dor o t same, but assign the \nreturn value to u sendr(mid) send a message for x with identi.er mid at r receiver(mid) receive the message \nmid at replica r Programs explicitly supply timestamps for do and message identi.ers for send and receive. \nWe require that they do this cor\u00adrectly, e.g., respect uniqueness of timestamps. When a driver pro\u00adgram \nterminates, it may produce a return value. For a program P , an implementation Dt , and a con.guration \n(R, T ), we let exec(Dt , (R, T ), P ) be the concrete execution of the data type li\u00adbrary [t . Dt ] \nstarting in (R, T ) that results from running P ; we de.ne result(Dt , (R, T ), P ) as the return value \nof P in this run.  6.3 Lower Bound for State-Based Counter (ctr) sat[Vstate TH EO R E M 15. If Dctr \n, T-Any] Fctr , then Dctr O(n). is O We start by formulating a suitable experiment family. sat[Vstate \nLEMM A 16. If Dctr , T-Any] Fctr , n = 2 and m = n is a multiple of (n - 1), then tuple (Q, n, m, C, \ne, rb) as de.ned in the left column of Fig. 11 is an experiment family. The idea of the experiments is \nto force replica 1 to remember one number for each of the other replicas in the system, which then introduces \nan overhead proportional to n; cf. the implementation in Fig. 2(b). We show one experiment in Fig. 12. \nAll experiments start with a common initialization phase, de.ned by init, where each of the replicas \n2..n performs m/(n-1) increments and sends a message after each increment. All messages remain undelivered \nuntil the second phase, de.ned by exp(a). There replica 1 receives exactly one message from each replica \nr = 2..n, selected using a(r). An experiment concludes with the read ea on the .rst replica. The read-back \nworks by performing separate tests for each of the replicas r = 2..n, de.ned by test(r). For example, \nto deter\u00admine which message was sent by replica 2 during the experiment in Fig. 12, the program test(2): \nreads the counter value at replica 1, getting 12; delivers the .nal message by replica 2 to it; and reads \nthe counter value at replica 1 again, getting 14. By observing the difference, the program can determine \nthe message sent during the experiment: a(2) = 5 - (14 - 12) = 3. PRO O F O F LEMM A 16. The only nontrivial \nobligation is to prove rb(state(ea)) = a. Let (Ra, Ta) = .nal(Ca). Then (i) a(r) = result(Dctr , (R0, \nT0), (init; exp(a); test(r))) = result(Dctr , (Ra, Ta), test(r)) (ii) = result(Dctr , (Rinit [(x, 1) \n. Ra(x, 1)], Tinit ), test(r)) = rb(Ra(x, 1))(r) = rb(state(ea))(r), Figure 11. Experiment families (Q, \nn, m, C, e, rb) used in the proofs of Theorem 15 (ctr) and Theorem 17 (orset) ctr orset Conditions on \nn, m (number of replicas/updates) m = n = 2 m = n = 2 m mod (n - 1) = 0 (m - 1) mod (n - 1) = 0 Index \nset Q Q = ([2..n] . [1.. m n-1 ]) Q = ([2..n] . [1.. m-1 n-1 ]) Family size |Q||Q| = ( m n-1 )n-1 |Q| \n= ( m-1 n-1 )n-1 Driver programs procedure init for all r . [2..n] for all i . [1.. m n-1 ] dor inc rm+i \nsendr(midr,i ) procedure init for all r . [2..n] for all i . [1.. m-1 n-1 ] dor add(0) rm+i sendr(midr,i \n) procedure exp(a) for all r . [2..n] receive1(midr,a(r)) do1 rd (n+2)m // read ea procedure exp(a) for \nall r . [2..n] receive1(midr,a(r)) do1 remove(0) (n+2)m do1 rd (n+3)m // read ea procedure test(r) u \n. do1 rd (n+3)m receive1(midr, m n-1 ) u ' . do1 rd (n+4)m return m n-1 - (u ' - u) procedure test(r) \nfor all i . [1..( m-1 n-1 )] receive1(midr,i ) u . do1 rd (n+4)m+i if 0 . u return i - 1 return m-1 n-1 \nDe.nition of executions Ca Ca = exec(Dt , (R0, T0), init; exp(a)) where (R0, T0) = ([x . Dt .is0], \u00d8) \nDe.nition of read-back function rb : Dt .S . Q rb(s) = .r : [2..n].result(Dt , (Rinit [(x, 1) . s], Tinit \n), test(r)) where (Rinit , Tinit ) = post(exec(Dt , (R0, T0), init)) Figure 12. Example experiment (n \n= 4 and m = 15) and test for ctr. Gray dashed lines represent the con.guration (Rinit [(x, 1) . Ra(x, \n1)], Tinit ) where the test driver program is applied. where: sat[Vstate (i) This is due to Dctr , T-Any] \nFctr , as we explained informally above. Let Ca ' = exec(Dctr , (R0, T0), (init; exp(a); test(r))). a \n' , Vstate Then the operation context in abs(C ) of the .rst read c n in test(r) contains r=2 a(r) increments, \nwhile that of the second read contains (m/(n - 1)) - a(r) more increments. (ii) We have Ta = Tinit because \nexp(a) does not send any mes\u00adsages. Also, Ra and Rinit [(x, 1) . Ra(x, 1)] can differ only in the states \nof the replicas 2..n. These cannot in.uence the run of test(r), since it performs events on replica 1 \nonly. DU  PRO O F O F TH EO R E M 15. Given n0, m0, we pick n = n0 and some m = n0 such that m is a \nmultiple of (n - 1) and m = n 2. Take the experiment family (Q, n, m, C, e, rb) given by Lemma 16. Then \nfor any a, Ca.rval(ea) is at most the total num\u00adber of increments m in Ca. Using Lemma 14 and m = n 2, \nfor some constants K1, K2, K3, K independent from n0, m0 we get: wcmo(Dctr , n, m) = Llg|.| |Q|J/(maxa.Q \nlen(Ca.rval(ea))) = m )n-1 v lg|.|( n-1 n lg(m/n) n lg m K1 = K2 = K3 = K n. DU lenN0 (m) lg m lg m \n 6.4 Lower Bound for State-Based OR-Set (orset) sat[Vstate TH EO R E M 17. If Dorset , T-Any] Forset \n, then Dorset is O O(n lg m). sat[Vstate LEMM A 18. If Dorset , T-Any] Forset , n = 2 and m = n is such \nthat (m - 1) is a multiple of (n - 1), then the tuple (Q, n, m, C, e, rb) on the right in Fig. 11 is \nan experiment family. The proof is the same as that of Lemma 16, except for obligation (i). We therefore \ngive only informal explanations. The main idea of the experiments de.ned in the lemma is to force replica \n1 to remember element instances even after they have been removed at that replica; cf. our explanation \nof the challenges of implementing the OR-set from \u00a75.3. The experiments follow a similar pattern to those \nfor ctr, but use different operations. In the m-1 common init phase, each replica 2..n performs n-1 operations \nadding a designated element 0, which are interleaved with sending messages. In the experiment phase exp(a), \none message from each replica r = 2..n, selected by a(r), is delivered to replica 1. At the end of execution, \nreplica 1 removes 0 from the set and performs the read ea. The return value of this read is always the \nempty set. To perform the read-back of a(r) for r = 2..n, test(r) delivers all messages by replica r \nto replica 1 in the order they were sent and, after each such delivery, checks if replica 1 now reports \nthe sat[Vstate element 0 as part of the set. From Dorset , T-Any] Forset and the de.nition (5) of Forset \n, we get that exactly the .rst a(r) such deliveries will have no effect on the contents of the set: the \nrespective add operations have already been observed by the remove operation that replica 1 performed \nin the experiment phase. Thus, if 0 appears in the set right after delivering the i-th message of replica \nr, then a(r) = i-1, and if 0 does not appear by the time the loop is .nished, then a(r) = (m - 1)/(n \n- 1). PRO O F OF TH EO R E M 17. Given n0, m0, we pick n = n0 and some m = n0 such that (m - 1) is a \nmultiple of (n - 1) and m = n 2. Take the experiment family (Q, n, m, C, e, rb) given by Lemma 18. For \nany a . Q, Ca.rval(ea) = \u00d8, which can be encoded with a constant length. Using Lemma 14 and m = n 2, \nfor some constants K1, K2, K we get: wcmo(Dorset , n, m) = Llg|.| |Q|J / (maxa.Q len(Ca.rval(ea))) v \n= K1n lg(m/n) = K2n lg m = K n lg m. UD 7. Store Correctness and Consistency Axioms Recall that we de.ne \na replicated store by a data type library D and a transport layer speci.cation T (\u00a74), and we specify \nits behavior by a function F from types t . dom(D) to data type speci.cations and a set of consistency \naxioms (\u00a73). The axioms are just constraints over abstract executions, such as those shown in Fig. 13; \nfrom now on we denote their sets by X. So far we have concentrated on single data type speci.cations \nF(t ) and their correspondence to implementations D(t ), as stated by Def. 7. In this section we consider \nconsistency axioms and formulate the notion of correctness of the whole store (D, T ) with respect to \nits speci.cation (F, X). Our .rst goal is to lift the statement of correctness given by Def. 7 to a store \n(D, T ) with multiple objects of different data types. To this end, we assume a function V mapping each \ntype t . dom(D) to its visibility witness V. This allows us to construct the visibility relation for \na concrete execution C . [D] n T by applying V(t) to its projection onto the events on every object of \ntype t: witness(V) = .C. {V(type(x))(C|x) | x . Obj}, where \u00b7|x projects to events over x. Then the \ncorrectness of every separate data type t in the store with respect to F(t) according to Def. 7 automatically \nensures that the behavior of the whole store is consistent with Fin the sense of Def. 5. PRO P O S ITI \nO N 19. (.t . dom(D). D(t) sat[V(t ), T ] F(t )) =. (.C . [D] n T . abs(C, witness(V)) |= F). This motivates \nthe following de.nition of store correctness. Let us write A |= X when the abstract execution A satis.es \nthe axioms X. DE FIN I T I ON 20. A store (D, T ) is correct with respect to a speci\u00ad.cation (F, X), \nif for some V: (i) .t . dom(D). (D(t) sat[V(t), T ] F(t )); and (ii) .C . [D] n T . (abs(C, witness(V)) \n|= X). We showed how to discharge (i) in \u00a75. The validity of axioms X required by (ii) most often depends \non the transport layer spec\u00adi.cation T : e.g., to disallow the anomaly (2) from \u00a71, T needs to provide \nguarantees on how messages pertaining to different objects are delivered. However, data type implementations \ncan also enforce axioms by putting enough information into messages: e.g., imple\u00admentations correct with \nrespect to Vstate from \u00a74 ensure that vis is transitive regardless of the behavior of the transport layer. \nFor\u00adtunately, to establish (ii) in practice, we do not need to consider the internals of data type implementations \nin D just knowing the visibility witnesses used in the statements of their correctness is enough, as \nformulated in the following de.nition. DE FIN I T I ON 21. A set W of visibility witnesses and a transport \nlayer speci.cation T validate axioms X, if .C, V. (C . T ) . ({V(t) | t . dom(V)} . W ) =. (abs(C, witness(V)) \n|= X). Since visibility witnesses are common to wide classes of data types (e.g., state-or op-based), \nour proofs of the validity of axioms will not have to be redone if we add new data type implementations \nto the store from a class already considered. We next present axioms formalizing several variants of \neventual consistency used in replicated stores (Fig. 13 and 14) and W and T that validate them. We then \nuse this as a basis for discussing connections with weak shared-memory models. Due to space con\u00adstraints, \nwe defer technical details and proofs to [12, \u00a7D]. Basic eventual consistency. EV EN TUA L and TH INAI \nR de.ne a weak form of eventual consistency. EVE NT UA L ensures that an event cannot be invisible to \nin.nitely many other events on the same object and thus implies (1) from \u00a71: informally, if updates stop, \nthen reads at all replicas will eventually see all updates and will return the same values (\u00a73.2). However, \nEV EN TUA L is stronger than quiescent consistency: the latter does not provide any guaran\u00adtees at all \nfor executions with in.nitely many updates to the store, whereas our speci.cation implies that the return \nvalues are com\u00adputed according to F(t) using increasingly up-to-date view of the store state. We formalize \nthese relationships in [12, \u00a7D]. TH I NAI R prohibits values from appearing out-of-thin\u00adair [28], like \n42 in Fig. 14(a) (recall that registers are initialized to 0). Cycles in ro . vis that lead to out-of-thin-airs \nusually arise  Figure 13. A selection of consistency axioms over an execution (E, repl, obj, oper, rval, \nro, vis, ar) Auxiliary relations sameobj(e, f) .. obj(e) = obj(f) Per-object causality (aka happens-before) \norder: hbo = ((ro n sameobj) . vis)+ Causality (aka happens-before) order: hb = (ro . vis)+ Axioms EVENTUAL: \nvis .e . E. \u00ac(. in.nitely many f . E. sameobj(e, f) . \u00ac(e -. f)) THINAIR: ro . vis is acyclic POCV (Per-Object \nCausal Visibility): hbo . vis POCA (Per-Object Causal Arbitration): hbo . ar COCV (Cross-Object Causal \nVisibility): (hb n sameobj) . vis COCA (Cross-Object Causal Arbitration): hb . ar is acyclic (a) Disallowed \nby THINAIR: x, y : intreg i = x.rd j = y.rd y.wr(i) x.wr(j) (b) Disallowed by POCV: x : orset x.add(1) \ni = x.rd j = x.rd x.add(2) x.add(3) (c) Allowed by COCV and COCA: x, y : intreg x.wr(1) y.wr(1) i = y.rd \nj = x.rd from effects of speculative computations, which are done by some older replicated stores [36]. \nTHINAIR is validated by {Vstate , Vop} and T-Any, and EVEN-TUAL by {Vstate , Vop} and the following condition \non C ensuring that every message is eventually delivered to all other replicas and every operation is \nfollowed by a message generation: (.e . C.E. .r, r ' . C.act(e) = send . C.repl(e) = r . r = r ' del(C) \n=. .f. C.repl(f) = r ' . e - --. f ) . roo(C) (.e . C.E. C.act(e) = do =. .f. act(f) = send . e - --. \nf ), where roo(C) is ro(C) projected to events on the same object. Causality guarantees. Many replicated \nstores achieve availabil\u00adity and partition tolerance while providing stronger guarantees, which we formalize \nby the other axioms in Fig. 13. We call an ex\u00adecution per-object, respectively, cross-object causally \nconsistent, if it is eventually consistent (as per above) and satis.es the ax\u00adioms POCV and POCA, respectively, \nCOCV and COCA. POCV guarantees that an operation sees all operations connected to it by a causal chain \nof events on the same object; COCV also consid\u00aders causal chains via different objects. Thus, POCV disallows \nthe execution in Fig. 14(b), and COCV the one in \u00a73.1, correspond\u00ading to (2) from \u00a71. POCA and COCA similarly \nrequire arbitration to be consistent with causality. The axioms highlight the principle of formalizing \nstronger consistency models: including more edges into vis and ar, so that clients have more up-to-date \ninformation. Cross-object causal consistency is implemented by, e.g., COPS [27] and Gemini [23]. It is \nweaker than strong consistency, as it allows reading stale data. For example, it allows the execution \nin Fig. 14(c), where both reads fetch the initial value of the register, despite writes to it by the \nother replica. It is easy to check that this outcome cannot be produced by any interleaving of the events \nat the two replicas, and is thus not strongly consistent. An interesting feature of per-object causal \nconsistency is that state-based data types ensure most of it just by the de.nition of Vstate: POCV is \nvalidated by {Vstate} and T-Any. If the witness set is {Vstate , Vop}, then we need T to guarantee the \nfollowing: in\u00adformally, if a send event e and another event f are connected by a causal chain of events \non the same object, then the message cre\u00adated by e is delivered to C.repl(f) by the time f is done. POCA \nis validated by {Vstate , Vop} and the transport layer speci.cation (roo(C) . del(C))+|do . ar(C). This \nstates that timestamps of events on every object behave like a Lamport clock [22]. Condi\u00adtions for COCV \nand COCA are similar. There also exist consistency levels in between basic eventual consistency and per-object \ncausal consistency, de.ned using so\u00adcalled session guarantees [35]. We cover them in [12, \u00a7D]. Comparison \nwith shared-memory consistency models. Inter\u00adestingly, the specializations of the consistency levels \nde.ned by the axioms in Fig. 13 to the type intreg of LWW-registers are very close to those adopted by \nthe memory model in the 2011 C and C++ standards [5]. Thus, POCA and POCV de.ne the semantics of the \nfragment of C/C++ restricted to so-called relaxed operations; there this semantics is de.ned using coherence \naxioms, which are analogous to session guarantees [35]. COCV and COCA are close to the semantics of C/C++ \nrestricted to release-acquire operations. However, C/C++ does not have an analog of EVENTUAL and does \nnot validate THINAIR, since it makes the effects of speculations visible to the programmer [4]. We formalize \nthe correspondence to C/C++ in [12, \u00a7D]. In the future, this correspondence may open the door to applying \ntechnology developed for shared-memory mod\u00adels to eventually consistent systems; promising directions \ninclude model checking [3, 9], automatic inference of required consistency levels [26] and compositional \nreasoning [4]. 8. Related Work For a comprehensive overview of replicated data type research we refer \nthe reader to Shapiro et al. [32]. Most papers proposing new data type implementations [6, 31 33] do \nnot provide their formal declarative speci.cations, save for the expected property (1) of qui\u00adescent \nconsistency or .rst speci.cation attempts for sets [6, 7]. For\u00admalizations of eventual consistency have \neither expressed quiescent consistency [8] or gave low-level operational speci.cations [17]. An exception \nis the work of Burckhardt et al. [10, 13], who pro\u00adposed an axiomatic model of causal eventual consistency \nbased on visibility and arbitration relations and an operational model based on revision diagrams. Their \nstore speci.cation does not provide customizable consistency guarantees, and their data type speci.ca\u00adtions \nare limited to the sequential S construction from \u00a73.2, which cannot express advanced con.ict resolution \nused by the multi-value register, the OR-set and many other data types [32]. More signif\u00adicantly, their \noperational model does not support general op-or state-based implementations, and is thus not suited \nfor studying the correctness or optimality of these commonly used patterns. Simulation relations have \nbeen applied to verify the correctness of sequential [25] and shared-memory concurrent data type imple\u00admentations \n[24]. We take this approach to the more complex set\u00adting of a replicated store, where the simulation \nneeds to take into account multiple object copies and messages and associate them with structures on \nevents, rather than single abstract states. This poses technical challenges not considered by prior work, \nwhich we address by our novel notion of replication-aware simulations. The distributed computing community \nhas established a num\u00adber of asymptotic lower bounds on the complexity of implement\u00ading certain distributed \nor concurrent abstractions, including one\u00adshot timestamp objects [20] and counting protocols [15, 30]. \nThese works have considered either programming models or metrics sig\u00adni.cantly different from ours. An \nexception is the work of Charron-Bost [14], who proved that the size of vector clocks [29] is optimal \nto represent the happens-before relation of a computation (similar to the visibility relation in our \nmodel). Speci.cations of mvr and orset rely on visibility; however, Charron-Bost s result does not directly \ntranslate into a lower bound on their implementation com\u00adplexity, since a speci.cation may not require \ncomplete knowledge about the relation and an implementation may represent it in an arbitrary manner, \nnot necessarily using a vector.  9. Conclusion and Future Work We have presented a comprehensive theoretical \ntoolkit to advance the study of replicated eventually consistent stores, by proposing methods for (1) \nspecifying the semantics of replicated data types and stores abstractly, (2) verifying implementations \nof replicated data types, and (3) proving that such implementations have optimal metadata overhead. By \nproving both correctness and optimality of four nontrivial data type implementations, we have demonstrated \nthat our methods can indeed be productively applied to the kinds of patterns used by practitioners and \nresearchers in this area. Although our work marks a big step forward, it is only a be\u00adginning, and creates \nplenty of opportunities for future research. We have already made the .rst steps in extending our speci.cation \nframework with more features, such as mixtures of consistency lev\u00adels [23] and transactions [34, 37]; \nsee [11]. In the future we would also like to study more data types, such as lists used for collab\u00adorative \nediting [32], and to investigate metadata bounds for data type implementations other than state-based \nones, including more detailed overhead metrics capturing optimizations invisible to the worst-case overhead \nanalysis. Even though our execution model for replicated stores follows the one used by replicated data \ntype designers [33], there are opportunities for bringing it closer to ac\u00adtual implementations. Thus, \nwe would like to verify the algorithms used by store implementations [27, 34, 37] that our semantics \nab\u00adstracts from. This includes fail-over and session migration proto\u00adcols, which permit clients to interact \nwith multiple physical repli\u00adcas, while being provided the illusion of a single virtual replica. Finally, \nby bringing together prior work on shared-memory models and data replication, we wish to promote an exchange \nof ideas and results between the research communities of program\u00adming languages and veri.cation on one \nside and distributed sys\u00adtems on the other. Acknowledgements. We thank Hagit Attiya, Anindya Banerjee, \nCarlos Baquero, Lindsey Kuper and Marc Shapiro for comments that helped improve the paper. Gotsman was \nsupported by the EU FET project ADVENT, and Yang by EPSRC. References [1] Riak key-value store. http://basho.com/products/riak-overview/. \n[2] S. V. Adve and K. Gharachorloo. Shared memory consistency models: A tutorial. Computer, 29(12), 1996. \n[3] J. Alglave, D. Kroening, V. Nimal, and M. Tautschnig. Software veri.cation for weak memory via program \ntransformation. In ESOP, 2013. [4] M. Batty, M. Dodds, and A. Gotsman. Library abstraction for C/C++ \nconcurrency. In POPL, 2013. [5] M. Batty, S. Owens, S. Sarkar, P. Sewell, and T. Weber. Mathematizing \nC++ concurrency. In POPL, 2011. [6] A. Bieniusa, M. Zawirski, N. Preguic\u00b8 a, M. Shapiro, C. Baquero, \nV. Balegas, and S. Duarte. An optimized con.ict-free replicated set. Technical Report 8083, INRIA, 2012. \n[7] A. Bieniusa, M. Zawirski, N. M. Preguic\u00b8 a, M. Shapiro, C. Baquero, V. Balegas, and S. Duarte. Brief \nannouncement: Semantics of eventu\u00adally consistent replicated sets. In DISC, 2012. [8] A.-M. Bosneag and \nM. Brockmeyer. A formal model for eventual consistency semantics. In IASTED PDCS, 2002. [9] S. Burckhardt, \nR. Alur, and M. M. K. Martin. Checkfence: checking consistency of concurrent data types on relaxed memory \nmodels. In PLDI, 2007. [10] S. Burckhardt, M. F \u00a8ahndrich, D. Leijen, and B. P. Wood. Cloud types for \neventual consistency. In ECOOP, 2012. [11] S. Burckhardt, A. Gotsman, and H. Yang. Understanding eventual \ncon\u00adsistency. Technical Report MSR-TR-2013-39, Microsoft Research, 2013. [12] S. Burckhardt, A. Gotsman, \nH. Yang, and M. Zawirski. Replicated data types: speci.cation, veri.cation, optimality (extended version), \n2013. http://research.microsoft.com/apps/pubs/?id=201602. [13] S. Burckhardt, D. Leijen, M. F \u00a8ahndrich, \nand M. Sagiv. Eventually consistent transactions. In ESOP, 2012. [14] B. Charron-Bost. Concerning the \nsize of logical clocks in distributed systems. Information Processing Letters, 39(1), 1991. [15] J.-Y. \nChen and G. Pandurangan. Optimal gossip-based aggregate computation. In SPAA, 2010. [16] N. Conway, R. \nMarczak, P. Alvaro, J. M. Hellerstein, and D. Maier. Logic and lattices for distributed programming. \nIn SOCC, 2012. [17] A. Fekete, D. Gupta, V. Luchangco, N. Lynch, and A. Shvartsman. Eventually-serializable \ndata services. In PODC, 1996. [18] G. DeCandia et al. Dynamo: Amazon s highly available key-value store. \nIn SOSP, 2007. [19] S. Gilbert and N. Lynch. Brewer s conjecture and the feasibility of consistent, available, \npartition-tolerant web services. SIGACT News, 33(2), 2002. [20] M. Helmi, L. Higham, E. Pacheco, and \nP. Woelfel. The space complex\u00adity of long-lived and one-shot timestamp implementations. In PODC, 2011. \n[21] C. A. R. Hoare. Proof of correctness of data representations. Acta Inf., 1, 1972. [22] L. Lamport. \nTime, clocks, and the ordering of events in a distributed system. Commun. ACM, 21(7), 1978. [23] C. Li, \nD. Porto, A. Clement, R. Rodrigues, N. Preguic\u00b8a, and J. Gehrke. Making geo-replicated systems fast if \npossible, consistent when nec\u00adessary. In OSDI, 2012. [24] H. Liang, X. Feng, and M. Fu. A rely-guarantee-based \nsimulation for verifying concurrent program transformations. In POPL, 2012. [25] B. Liskov and S. Zilles. \nProgramming with abstract data types. In ACM Symposium on Very High Level Languages, 1974. [26] F. Liu, \nN. Nedev, N. Prisadnikov, M. T. Vechev, and E. Yahav. Dy\u00adnamic synthesis for relaxed memory models. In \nPLDI, 2012. [27] W. Lloyd, M. J. Freedman, M. Kaminsky, and D. G. Andersen. Don t settle for eventual: \nscalable causal consistency for wide-area storage with COPS. In SOSP, 2011. [28] J. Manson, W. Pugh, \nand S. V. Adve. The Java memory model. In POPL, 2005. [29] F. Mattern. Virtual time and global states \nof distributed systems. Parallel and Distributed Algorithms, 1989. [30] S. Moran, G. Taubenfeld, and \nI. Yadin. Concurrent counting. In PODC, 1992. [31] H.-G. Roh, M. Jeon, J.-S. Kim, and J. Lee. Replicated \nabstract data types: Building blocks for collaborative applications. J. Parallel Distrib. Comput., 71(3), \n2011. [32] M. Shapiro, N. Preguic\u00b8a, C. Baquero, and M. Zawirski. A comprehen\u00adsive study of Convergent \nand Commutative Replicated Data Types. Technical Report 7506, INRIA, 2011. [33] M. Shapiro, N. M. Preguic\u00b8 \na, C. Baquero, and M. Zawirski. Con.ict\u00adfree replicated data types. In SSS, 2011. [34] Y. Sovran, R. \nPower, M. K. Aguilera, and J. Li. Transactional storage for geo-replicated systems. In SOSP, 2011. [35] \nD. B. Terry, A. J. Demers, K. Petersen, M. Spreitzer, M. Theimer, and B. W. Welch. Session guarantees \nfor weakly consistent replicated data. In PDIS, 1994.  [36] D. B. Terry, M. M. Theimer, K. Petersen, \nA. J. Demers, M. J. Spreitzer, and C. H. Hauser. Managing update con.icts in Bayou, a weakly connected \nreplicated storage system. In SOSP, 1995. [37] M. Zawirski, A. Bieniusa, V. Balegas, S. Duarte, C. Baquero, \n M. Shapiro, and N. Preguic\u00b8 a. SwiftCloud: Fault-tolerant geo\u00adreplication integrated all the way to \nthe client machine. Technical Report 8347, INRIA, 2013.    \n\t\t\t", "proc_id": "2535838", "abstract": "<p>Geographically distributed systems often rely on replicated eventually consistent data stores to achieve availability and performance. To resolve conflicting updates at different replicas, researchers and practitioners have proposed specialized consistency protocols, called replicated data types, that implement objects such as registers, counters, sets or lists. Reasoning about replicated data types has however not been on par with comparable work on abstract data types and concurrent data types, lacking specifications, correctness proofs, and optimality results.</p> <p>To fill in this gap, we propose a framework for specifying replicated data types using relations over events and verifying their implementations using replication-aware simulations. We apply it to 7 existing implementations of 4 data types with nontrivial conflict-resolution strategies and optimizations (last-writer-wins register, counter, multi-value register and observed-remove set). We also present a novel technique for obtaining lower bounds on the worst-case space overhead of data type implementations and use it to prove optimality of 4 implementations. Finally, we show how to specify consistency of replicated stores with multiple objects axiomatically, in analogy to prior work on weak memory models. Overall, our work provides foundational reasoning tools to support research on replicated eventually consistent stores.</p>", "authors": [{"name": "Sebastian Burckhardt", "author_profile_id": "81350574118", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P4383819", "email_address": "sburckha@microsoft.com", "orcid_id": ""}, {"name": "Alexey Gotsman", "author_profile_id": "81322494535", "affiliation": "IMDEA Software Institute, Madrid, Spain", "person_id": "P4383820", "email_address": "Alexey.Gotsman@imdea.org", "orcid_id": ""}, {"name": "Hongseok Yang", "author_profile_id": "81100355747", "affiliation": "University of Oxford, Oxford, United Kingdom", "person_id": "P4383821", "email_address": "Hongseok.Yang@cs.ox.ac.uk", "orcid_id": ""}, {"name": "Marek Zawirski", "author_profile_id": "81490695084", "affiliation": "INRIA &#38; UPMC-LIP6, Paris, France", "person_id": "P4383822", "email_address": "Marek.Zawirski@lip6.fr", "orcid_id": ""}], "doi_number": "10.1145/2535838.2535848", "year": "2014", "article_id": "2535848", "conference": "POPL", "title": "Replicated data types: specification, verification, optimality", "url": "http://dl.acm.org/citation.cfm?id=2535848"}