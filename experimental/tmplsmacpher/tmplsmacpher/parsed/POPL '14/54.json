{"article_publication_date": "01-08-2014", "fulltext": "\n Closed Type Families with Overlapping Equations Richard A. Eisenberg Dimitrios Vytiniotis Stephanie \nWeirich University of Pennsylvania Simon Peyton Jones University of Pennsylvania eir@cis.upenn.edu Microsoft \nResearch Cambridge sweirich@cis.upenn.edu {dimitris,simonpj}@microsoft.com Abstract Open, type-level \nfunctions are a recent innovation in Haskell that move Haskell towards the expressiveness of dependent \ntypes, while retaining the look and feel of a practical programming language. This paper shows how to \nincrease expressiveness still further, by adding closed type functions whose equations may overlap, and \nmay have non-linear patterns over an open type universe. Although practically useful and simple to implement, \nthese features go be\u00adyond conventional dependent type theory in some respects, and have a subtle metatheory. \nCategories and Subject Descriptors F.3.3 [Logics and Mean\u00adings of Programs]: Studies of Program Constructs \ntype structure; D.3.3 [Programming Languages]: Language Constructs and Fea\u00adtures; F.4.2 [Mathematical \nLogic and Formal Languages]: Gram\u00admars and Other Rewriting Systems parallel rewriting systems General \nTerms Design, Languages, Theory Keywords Type families; Type-level computation; Haskell; Sys\u00adtem FC 1. \nIntroduction Type families are a relatively recent extension to Haskell that allows the programmer to \nexpress type-level computation (Chakravarty et al. 2005). For example, one can say type family Elt (a \n:: *) :: * type instance Elt ByteString = Word8 type instance Elt [b] = b The .rst line declares the \ntype family Elt and gives its kind; the second and third are two independent declarations that give two \nequations for Elt. Now the types (Elt ByteString ) and Word8 are considered equivalent by the type inference \nengine, and likewise (Elt [Int ]) and Int. Type families have proved to be a popular feature in Haskell, \ndovetailing particularly nicely with Haskell s type classes. Type families are naturally partial and \nopen. For example, there is no equation for Elt Char above, so Elt Char will never be equal to any other \ntype. On the other hand, the author of a new library is free to add a new instance, such as this one: \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. Copyrights for components of \nthis work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, \nor republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. Request permissions from permissions@acm.org. type instance Elt (Set b) = b However, not all \ntype-level functions can be de.ned by open type families. An important example is the equality function, \nwhich determines whether two types can be shown equal at compile\u00adtime:1 type family Equal a b :: Bool \ntype instance Equal a a = True --Instance (A) type instance Equal a b = False --Instance (B) The programmer \nintends these equations to be read top-to-bottom, like a term-level function de.nition in Haskell. However, \nbecause GHC s current type families are open, they must be de.ned by inde\u00adpendent, un-ordered type instance \nequations. The two equations overlap, so they are rightly rejected lest they be used to deduce unsound \ntype equalities. For example, we could reduce the type Equal Int Int to both True and False , since both \npatterns match. Yet equality is a well-de.ned function, and a useful one too, as we discuss in Section \n2. To .x this omission we introduce closed type families with ordered equations, thus: type family Equal \na b :: Bool where Equal a a = True Equal a b = False  Now all the equations for the type family are \ngiven together, and can be read top-to-bottom. However, behind this simple idea lie a number of complexities. \nIn this paper we describe these pitfalls and their sometimes non-obvious solutions. We make the following \ncontributions: We introduce closed type families with overlapping equations, and show how they can readily \nexpress programs that were previously inexpressible or required indirect encodings (Sec\u00adtion 2).  Our \nsystem supports non-linear left-hand sides, such as that for Equal above, where the variable a is repeated \nin the .rst equa\u00adtion. It also supports coincident overlap, which allows some lightweight theorem-proving \ncapability to be incorporated in the de.nitional equality of types (Section 3.4).  We give the subtle \nrules that govern type family simpli.ca\u00adtion, including those that determine when a pattern cannot be \nmatched by a type (Section 3).  We describe a typed core language that includes both open and closed \ntype families (Section 4), and prove that it is type-safe, assuming that type families terminate (Section \n5). We do that by establishing a consistency property of the type equations induced by type families. \n POPL 14, January 22 24, 2014, San Diego, CA, USA. Copyright &#38;#169; 2014 ACM 978-1-4503-2544-8/14/01. \n. . $15.00. 1 Here we use datatype promotion, allowing data types like Bool , and lists, http://dx.doi.org/10.1145/2535838.2535856 \nto be used as kinds (Yorgey et al. 2012).  We identify the complications for consistency that arise \nfrom non-terminating type families and we expose a subtle oversight in GHC s current rules for open type \nfamilies in Section 6.  We have implemented closed type families in GHC as well as a number of case \nstudies, such as the units package, an extensible framework for dimensional analysis, presented in the \nextended version of this paper (Eisenberg et al. 2013). Closed type families are available now in GHC \n7.8.  In short, the programmer sees a simple, intuitive language fea\u00adture, but the design space (and \nits metatheory) is subtle. Although type families resemble the type-level computation and large elim\u00adinations \nfound in full-spectrum dependently-typed languages like Coq and Agda, there are important semantic and \npractical differ\u00adences. We discuss these in Section 8. 2. Closed type families Haskell (in its implementation \nin GHC) has supported type families for several years. They were introduced to support associated types, \na feature that Garcia et al. s (2003) comparison between C++, Haskell, and ML, noted as a C++ s main \nsuperiority for generic programming. Type families were designed to dovetail smoothly with type classes. \nFor example, the type function2 Elt above could be used to specify the element type in a container class: \nclass Container c where empty :: c member :: Elt c . c . Bool instance Container [a] where ... instance \nContainer ByteString where ... New instances for Container can be de.ned as new types are introduced, \noften in different modules, and correspondingly new equations for Elt must be added too. Hence Elt must \nbe open (that is, can be extended in modules that import it), and distributed (can be scattered over \nmany different modules). This contrasts with term-level functions where we are required to de.ne the \nfunction all in one place. The open, distributed nature of type families, typically associ\u00adated with \nclasses, requires strong restrictions on overlap to maintain soundness. Consider type family F a b :: \n* type instance F Int a = Bool type instance F a Bool = Char Now consider the type (F Int Bool ). Using \nthe .rst equation, this type is equal to Bool , but using the second it is equal to Char . So if we are \nnot careful, we could pass a Bool to a function expecting a Char , which would be embarrassing. GHC therefore \nbrutally insists that the left-hand sides of two type instance equations must not overlap (unify). (At \nleast, unless the right-hand sides would then coincide; see Section 3.4.) 2.1 Closed families: the basic \nidea As we saw in the Introduction, disallowing overlap means that use\u00adful, well-de.ned type-level functions, \nsuch as type level equality, cannot be expressed. Since openness is the root of the overlap prob\u00adlem, \nit can be solved by de.ning the equations for the type family all in one place. We call this a closed \ntype family and de.ne it using a where clause on the function s original declaration. The equa\u00adtions \nmay overlap, and are matched top-to-bottom. For example: 2 We use type family and type function interchangeably. \ntype family And (a :: Bool ) (b :: Bool ) :: Bool where And True True = True And a b = False Since the \ndomain of And is closed and .nite, it is natural to write all its equations in one place. Doing so directly \nexpresses the fact that no further equations are expected. Although we have used overlap in this example, \none can always write functions over .nite domains without overlap: type family And (a :: Bool ) (b :: \nBool ) :: Bool where And True True = True And False True = False And True False = False And False False \n= False Nevertheless, overlap is convenient for the programmer, mirrors what happens at the term level, \navoids a polynomial blowup in program size, and is more ef.cient (for the type checker) to execute. Furthermore, \nwhen de.ned over an open kind, such as *, closed type families allow a programmer to express relationships \n(such as inequality of types see Section 2.4) that are otherwise out of reach. 2.2 Non-linear patterns \nLet us return to our equality function, which can now be de.ned thus: type family Equal (a :: *) (b :: \n*) :: Bool where Equal a a = True Equal a b = False  This declaration introduces the type function Equal, \ngives its kind and, in the where clause, speci.es all its equations. The .rst equa\u00adtion has a non-linear \npattern, in which a is repeated, and it overlaps with the second equation. If the domain were .nite we \ncould avoid both features by writing out all the equations exhaustively, but new types can be introduced \nat any time, so we cannot do that here. The issue becomes even clearer when we use kind polymorphism \n(Yorgey et al. 2012), thus: type family Equal (a :: .) (b :: .) :: Bool where Equal a a = True Equal \na b = False  For example, (Equal Maybe List ) should evaluate to False . It may seem unusual to de.ne \na function to compute equality even over types of function kind (* . *). After all, there is no construct \nthat can compare functions at the term level. At the type level, however, the type checker decides equality \nat function kinds all the time! In the world of Haskell types there exist no anonymous type-level functions, \nnor can type families appear partially applied, so this equality test which checks for de.nitional equality, \nin type theory jargon is straightforward. All Equal does is reify the (non-extensional) equality test \nof the type checker. In fact, Haskell programmers are used to this kind of equality matching on types; \nfor example, even in Haskell 98 one can write instance Num a . Num (T a a) where ... Because the type \ninference engine already supports decidable equality, it is very straightforward to implement non-linear \npat\u00adterns for type functions as well as type classes. Non-linear patterns are convenient for the programmer, \nexpected by Haskell users, and add useful expressiveness. They do make the metatheory much harder, as \nwe shall see, but that is a problem that has to be solved only once.  2.3 Type structure matching In \nour experience, most cases where closed type families with over\u00adlapping equations are useful involve \na variation on type equality. However, sometimes we would like to determine whether a type matches a \nspeci.c top-level structure. For example, we might want to look at a function type of the form Int . \n(Bool . Char ) . Int . Bool and determine that this is a function of three arguments. data Nat = Zero \n| Succ Nat type family CountArgs (f :: *) :: Nat where CountArgs (a . b) = Succ (CountArgs b) CountArgs \nresult = Zero Because the equations are tried in order, any function type will trigger the .rst equation \nand any ground non-function type (that is, a type that is not a type variable or an arrow type) will \ntrigger the second. Thus, the type family effectively counts the number of parameters a function requires. \nWhen might this be useful? We have used this type family to write a variable-arity zipWith function that \ninfers the correct ar\u00adity, assuming that the result type is not a function type. Other approaches that \nwe are aware of (Fridlender and Indrika 2000; McBride 2002; Weirich and Casinghino 2010) require some \nencod\u00ading of the desired arity to be passed explicitly. A full presentation of the variable-arity zipWith \nis presented in the extended version of this paper. To achieve the same functionality in a typical depen\u00addently \ntyped language like Agda or Coq, we must pattern-match over some inductive universe of codes that can \nbe interpreted into types. 2.4 Observing inequality Type families such as Equal allow programmers to \nobserve when types do not match. In other words, Equal Int Bool automatically reduces to False , via \nthe second equation. With open type families, we could only add a .nite number of reductions of un-equal \ntypes to False . However, the ability to observe inequality is extremely use\u00adful for expressing failure \nin compile-time search algorithms. This search could be a simple linear search, such as .nding an element \nin a list. Such search underlies the HList library and its encod\u00ading of heterogeneous lists and extensible \nrecords (Kiselyov et al. 2004). It also supports Swierstra s solution to the expression prob\u00adlem via \nextensible datatypes (Swierstra 2008). Both of these pro\u00adposals use the extension -XOverlappingInstances \nto implement a compile-time equality function.3 Type families can directly encode more sophisticated \nsearch al\u00adgorithms than linear list searching, including those requiring back\u00adtracking, simply by writing \na functional program. For example, the following closed type family determines whether a given element \nis present in a tree. data Tree a = Leaf a | Branch (Tree a) (Tree a) type family TMember (e :: .) (set \n:: Tree .) :: Bool where TMember e (Leaf x) = Equal e x TMember e (Branch left right ) = Or (TMember \ne left ) (TMember e right ) Implementing this search using overlapping type classes, which do not support \nbacktracking, requires an intricate encoding with explicit stack manipulation. 3 This extension allows \nclass instances, but not type family instances, to overlap. If the type inference engine chooses the \nwrong class instance, a program may have incoherent behavior, but it is believed that type safety is \nnot compromised. See Morris and Jones (2010) for relevant discussion. t, s Types . Type patterns (no \ntype families) F Type families O Substitutions from type variables to types Figure 1. Grammar of Haskell \nmetavariables  2.5 Summary Type-level computation is a powerful idea: it allows a programmer to express \napplication-speci.c compile-time reasoning in the type system. Closed type families .ll in a missing \npiece in the design space, making type families more expressive, convenient, and more uniform with term-level \nfunctional programming. 3. Simplifying closed family applications We have shown in the previous sections \nhow type family reduc\u00adtion can be used to equate types. For example, a function requir\u00ading an argument \nof type T True can take an argument of type T (And True True ), because the latter reduces to the former. \nBecause the de.nition of type equality is determined by type family reduction, the static semantics must \nprecisely de.ne what reductions are allowed to occur. That de.nition turns out to be quite subtle, so \nthis section develops an increasingly re.ned notion of type family reduction, motivated by a series of \nexamples. The presentation gives a number of de.nitions, using the vocabulary of Figure 1, but we eschew \nfull formality until Section 4. We use the term target to designate the type-function application that \nwe are trying to simplify. We say that a type t1 simpli.es or reduces to another type t2 if we can rewrite \nthe t1 to t2 using a (potentially empty) sequence of left-to-right applications of type family equations. \nWe also use the notation t1 . t2 to denote exactly one application of a type family equation and t1 .* \nt2 to denote an arbitrary number of reductions. Type equality is de.ned to be roughly the re.exive, symmetric, \ntransitive, congruent closure of type reduction; details are in Section 4.3. We frequently refer to the \nexample in the introduction, repeated below, with the variables renamed to aid in understanding: type \nfamily Equal (a :: .) (b :: .) :: Bool where Equal a a = True --Eqn (A) Equal b c = False --Eqn (B) \n 3.1 No functions on the LHS If we wish to simplify Equal Int Int , equation (A) of the de.nition matches, \nso we can safely .re the equation (A) to simplify the application to True . Even here we must take a \nlittle care. What happens if try this? type family F (a :: Bool ) where F False = False F True = True \nF (Equal x y ) = True  Then F (Equal Int Bool ) super.cially appears to match only the third equation. \nBut of course, if we simplify the argument of F in the target, it would become F False , which matches \nthe .rst equation. The solution here is quite standard: in type family de.nitions (both open and closed) \nwe do not allow functions in the argument types on the LHS. In terms of Figure 1, the LHS of a function \naxiom must be a pattern .. This is directly analogous to allowing only constructor patterns in term-level \nfunction de.nitions, and is already required for Haskell s existing open type families. We then propose \nthe following .rst attempt at a reduction strat\u00adegy: Candidate Rule 1 (Closed type family simpli.cation). \nAn equa\u00adtion for a closed type family F can be used to simplify a target (F t) if (a) the target matches \nthe LHS of the equation, and (b) no LHS of an earlier equation for F matches the target. The formal de.nition \nof matching follows: De.nition 1 (Matching). A pattern . matches a type t , written match(., t ), when \nthere is a well-kinded substitution O such that O(.) = t . The domain of O must be a subset of the set \nof free variables of the pattern ..  3.2 Avoiding premature matches with apartness Suppose we want to \nsimplify Equal Bool d . Equation (A) above fails to match, but (B) matches with a substitution O = [b \n. Bool , c . d ]. But it would be a mistake to simplify Equal Bool d to False . Consider the following \ncode: type family FunIf (b :: Bool ) :: * where FunIf True = Int . Int FunIf False = () bad :: d . FunIf \n(Equal Bool d ) bad = () segFault :: Int segFault = bad True 5 If we do simplify the type Equal Bool \nd to False then we can show that bad is well typed, since FunIf False is (). But then segFault calls \nbad with d instantiated to Bool . So segFault ex\u00adpects bad True to return a result of type FunIf (Equal \nBool Bool ), which reduces to Int . Int, so the call in segFault type-checks too. Result: we apply () \nas a function to 5, and crash. The error, of course, is that we wrongly simpli.ed the type (Equal Bool \nd ) to False ; wrongly because the choice of which equation to match depends on how d is instantiated. \nWhile the target (Equal Bool d ) does not match the earlier equation, there is a substitution for d that \ncauses it to match the earlier equation. Our Candidate Rule 1 is insuf.cient to ensure type soundness. \nWe need a stronger notion of apartness between a (target) type and a pattern, which we write as apart(., \nt ) in what follows. Candidate Rule 2 (Closed type family simpli.cation). An equa\u00adtion for a closed type \nfamily F can be used to simplify a target (F t ) if (a) the target matches the LHS of the equation, and \n(b) every LHS . of an earlier equation for F is apart from the target; that is, apart(., t). As a notational \nconvention, apart(., t ) considers the lists . and t as tuples of types; the apartness check does not \ngo element\u00adby-element. We similarly treat uses of match and unify (de.ned shortly) when applied to lists. \nTo rule out our counterexample to type soundness, apartness must at the very least satisfy the following \nproperty: Property 2 (Apartness through substitution). If apart(., t ) then there exists no O such that \nmatch(., O(t)). An appealing implementation of apart(., t ) that satis.es Prop\u00aderty 2 is to check that \nthe target t and the pattern . are not uni.able, under the following de.nition: De.nition 3 (Uni.cation). \nA type t1 uni.es with a type t2 when there is a well-kinded substitution O such that O(t1) = O(t2). We \nwrite unify(t1, t2) = O for the most general such uni.er if it exists.4 However this test is not suf.cient \nfor type soundness. Consider the type Equal Int (G Bool ), where G is a type family. This type does not \nmatch equation (A), nor does it unify with (A), but it does match (B). So according to our rule, we can \nuse (B) to simplify Equal Int (G Bool ) to False . But, if G were a type function with equation type \ninstance G Bool = Int then we could use this equation to rewrite the type to Equal Int Int , which patently \ndoes match (A) and simpli.es to True ! In our check of previous equations of a closed family, we wish \nto ensure that no previous equation can ever apply to a given ap\u00adplication. Simply checking for uni.cation \nof a previous pattern and the target is not enough. To rule out this counterexample we need yet another \nproperty from the apart(., t ) check, which ensures that the target cannot match a pattern of an earlier \nequation through ar\u00adbitrary reduction too. Property 4 (Apartness through reduction). If apart(., t ), \nthen for any t ' such that t * t': \u00acmatch(., t '). 3.3 A de.nition of apartness We have so far sketched \nnecessary properties that the apartness check must satisfy otherwise, our type system surely is not sound. \nWe have also described why a simple uni.cation-based test does not meet these conditions, but we have \nnot yet given a concrete de.nition of this check. Note that we cannot use Property 4 to de.ne apart(., \nt ) be\u00adcause it would not be well founded. We need apart(., t ) to de\u00ad.ne how type families should reduce, \nbut Property 4 itself refers to type family reduction. Furthermore, even if this were acceptable, it \nseems hard to implement. We have to ensure that, for any sub\u00adstitution, no reducts of a target can possibly \nmatch a pattern; there can be exponentially many reducts in the size of the type and the substitution. \nHence we seek a conservative but cheap test. Let us consider again why uni.cation is not suf.cient. In \nthe example from the previous section, we showed that type Equal Int (G Bool ) does not match equation \n(A), nor does it unify with (A). However, Equal Int (G Bool ) can simplify to Equal Int Int and now equation \n(A) does match the reduct. To take the behavior of type families into account, we .rst .atten any type \nfamily applications in the arguments of the target (i.e., the types t in a target F t ) to fresh variables. \nOnly then do we check that the new target is not uni.able with the pattern. This captures the notion \nthat a type family can potentially reduce to any type anything more re.ned would require advance knowledge \nof all type families, impossible in a modular system. In our example, we must check apart((a, a), (Int, \nG Bool )) when trying to use the second equation of Equal to simplify Equal Int (G Bool ). We .rst .atten \n(Int, G Bool ) into (Int, x) (for some fresh variable x). Then we check whether (a, a) cannot be uni.ed \nwith (Int, x). We quickly discover that these types can be uni.ed. Thus, (a, a) and (Int, G Bool ) are \nnot apart and simplifying Equal Int (G Bool ) to False is prohibited. What if two type family applications \nin the target type are syntactically identical? Consider the type family F below: 4 For instance, the \nimplementation of unify can be the standard .rst-order uni.cation algorithm of Robinson. type family \nF a b where F Int Bool = Char Fa a = Bool Should the type F (G Int ) (G Int ) be apart from the left-hand\u00adside \nF Int Bool ? If we .atten to two distinct type variables then it is not apart; if we .atten using a common \ntype variable then it becomes apart. How can we choose if .attening should preserve sharing or not? Let \nus consider the type F b b, which matches the second equation. It is de.nitely apart from F Int Bool \nand can indeed be simpli.ed by the second equation. What happens, though, if we substitute G Int for \nb in F b b? If .attening did not take sharing into account, (G Int , G Int ) would not be apart from \n(Int, Bool ), and F (G Int ) (G Int ) wouldn t reduce. Hence, the ability to simplify would not be stable \nunder substitution. This, in turn, threatens the preservation theorem. Thus, we must identify repeated \ntype family applications and .atten these to the same variable. In this way, F (G Int ) (G Int ) is .attened \nto F x x (never F x y), will be apart from the .rst equation, and will be able to simplify to Bool , \nas desired. With these considerations in mind, we can now give our imple\u00admentation of the apartness check: \nDe.nition 5 (Flattening). To .atten a type t into t ', written t ' = .atten(t ), process the type t in \na top-down fashion, replacing every type family application with a type variable. Two or more syntactically \nidentical type family applications are .attened to the same variable; distinct type family applications \nare .attened to distinct fresh variables. De.nition 6 (Apartness). To test for apart(., t ), let t ' \n= .atten(t ) and check unify(., t ' ). If this uni.cation fails, then . and t are apart. More succinctly: \napart(., t ) = \u00acunify(., .atten(t)). We can show that this de.nition does indeed satisfy the identi\u00ad.ed \nnecessary properties from Section 3.2. In Section 5.1 we will also identify the suf.cient conditions \nfor type soundness for any possible type-safe implementation of apartness, show that these conditions \nimply the properties identi.ed in the previous section (a useful sanity check!) and prove that the de.nition \nof apartness that we just proposed meets these suf.cient conditions.  3.4 Allowing more reductions with \ncompatibility Checking for apartness in previous equations might be unneces\u00adsarily restrictive. Consider \nthis code, which uses the function And from Section 2.1: f :: T a . T b . T (And a b) tt :: T True g \n:: T a . T a g x = f x tt Will the de.nition of g type-check? Alas no: the call (f x tt) returns a result \nof type T (And a True ), and that matches neither of the equations for And. Perhaps we can .x this by \nadding an equation to the de.nition of And, thus: type family And (a :: Bool ) (b :: Bool ) :: Bool where \nAnd True True = True --(1) And a True = a --(2) And a b = False --(3) But that does not work either: \nthe target (And a True ) matches (2) but is not apart from (1), so (2) cannot .re. And yet we would like \nto be able to simplify (And a True ) to a, as Eqn (2) suggests. Why should this be sound? Because anything \nthat matches both (1) and (2) will reduce to True using either equation. We say that the two equations \ncoincide on these arguments. When such a coincidence happens, the apartness check is not needed. We \ncan easily formalize this intuition. Let us say that two equations are compatible when any type that \nmatches both left\u00adhand sides would be rewritten by both equations to the same result, eliminating non-convergent \ncritical pairs in the induced rewriting system: De.nition 7 (Compatibility). Two type-family equations \np and q are compatible iff O1(lhsp) = O2(lhsq ) implies O1(rhsp) = O2(rhsq ). For example, (1) and (2) \nare compatible because a type, such as And True True , would be rewritten by both to the same type, namely \nTrue . It is easy to test for compatibility: De.nition 8 (Compatibility implementation). The test for \ncompat\u00adibility, written compat(p, q), checks that unify(lhsp, lhsq ) = O im\u00adplies O(rhsp ) = O(rhsq ). \nIf unify(lhsp , lhsq ) fails, compat(p, q) holds vacuously. The proof that compat(p, q) implies that \np and q are compatible appears in the extended version of this paper and is straightforward. We can now \nstate our .nal simpli.cation rule for closed type families: Rule 9 (Closed type family simpli.cation). \nAn equation q of a closed type family can be used to simplify a target application F t if the following \nconditions hold: 1. The target t matches the type pattern lhsq . 2. For each earlier equation p, either \ncompat(p, q) or apart(lhsp, t ).   For example, we can .re equation (2) on a target that is not apart \nfrom (1), because (1) and (2) are compatible. We show that Rule 9 is suf.cient for establishing type \nsoundness in Section 5. Through this use of compatibility, we allow for a limited form of theorem proving \nwithin a closed type family de.nition. The fact that equation (2) is compatible with (1) essentially \nmeans that the rewrite rule for (2) is admissible given that for (1). By being able to write such equations \nin the closed type family de.nition, we can expand Haskell s de.nitional equality to relate more types. \n 3.5 Optimized matching In our original Candidate Rule 2 above, when simplifying a target F t with an \nequation q, we are obliged to check apart(lhsp, t ), for every earlier equation p. But much of this checking \nis wasted duplication. For example, consider type family F a where F Int = Char --(1) F Bool = Bool --(2) \nF x = Int --(3)  If a target matches (2) there is really no point in checking its apartness from (1), \nbecause anything that matches (2) will be apart from (1). We need only check that the target is apart \nfrom any preceding equations that could possibly match the same target. Happily, this intuition is already \nembodied in our new simpli.\u00adcation Rule 9. This rule checks compat(p, q) . apart(lhsp, t ) for each preceding \nequation p. But we can precompute compat(p, q) (since it is independent of the target), and in the simpli.cation \nrule we need check apartness only for the pre-computed list of earlier incompatible equations. In our \nexample, equations (1) and (2) are vacuously compatible, since their left-hand sides do not unify, and \nhence no type can match both. Thus, there is no need to check for apartness from (1) of a target matching \n(2). 3.6 Compatibility for open families As discussed in the introduction, type instance declarations \nfor open type families must not overlap. With our de.nition of com\u00adpatibility, however, we can treat \nopen and closed families more uniformly by insisting that any two instances of the same open type family \nare compatible: De.nition 10 (Open type family overlap check). Every pair of equations p and q for an \nopen type family F must satisfy compat(p, q). Notice that this de.nition also allows for coincident right-hand \nsides (as in the case for closed type families, Section 3.4). For example, these declarations are legal: \ntype family Coincide a b type instance Coincide Int b = Int type instance Coincide a Bool = a These equations \noverlap, but in the region of overlap they always produce the same result, and so they should be allowed. \n(GHC already allowed this prior to our extensions.)  3.7 Type inference for closed type families Given \nthe dif.culty of type inference for open type families (Chak\u00adravarty et al. 2005; Schrijvers et al. 2008), \nhow do we deal with closed ones? Thankfully, this turns out to be remarkably easy: we simply use Rule \n9 to simplify closed families in exactly the same stage of type inference that we would simplify an open \none. The implementation in GHC is accordingly quite straightforward. Despite the ease of implementation, \nthere are perhaps complex new possibilities opened by the use of closed families these are explored in \nSection 7.6. 4. System \u00b5FC: formalizing the problem Thus far we have argued informally. In this section \nwe formalize our design and show that it satis.es the usual desirable properties of type preservation \nand progress, assuming termination of type family reduction. It is too hard to formulate these proofs \nfor all of Haskell, so instead we formalize \u00b5FC, a small, explicitly-typed lambda calculus. This is more \nthan a theoretical exercise: GHC really does elaborate all of Haskell into System FC (Sulzmann et al. \n2007a; Weirich et al. 2013), of which \u00b5FC is a large subset that omits some details of FC such as kind \npolymorphism (Yorgey et al. 2012) that are irrelevant here. 4.1 System \u00b5FC System \u00b5FC is an extension \nof System F, including kinds and explicit equality coercions. Its syntax is presented in Figure 2. This \nsyntax is very similar to recent treatments of System FC (Weirich et al. 2013). We omit from the presentation \nthe choice of ground types and their constructors and destructors, as they are irrelevant for our purposes. \nThere are a few points to note about type families, all visible in Figure 2. A type family has a particular \narity, and always appears saturated in types. That explains the .rst-order notation F (.):. ' in ground \ncontexts S, and F (t) in types. A closed type family appears in \u00b5FC as a kind signature F (.):. ', and \na single axiom C :., both in the top-level ground context S. The type . of the axiom is a list of equations, \neach of form [a:.]. F (t ) ~ s, just as we have seen before except that the quanti.cation is explicit. \nFor example, the axiom for Equal (restricted for simplicity to kind *) looks like this: axiomEq : [a:*].(Equal \na a) ~ True ; [a:*, \u00df:*].(Equal a \u00df) ~ False Although our notation for lists does not make it apparent, \nwe restrict the form of the equations to require that F refers to only one type family that is, there \nare no independent Fi . We use Expressions: e ::= x | .x:t .e | e1 e2 | .a:..e | e t | e C . Cast | . \n. . Constructors and destruc\u00ad tors of datatypes Types: t, s, ::= a | t1 . t2 | . a:..t ., . | t1 t2 Application \n| F (t ) Saturated type family | H Datatype, such as Int . denotes a type pattern (with no type families) \n. ::= * | .1 . .2 Kinds Propositions: f ::= t1 ~ t2 Equality propositions F ::= [a:.]. F (.) ~ s Axiom \nequations . ::= F List of axiom eqns. (axiom types) Coercions: ., . ::= .1 . .2 | . a:... | .1 .2 | F(.) \n| (t ) Re.exivity | sym . Symmetry | .1 9 .2 Transitivity | left . Left decomposition | right . Right \ndecomposition | C [i] t Axiom application Contexts: Ground: S ::= \u00b7 | S, H :. . * | S, F (.):. ' | S, \nC :. Variables: . ::= \u00b7 | ., x:t | ., a:. Combined: G ::= S; . Substitutions: O ::= [a . t ] Figure \n2. The grammar of System \u00b5FC G ftm e : t Expression typing G fty t : . Type kinding G fco . : f Coercion \ntyping fgnd S Ground context validity S fvar . Variables context validity fctx G Context validity Figure \n3. Typing judgments for System \u00b5FC subscripts on metavariables to denote which equation they refer to, \nand we refer to the types .i as the type patterns of the i th equation. We assume that the variables \na bound in each equation are distinct from the variables bound in other equations. An open type family \nappears as a kind signature and zero or more separate axioms, each with one equation. 4.2 Static semantics \nTyping in \u00b5FC is given by the judgments in Figure 3. Most of the rules are uninteresting and are thus \npresented in the extended version of this paper. The typing rules for expressions are entirely straightforward. \nThe only noteworthy rule is the one for casting, which gives the raison d etre for coercions: G fco . \n: t1 ~ t2 G ftm e : t1 TM CA S T G ftm e C . : t2 Here, we see that a cast by a coercion changes the \ntype of an ex\u00adpression. This is what we mean by saying that a coercion witnesses the equality of two \ntypes if there is a coercion between t1 and t2, then any expression of type t1 can be cast into one of \ntype t2. The rules for deriving the kind of a type are straightforward and are omitted from this presentation. \n 4.3 Coercions and axiom application Coercions are less familiar, so we present the coercion typing \nrules in full, in Figure 4. The .rst four rules say that equality is congru\u00adent that is, types can be \nconsidered equal when they are formed of components that are considered equal. The following three rules \nas\u00adsert that coercibility is a proper equivalence relation. The CO LEF T and CO RI G H T rules assert \nthat we can decompose complex equal\u00adities to simpler ones. These formation rules are incomplete with \nrespect to some unspeci.ed notion of semantic equality that is, we can imagine writing down two types \nthat we know are equal, but for which no coercion is derivable. For example, there is no way to use induction \nover a data structure to prove equality. How\u00adever, recall that these coercions must all be inferred from \na source program, and it is unclear how we would reliably infer inductive coercions. The last rule of \ncoercion formation, CO AXI O M, is the one that we are most interested in. The coercion C [i] t witnesses \nthe equality obtained by instantiating the i th equation of axiom C with the types t . For example, axiomEq[0] \nInt : Equal Int Int ~ True This says that if we pick the .rst equation of axiomEq (we in\u00addex from 0), \nand instantiate it at Int, we have a witness for Equal Int Int ~ True . Notice that the coercion C [i] \nt speci.es exactly which equation is picked (the i th one); \u00b5FC is a fully-explicit language. However, \nthe typing rules for \u00b5FC must reject unsound coercions like axiomEq[1] Int Int : Equal Int Int ~ False \nand that is expressed by rule CO AX I OM. The premises of the rule check to ensure that S; . is a valid \ncontext and that all the types t are of appropriate kinds to be applied in the i th equation. The last \npremise implements Rule 9 (Section 3.4), by checking no con.ict for each preceding equation j. The no \ncon.ict judgment simply checks that either (NC COM PAT I B LE) the i th and j th equation for C are compatible, \nor (NC APA RT) that the target is apart from the LHS of the j th equation, just as in Rule 9. In NC CO \nM PAT I B L E, note that the compat judgment does not take the types t: compatibility is a property of \nequations, and is independent of the speci.c arguments at an application site. The two rules for compat \nare exactly equivalent to De.nition 8. These judgments refer to algorithms apart and unify. We as\u00adsume \na correct implementation of unify and propose suf.cient properties of apart in Section 5.1. We then show \nthat our chosen algorithm for apart (De.nition 6) satis.es these properties. As a .nal note, the rules \ndo not check the closed type family axioms for exhaustiveness. A type-family application that matches \nno axiom simply does not reduce. Adding an exhaustiveness check based on the kind of the arguments of \nthe type family might be a useful, but orthogonal, feature. 5. Metatheory A summary of the structure \nof the type safety proof, highlighting the parts that are considered in this paper, is in Figure 5. Our \nmain goals are to prove (i) the substitution lemma of types into coercions (Section 5.2), and (ii) a \nconsistency property that ensures we never equate two types such as Int and Bool (Section 5.3). The substitution \nand consistency lemmas lead to the preservation and progress theorems respectively, which together ensure \ntype safety. We omit the operational semantics of \u00b5FC as well as the other G fco . : f Coercion typing \nG fco .1 : t1 ~ t1 ' G fco .2 : t2 ~ t2 ' G fty t1 . t2 : * CO AR ROW G fco .1 . .2 : (t1 . t2) ~ (t1 \n' . t2 ' ) G, a:. fco . : t1 ~ t2 G fty . a:..t1 : * CO FO RAL L G fco . a:... : (. a:..t1) ~ (. a:..t2) \nG fco .1 : t1 ~ s1 G fco .2 : t2 ~ s2 G fty t1 t2 : . CO AP P G fco .1 .2 : (t1 t2) ~ (s1 s2) G fco \n. : t1 ~ t2 G fty F (t1) : . CO TYFAM G fco F (.) : F (t1) ~ F (t2) G fty t : . CO RE FL G fco (t) : \nt ~ t G fco . : t1 ~ t2 CO SYM G fco sym . : t2 ~ t1 G fco .1 : t1 ~ t2 G fco .2 : t2 ~ t3 CO TRA N \nS G fco .1 9 .2 : t1 ~ t3 G fco . : t1 t2 ~ s1 s2 G fty t1 : . G fty s1 : . CO LEFT G fco left . : t1 \n~ s1 G fco . : t1 t2 ~ s1 s2 G fty t2 : . G fty s2 : . CO RI G HT G fco right . : t2 ~ s2 C :. . S .= \n[a:.]. F(.) ~ . S; . fty t : .i fctx S; . . j < i, no con.ict(., i, t , j ) CO AX IOM S; . fco C [i] \nt : F (.i [t /ai ]) ~ .i [t /ai ] no con.ict(., i, t , j) Check for equation con.icts . = [a:.]. F(.) \n~ . apart(.j , .i [t /ai ]) NC APART no con.ict(., i, t, j ) compat(.[i], .[j ]) NC CO M PATI B L E \nno con.ict(., i, t , j ) compat(F1, F2) Equation compatibility F1 = [a1:.1]. F (.1) ~ .1 F2 = [a2:.2]. \nF (.2) ~ .2 unify(.1, .2) = O O(.1) = O(.2) CO M PAT CO INC IDENT compat(F1, F2) F1 = [a1:.1]. F (.1) \n~ .1 F2 = [a2:.2]. F (.2) ~ .2 unify(.1, .2) fails CO MPAT DIST I N C T compat(F1, F2) Figure 4. Coercion \nformation rules  Type subst. lemma Good S (\u00a75.4) Coercion subst. lemma  assume(\u00a75.2) termination Con.uence \n Term subst. lemma Consistency (\u00a75.3) Preservation Progress Type Safety Figure 5. Structure of type \nsafety proof. The arrows represent implications. The nodes highlighted in gray are the parts considered \nin the present work. lemmas in the main proofs of preservation and progress, because these are all direct \nadaptations from previous work (Weirich et al. 2011; Sulzmann et al. 2007a). We stress that, as Figure \n5 indicates, we have proved type safety only for terminating type families. What exactly does that mean? \nWe formally de.ne the rewrite relation, now written S f \u00b7 \u00b7 to explicit mention the set of axioms, with \nthe following rule: C :. . S .= [a:.]. F (.) ~ . fgnd S t = .i [./ai ] t ' = .i [./ai ] . j < i, no con.ict(., \ni, ., j ) RE D S f C[F (t )] C[t ' ] In the conclusion of this rule, C[\u00b7] denotes a type context with \nexactly one hole. Its use in the rule means that a type family can simplify anywhere within a type. Note \nthat the no con.ict premise of this rule is identical to that of the CO AX I OM rule. By terminating \ntype families we mean that the S f \u00b7 \u00b7 relation cannot have in.nite chains. We discuss non-terminating \ntype families in Section 6. As a notational convention, we extend the relation to lists of types by using \nS f t1 t2 to mean that exactly one of the types in t1 steps to the corresponding type in t2; in all other \npositions t1 and t2 are identical. 5.1 Preliminaries: properties of uni.cation and apartness In order \nto prove properties about no con.ict, we must assume the correctness of the uni.cation algorithm: Property \n11 (unify correct). If there exists a substitution O such that O(s) = O(t), then unify(s, t) succeeds. \nIf unify(s, t) = O then O is a most general uni.er of s and t . In Section 3.2, we gave some necessary \nproperties of apart, namely Properties 2 and 4. To prove type soundness we need suf\u00ad.cient properties, \nsuch as the following three. Any implementation of apart that has these three properties would lead to \ntype safety. We prove (in the extended version of this paper) that the given al\u00adgorithm for apart (De.nition \n6) satis.es these properties. Due to .attening in the de.nition of apart, this proof is non-trivial. \nAs a sanity check, we also prove that the suf.cient properties imply the necessary ones of Section 3.2. \n Property 12 (Apartness is stable under type substitution). If apart(., t ), then for all substitutions \nO, apart(., O(t )). Property 13 (No uni.ers for apart types). If apart(., t), then there exists no substitution \nO such that O(.) = O(t). The .nal property of the apartness check is the most complex. It ensures that, \nif an equation can .re for a given target and that target steps, then it is possible to simplify the \nreduct even further so that the same equation can .re on the .nal reduct. Property 14 (Apartness can \nbe regained after reduction). If t = ' '' O(.) and S f t t , then there exists a t such that 1. S f \nt ' * t '' , '' 2. t = O ' (.) for some O ', and '' ).  3. for every . ' such that apart(. ' , t ): \napart(. ' , t  Here is an example of Property 14 in action. Consider the following type families F \nand G: type family F a where F (Int, Bool ) = Char --(A) F (a, a) = Bool --(B) type family G x where \nG Int = Double Suppose that our target is F (G Int , G Int ), and that our partic\u00adular implementation \nof apart allows equation (B) to .re; that is, apart((Int, Bool ), (G Int , G Int )). Now, suppose that \ninstead of .ring (B) we chose to reduce the .rst G Int argument to Double. The new target is now F (Double, \nG Int ). Now (B) cannot .re, because the new target simply does not match (B) any more. Prop\u00aderty 14 \nensures that there exist further reductions on the new target that make (B) .rable again in this case, \nstepping the second G Int to Double does the job. Conditions (2) and (3) of Property 14 for\u00admalize the \nnotion make (B) .rable again . 5.2 Type substitution in coercions System \u00b5FC enjoys a standard term \nsubstitution lemma. This lemma is required to prove the preservation theorem. As shown in Figure 5, the \nterm substitution lemma depends on the substi\u00adtution lemma for coercions. We consider only the case of \ninterest here, that of substitution in the rule CO AXI O M. Lemma 15 (CO AXI O M Substitution). If S; \n., \u00df:., . ' fco C [i] t : F (.i [t /ai ]) ~ .i [t /ai ] and S; . fty s : ., then S; ., . ' [s/\u00df] fco \nC [i] t[s/\u00df] : F (.i [t /ai ][s/\u00df]) ~ .i [t /ai ][s/\u00df]. The proof of this lemma, presented in the extended \nversion of this paper, proceeds by case analysis on the no con.ict judgment. It requires the use of the \n(standard) type substitution lemma and Property 12, but is otherwise unremarkable. 5.3 Consistency As \ndiscussed at the beginning of this section, to establish progress we must show consistency. Consistency \nensures that we can never deduce equalities between distinct value types, denoted with .: . ::= H t | \nt1 . t2 | . a:..t For example, Int, Bool , and . a:*.a . a are all value types. A set of axioms is consistent \nif we cannot deduce bogus equalities like Int ~ Bool or Int ~ . a:*.a . a: De.nition 16 (Consistent \ncontexts). A ground context S is consis\u00adtent if, for all coercions . such that S; \u00b7 fco . : .1 ~ .2: \n1. if .1 = H t1, then .2 = H t2, 2. if .1 = t1 . t1 ' , then .2 = t2 . t2 ' , and 3. if .1 = . a:..t1, \nthen .2 = . \u00df:..t2.  How can we check whether an axiom set is consistent? It is extremely hard to do \nso in general, so instead, following previous work (Weirich et al. 2011), we place syntactic restrictions \non the axioms that conservatively guarantee consistency. A set of axioms that pass this check are said \nto be Good. We then prove the consistency lemma: Lemma 17 (Consistency). If Good S, then S is consistent. \nFollowing previous proofs, we show that if Good S and S; \u00b7 fco . : s1 ~ s2, then s1 and s2 have a common \nreduct in the relation. Because the simpli.cation relation preserves type constructors on the heads of \ntypes, we may conclude that S is consistent. However, one of the cases in this argument is transitivity: \nthe joinability relation must be transitive. That is, if t1 and t2 have a common reduct s1, and if t2 \nand t3 have a common reduct s2, then t1 and t3 must have a common reduct (they are joinable). To show \ntransitivity of joinability, we must show con.uence of the rewrite relation, in order to .nd the common \nreduct of s1 and s2 (which share t2 as an ancestor). Our approach to this problem is to show local con.uence \n(see Figure 6) and then use Newman s Lemma (1942) to get full con\u00ad.uence. Newman s Lemma requires that \nthe rewrite system is terminating this is where the assumption of termination is used. The full, detailed \nproof appears in the extended version of this paper (Eisenberg et al. 2013).  5.4 Good contexts What \nsort of checks should be in our syntactic conditions, Good? We would like Good to be a small set of common-sense \nconditions for a type reduction system, such as the following: De.nition 18 (Good contexts). We have \nGood S whenever the following four conditions hold: 1. For all C :. . S: . is of the form [a:.]. F (.) \n~ . where all of the Fi are the same type family F and all of the type patterns .i do not mention any \ntype families. 2. For all C :. . S and equations [a:.]. F (.) ~ . in .: the variables a all appear free \nat least once in .. 3. For all C :. . S: if . de.nes an axiom over a type family F and has multiple \nequations, then no other axiom C ' :. ' . S de.nes an axiom over F . That is, all type families with \nordered equations are closed. 4. For all C1:F1 . S and C2:F2 . S (each with only one equation), compat(F1, \nF2). That is, among open type families, the patterns of distinct equations do not overlap.  The clauses \nof the de.nition of Good are straightforward syntactic checks. In fact, these conditions are exactly \nwhat GHC checks for when compiling type family instances. This de.nition of Good leads to the proof of \nLemma 17, as described above. 6. Non-terminating type families By default GHC checks every type family \nfor termination, to guar\u00adantee that the type checker will never loop. Any such check is necessarily conservative; \nindeed, GHC rejects the TMember func\u00adtion of Section 2.4 (Schrijvers et al. 2008). Although GHC s test \ncould readily be improved, any conservative check limits expres\u00adsiveness or convenience, so GHC allows \nthe programmer to disable s0 s0 s0 * * s1 s2 s1 s2 s1 s2 ** ** 0 or 1 0 or 1 s3 s3 s3 (a) Con.uence \n(b) Local con.uence (c) Local diamond Figure 6. Graphical representation of con.uence properties. A \nsolid line is a universally quanti.ed input, and a dashed line is an existentially quanti.ed output. \nthe check. This may make the type checker loop, but it should not threaten soundness. However, the soundness \nresult of Section 5 covers only termi\u00adnating type families. Surprisingly (to us) non-termination really \ndoes lead to a soundness problem (Section 6.1). We propose a so\u00adlution that (we believe) rules out this \nproblem (Section 6.2), but explain why the main result of this paper is dif.cult to generalize to non-terminating \ntype families, leaving an open problem for fur\u00adther work. 6.1 The problem with in.nity Consider this \ntype family, adapted from Huet (1980): type family D x where D ([b], b) = Bool D (c, c) = Int  We wish \nto simplify the target D (a, a). The type (a, a) matches the second pattern (c, c), but is it apart from \nthe .rst pattern ([b], b)? De.nition 6 asserts that they are apart since they do not unify: uni.cation \nfails with an occurs check error. Accordingly, Rule 9 would simplify D (a, a) to Int. But consider the \nfollowing de.nitions, where type family Loop is a nullary (0-argument) type family: type family Loop \ntype instance Loop = [ Loop ] If we instantiate a with Loop we get (Loop, Loop) which can sim\u00adplify \nto ([Loop ], Loop). The latter does match the pattern ([b], b), violating Property 4, a necessary condition \nfor soundness. So, in a non-terminating system our apartness check is unsound. Concretely, using our \napartness implementation from De.nition 6, we can equate types Int and Bool , thus: Int ~ D (Loop, Loop) \n~ D ([Loop ], Loop) ~ Bool Conclusion: we must not treat (a, a) as apart from the pattern ([b], b), \neven though they do not unify. In some ways this is not so surprising. In our earlier examples, apartness \nwas based on an explicit contradiction ( a Bool cannot be an Int ), but here uni.cation fails only because \nof an occurs check. As the Loop example shows, allowing non-terminating type-family de.nitions amounts \nto introducing in.nite types, and if we were to allow in.nite types, then (a, a) does unify with ([b], \nb)! 6.2 Fixing the problem The problem with the current apartness check is that .nite uni.ca\u00adtion fails \ntoo often. We need to replace the uni.cation test in the de.nition of apartness with uni.cation over \nin.nite types: type instance A = C A type instance C x = D x (C x ) type instance D x x = Int (1) A \nC A D A (C A) D (C A) (C A) Int (2) A CA by (1) * C Int Int and C Int have no common reduct. Figure 7. \nCounter-example to con.uence De.nition 19 (In.nite uni.cation). Two types t1, t2 are in.nitely uni.able, \nwritten unify8(t1, t2), if there exists a substitution . whose range may include in.nite types, such \nthat .(t1) = .(t2). For example types (a, a) and ([b], b) are uni.able with a sub\u00adstitution . = [a . \n[ [ [ ...] ] ], b . [ [ [ ...] ] ] ]. Ef.cient algorithms to decide uni.cation over in.nite types (and \ncompute most gen\u00aderal uni.ers) have existed for some time and are based on well\u00adestablished theory (Huet \n1976; Courcelle 1983). See Jaffar (1984) for such an algorithm, and Knight (1989) for a general survey. \nWe conjecture that replacing all uses of unify with unify8 in our de.nitions guarantees soundness, even \nin the presence of non-terminating family equations. Alas, this conjecture turns out to be very hard \nto prove, and touches on open problems in the term-rewriting literature. For example, a rewrite system \nthat has (a) in.nite rewrite sequences and (b) non-left-linear patterns, does not necessarily guarantee \ncon.uence, even if its patterns do not overlap. Figure 7 gives an example, from Klop (1993). Notice that \nreplacing unify with unify8 may change the reduc\u00adtion relation. For example, a target which is apart \nfrom a pattern with a unify-based apartness check may no longer be apart from the same pattern with the \nmore conservative unify8-based apartness check. Yet, type safety (for terminating axiom sets) is not \ncompro\u00admised since Property 11 carries over to uni.cation algorithms over in.nite types (Huet 1976). \n 6.3 Rami.cations for open families We pause brie.y to consider the implications for GHC s existing \nopen type families. GHC allows the following de.nition for an open type family D : type family D x y \ntype instance D [b] b = Bool type instance D c c = Int As described in Section 2, the type instance equations \nof an open type family are required to have non-overlapping left-hand sides, and GHC 7.6 believes that \nthe two equations do not overlap because they do not unify. But, using certain .ags, GHC also accepts \nthe de.nition of Loop, and the target (D Loop Loop) demonstrates that the combination is unsound precisely \nas described above.5 Happily, if the conjecture of Section 6.2 holds true, we can apply the same .x for \nopen families as we did for closed families: simply use unify8 instead of unify when checking for overlap. \nIndeed, this is exactly how we have corrected this oversight in GHC 7.8. 7. Discussion and Future Work \nThe study of closed type families opens up a wide array of related issues. This section discusses some \nof the more interesting points we came across in our work. 5 Akio Takano has posted an example of how \nthis can cause a program to fail, at http://ghc.haskell.org/trac/ghc/ticket/8162. 7.1 Denotational techniques \nfor consistency We do not have a proof of consistency for a system with non\u00adterminating, non-left-linear \naxioms (even when using unify8 in\u00adstead of unify). We have seen that con.uence is false, and hence cannot \nbe used as a means to show consistency. A possible alternative approach to proving consistency side\u00adstepping \ncon.uence is via a denotational semantics for types. We would have to show that if we can build a coercion \n. such that G f . : t ~ s, then [t ] = [s], for some interpretation of types into a semantic domain. \nThe obvious domain for such a seman\u00adtics, in the presence of non-terminating computations, is the domain \nthat includes . as well as .nite and in.nite trees. Typically in de\u00adnotational semantics, recursive type \nfamilies would be interpreted as the limit of approximations of continuous functions. However, the obvious \ninterpretation of type families in this simple domain is not monotone. Consider this type family: type \nfamily F a b where Fx x = Int F [x ] (Maybe x ) = Char  It is the case that (. . [.]) and (. . Maybe \n.), but the semantic interpretation of F , call it f, should satisfy f(., .) = Int and f([.], Maybe .) \n= Char . Hence, monotonicity breaks. The lack of monotonicity means that limits of chains of approximations \ndo not exist, and thus that interpretations of functions, such as f, are ill-de.ned. An alternate de.nition \nwould give f(., .) = ., but then sub\u00adstitutivity breaks. Indeed, the proof theory can deduce that F x \nx is equal to Int for any type x, even those that have denotation .. Alternatively to these approaches, \none might want to explore different domains to host the interpretation of types. 7.2 Conservativity \nof apartness We note in Section 3.3 that our implementation of apartness is conservative. This conservativity \nis unavoidable it is possible for open type families to have instances scattered across modules, and \nthus the apartness check cannot adequately simplify the types involved in every case. However, the current \ncheck considers none of the type family axioms available, even if one would inform the apartness check. \nFor example, consider type family G a where G Int = Bool G [a] = Char  and we wish to simplify target \nEqual Double (G b). It is clear that an application of G can never simplify to Double, so we could imagine \na more re.ned apartness check that could reduce this target to False . We leave the details of such a \ncheck to future work. 7.3 Conservativity of coincident overlap: partial knowledge It is worth noting \nthat the compatibility check (De.nition 8) is somewhat conservative. For example, take the type family \ntype family F a b where F Bool c = Int Fd e = e  Consider a target F g Int . The target matches the \nsecond equation, but not the .rst. But, the simpli.cation rule does not allow us to .re the second equation \nthe two equations are not compatible, and the target is not apart from the .rst equation. Yet it clearly \nwould be safe to .re the second equation in this case, because even if g turns out to be Bool , the .rst \nequation would give the same result. It would, however, be easy to modify F to allow the desired simpli.cation: \njust add a new second equation F a Int = Int. This new equation would be compatible with the .rst one \nand therefore would allow the simpli.cation of F g Int .  7.4 Conservativity of coincident overlap: \nrequiring syntactic equality The compatibility check is conservative in a different dimension: it requires \nsyntactic equality of the RHSs after substitution. Consider this tantalizing example: type family Plus \na b where Plus Zero a = a Plus (Succ b) c = Succ (Plus b c ) Plus d Zero = d Plus e (Succ f ) = Succ \n(Plus e f ) --(A) --(B) --(C) --(D) If this type family worked as one would naively expect, it would \nsimplify an addition once either argument s top-level constructor were known. (In other dependently typed \nlanguages, de.nitions like this are not possible and require auxiliary lemmas to reduce when the second \nargument s structure only is known.) Alas, it does not work as well as we would hope. The problem is \nthat not all the equations are compatible. Let s look at (B) and (C). To check if these are compatible, \nwe unify ((Succ b), c) with (d, Zero) to get [c . Zero, d . Succ b ]. The right-hand sides under this \nsubstitution are Succ (Plus b Zero ) and Succ b. However, these are not syntactically identical, so equations \n(B) and (C) are not compatible, and a target such as Plus g Zero is stuck. Why not just allow reduction \nin the RHSs before checking for compatibility? Because doing so is not obviously well-founded! Reducing \nthe Succ (Plus b Zero ) type that occurred during the compatibility check above requires knowing that \nequations (B) and (C) are compatible, which is exactly what we re trying to establish. So, we require \nsyntactic equality to support compatibility, and leave the more general check for future work. 7.5 Lack \nof inequality evidence One drawback of closed type families is that they sometimes do not compose well \nwith generalized algebraic datatypes (GADTs). Consider the following sensible-looking example: data X \na where XInt :: X Int XBool :: X Bool XChar :: X Char type family Collapse a where Collapse Int = Int \nCollapse x = Char collapse :: X a . X (Collapse a) collapse XInt = XInt collapse = XChar The type function \nCollapse takes Int to itself and every other type to Char . Note the type of the term-level function \ncollapse. Its im\u00adplementation is to match XInt the only constructor of X param\u00adeterized by Int and return \nXInt; all other constructors become XChar . The structure of collapse exactly mimics that of Collapse. \nYet, this code does not compile. The problem is that the type system has no evidence that, in the second \nequation for collapse, the type variable a cannot be Int. So, when type-checking the right-hand side \nXChar , it is not type-safe to equate Collapse a with Char . The source of this problem is that the type \nsystem has no notion of inequality. If the case construct were enhanced to track inequality evidence \nand axiom application could consider such evidence, it is conceivable that the example above could be \nmade to type-check. Such a notion of inequality has not yet been considered in depth, and we leave it \nas future work.  7.6 Type inference The addition of closed type families to Haskell opens up new possi\u00adbilities \nin type inference. By de.nition, the full behavior of a closed type family is known all at once. This \nclosed-world assumption al\u00adlows the type inference engine to perform more improvement on types than would \notherwise be possible. Consider the following type family: type family Inj a where Inj Int = Bool Inj \nBool = Char Inj Char = Double  Type inference can discover in this case that Inj is indeed an injective \ntype function. When trying to solve a constraint of the form Inj Int ~ Inj q the type inference engine \ncan deduce that q must be equal to Int for the constraint to have a solution. By contrast, if Inj were \nnot identi.ed as injective, we would be left with an unsolved constraint as in principle there could \nbe multiple other types for q that could satisfy Inj Int ~ Inj q. Along similar lines, we can imagine \nimproving the connection between Equal and ( ~ ). Currently, if a proof a ~ b is available, type inference \nwill replace all occurrences of a with b, after which Equal a b will reduce to True . However, the other \ndirection does not work: if the inference engine knows Equal a b ~ True , it will not deduce a ~ b. Given \nthe closed de.nition of Equal, though, it seems possible to enhance the inference engine to be able to \ngo both ways. These deductions are not currently implemented, but remain as compelling future work. 8. \nRelated work 8.1 Previous work on System FC The proof of type soundness presented in this paper depends \nheav\u00adily on previous work for System FC, .rst presented by Sulzmann et al. (2007a). That work proves \nconsistency only for terminating type families, as we do here. In a non-terminating system, local con.uence \ndoes not imply con.uence. Therefore, previous work (Weirich et al. 2011) showed con.uence of the rewrite \nsystem induced by the (potentially non\u00adterminating) axiom set by establishing a local diamond property \n(see Figure 6). However, the proof took a shortcut: the require\u00adments for good contexts effectively limited \nall axioms to be left\u00adlinear. The local diamond proof relies on the fact that, in a system with linear \npatterns, matching is preserved under reduction. For in\u00adstance, consider these axioms: type instance \nF a b = H a type instance G Int = Bool The type F (G Int ) (G Int ) matches the equation for F and can \npotentially simplify to F (G Int ) Bool or to F Bool (G Int ) or even to F Bool Bool . But, in all cases \nthe reduct also matches the very same pattern for F , allowing local diamond property to be true.6 What \nis necessary to support a local diamond property in a system with closed type families, still restricted \nto linear patterns? We need this property: If F t can reduce by some equation q, and ' t t ', then F \nt can reduce by that same equation q. With only open families, this property means that matching must \nbe preserved by reduction. With closed families, however, both matching and apartness must be preserved \nby reduction. Consider the de.nition for F below (where H is some other type family): 6 Actually, under \nparallel reduction; see (Weirich et al. 2011). type family F a b where F Int Bool = Char F a b = H a \n We know that F (G Int ) (G Int) matches the second equation and is apart (De.nition 6) from the .rst \nequation. The reduct F (G Int ) Bool also matches the second equation but is not apart from the .rst \nequation. Hence, F (G Int ) Bool cannot simplify by either equation for F , and the local diamond property \ndoes not hold. Put simply, our apartness implementation is not preserved by reduction. In a terminating \nsystem, we are able to get away with the weaker Property 14 for apart (where apartness is not directly \npreserved under reduction), which our implementation does satisfy. We have designed an implementation \nof apart which is provably stable under reduction, but it is more conservative and less intuitive for \nprogrammers. Given that this alternative de.nition of apart brought a proof of type safety only for potentially \nnon-terminating but linear patterns (prohibiting our canonical example Equal), and that it often led \nto stuck targets where a reduction naively seemed possible, we have dismissed it as being impractical. \nWe thus seek out a proof of type safety in the presence of non-terminating, non\u00adleft-linear axiom sets. \n 8.2 Type families vs. functional dependencies Functional dependencies (Jones 2000) (further formalized \nby Sulz\u00admann et al. (2007b)) allow a programmer to specify a dependency between two or more parameters \nof a type class. For example, Kise\u00adlyov et al. (2004) use this class for their type-level equality func\u00adtion:7 \nclass HEq x y (b :: Bool ) | x y . b instance HEq x x True instance (b ~ False ) . HEq x y b The annotation \nx y . b in the class header declares a functional dependency from x and y to b. In other words, given \nx and y, we can always .nd b. Functional dependencies have no analogue in GHC s internal language, System \nFC; indeed they predate it. Rather, functional de\u00adpendencies simply add extra uni.cation constraints \nthat guide type inference. This can lead to very compact and convenient code, es\u00adpecially when there \nare multiple class parameters and bi-directional functional dependencies. However, functional dependencies \ndo not generate coercions witnessing the equality between two types. Hence they interact poorly with \nGADTs and, more generally, with local type equalities. For example, consider the following: class Same \na b | a . b instance Same Int Int data T a where T1 :: T Int T2 :: T a data S a where MkS :: Same a \nb . b . S a f :: T a . S a . Int f T1 (MkS b) = b f T2 s = 3 In the T1 branch of f we know that a is \nInt, and hence (via the functional dependency and the Same Int Int instance declaration) the existentially-quanti.ed \nb must also be Int, and the de.nition should type-check. But GHC rejects f , because it cannot produce \na well-typed FC term equivalent to it. Could we .x this, by producing 7 Available from http://okmij.org/ftp/Haskell/types.html# \nHList. evidence in System FC for functional dependencies? Yes; indeed, one can regard functional dependencies \nas a convenient syntactic sugar for a program using type families. For example we could translate the \nexample like this: class F a ~ b . Same a b where type F a instance Same Int Int where type F Int = Int \n Now the (unchanged) de.nition of f type-checks. A stylistic difference is that functional dependencies \nand type classes encourage logic programming in the type system, whereas type families encourage functional \nprogramming. 8.3 Controlling overlap Morris and Jones (2010) introduce instance chains, which obviate \nthe need for overlapping instances by introducing a syntax for ordered overlap among instances. Their \nideas are quite similar to the ones we present here, with a careful check to make sure that one instance \nis impossible before moving onto the next. However, the proof burden for their work is lower than ours \na .aw in instance selection may lead to incoherent behavior (e.g., different instances selected for the \nsame code in different modules), but it cannot violate type safety. This is because class instances are \ncompiled solely into term-level constructs (dictionaries), not type\u00adlevel constructs. In particular, \nno equalities between different types are created as part of instance compilation. 8.4 Full-spectrum \ndependently typed languages Type families resemble the type-level computation supported by dependently \ntyped languages. Languages such as Coq (Coq devel\u00adopment team 2004) and Agda (Norell 2007) allow ordinary \nfunc\u00adtions to return types. As in Haskell, type equality in these languages is de.ned to include \u00df-reduction \nof function application and .\u00adreduction of pattern matching. However, there are several signi.cant differences \nbetween these type-level functions and type families. The .rst is that Coq and Agda do not allow the \nelimination of their equivalents of kind *. There is no way to write a Coq/Agda function analogous to \nthe closed type family below, which returns True for function types and False otherwise. type family \nIsArrow (a :: *) :: Bool where IsArrow (a . b) = True IsArrow a = False  Instead, pattern matching is \nonly available for inductive datatypes. The consistency of these languages prohibits the elimination \nof non-inductive types such as * (or Set, Prop, and Type ). Furthermore, pattern matching in Coq and \nAgda does not sup\u00adport non-linear patterns. As we discussed above, non-linear patterns allow computation \nto observe whether two types are equal. How\u00adever, the equational theory of full spectrum languages is \nmuch more expressive than that of Haskell. Because these languages allow un\u00adsaturated functions in types, \nit must de.ne when two functions are equal. This comparison is intensional, and allowing computation \nto observe intensional equality is somewhat suspicious. However, in Haskell, where all type functions \nmust always appear saturated, this issue does not arise. Due to the lack of non-linear patterns, Coq \nand Agda program\u00admers must de.ne individual functions for every type that supports decidable equality. \n(Coq provides a tactic decide equality to automate this de.nition.) Furthermore, these de.nitions do \nnot immediately imply that equality is re.exive; this result must be proved separately and manually applied. \nIn contrast, the closed type family Equal a a immediately reduces to True . Similarly, functions in \nCoq and Agda do not support coincident overlap at de.nition time. Again, these identities can be proven \nas lemmas, but must be manually applied.  8.5 Other functional programming languages Is our work on \nclosed type families translatable to other func\u00adtional programming languages with rich type-level programming? \nWe think so. Though the presentation in this paper is tied closely to Haskell, we believe that the notion \nof apartness would be quite similar (if not the same) in another programming language. Ac\u00adcordingly, \nthe analysis of Section 3 would carry over without much change. The one caveat is that, as mentioned \nabove, non-linear pat\u00adtern matching depends on the saturation of all type-level functions. If this criterion \nis met, however, we believe that other languages could adopt the surface syntax and behavior of closed \ntype families as presented here without much change. 9. Conclusions Closed type families improve the \nusability of type-level compu\u00adtation, and make programming at the type level more reminis\u00adcent of ordinary \nterm-level programming. At the same time, closed families allow for the de.nition of manifestly-re.exive, \ndecidable equality on types of any kind. They allow automatic reductions of types with free variables \nand allow the user to specify multiple, po\u00adtentially overlapping but coherent reduction strategies (such \nas the equations for the And example). On the theoretical side, the question of consistency for non\u00adterminating \nnon-left-linear rewrite systems is an interesting re\u00adsearch problem in its own right, quite independent \nof Haskell or type families, and we offer it as a challenge problem to the reader. Acknowledgments We \nparticularly thank Conor McBride, Joxan Jaffar, and Stefan Kahrs for helping us navigate the literature \non term rewriting, and on uni.cation over in.nite types. Stefan Kahrs provided the counter-example to \ncon.uence. Thanks also to Jos\u00b4e Pedro Mag\u00adalh aes for detailed and helpful feedback on the paper. This \nmaterial is partly supported by the National Science Foun\u00addation under Grant Nos. 1116620 and 1319880. \nReferences M. Chakravarty, G. Keller, and S. Peyton Jones. Associated type synonyms. In ACM SIGPLAN International \nConference on Functional Program\u00adming (ICFP 05), Tallinn, Estonia, 2005. Coq development team. The Coq \nproof assistant reference manual. LogiCal Project, 2004. URL http://coq.inria.fr. Version 8.0. B. Courcelle. \nFundamental properties of in.nite trees. Theoretical com\u00adputer science, 25(2):95 169, 1983. R. A. Eisenberg, \nD. Vytiniotis, S. Peyton Jones, and S. Weirich. Closed type families with overlapping equations (extended \nversion). Technical report, University of Pennsylvania, 2013. D. Fridlender and M. Indrika. Functional \npearl: Do we need dependent types? Journal of functional programming, 10(4):409 415, 2000. R. Garcia, \nJ. Jarvi, A. Lumsdaine, J. G. Siek, and J. Willcock. A compar\u00adative study of language support for generic \nprogramming. In Proceed\u00adings of the 18th annual ACM SIGPLAN conference on Object-oriented programing, \nsystems, languages, and applications, OOPSLA 03, pages 115 134, New York, NY, USA, 2003. ACM. ISBN 1-58113-712-5. \n. URL http://doi.acm.org/10.1145/949305.949317. G. Huet. R \u00b4esolution d \u00b4equations dans les langages \nd ordre 1, 2, . . . , .. PhD thesis, Universit\u00b4 e de Paris VII, 1976. G. Huet. Con.uent reductions: Abstract \nproperties and applications to term rewriting systems. J. ACM, 27(4):797 821, Oct. 1980. ISSN 0004-5411. \n. URL http://doi.acm.org/10.1145/322217.322230. J. Jaffar. Ef.cient uni.cation over in.nite terms. New \nGeneration Comput\u00ading, 2(3):207 219, 1984. ISSN 0288-3635. . URL http://dx.doi. org/10.1007/BF03037057. \nM. P. Jones. Type classes with functional dependencies. In G. Smolka, editor, ESOP, volume 1782 of Lecture \nNotes in Computer Science, pages 230 244. Springer, 2000. ISBN 3-540-67262-1. O. Kiselyov, R. L\u00a8ammel, \nand K. Schupke. Strongly typed heterogeneous collections. In Proc. 2004 ACM SIGPLAN Workshop on Haskell, \nHaskell 04, pages 96 107. ACM, 2004. J. Klop. Term rewriting systems. In Handbook of logic in computer \nscience (vol. 2), pages 1 116. Oxford University Press, Inc., 1993. K. Knight. Uni.cation: a multidisciplinary \nsurvey. ACM Comput. Surv., 21 (1):93 124, Mar. 1989. ISSN 0360-0300. . URL http://doi.acm. org/10.1145/62029.62030. \nC. McBride. Faking it: Simulating dependent types in Haskell. J. Funct. Program., 12(5):375 392, July \n2002. J. G. Morris and M. P. Jones. Instance chains: type class programming with\u00adout overlapping instances. \nIn Proceedings of the 15th ACM SIGPLAN international conference on Functional programming, ICFP 10, pages \n375 386, New York, NY, USA, 2010. ACM. ISBN 978-1-60558-794-3. . URL http://doi.acm.org/10.1145/1863543.1863596. \nM. H. A. Newman. On theories with a combinatorial de.nition of equiv\u00adalence . Annals of Mathematics, \n43(2):pp. 223 243, 1942. ISSN 0003486X. URL http://www.jstor.org/stable/1968867. U. Norell. Towards a \npractical programming language based on dependent type theory. PhD thesis, Department of Computer Science \nand Engineer\u00ading, Chalmers University of Technology, SE-412 96 G \u00a8oteborg, Sweden, September 2007. T. \nSchrijvers, S. Peyton Jones, M. Chakravarty, and M. Sulzmann. Type checking with open type functions. \nIn Proceedings of the 13th ACM SIGPLAN international conference on Functional programming, ICFP 08, pages \n51 62, New York, NY, USA, 2008. ACM. ISBN 978-1\u00ad59593-919-7. . URL http://doi.acm.org/10.1145/1411204. \n1411215. M. Sulzmann, M. M. T. Chakravarty, S. Peyton Jones, and K. Donnelly. System F with type equality \ncoercions. In Proceedings of the 2007 ACM SIGPLAN international workshop on Types in languages design \nand implementation, TLDI 07, pages 53 66, New York, NY, USA, 2007a. ACM. M. Sulzmann, G. Duck, S. Peyton \nJones, and P. Stuckey. Understanding functional dependencies via constraint handling rules. Journal of \nFunc\u00adtional Programming, 17:83 130, Jan. 2007b. W. Swierstra. Data types a la carte. `J. Funct. Program., \n18(4):423 436, July 2008. ISSN 0956-7968. . URL http://dx.doi.org/10.1017/ S0956796808006758. S. Weirich \nand C. Casinghino. Arity-generic datatype-generic program\u00adming. In Proceedings of the 4th ACM SIGPLAN \nworkshop on Program\u00adming languages meets program veri.cation, PLPV 10, pages 15 26, New York, NY, USA, \n2010. ACM. ISBN 978-1-60558-890-2. . URL http://doi.acm.org/10.1145/1707790.1707799. S. Weirich, D. Vytiniotis, \nS. Peyton Jones, and S. Zdancewic. Generative type abstraction and type-level computation. In Proceedings \nof the 38th annual ACM SIGPLAN-SIGACT symposium on Principles of program\u00adming languages, POPL 11, pages \n227 240, New York, NY, USA, 2011. ACM. S. Weirich, J. Hsu, and R. A. Eisenberg. Towards dependently typed \nHaskell: System FC with kind equality. In Proceedings of the 18th ACM SIGPLAN International Conference \non Functional Programming, ICFP 13, Boston, MA, USA, New York, NY, USA, 2013. ACM. To appear. B. A. Yorgey, \nS. Weirich, J. Cretin, S. Peyton Jones, D. Vytiniotis, and J. P. Magalh aes. Giving Haskell a promotion. \nIn Proc. 8th ACM SIGPLAN workshop on Types in Language Design and Implementation, TLDI 12, pages 53 66. \nACM, 2012.     \n\t\t\t", "proc_id": "2535838", "abstract": "<p>Open, type-level functions are a recent innovation in Haskell that move Haskell towards the expressiveness of dependent types, while retaining the look and feel of a practical programming language. This paper shows how to increase expressiveness still further, by adding closed type functions whose equations may overlap, and may have non-linear patterns over an open type universe. Although practically useful and simple to implement, these features go <i>beyond</i> conventional dependent type theory in some respects, and have a subtle metatheory.</p>", "authors": [{"name": "Richard A. Eisenberg", "author_profile_id": "81542549256", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P4383931", "email_address": "eir@cis.upenn.edu", "orcid_id": ""}, {"name": "Dimitrios Vytiniotis", "author_profile_id": "81100156369", "affiliation": "Microsoft Research Cambridge, Cambridge, United Kingdom", "person_id": "P4383932", "email_address": "dimitris@microsoft.com", "orcid_id": ""}, {"name": "Simon Peyton Jones", "author_profile_id": "81100271851", "affiliation": "Microsoft Research Cambridge, Cambridge, United Kingdom", "person_id": "P4383933", "email_address": "simonpj@microsoft.com", "orcid_id": ""}, {"name": "Stephanie Weirich", "author_profile_id": "81100093135", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P4383934", "email_address": "sweirich@cis.upenn.edu", "orcid_id": ""}], "doi_number": "10.1145/2535838.2535856", "year": "2014", "article_id": "2535856", "conference": "POPL", "title": "Closed type families with overlapping equations", "url": "http://dl.acm.org/citation.cfm?id=2535856"}