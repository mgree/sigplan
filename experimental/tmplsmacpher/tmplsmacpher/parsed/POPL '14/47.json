{"article_publication_date": "01-08-2014", "fulltext": "\n Counter-Factual Typing for Debugging Type Errors * Sheng Chen Martin Erwig School of EECS, Oregon State \nUniversity School of EECS, Oregon State University chensh@eecs.oregonstate.edu erwig@eecs.oregonstate.edu \nAbstract Changing a program in response to a type error plays an important part in modern software development. \nHowever, the generation of good type error messages remains a problem for highly expressive type systems. \nExisting approaches often suffer from a lack of pre\u00adcision in locating errors and proposing remedies. \nSpeci.cally, they either fail to locate the source of the type error consistently, or they report too \nmany potential error locations. Moreover, the change suggestions offered are often incorrect. This makes \nthe debugging process tedious and ineffective. We present an approach to the problem of type debugging \nthat is based on generating and .ltering a comprehensive set of type-change suggestions. Speci.cally, \nwe generate all (program\u00adstructure-preserving) type changes that can possibly .x the type error. These \nsuggestions will be ranked and presented to the pro\u00adgrammer in an iterative fashion. In some cases we \nalso produce suggestions to change the program. In most situations, this strate\u00adgy delivers the correct \nchange suggestions quickly, and at the same time never misses any rare suggestions. The computation of \nthe po\u00adtentially huge set of type-change suggestions is ef.cient since it is based on a variational type \ninference algorithm that type checks a program with variations only once, ef.ciently reusing type infor\u00admation \nfor shared parts. We have evaluated our method and compared it with previous approaches. Based on a large \nset of examples drawn from the litera\u00adture, we have found that our method outperforms other approaches \nand provides a viable alternative. Categories and Subject Descriptors F.3.3 [Logics and Mean\u00adings of \nPrograms]: Studies of Program Constructs Functional constructs,Type structure; D.3.2 [Programming Languages]: \nLan\u00adguage Classi.cations Applicative (functional) languages; D.2.5 [Software Engineering]: Testing and \nDebugging General Terms Languages, Theory Keywords Type inference, error localization, type error messages, \nchoice types, change suggestions, type-error debugging * This work is supported by the National Science \nFoundation under the grants CCF-0917092, CCF-1219165, and IIS-1314384. Permission to make digital or \nhard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. Copyrights for components of this work owned by others than the \nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to \npost on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. Request \npermissions from Permissions@acm.org. POPL 14, January 22 24, 2014, San Diego, CA, USA. ACM 978-1-4503-2544-8/14/01...$15.00. \nCopyright is held by the owner/author(s). Publication rights licensed to ACM. http://dx.doi.org/10.1145/2535838.2535863. \n 1. Introduction Generating informative and helpful type error messages remains a challenge for implementing \ntype inference algorithms. Soon after the algorithm W [8] had been developed, this problem was rec\u00adognized \n[15, 26]. It has since prompted numerous research effort\u00ads [7, 12, 14, 16 18, 20, 21, 23, 25, 27, 29]. \nAlthough considerable progress has been made, there is still no single method that consis\u00adtently produces \nsatisfactory results. Most of the existing approaches perform poorly in certain cases. As an example, \nconsider the following Haskell function palin, which checks whether a list is a palindrome [24]. The \n.rst equation for fold contains a type error and should return z instead of [z]. fold f z [] = [z] fold \nf z (x:xs) = fold f (f z x) xs flip f x y = f y x rev = fold (flip (:)) [] palin xs = rev xs == xs Existing \ntools have dif.culties in .nding this error. For example, the Glasgow Haskell Compiler (GHC) 7.61 produces \nthe following 2 error message. Occurs check: cannot construct the infinite type: t0 = [t0] Expected type: \n[[t0]] Actual type: [t0] In the second argument of (==) , namely xs In the expression: rev xs == xs While \ntechnically accurate, the error message doesn t directly point to the source of the error, and it doesn \nt tell the user how it could be .xed either. The use of compiler jargon makes the error mes\u00adsage dif.cult \nto understand for many programmers. While giving reasons for the failure of uni.cation might be useful \nfor experi\u00adenced programmers and type system experts, such error messages still require some effort to \nmanually reconstruct some of the types and solve uni.cation problems. (Hugs983 produces a similar error \nmessage and suffers from the same problems.) One of the problems of the approach taken in GHC is that \nit commits to a single error location, because in some cases the program text does not contain enough \ninformation to con.dently make the right decision about the correct error location. This has led to a \nnumber of program slicing approaches that try to identify a set of possible error locations instead. \nThe basic idea is to .nd all program positions that contribute to a type error and exclude those that \ndo not. For example, the Skalpel4 type error slicer for SML [12] produces the following 1 www.haskell.org/ghc/ \n2 For presentation purposes, we have slightly edited the outputs of some tools by changing their indentation \nand line breaks. 3 www.haskell.org/hugs/ 4 www.macs.hw.ac.uk/ultra/skalpel/ result. (We have translated \nthe program into ML for Skalpel to work.) fun fold f z [] = [z] ; | fold f z (x::xs) = fold f (f (z,x)) \nxs ; fun flip f (x,y) = f (y, x) ; fun rev xs = fold ( (flip op ::)) [] xs ; fun palin xs = rev xs = \nxs ; Showing too many program locations involved in the type error di\u00adminishes the value of the slicing \napproach because of the cognitive burden put on the programmer to work through all marked code and to \nsingle out the proper error location. To address this problem, techniques have been developed that try \nto minimize the possible locations contributing to a type error. An example is the Chameleon Type Debugger,5 \nwhich produces the following output. fold f z [] = [z] ; fold f z (x:xs)= fold f (f z x) xs ; flip f \nx y = f y x ; rev = fold (flip (:)) [] ; palin xs = rev xs = xs ; Chameleon is based on constraint solving \nand identi.es a mini\u00admal set of unsatis.able constraints, from which the corresponding places in the \nprogram contributing to the type error are derived. While Chameleon is a clear improvement over other \nslicing ap\u00adproaches in reporting fewer potential error locations, a programmer still has to work through \nseveral code parts to .nd the type error. In particular, .guring out which types should be used at speci.c \nlocations can be quite time consuming. On the other end of the single-vs.-many location spectrum we .nd \napproaches that, like GHC or Hugs, follow Johnson and Walz s idea of .nding the most likely erroneous \nlocation and try to add ex\u00adplanations or suggestions for how to correct the error. One example is the \nHelium compiler6, which was developed to support the teach\u00ading of typed functional programming languages. \nA declared focus of Helium is to generate good error messages [14]. For our exam\u00adple, it produces the \nfollowing message. (5,19): Type error in infix application expression : rev xs == xs operator : == type \n: a -> a -> Bool does not match : [[b]] -> [b] -> c because : unification would give infinite type Unfortunately, \nHelium doesn t perform much better than GHC or Hugs on this example and provides feedback only in terms \nof internal representations used by the compiler. Seminal7 is a tool for type checking ML programs that \nalso produces change suggestions [18, 19]. Seminal blames the type error on the function palin and suggests \nthe following corrective change. 5 ww2.cs.mu.oz.au/~sulzmann/chameleon/. Since Chameleon does\u00adn t offer \na type diagnosis option anymore, the result is reproduced directly from [24]. 6 www.cs.uu.nl/wiki/bin/view/Helium/WebHome \n7 cs.brown.edu/~blerner/papers/seminal_prototype.html File \"Palin.ml\", line 8, characters 21-27: This \nexpression has type a list list but is here used with type a list Relevant code: rev xs File \"Palin.ml\", \nline 8, characters 15-17: Try replacing xs == (rev xs) with ( == ) (xs, (rev xs)) of type b list * b \nlist list -> bool within context let palin xs = ( == ) (xs, (rev xs)) ;; Unfortunately, the suggested \nerror location is not correct (according to [24]), and although the suggested change will eliminate the \ntype error, it changes the wrong code (the suggested change of partially applying == to the pair of differently \ntyped lists turns palin s type into a list -> a list * a list list -> Bool.) Offering change suggestions \nis a double-edged sword: While it can be very helpful in simplifying the task of .xing type errors, it \ncan also be sometimes very misleading, and frustrating when the suggested change doesn t work. In the \nshown example, both change-suggesting tools fail to correctly locate the error location. The tasks of \ndebugging type errors seems to be an inherently ambiguous undertaking, because in some situations there \nis just not enough information present in the program to generate a correct change suggestion. Consider, \nfor example, the expression not 1. The error in this expression is either not or 1, 8 but without any \nadditional knowledge about the purpose of the expression, there is no way to decide whether to replace \nthe function or the argument. This is why it is generally impossible to isolate one point in the program \nas the source of a type error. This fact provides a strong justi.cation for slicing approaches that try \nto provide an unbiased account of error situations. On the other hand, in many cases some locations are \nmore likely than others, and speci.cally in larger programs, information about the context of an erroneous \nexpression can go a long way of isolating a single location for a type error. Thus, a reasonable compromise \nbetween slicing and single\u00aderror-reporting approaches could be a method to principally com\u00adpute all possible \ntype error locations (together with possible change suggestions) and present them ranked and in small \nportions to the programmer. At the core of such an approach has to be a type checker that produces a \ncomplete set of type changes that would make the program type correct. In this paper we present a method \nfor counter-factual change inference, whose core is a technique to answer the question What type should \na particular subexpression have to remove type errors in a program . We have also implemented and evaluated \na prototype for a type checker that is based on this technique. To keep the complexity manageable we \nonly produce so-called atomic type changes, that is, type changes for the leaves of the program s abstract \nsyntax tree. This helps avoid the introduction of too exotic or too extreme changes. Consider, for example, \nthe non\u00adatomic type change suggested by Seminal for the palin program, which seems to be not realistic. \nOr consider changing a whole program to a value of type Bool or Int, which always works but is hardly \never correct. However, errors that are best .xed by non-atomic expression changes are quite common. Examples \nare the swapping of function arguments or the addition of missing function arguments. The iden\u00adti.cation \nof such non-atomic program changes is not ruled out by 8 It could also be the case that the whole expression \nis incorrect and should be replaced by something else, but we ignore this case for now. Rank Loc Code \nChange code of type/expression To new type/expression Result type 1 (1,19) (:)9 a -> [a] -> [a] a -> \n[b] -> a [a] -> Bool [z] z 2 (5,22) xs [a] [[a]] [a] -> Bool 3 (5,12) rev [a] -> [[a]] [a] -> [a] [a] \n-> Bool 4 (5,19) (==) [a] -> [a] -> Bool [[a]] -> [a] -> b [a] -> b 5 (4,7) fold (a -> b -> a) -> a -> \n[b] -> [a] ([a] -> a -> [a]) -> [b] -> [a] -> [a] [a] -> Bool Figure 1: Ranked list of single-location \ntype and expression change suggestions inferred for the palin example. the approach taken and can actually \noften be achieved by deducing expression changes from type changes. Returning to the palin example, Figure \n1 shows a ranked list of all (single-location) type changes, computed by our prototype, that can .x the \ntype error. The correct change ranks .rst in our method. Note that this is not a representation intended \nto be given to end users. We rather envision an integration into a user interface in which locations \nare underlined and hovering over those loca\u00adtions with the mouse will pop up windows with individual \nchange suggestions. In this paper we focus on the technical foundation to compute the information required \nfor implementing such a user in\u00adterface. Each suggestion is essentially represented by the expression \nthat requires a change together with the inferred actual and expected type of that expression. (Since \nwe are only considering atomic type changes, this expression will always be a constant or variable in \ncase of a type change, but it can be a more complicated expression in case of deduced expression change.) \nWe also show the position of the code in the program10 and the result types of the program if the corresponding \nchange is adopted. This information is meant as an additional guide for programmers to select among suggestions. \nThe list of shown suggestions is produced in several steps. First, we generate (lazily) all possible \ntype changes, that is, even those that involve several locations. Note that sometimes the suggested types \nare unexpected. For example, the suggested type for fold is ([a] -> a -> [a]) -> [b] -> [a] -> [a] although \n(a -> b -> a) -> a -> [b] -> a would be preferable. This phenomenon can be generally attributed to the \ncontext of the expression. On the one hand, the given context can be too restrictive and coerce the inferred \ntype to be more speci.c than it has to be, just as in this example the .rst argument flip (:) forces \nfold to have [a] -> a -> [a] as the type of its .rst argument. On the other hand, the context could also \nbe too unrestrictive. There is no information about how fold is related to [] in the fourth line of the \nprogram. Thus, the type of the second argument of fold is inferred as [b]. This imprecision can t be \nremedied by exploiting type information of the program. Second, we .lter out those type changes that \ninvolve only one location. We present those .rst to the programmer since these are generally easier to \nunderstand and to adopt than multi-location change suggestions. Should the programmer reject all these \nsingle\u00adlocation suggestions, two-location suggestions will be presented next, and so on. Third, in addition \nto type-change suggestions, we also try to infer some non-atomic expression changes from type changes. \nIn general, only the programmer who wrote the program knows how to translate required type changes into \nexpression changes. How\u00adever, there are a number of common programming mistakes, such as swapping or \nforgetting arguments, that are indicated by type\u00adchange suggestions. Similar to Seminal, our prototype \nidenti.es 9 Our prototype represents [z] as (:) z []. 10 We have added the line and column numbers by \nhand since our prototype currently works on abstract syntax and doesn t have access to the informa\u00adtion \nfrom the parser.  these kind of changes that are mechanical and do not require a deep understanding \nof the program semantics. In our example, we infer the replacement of [z] by z, because the expected \ntype requires that the return type be the same as the .rst argument type. We thus suggest to use the \n.rst argument, that is z, to replace the application (:) z []. Note however, that we don t infer a similar \nchange for the .fth type change because fold is partially applied in the de.nition, and we have no access \nto the third argument of fold. Had the rev function been implemented using an eta-expanded list argument, \nsay xs, we would have also inferred the suggestion to change fold (flip (:)) [] xs to xs. Note also that \nwe do not supplement type-change suggestions with atomic expression changes. For example, in the second \nsug\u00adgestion, we do not suggest to replace xs by [xs]. There are two reasons for this. On the one hand, \nwe believe that, given the very speci.c term to change, the inferred type, and the expected type, the \ncorresponding required expression change is often easy to deduce for a programmer. On the other hand, \nsuggesting speci.c expres\u00adsion changes requires knowledge about program semantics that is in many cases \nnot readily available in the program. Thus, such sug\u00adgestions can often be misleading. Finally, all the \ntype-change suggestions are ranked according to a few simple, but effective complexity heuristics. At \nthe core of the proposed method is a type system for inferring a set of type-change suggestions. This \ntype system is described in detail in Section 4. We show that the type system generates a complete and \ncorrect set of atomic type change suggestions. The type system is based on a systematic variation of \nthe types of atomic expressions in a program. Therefore, some background information on how to represent \nvariation in expressions and type\u00ads, how to make use of it for the purpose of type inference, and what \ntechnical challenges this poses, is provided in Section 2. E\u00adquipped with the necessary technical background, \nthe rationale be\u00adhind variation-based type-change inference can then be explained on a high level in \nSection 3. The algorithmic aspects of type inference and some measures for controlling runtime complexity \nare discussed in Section 5. We also brie.y describe a set of heuristics that we use for ranking change \nsuggestions. The method of deducing expression changes from type changes is discussed in Section 6. We \nhave evaluated our prototype implementation by comparing it with three closely related tools and found \nthat counter-factual typing can generate correct change suggestions more often than the other approaches. \nThe evaluation is described in Section 7. Related work is discussed in Section 8, and conclusions presented \nin Section 9 complete this paper. 2. Variation-Based Typing The idea of variation-based type change inference \nis to explicitly represent and reason about discrepancies between inferred and expected types that are \ndetected by the type checker. This idea can be realized in different ways, and the counter-factual (CF) \ntype inference presented in this paper is just one incarnation of this more general strategy. In this \nsection we will introduce the idea of variation-based typing, and gather some technical machinery that \nwill then be employed to formalize counter-factual type change inference. First, the goal of CF type \ninference is to generate suggestions for how to change types and expressions in a program to .x a type \nerror. Both kinds of changes will be represented using the generic choice representation of the choice \ncalculus that was introduced in [11]. The .rst application of this representation in the context of type \nchecking was to extend type inference to program families (that is, a set of related programs) [5]. We \nwill introduce the concept of choices, variational expressions and types, and some related concepts in \nSection 2.1. Second, when type checking a program family, it is important to obtain the types of some \nprograms (family members) even if the typing of other programs fails. This leads to the notion of partial \ntypes, typing patterns, and an associate method for partial uni.ca\u00adtion. The application rule will be \nfurther generalized to accommo\u00addate partial types. We will explain these concepts in Section 2.2. 2.1 \nVariational Expressions and Variational Types The Choice Calculus [11] provides a disciplined way of \nrepresent\u00ading variation in software. The most important concept is the named choice, which can be used \nto represent variation points in both ex\u00adpressions and types. For example, the variational expression \ne = not A(1, True) contains the named choice A that represents a choice between the two constants 1 and \nTrue as the argument to not . The process of eliminating a variation point is called selection. Selection \ntakes a selector of the form D.i, where D is the name of the variation point, traverses the expression \nand replaces all the variation points named D with its corresponding ith alternative. In this paper, \nwe are only concerned with binary choices, that is, i will be either 1 or 2. For example, selecting A.1 \nfrom e yields the plain expression not 1. Plain expressions are obtained after all choic\u00ades are eliminated \nfrom a variational expression. Note that varia\u00adtion points with different names vary independently of \none another, and only those with the same name are synchronized during selec\u00adtion. For example, the variational \nexpression A(odd,not) A(1,True) represents only the two expressions odd 1 and not True, while A(odd,not) \nB(1,True) represents the four expressions odd 1, odd True, not 1, and not True. Through the use of independent \nchoices, variational program\u00ads can very quickly encode a huge number of programs that differ only slightly. \nEnsuring the type correctness of all selectable plain programs is challenging because the brute-force \napproach of gener\u00adating and checking each variant individually is generally infeasible. Variational typing \n[5] solves this problem by introducing variation\u00adal types and a method for typing variational programs \nin one run. The result of type checking a variational program is a variational type, from which the types \nfor individual program variants can be obtained with the same selection as the program is derived. The \nsyntax of variational types is shown below where a ranges over type variables, and . ranges over type \nconstants. f ::= . | a | f . f | D(f,f) | . The type . is used to denote the occurrences of type errors \nand will be discussed shortly in Section 2.2. Under variational typing, the expression A(odd,not) has \nthe type A(Int . Bool,Bool . Bool). The most important property of variational typing is that the type \nfor each plain expression selected from the variational expression can be obtained through the same selections \nfrom the corresponding variational type. For example, selecting A.2 from both the variational expression \nand type, the expression not has the type Bool . Bool. Typing patterns p ::= . | T | D(p,p) . : f . f \n.(f1 . f2) = f1 . f2 .(D(f1 . f'1, f2 . f'2)) = D(f1,f2) . D(f1',f'2) .(D(f1, f2)) = .(D(.(f1),.(f2))) \n.(f) = . . . (otherwise) N : f \u00d7 f . p f N f = T D(f1) N D(f2) = D(f1 N f2) . N f = . D(f) N f' = D(f \nN f') f N . = . f' N D(f) = D(f' N f) f N f' = . f1 . f2 N f'1 . f'2 = (f1 N f1') . (f2 N f2') < : p \n\u00d7 f . f . : p \u00d7 p . p . <f = . T . p = p T <f = f . . p = . D(p) <f = D(p <f) D(f) . f' = D(f . f') Figure \n2: Operations for typing applications An important technical part of variational typing is the fact \nthat the equivalence of choices is not merely syntactical, but governed by a set of equivalence rules, \noriginally described in [11]. For ex\u00adample, A(Int,Int) is equivalent to Int, written as A(Int, Int) = \nInt, since either decision in A yields Int. The equivalence rela\u00adtionship plays an important part in, \nand poses a challenge to, the uni.cation of variational types. For details we refer to [5]. A shortcoming \nof the variational typing approach is that it can succeed only if all variants are well typed, that is, \nit is impossible to assign a type to the variational expression A(odd, not) 1, even though one of its \nvariants is type correct. Error-tolerant variational typing addresses this issue. 2.2 Error-Tolerant \nVariational Typing The idea of error-tolerant typing [4] is to assign the type . to pro\u00adgram variants \nthat contain type errors. The explicit representation of type errors via . as normal types supports the \ncontinuation of the typing process in the presence of type errors. Moreover, each variational program \ncan be typed, and the resulting variational type contains . for all variants that are type incorrect \nand a plain type for all type-correct variants. For example, A(odd,not) 1 has the type A(Bool, .), which \nencodes exactly the types that we obtain if we generate and type each expression separately. The most \nchallenging part of the error-tolerant type system is the handling of function applications because type \nerrors can be introduced in different ways. For example, the function might not have an arrow type, or \nthe type of the argument might not match the argument type of the function. Moreover, we have to consider \nthe case of partial matching, that is, in the case of variational types, the argument type of the function \nand the type of the argument might be compatible for some variants only. Deciding in such a case that \nthe whole application is of type . would be too restrictive. This challenge is addressed by the following \ntyping rule [4]. G f e1 : f1 G f e2 : f2 f'2 . f' = .(f1) p = f'2 N f2 f = p <f' G f e1 e2 : f The \n.rst two premises retrieve the types for the function and argu\u00adment. Unlike in the traditional application \nrule, however, we do not require f1 to be a function type. Instead, the third premise tries to lift \nf1 into an arrow type using a function . that is de.ned at the top of Figure 2. Lifting speci.cally accounts \nfor the case in which f1 is a choice between arrow types, as in .(A(Bool . Bool,Int . Bool)) = A(Bool,Int) \n. A(Bool,Bool), and it also deals with, and introduces if necessary, error types. For example, .(A(Int \n. Bool,Int)) can succeed only by introducing an error type and thus yields A(Int,.) . A(Bool, .). The \nfourth premise computes a typing pattern p that records to what degree (that is, in which variants) the \ntype of e2 matches the argument type of the (partial) arrow type obtained for e1. As can be seen in Figure \n2, a typing pattern is a (possibly deeply nested) choice of the two values . (type error) and typing \nsuccess (T). The computation of a typing pattern proceeds by induction over the type structure of its \narguments. Note that the de.nition given in Figure 2 contains overlapping patterns and assumes that more \nspeci.c cases are applied before more general ones. When two rules are equally applicable, the computed \nresult is equivalent modulo the = rela\u00adtion [4]. Note also that we employ the abbreviating notation x \nfor a sequence of alternatives x1, . . . , xn (types or expressions) used with\u00adin choices. (In Figure \n2, this applies only to the case n = 2.) For two plain types, matching reduces to checking equality. \nFor example, Int N Int = T and Int N Bool = .. On the other hand, matching a plain type with a variational \ntype results in a choice pattern. For example, Int N D(Int,Bool) = D(T,.). Note that for two arrow types \nto be matched successfully, both their corresponding argument types and return types have to be matched \nsuccessfully. There is no partial matching for function types. We de.ne the operation . to achieve this, \nwhich is also presented in Figure 2. We can essentially view it as the logical and operation if we treat \nT as true and . as false. For example, when computing Int . A(Bool, Int) N B(Int,.) . Bool, we .rst obtain \nB(T,.) and A(.,T) for matching the argument types and return types, respectively. Next, we use . to derive \nthe .nal result as A(., B(T,.)). In the .fth and .nal premise, the typing pattern is used to preserve \nthe type errors that the fourth premise has potentially produced. This is done by masking the return \ntype with the typing pattern. The masking operation essentially replaces all the Ts in the typing pattern \nwith the variants in the return type and leaves all .s unchanged, denoting the occurrences of type errors. \nTo see the application rule in action, consider the expression A(not,odd) B(1,True). The .rst two premises \nproduce the follow\u00ading typing judgments. A(not,odd) : A(Bool . Bool,Int . Bool) B(1,True) : B(Int,Bool) \nLifting transforms the type of the function into A(Bool,Int) . A(Bool,Bool), which is equivalent to A(Bool,Int) \n. Bool. The computation of A(Bool,Int) N B(Int,Bool) yields p = A(B(.,T),B(T,.)), and masking the return \ntype of the function, Bool, with p yields A(B(.,Bool),B(Bool,.)). 3. Counter-Factual Typing The main \nidea behind counter-factual typing is to systematically vary parts of the ill-typed program to .nd changes \nthat can elimi\u00adnate the corresponding type error(s) from the program. It is infea\u00adsible to apply this \nstrategy directly on the expression level since there are generally in.nitely many changes that one could \nconsid\u00ader. Therefore, we perform the variation on the type level. Basically, we ask for each atomic expression \ne the counter-factual question: What type should e have to make the program well typed? The counter-factual \nreasoning is built into the type checking process in the following way. To determine the type of an expres\u00adsion \ne we .rst infer e s type, say f. But then, instead of .xing this type, we leave the decision open and \nassume e to have the type D(f, a), where D is a fresh name and a is a fresh type variable. By leaving \nthe type of e open to revision we account for the fact that e may, in fact, be the source of a type error. \nBy choosing a fresh type variable for e s alternative type, we enable type information to .ow from the \ncontext of e to forge an alternative type f' that .ts into the context in case f doesn t. If f does .t \nthe context, it is uni.able with f', and the choice could in principle be removed. However, this is not \nreally necessary (and we, in fact, don t do this) since in case of a type-correct program, we can .nd \nthe type at the end of the typing process by simply selecting the .rst option from all generated choices. \n Let us illustrate this idea with a simple example. Consider the expression e = not 1. If we vary the \ntypes of both not and 1, we obtain the following typing judgments. not : A(Bool . Bool, a1) 1 : B(Int,a2) \n where a1 and a2 represent the expected types of not and 1 accord\u00ading to their respective contexts. To \n.nd the types a1 and a2, we have to solve the following uni.cation problem. A(Bool . Bool,a1) =? B(Int,a2) \n. a3 where a3 denotes the result type of the application and =? denotes that the uni.cation problem \nis solved modulo the type equivalence relation mentioned in Section 2.1 rather than the usual syntactical \nidentity. Another subtlety of the uni.cation problem is that two types may not be uni.able. In that case \na solution to the uni.cation problem consists of a so-called partial uni.er, which is both most general \nand introduces as few errors as possible. The uni.cation algorithm developed in [4] achieves both these \ngoals. For the above uni.cation problem, the following uni.er is com\u00adputed. The generality introduced \nby a6 and a7 ensures that only the second alternatives of choices A and B are constrained [5]. {a1 . \nA(a6,B(Int,a4) . a5), a2 . B(a7,A(Bool,a4)), a3 . A(Bool,a5)} Additionally, the uni.cation algorithm \nreturns a typing pattern that characterizes all the viable variants and helps to compute the result type \nof the varied expression. In this case we obtain A(B(.,T),T). Based on the uni.er and the typing pattern, \nwe can compute that the result type of the varied expression of not 1 is f = A(B(.,Bool),a5). From the \nresult type and the uni.er, we can draw the following conclusions. If we don t change e, that is, we \nselect A.1 and B.1 from the varied expression, the type of the expression is . (the variant corresponds \nto A.1 and B.1 in the result type), which re.ects the fact that the original expression is ill typed. \n If we vary not to some other expression f , that is, if we select variant A.2 and B.1 from the variational \nresult type, the result type will be a5. Moreover, the type of f is obtained by selecting A.2 and B.1 \nfrom the type that a1 is mapped to, which yields Int . a5. In other words, by changing not to an expression \nof type Int . a5, not 1 becomes well typed. In the larger context, a5 may be further constrained to have \nsome other type.  If we vary 1 to some expression g, that is, if we select A.1 and B.2 from the variational \ntype, then the result type becomes Bool.  If we vary both not to f and 1 to g, which means to select \n A.2 and B.2, the result type is a5. Moreover, from the uni.er we know that f and g should have the \ntypes a4 . a5 and a4, respectively.  Term variables x, y, z Value constants c Type variables a, \u00df Type \nconstants . Expressions e, f ::= c | x | .x.e | e e | let x = e in e |if e then e else e Monotypes t \n::= . | a | t . t Variational types f ::= t | . | D(f,f) | f . f Type schemas s ::= f | .a.f Selectors \ns ::= D.i Type environments G ::= \u00d8| G,x . s Substitutions ., . ::= \u00d8| .,a . f Choice environments . \n::= \u00d8| ., (l,D(f,f)) Figure 3: Syntax of expressions, types, and environments This gives us all atomic \ntype changes for the expression not 1. The combination of creating variations at the type level and vari\u00adational \ntyping provides an ef.cient way of .nding all possible type changes. 4. Type-Change Inference This section \npresents the type system that generates a complete set of atomic corrective type changes. After de.ning \nthe syntax for expressions and types in Section 4.1, we present the typing rules for type-change inference \nin Section 4.2. In Section 4.3 we investigate some important properties of the type-change inference \nsystem. 4.1 Syntax We consider a type checker for lambda calculus with let\u00adpolymorphism. Figure 3 shows \nthe syntax for the expressions, type\u00ads, and meta environments for the type system. We extend the bar \nnotation to other sequences of elements, such as bindings. Both the de.nitions of expressions and types \nare conventional, except for variational types, which introduce choice types and the error type. We use \nl to denote program locations, in particular, leaves in ASTs. We assume that there is a function ee( \nf ) that returns l for f in e. For presentation purposes, we assume that f uniquely determines a location. \nWe may omit the subscript e when the context is clear. The exact de.nition of e(\u00b7) does not matter. As \nusual, G binds type variables to type schemas for storing typing assumptions. We use . to denote type \nsubstitutions that map type variables to variational types. The metavariable . ranges over type substitutions \nthat are uni.ers for uni.able types or partial uni\u00ad.ers for nonuni.able types. Finally, we use the choice \nenvironment . to associate choice types that were generated during the typing process with the corresponding \nlocation in the program. Operations on types can be lifted to . by applying them to the types in .. We \nstipulate the conventional de.nition of FV that computes the free type variables in types, type schemas, \nand type environments. We write ./S for {a . f . . | a ./S}. The application of a type substitution to \na type schema is written as .(s) and replaces free type variables in s by the corresponding images in \n.. The de.nition is as follows. .(.) = . .(f1 . f2) = .(f1) . .(f2) .(.a.f) = .a../a(f) a if a ./dom(.) \n.(a) = .(D(f)) = D(.(f)) f if a . f . . Note that we do not consider variational polymorphic types. This \nis not a problem since we can always lift quanti.ers out of choices. For instance, D(.a.f1, .\u00df.f2) can \nbe transformed to G f e : f|. CO N c is of type . D fresh G f c : D(.,f)|{(e(c), D(.,f))} VA R G(x) = \n.a.f1 D fresh f = {a . f' }(f1) G f x : D(f,f2)|{(e(x),D(f, f2))} UN B O U N D AB S x ./dom(G) D fresh \nG,x . f f e : f' |. G f x : D(.,f)|{(e(x),D(.,f))} G f .x.e : f . f' |. LE T G,x . f f e : f|. a = FV(f) \n- FV(G) G,x . .a.f f e ' : f' |.' G f let x = e in e ' : f' |. . .' AP P G f e1 : f1|.1 G f e2 : f2|.2 \nf' 2 . f' = .(f1) p = f' 2 N f2 f = p <f' G f e1 e2 : f|.1 . .2 IF (G f ei : fi|.i)i:1..3 p1 = f1 N Bool \np2 = f2 N f3 f = p1 <(p2 <f2) G f if e1 then e2 else e3 : f|.1 . .2 . .3 Figure 4: Rules for type-change \ninference .a1\u00df1.D(f' 1, f2 ' ) with a1 ./FV(f1) and \u00df1 ./FV(f2), and f' = 1 {a . a1}(f1) and f' = {\u00df \n. \u00df1}(f2). 2  4.2 Typing Rules Figure 4 presents the typing rules for inferring type changes. The typing \njudgment is of the form G f e : f|. and produces as a result a variational type f that represents all \nthe typing potential for e plus a set of type changes . for the atomic subexpressions of e that will \nlead to the types in f. Since we are only interested in atomic changes during this phase, we only vary \nthe leaves in the AST of programs, which are constants and variable references. This is re.ected in the \ntyp\u00ading rules as we generate fresh choices in rules CO N, VA R, and UN B O U N D. In each case, we place \nthe actual type in the .rst alter\u00adnative and an arbitrary type in the second alternative of the choice. \nWhen an unbound variable is accessed, it causes a type error. We thus put . in the .rst alternative of \nthe choice. The rules AB S and LE T for abstractions and let-expressions are very similar to those in \nother type systems except that variables are bound to variational types. The rule AP P for typing applications \nis very similar to the application rule discussed in Section 2.2. The only difference is that the rule \nhere keeps track of the information for .. The IF rule employs the same machinery as the AP P rule for \nthe potential introduction of type errors and partially correct types. In particular, the condition e1 \nis not strictly required to have the type Bool. However, only the variants that are equivalent to Bool \nare type correct. Likewise, only the variants in which both branches are equivalent are type correct. \n . . .' . . .' .t: D(f) = t . . .' \u00ac.t: D(f) = t \u00d8. \u00d8 .,(l,D(f)) . .' .,(l,D(f)) . .' , (l,D(f)) l J \n: f \u00d7 s . f ltJs = t lf1 . f2Js = lf1Js . lf2Js l.Js = . lB(f)JA.i = B(lfJA.i) if A = B lB(f)JB.i = lfiJB.i \nFigure 5: Simpli.cations and selection  4.3 Properties In this section we investigate some important \nproperties of the type-change inference system. We show that it is consistent in the sense that any type \nselected from the result variational type can be obtained by applying the changes as indicated by that \nselection. We also show that the type-change inference is complete in .nding all corrective atomic type \nchanges. Based on this result we also show that the type-change inference system is a conservative extension \nof the Hindley-Milner type system (HM). We start with the observation that type-change inference always \nsucceeds in deriving a type for any given expression and type environment. LEMM A 1. Given e and G, there \nexist f and . such that G f e : f|.. The proof of this lemma is obvious because for any construct in \nthe language, even for unbound variables, there is a corresponding typing rule in Figure 4 that is applicable \nand returns a type. Next, we need to simplify . in the judgment G f e : f|. to investigate the properties \nof the type system. Speci.cally, we de.ne a simpli.cation relation . in Figure 5 that eliminates idempotent \nchoices from .. Note that the sole purpose of simpli.cation is to eliminate choice types that are equivalent \nto monotypes, or equivalently, remove all positions that don t contribute to type errors. Thus, there \nis no need to simplify types nested in choice D in Figure 5. Also, we formally de.ne the selection operation \nlfJs in Figure 5. Selection extends naturally to lists of selectors in the following way: lfJs ' s = \nllfJs ' Js. Next we want to establish the correctness of the inferred type changes. Formally, a type \nupdate is a mapping from program loca\u00adtions to monotypes. The intended meaning of one particular type \nupdate l . t is to change the expression at l to an expression of type t. We use d to range over type \nupdates. A type update is given by the locations and the second component of the corresponding choice \ntypes in the choice environment. We use .\u00b7 to extract that mapping from .. The de.nition is .. = {l . \nt2 | (l,D(t1,t2)) . .}. (For the time being we assume that all the alternatives of choic\u00ades in . are \nmonotypes; we will lift this restriction later.) For exam\u00adple, with . = {(l,A(Int, Bool))} we have .. \n= {l . Bool}. The application of a type update is part of a type update sys\u00adtem that is de.ned by the \nset of typing rules shown in Figure 6. These typing rules are identical to an ordinary Hindley-Milner \ntype system, except that they allow to override the types of atomic ex\u00adpressions according to a type \nupdate d that is a parameter for the rules. We only show the rules for constants, variables, and applica\u00adtions \nsince those for abstractions and let-expressions are obtained from the HM ones in the same way as the \napplication rule by sim\u00adply adding the d parameter. We write more shortly d(e) for d(e(e)), and we use \nthe orelse notation d(e)||t to pick the type d(e) if d(e) is de.ned and t otherwise. CO N -C c is of \ntype . G;d f c : d(c)||. VA R -C G;d f x : d(x)||{a . t}(G(x)) AP P -C G;d f e1 : t1 . t G;d f e2 : \nt1 G;d f e1 e2 : t Figure 6: Rules for the type-update system The rules CO N -C and VA R -C employ a \ntype update if it exist\u00ad s. Otherwise, the usual typing rules apply. Rule AP P -C delegates the application \nof change updates to subexpressions since we are considering atomic change suggestions only. We can now \nshow that by applying any of the inferred type changes (using the rules in Figure 6), we obtain the same \ntype\u00ads that are encoded in the variational type potential computed by type-change inference. We employ \nthe following additional nota\u00adtion. We write ..2 for the list of selectors D.2 for each choice D() in \n.. For example, {(e1,A(Int,Bool)),(e2, B(Bool,Int))}.2 = [A.2,B.2]. Formally, we have the following result. \n(We assume that . has been simpli.ed by . in Figure 5 and the alternatives of choic\u00ades in . are plain, \nas mentioned before.) TH E O R E M 1 (Type-change inference is consistent). For any given e and G, if \nG f e : f|. and there is some t such that lfJ..2 = t, then G;.. f e : t. Moreover, the type-change inference \nis complete since it can gen\u00aderate a set of type changes for any desired type. TH E O R E M 2 (Type-change \ninference is complete). For any e, G and d, if G; d f e : t, then there exist f, ., and a typing derivation \nfor G f e : f|. such that .. = d and lfJ..2 = t. The proofs for these two theorems can be constructed \nthrough an induction over the typing derivations of both type systems. In particular, note that constants \nand variable reference have the same type in these two systems, regardless of whether or not they are \nchanged. The introduction of arbitrary alternative types in rules CO N, VA R, and UN B O U N D are the \nreason that type-change inference is highly non-deterministic, that is, for any expression e we can gen\u00aderate \nan arbitrary number of type derivations with different type potentials and corresponding type changes. \nMany of those derivations don t make much sense. For example, we can derive G f 5 : A(Int,Bool)|. where \n. = {(e5 (5), A(Int,Bool))}. However, since the expression 5 is type correct, it doesn t make sense to \nsuggest a change for it. On the other hand, the ill-typed expression e = not (succ 5) can be typed in \ntwo different ways that can correct the error, yield\u00ading two different type potentials and type changes. \nWe can either suggest to change succ to an expression of type Int . Bool, or we can suggest to change \nnot into something of type Int . a1. The .rst suggestion is obtained by a derivation for G f e : A(.,a1)|.1 \nwith .1 = {(ee(not),A(Bool . Bool,Int . a1))}. The second suggestion is obtained by a derivation for \nG f e : B(., Bool)|.2 with .2 = {(ee(succ),B(Int . Int,Int . Bool))}. Interestingly, we can combine both \nsuggestions by deriving a more general typing statement, that is, we can derive the judgment G f e : \nA(B(.,Bool),B(a1,a2))|.3 where .3 = {(ee(not),A(Bool . Bool,B(Int . a1,a3 . a2))), (ee(succ),B(Int . \nInt,A(Int . Bool, Int . a3)))}  We can show that the third typing is better than the .rst two in the \nsense that its result type (a) contains fewer type errors than either of the result types and (b) is \nmore general. For example, by selecting [A.1,B.2] from both result types, we obtain . and Bool, respectively. \nMaking the same selection into the third result type, we obtain Bool. Likewise, when we select with [A.2, \nB.1], we get the types a1, ., and a1, respectively. For each selection, the third result type is better \nthan either one of the .rst two. In the following we show that this is not an accident, but that we can, \nin fact, always .nd a most general change suggestion from which all other suggestions can be instantiated. \nFirst, we extend the function . to take as an additional parameter a list of selectors s. We also extend \nthe de.nition to work with general variational types (and not just monotypes). .s. = {l . lf2Js | (l,D(f1,f2)) \n. . . D.2 . s} Intuitively, we consider all the locations for which the second alternative of the corresponding \nchoices are chosen. We need to apply the selection lf2Js because each variational type may include other \nchoice types that are subject to selection by s. Next we will show that type-change inference produces \nmost general type changes from which any individual type change can be instantiated. We observe that \ntype potentials and type changes can be compared in principally two different ways. First, the result \nof type-change inference f|. can be more de.ned than another result f' |.', which means that for any \ns for which lf' Js yields a monotype then so does lfJs. Second, a result f|. can be more general than \nanother result f' |.', written as f = f', if there is some type substitution . such that f' = .(f). (Similarly, \nwe call a type update d1 more general than another type update d2, written as d1 = d2, if dom(d1) = dom(d2) \nand there is some . such that for all l d2(l) = .(d1(l)). Since we have these two different relationships \nbetween type changes, we have to show the generality of type-change inference in several steps. First, \nwe show that we can generalize any type change that pro\u00adduces a type error in the resulting variational \ntype for a particular selection when there is another type change that does not produce a type error \nfor the same selection. LEMM A 2 (Most de.ned type changes). Given e and G and two typings G f e : f1|.1 \nand G f e : f2|.2, if lf1Js = . and lf2Js = t, then there is a typing G f e : f3|.3 such that ' lf3Js \n= lf2Js and for all other s lf3Js ' = lf1Js ' . ' .s.3 = .s.2 and .s ' .3 = .s ' .2 for all other s \n. Next we show that given any two type changes, we can always .nd a type change that generalizes the \ntwo. LEMM A 3 (Generalizability of type changes). For any two typ\u00adings G f e : f1|.1 and G f e : f2|.2, \nif neither lf1Js = lf2Js nor lf2Js = lf1Js holds, there is a typing G f e : f3|.3 such that ' lf3Js = \nlf1Js, lf3Js = lf2Js and for all other s , lf3Js ' = lf1Js ' . ' .s.3 = .s.1, .s.3 = .s.2 and for all \nother s , .s ' .3 = .s ' .1. We can now combine and generalize Lemmas 2 and 3 and see that type-change \ninference can always produce maximally error-free and general results at the same time. This is an important \nresult, captured in the following theorem. TH EO R E M 3 (Most general and error-free type changes). \nGiven e and G and two typings G f e : f1|.1 and G f e : f2|.2, there is a typing G f e : f3|.3 such that \nfor any s, if lf1Js = . and lf2Js = t, then lf3Js = t and .s.3 = .s.2. if lf2Js = . and lf1Js = t, then \nlf3Js = t and .s.3 = .s.1.  if lf1Js = t1 and lf2Js = t2, then lf3Js = t1 and lf3Js = t2. Moreover, \n.s.3 = .s.1 and .s.3 = .s.2.  The proofs for Lemma 2, Lemma 3 and Theorem 3 can be estab\u00adlished by \nshowing that in each derivation step, the result types from two derivations can always be combined into \nthe result type for a third derivation such that the new result type is both more general and contains \nfewer errors. The key ingredient we need is that given a variational type, we can change the type for \na speci.c variant and leave all other variants unchanged. From Theorems 3 and 2 it follows that there \nis a typing for com\u00adplete and principal type changes. We express this in the following theorem. TH E \nO R E M 4 (Complete and principal type changes). Given e and G, there is a typing G f e : f|. such that \nfor any d if G;d f e : t, then there is some s such that lfJs = t and .s. = d. Finally, there is a close \nrelationship between type-change inference and the HM type system. When type-change inference succeeds \nwith an empty set of type changes, it produces a non-variational type that is identical to the one derived \nby HM. This result is captured in the following theorem, where we write G f e : t to express that expression \ne has the type t under G in the HM type system. TH E O R E M 5. For any given e and G, G;\u00d8f e : t .. \nG f e : t. Based on Theorem 1, Theorem 2, Theorem 5 and the fact that .\u00d8= \u00d8, we can infer that when a \nprogram is well typed, the type change-inference system and the HM system produce the same result. TH \nE O R E M 6. G f e : t|\u00d8if and only if G f e : t. Note that G f e : t|\u00d8implies that G f e : f|., f = \nt, and . . \u00d8. This theorem also implies that type-change inference will never assign a monotype to a \ntype-incorrect program. 5. A Change Inference Algorithm This section presents an algorithm for inferring \ntype changes. We will discuss properties of the algorithm as well as strategies to bound its complexity. \nGiven the partial type uni.cation algorithm presented in [4], the inference algorithm is obtained by \na straightforward translation of the typing rules presented in Figure 4. The cases for variable reference \nand if statements are shown below. Function application is very similar to if statements, and the cases \nfor abstractions and let-expressions can be derived from W by simply adding the threading of .. infer \n: G \u00d7 e . . \u00d7 f \u00d7 . infer(G, x) = f' . inst(G(x)) returns . when x is unbound f . D(f' ,a) D and a \nare fresh return (\u00d8,f,{(e(x),f)}) infer(G, if e1 then e2 else e3) = (.1,f1,.1) . infer(G,e1) (.' ,p' \n) . vunify(f1,Bool) (.2,f2,.2) . infer(.'.1(G),e2) (.3,f3,.3) . infer(.2.'.1(G), e3) (.4,p4) . vunify(.3(f2),f3,) \n. . .4.3.2.'.1 return (.,p' <(p4 <.4(f3)),.(.1 . .2 . .3))  For variable reference, the algorithm .rst \ntries to .nd the type of the variable in G and either instantiates the found type schema with fresh type \nvariables or returns . if the variable is unbound. After that, a fresh choice containing a fresh type \nvariable is returned. The variable then has the returned choice type with the inferred type in the .rst \nalternative and the type variable in the second. For typing if statements, we use an algorithm vunify(f1,f2) \nfor partial uni.cation [4]. In addition to a partial uni.er a typing pattern is generated to describe \nwhich variants are uni.ed successfully and which aren t (see Section 3). Otherwise, the algorithm follows \nin a straightforward way the usual strategy for type inference. We can prove that the algorithm infer \ncorrectly implements the typing rules in Figure 4, as expressed in the following theorems. TH EO R E \nM 7 (Type-change inference is sound). Given any e and G, if infer(G,e) = (.,f,.), then .(G) f e : f|.. \nAt the same time, the type inference is complete and principal. We use the auxiliary relation f1 : f2 \nto express that for any s, either lf2Js = . or lf1Js = lf2Js. Intuitively, this expresses that either \nthe corresponding variant in f1 is more general or more correct. We also de.ne .1 : .2 if for any (l, \nf1) . .1 and (l,f2) . .2 the condition f1 = f2 holds. TH EO R E M 8 (Type-change inference is complete \nand principal). If .(G) f e : f|., then infer(G,e) = (.1,f1, .1) such that . = .1.1 for some .1, .1 : \n., and f1 : f. From Theorems 3 and 8 it follows that our type-change inference algorithm correctly computes \nall type changes for a given expres\u00adsion in one single run. During the type-change inference process, \nchoice types can become deeply nested and the size of types can become ex\u00adponential in the nesting levels. \nFortunately, this occurs only with deep nestings of function applications where each argumen\u00adt type is \nrequired to be the same. For example, the function f : a . a . . . . . a is more likely to cause this \nproblem than the functions g : a1 . a2 . . . . . an and h : . . . . . . . . . be\u00adcause only the function \nf requires all argument types to be uni.ed, which causes choice nesting to happen. To keep the run-time \ncomplexity of our inference algorithm un\u00adder control, we eliminate choices beyond an adjustable nesting \nlev\u00adel that satisfy one of the following conditions: (A) choices whose alternatives are uni.able, and \n(B) choices whose alternatives con\u00adtain errors in the same places. These two conditions ensure that the \neliminated choices are unlikely to contribute to type errors. There are cases in which this strategy \nfails to eliminate choices, but this happens only when there are already too many type errors in the \nprogram, and we therefore stop the inference process and report type errors and change suggestions found \nso far. This strategy allows us to maintain choices whose correspond\u00ading locations are likely sources \nof type errors and discard those that aren t. Note, however, that this strategy sacri.ces the completeness \nproperty captured in Theorem 8. We have evaluated the running time and the precision of error diagnosis \nagainst the choice nesting levels (see Section 7). We observed that only in very rare cases will the \nchoice nesting level reach 17, a value that variational typing is able to deal with decently [5]. Finally, \nwe brie.y describe a set of simple heuristics that de.ne the ranking of type and expression changes. \n(1) We prefer places that have deduced expression changes (see Section 6) because these changes re.ect \ncommon editing mistakes [18]. (2) We favor changes that are lower in the abstract syntax trees because \nchanges at those places have least effect on the context and are least likely to introduce exotic results. \n(3) We prefer changes that have minimal shape difference between the inferred type and the expected type. \nFor example, a change that doesn t in.uence the arities of function types is ranked higher than a change \nthat does change arities. 6. Deducing Expression Changes While it is generally impossible to deduce \nexpression changes from type changes, there are several idiosyncratic situations in which type changes \ndo point to likely expression changes. These situations can be identi.ed by unifying both types of a \ntype change where the uni.cation is performed modulo a set of axioms that represent the pattern inherent \nin the expression change. As an example, consider the following expression.11 zipWith (\\(x,y) -> x+y) \n[1,2] [3,4] Our type change inference suggests to change zipWith from its o\u00adriginal type (a -> b -> \nc) -> [a] -> [b] -> [c] to something of type ((Int,Int) -> Int) -> [Int] -> [Int] -> d. Given these two \ntypes, we can deduce to curry the .rst argument to the function zipWith to remove the type error. (At \nthe same time, we substitute d in the result type with Int.) By employing uni.cation modulo different \ntheories, M\u00adcAdam [21] has developed a theory and an algorithm to system\u00adatically deduce changes of this \nsort. We have adopted this approach (and extended it slightly) for deducing expression changes, such \nas swapping the arguments of function calls, currying and uncurrying of functions, or adding and removing \narguments of function calls. The extension is based on a simple form of identifying non\u00adarity-preserving \ntype changes. Such a change is used to modify the types, then McAdam s approach is applied, and the result \nis then interpreted in light of the non-arity-preserving type change as a new form of expression change. \nAs an example, here is the method of identifying the addition or removal of arguments to function calls. \nIn this case, the differences in the two types to be uni.ed will lead to a second-level type change that \npads one of the types with an extra type variable. For example, given the inferred type t1 . t3 and the \nexpected type t1 . t2 . t3, we turn the .rst type into a . t1 . t3. The application of McAdam s approach \nsuggests to swap the arguments. Also, a is mapped to t2. Interpreting the swapping suggestion through \nthe second-level type change of padding, we deduce the removal of the second argument. Besides these \nsystematic change deductions, we also support some ad-hoc expression changes. Speci.cally, we infer changes \nby inspecting the expected type only. For example, if the inferred type for f in f g e is b -> c while \nthe expected type is (a -> b) -> a -> c, we suggest to change f g e to f (g e). Another example are situations \nin which the result type of an expected type matches exactly one of its (several) argument types. In \nthat case we suggest to replace the whole expression with the corresponding argument. This case applies, \nin fact, to the palin example, where the type change for (:) is to replace a -> [a] -> [a] by a -> [b] \n-> a. We therefore infer to replace (:) z [], which is [z], by z because the .rst argument type is the \nsame as the return type. Another case is when in expression f g h the expected type for f is (a -> b) \n-> a -> b. Then we suggest to remove f from the expression. There are more such ad-hoc changes that are \nuseful in some situations, but we will not discuss them here. In Section 8 we will compare our method \nwith McAdam s original. Here we only note that the success of the method in our prototype depends to \na large degree on the additional information provided by type-change inference, speci.cally, the more \nprecise and less biased expected types that are used for the uni.cation. 7. Evaluation To evaluate the \nusefulness and ef.ciency of the counter-factual typing approach, we have implemented a prototype of type-change \ninference and expression-change deduction in Haskell. (In addition 11 This example is adapted from [18], \nwhere zipWith is called map2. 86 examples with Oracle 35 ambiguous examples 1 2 3 = 4 never complete \npartial incorrect CF typing 67.4 80.2 88.4 91.9 8.1 100.0 0.0 0.0 Seminal 47.7 54.7 58.1 59.3 40.7 40.0 \n25.7 34.3 Helium 61.6 --61.6 38.4 0.0 100.0 0.0 GHC 17.4 --17.4 82.6 0.0 34.3 65.7 Figure 7: Evaluation \nresults for different approaches over 121 col\u00adlected examples (in %). to the constructs shown in Section \n4 the prototype also supports some minor, straightforward extensions, such as data types and case expressions.) \nWe compare the results produced by our CF typing tool to Seminal [18, 19], Helium [13, 14], and GHC. \nThere are several reasons for selecting this group of tools. First, they provide currently running implementations. \nSecond, these tools provide a similar functionality as CF typing, namely, locating type errors and presenting \nchange suggestions, both at the type and the expression level. We have deliberately excluded slicing \ntools from the comparison because they only show all possible locations, and don t suggest changes.12 \nFor evaluating the applicability and accuracy of the tools we have gathered a collection of 121 examples \nfrom 22 publications about type-error diagnosis. These papers include recent Ph.D. the\u00adses [14, 21, 27, \n29] and papers that represent most recent and older work [15, 18, 23]. These papers cover many different \nperspectives of the type-error debugging problem, including error slicing, expla\u00adnation systems, reordering \nof uni.cation, automatic repairing, and interactive debugging. Since the examples presented in each pa\u00adper \nhave been carefully chosen or designed to illustrate important problem cases for type-error debugging, \nwe have included them all, except for examples that involve type classes since our tool (as well as Seminal) \ndoesn t currently support type classes. This exclusion did not have a signi.cant effect. We gathered \n8 unique examples regarding type classes involved in type errors discussed in [24, 24, 27]. Both GHC \nand Helium were able to produce a help\u00adful error message in only 1 case. Otherwise, the examples range \nfrom very simple, such as test = map [1,10] even to very com\u00adplex ones, such as the plot example introduced \nin [27]. We have grouped the examples into two categories. The .rst group ( with Oracle ) contains 86 \nexamples for which the correct version is known (because it either is mentioned in the paper or is obvious \nfrom the context). The other group ( ambiguous ) contains the remaining 35 examples that can be reasonably \n.xed by several different single-location changes. For the examples in the with Oracle group, we have \nrecorded how many correct suggestions each tool can .nd with at most n attempts. For the examples in \nthe ambiguous group, we have determined how often a tool produces a complete, partial, or incorrect set \nof suggestions. For example, for the expression \\f g a -> (f a, f 1, g a, g True), which is given in \n[2], Helium suggests to change True to something of type Int. While this is correct, there are also other \nchanges possible, for example, changing f 1 to f True. Since these are not mentioned, the result is categorized \nas partial. Figure 7 presents the results for the different tools and examples with unconstrained choice \nnesting level for CF typing. Note that GHC s output is considered correct only when it points to the \ncorrect location and produces an error message that is not simply reporting a uni.cation failure or some \nother compiler-centric point 12 There are a few interactive approaches that have been proposed [6, 24], \nbut they do currently not provide running implementations. Moreover, Chameleon [27] has evolved to focus \non typing extensions of the Haskell type system. Since the tool has switched off its type-debugging facilities, \nit is not a viable candidate for comparison. Figure 8: Running time for typing x% of the examples 10 \ntimes. of view. We have included GHC only as a baseline since it is widely known. The comparison of \neffectiveness is meant to be between CF typing, Seminal, and Helium. The numbers show that CF typing \nperforms overall best. Even if we only consider the .rst change suggestion, it outperforms Helium which \ncomes in second. Taking into account second and third suggestions, Seminal catches up, but CF typing \nperforms even better. In cases where Helium produces multiple suggestions, all sug\u00adgestions are wrong. \nFor CF typing 21 out of the 58 correct sugges\u00adtions (that is, 36%) are expression changes. For Seminal \nthe num\u00adbers are 20 out of 41 (or 51%), and for Helium it is 15 out of 52 (or 29%). This shows that Seminal \nproduces a higher rate of expression change suggestions at a lower overall correctness rate. Most of \nHelium and Seminal s failures are due to incorrectly identi.ed change locations. Another main reason \nfor Seminal s incorrect suggestions is that it introduces too extreme changes. In several cases, Seminal \ns change suggestion doesn t .x the type error. Most cases for which CF typing fails are caused by missing \nparentheses. For example, for the expression print \"a\" ++ \"b\" [18], our approach suggests to change print \nfrom the inferred type a -> IO () to the type String -> String or change (++) from the expected type \n[a] -> [a] -> [a] to the inferred type IO () -> String -> String. Neither of the suggestions allows us \nto deduce the regrouping of the expression. To summarize, since the examples that we used have been de\u00adsigned \nto test very speci.c cases, the numbers do not tell much about how the systems would perform in everyday \npractice. They provide more like a stress test for the tools, but the direct compari\u00adson shows that CF \ntyping performs very well compared with other tools and thus presents a viable alternative to type debugging. \nWith the help of variational typing, we can generate all the potential changes very ef.ciently. The running \ntime for all the collected examples is within 2 seconds. Figure 8 shows the running time for both our \napproach and Seminal for processing the reported examples. For each point (x,y) on the curve, it means \nthat x% of all examples are processed with y seconds. The running time for our approach is measured on \na laptop with a 2.8GHz dual core processor and 3GB RAM running Windows XP and GHC 7.0.2. The running \ntime for Seminal is measured on the same machine with Cygwin 5.1. The purpose of the graph is simply \nto demonstrate the feasibility of our approach. Second, we have evaluated how increasing levels of choice \nnest\u00adings affect the ef.ciency of the inference algorithm and how putting a limit on maximum nesting \nlevels as described in Section 5 can re\u00adgain ef.ciency at the cost of precision. For this purpose, we \nhave automatically generated large examples, and we use functions of types like a . a . . . . . a to \ntrigger the choice elimination s\u00adFigure 9: Limits on choice nesting trade ef.ciency for precision.  \ntrategies discussed in Section 5. We .rst generated 200 type correct examples and then introduced one \nor two type errors in each exam\u00adple by changing the leaves, swapping arguments and so on. Each example \ncontains about 60000 nodes in its tree representation. Figure 9 presents the running time and precision \nagainst choice nesting levels for these generated examples. A change suggestion is considered correct \nif it .xes a type error and appears among the .rst four changes for that example. Precision is measured \nby divid\u00ading the number of examples that have correct change suggestions over the number of all examples. \nFrom the .gure we observe that a nesting level cut-off between 12 and 18 achieves both high preci\u00adsion \nand ef.ciency. 8. Related Work We have grouped our discussion of related work according to major features \nshared by the different approaches. Reporting single locations Most of the single-error-location ap\u00adproaches \nare based on some variant of the algorithm W and report an error as soon as the algorithm fails. Since \nthe original algorithm W is biased in the order in which uni.cation problems are solved (which has a \nnegative impact on locating errors), many approaches have tried to eliminate this bias. Examples are \nalgorithms M [17], G [10], W SYM and M SYM [20], and UAE and I E I [30]. All these algorithms interpret \nthe place of uni.cation failure as the source of the type error. In contrast, Johnson and Walz [15] and \nthe Helium tool [13, 14] use heuristics to select the most likely error location from a set of potential \nplaces. Although heuristics often work well and lead to more accurate locations, they can still get confused \ndue to the single-location constraint. In contrast, we explore all poten\u00adtial changes and rank them from \nmost to least likely. In deducing expression changes from type changes, we have used (an extension of) \nMcAdam s technique [21]. Since his ap\u00adproach is based on the algorithm W , it suffers from the bias of \nerror locating mentioned above. Moreover, his approach doesn t have ac\u00adcess to the precise expected type, \nwhich helps in our approach to ensure that deduced expression changes will not have an impact on the \nprogram as a whole. Explaining type con.icts Some approaches have focused on i\u00addentifying and explaining \nthe causes of type con.icts. Wand [26] records each uni.cation step so that they can be tracked back \nto the failure point. Duggan and Bent [9] on the other hand record the reason for each uni.cation that \nis being performed. Beaven and S\u00adtansifer [1] and Yang [28] produce textual explanation for the cause \nof the type errors. While these techniques can be useful in many cases, there are also potential downsides. \nFirst, the explanation can become quite verbose and repetitive, and the size grows rapidly as the program \nsize increases. Second, the explanation is inherently coupled to the underlying algorithm that performs \nthe inference. Thus, knowledge about how the algorithms work is often needed to understand the produced \nmessages. Third, the explanations usually lead to the failure point, which is often the result of biased \nuni.cation and not the true cause of the type error. Finally, although a potential .x for the type error \nmay lurk in the middle of the explanation chain, it s not always clear about how to exploit it and change \nthe program. Interactive debugging While many tools attempt to improve the static presentation of type \nerror information, interactive approaches give users a better understanding about the type error or why \ncertain types have been inferred for certain expressions. Consequently, sev\u00aderal approaches to interactive \ntype debugging have been pursued. The ability to infer types for unbound variables enable a type debugging \nparadigm that is based on the idea of replacing a suspi\u00adcious program snippet by a fresh variable [2]. \nIf such replacement leads to a type correct program, then the error location has been identi.ed. However, \nthe original system proposed by Berstein and Stark requires users to do these steps manually. Later, \nBra\u00dfel [3] automated this process by systematically commenting out parts of the program and running the \ntype checker iteratively. Since type changing is based on uni.cation, it can again introduce the bias \nproblem. Also, it is unclear how to handle programs that contain more than one type error. Through employing \na number of different techniques, Chitil [6], Neubauer and Thiemann [22], and Stuckey [24, 27] have developed \ntools that allow users to explore a program and inspect the types for any subexpression. Chameleon [24, \n27] also allows users to query how the types for speci.c expressions are inferred. All these approaches \nprovide a mechanism for users to explore a program and view the type information. However, none of them \nprovides direct support for .nding or .xing type errors. Error slicing The main advantage of slicing \napproaches [12, 23, 25] is that they return all locations related to type errors. The down\u00adside is that \nthey cover too many locations. Recent improvements in Chameleon [27] have helped to reduce the number \nof locations, but the problem still persists (recall the example in the Introduction). Moreover, slicing \ntools do not provide suggestions of how to get rid of the type error. Like error slicing approaches, \nour CF typing approach is com\u00adplete in not missing any potential change. However, the changes we presented \nto users involve fewer locations. Usually, users have to focus on only one location and its suggestions \nfor type changes. Embracing type uncertainty Similar to choice types, sum types can also encode many \ntypes. Neubauer and Thiemann [22] devel\u00adoped a type system based on discriminative sum types to record \nthe causes of type errors. Speci.cally, they place two non-uni.able types into a sum type. Technically, \nnamed choice types provide more .ne-grained control over variations in types than discrimina\u00adtive sum \ntypes. While sum types are uni.ed component-wise, this is only the case for choice types of the same \nname. Each alternative in a choice type is uni.ed with all the alternatives in other choic\u00ades with different \nnames. Also, their system returns a set of sources related to type errors. Thus, it can be viewed as \nan error slicing approach. However, compared to other slicing approaches, it is not guaranteed that the \nreturned set of locations is minimal. Moreover, the approach doesn t provide speci.c change locations \nor change suggestions. Typing by searching CF typing and Seminal [18, 19] could both be called search \nbased , although the search happens at different levels. While CF typing explores changes on the type \nlevel, Seminal works on the expression level directly, which makes it impossible for Seminal to generate \na complete set of type-change suggestions. Given an ill-typed program, Seminal .rst has to decide where \nthe type error is. Seminal uses a binary search to locate the erroneous place. This way of searching \ncauses Seminal to make mistakes in locating errors when the .rst part of the program itself doesn t contain \na type error but actually triggers type errors because it s too constrained. For example, the cause of \nthe type error in the palin example discussed in Section 1 is the fold function, which is itself well \ntyped. As a result, Seminal fails to .nd a correct suggestion. Once the problematic expression is found, \nSeminal searches for a type-corrected program by creating mutations of the original pro\u00adgram. For example, \nby swapping the arguments to functions, cur\u00adrying or uncurrying function calls, and so on. Compared to \nour change deduction approach, this has both advantages and disad\u00advantages. In some cases, it can .nd \na correct change while our ap\u00adproach fails to do so, as, for example, in the missing-parentheses problem \ndiscussed in Section 7. On the other hand, its power to generate arbitrarily complicated changes can \nlead to bizarre sug\u00adgestions, such as the suggestion to change xs == (rev xs) to (==) (xs,(rev xs)). \n9. Conclusions We have presented a new method for debugging type errors. The approach is based on the \nnotion of counter-factual typing, which is the idea of systematically varying the types of all atomic \nprogram elements to generate a typing potential for the erroneous program that can be explored and reasoned \nabout. We have exploited this typing potential and the associated set of type changes to create a ranked \nlist of type-change and expression-change suggestions that can eliminate type errors from programs. A \ncomparison of a pro\u00adtotype implementation with other tools has demonstrated that the approach works very \nwell and, in fact, outperforms its competitors. In future work, we plan to investigate other uses of \ntyping po\u00adtentials and type changes. For example, the integrated choice-based representation provides \nopportunities for de.ning type queries that can be used to examine programs and also form the basis for \nsophis\u00adticated user interfaces to support more interactive forms of type de\u00adbugging. We also plan to \ninvestigate how well the approach works for the debugging of type errors in richer type systems. References \n[1] M. Beaven and R. Stansifer. Explaining type errors in polymorphic languages. ACM Letters on Programming \nLanguages and Systems, 2:17 30, 1994. [2] K. L. Bernstein and E. W. Stark. Debugging type errors. Technical \nreport, State University of New York at Stony Brook, 1995. [3] B. Bra\u00dfel. Typehope: There is hope for \nyour type errors. In Int. Workshop on Implementation of Functional Languages, 2004. [4] S. Chen, M. Erwig, \nand E. Walkingshaw. An Error-Tolerant Type System for Variational Lambda Calculus. In ACM Int. Conf. \non Functional Programming, pages 29 40, 2012. [5] S. Chen, M. Erwig, and E. Walkingshaw. Extending Type \nInference to Variational Programs. ACM Trans. on Programming Languages and Systems, 2013. To appear. \n[6] O. Chitil. Compositional explanation of types and algorithmic debug\u00adging of type errors. In ACM Int. \nConf. on Functional Programming, pages 193 204, September 2001. [7] V. Choppella. Uni.cation Source-Tracking \nwith Application To Diag\u00adnosis of Type Inference. PhD thesis, Indiana University, 2002. [8] L. Damas \nand R. Milner. Principal type-schemes for functional pro\u00adgrams. In ACM Symp. on Principles of Programming \nLanguages, pages 207 212, 1982. [9] D. Duggan and F. Bent. Explaining type inference. In Science of Computer \nProgramming, pages 37 83, 1995. [10] H. Eo, O. Lee, and K. Yi. Proofs of a set of hybrid let-polymorphic \ntype inference algorithms. New Generation Computing, 22(1):1 36, 2004. [11] M. Erwig and E. Walkingshaw. \nThe Choice Calculus: A Representa\u00adtion for Software Variation. ACM Trans. on Software Engineering and \nMethodology, 21(1):6:1 6:27, 2011. [12] C. Haack and J. B. Wells. Type error slicing in implicitly typed \nhigher\u00adorder languages. In European Symposium on Programming, pages 284 301, 2003. [13] B. Heeren, D. \nLeijen, and A. van IJzendoorn. Helium, for learning haskell. In Proceedings of the 2003 ACM SIGPLAN workshop \non Haskell, Haskell 03, pages 62 71, New York, NY, USA, 2003. ACM. [14] B. J. Heeren. Top Quality Type \nError Messages. PhD thesis, Univer\u00adsiteit Utrecht, The Netherlands, Sept. 2005. [15] G. F. Johnson and \nJ. A. Walz. A maximum-.ow approach to anomaly isolation in uni.cation-based incremental type inference. \nIn ACM Symp. on Principles of Programming Languages, pages 44 57, 1986. [16] O. Lee and K. Yi. Proofs \nabout a folklore let-polymorphic type inference algorithm. ACM Trans. on Programming Languages and Systems, \n20(4):707 723, July 1998. [17] O. Lee and K. Yi. A generalized let-polymorphic type inference algorithm. \nTechnical report, Technical Memorandum ROPAS-2000\u00ad5, Research on Program Analysis System, Korea Advanced \nInstitute of Science and Technology, 2000. [18] B. Lerner, M. Flower, D. Grossman, and C. Chambers. Searching \nfor type-error messages. In ACM Int. Conf. on Programming Language Design and Implementation, pages 425 \n434, 2007. [19] B. Lerner, D. Grossman, and C. Chambers. Seminal: searching for ml type-error messages. \nIn Workshop on ML, pages 63 73, 2006. [20] B. J. McAdam. Repairing type errors in functional programs. \nPhD thesis, University of Edinburgh. College of Science and Engineering. School of Informatics., 2002. \n[21] B. J. McAdam. Reporting Type Errors in Functional Programs. PhD thesis, Larboratory for Foundations \nof Computer Science, The University of Edinburgh, 2002. [22] M. Neubauer and P. Thiemann. Discriminative \nsum types locate the source of type errors. In ACM Int. Conf. on Functional Programming, pages 15 26, \n2003. [23] T. Schilling. Constraint-free type error slicing. In Trends in Functional Programming, pages \n1 16. Springer, 2012. [24] P. J. Stuckey, M. Sulzmann, and J. Wazny. Interactive type debugging in haskell. \nIn ACM SIGPLAN Workshop on Haskell, pages 72 83, 2003. [25] F. Tip and T. B. Dinesh. A slicing-based \napproach for locating type er\u00adrors. ACM Trans. on Software Engineering and Methodology, 10(1):5 55, Jan. \n2001. [26] M. Wand. Finding the source of type errors. In ACM Symp. on Principles of Programming Languages, \npages 38 43, 1986. [27] J. R. Wazny. Type inference and type error diagnosis for Hind\u00adley/Milner with \nextensions. PhD thesis, The University of Melbourne, January 2006. [28] J. Yang. Explaining type errors \nby .nding the source of a type con.ict. In Trends in Functional Programming, pages 58 66. Intellect Books, \n2000. [29] J. Yang. Improving Polymorphic Type Explanations. PhD thesis, Heriot-Watt University, May \n2001. [30] J. Yang, G. Michaelson, P. Trinder, and J. B. Wells. Improved type error reporting. In Int. \nWorkshop on Implementation of Functional Languages, pages 71 86, 2000.  \n\t\t\t", "proc_id": "2535838", "abstract": "<p>Changing a program in response to a type error plays an important part in modern software development. However, the generation of good type error messages remains a problem for highly expressive type systems. Existing approaches often suffer from a lack of precision in locating errors and proposing remedies. Specifically, they either fail to locate the source of the type error consistently, or they report too many potential error locations. Moreover, the change suggestions offered are often incorrect. This makes the debugging process tedious and ineffective.</p> <p>We present an approach to the problem of type debugging that is based on generating and filtering a comprehensive set of type-change suggestions. Specifically, we generate all (program-structure-preserving) type changes that can possibly fix the type error. These suggestions will be ranked and presented to the programmer in an iterative fashion. In some cases we also produce suggestions to change the program. In most situations, this strategy delivers the correct change suggestions quickly, and at the same time never misses any rare suggestions. The computation of the potentially huge set of type-change suggestions is efficient since it is based on a variational type inference algorithm that type checks a program with variations only once, efficiently reusing type information for shared parts.</p> <p>We have evaluated our method and compared it with previous approaches. Based on a large set of examples drawn from the literature, we have found that our method outperforms other approaches and provides a viable alternative.</p>", "authors": [{"name": "Sheng Chen", "author_profile_id": "81548019885", "affiliation": "Oregon State University, Corvallis, OR, USA", "person_id": "P4383907", "email_address": "chensh@eecs.oregonstate.edu", "orcid_id": ""}, {"name": "Martin Erwig", "author_profile_id": "81100586223", "affiliation": "Oregon State University, Corvallis, OR, USA", "person_id": "P4383908", "email_address": "erwig@eecs.oregonstate.edu", "orcid_id": ""}], "doi_number": "10.1145/2535838.2535863", "year": "2014", "article_id": "2535863", "conference": "POPL", "title": "Counter-factual typing for debugging type errors", "url": "http://dl.acm.org/citation.cfm?id=2535863"}