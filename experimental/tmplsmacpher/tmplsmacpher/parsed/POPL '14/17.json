{"article_publication_date": "01-08-2014", "fulltext": "\n Bridging Boolean and Quantitative Synthesis Using Smoothed Proof Search * Swarat Chaudhuri Martin Clochard \nArmando Solar-Lezama Rice University ENS Paris &#38; MIT swarat&#38;#169;rice.edu Universit\u00e9 Paris-Sud \n(LRI &#38; Inria Saclay) asolar&#38;#169;csail.mit.edu martin.clochard&#38;#169;lri.fr Abstract We present \na new technique for parameter synthesis under boolean and quantitative objectives. The input to the technique \nis a sketch a program with missing numerical parameters and a proba\u00adbilistic assumption about the program \ns inputs. The goal is to au\u00adtomatically synthesize values for the parameters such that the re\u00adsulting \nprogram satis.es: (1) a boolean speci.cation, which states that the program must meet certain assertions, \nand (2) a quantitative speci.cation, which assigns a real valued rating to every program and which the \nsynthesizer is expected to optimize. Our method called smoothed proof search reduces this task to a \nsequence of unconstrained smooth optimization problems that are then solved numerically. By iteratively \nsolving these prob\u00adlems, we obtain parameter values that get closer and closer to meet\u00ading the boolean \nspeci.cation; at the limit, we obtain values that provably meet the speci.cation. The approximations \nare computed using a new notion of smoothing for program abstractions, where an abstract transformer \nis approximated by a function that is con\u00adtinuous according to a metric over abstract states. We present \na prototype implementation of our synthesis proce\u00addure, and experimental results on two benchmarks from \nthe em\u00adbedded control domain. The experiments demonstrate the bene.ts of smoothed proof search over an \napproach that does not meet the boolean and quantitative synthesis goals simultaneously. Categories and \nSubject Descriptors D.2.4 [Software/Program Veri.cation]: Correctness proofs; F.3.2 [Semantics of Program\u00adming \nLanguages]: Program analysis; I.2.2 [Automatic Program\u00adming]: Program synthesis; I.2.3 [Deduction and \nTheorem Prov\u00ading]: Uncertainty, fuzzy, , and probabilistic reasoning Keywords Synthesis; Probabilistic \nVeri.cation; Probabilistic Pro\u00adgrams; Program Smoothing; Abstract Interpretation * The authors are ordered \nalphabetically. This work was supported by NSF Award #1162076. Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. Copyrights for components of this work owned by others than the author(s) \nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. Request permissions from \npermissions@acm.org. POPL 14, January 22 24, 2014, San Diego, CA, USA. Copyright is held by the owner/author(s). \nPublication rights licensed to ACM. ACM 978-1-4503-2544-8/14/01. . . $15.00. http://dx.doi.org/10.1145/2535838.2535859 \n 1. Introduction Traditional reasoning tasks in formal methods are boolean: we are asked to prove that \na program satis.es a set of boolean properties (program veri.cation), or to realize a given logical speci.cation \nin the form of an implementation (program synthesis). However, in many applications, boolean reasoning \nalone is not enough we also need quantitative reasoning. The need for combined boolean and quantitative \nreasoning is especially prominent in program synthesis. Here, a boolean speci\u00ad.cation is naturally used \nto set a lower bound on the desirability of the synthesized implementation: the program should at least \nmeet the following safety properties. However, there can be many implementations that meet these properties, \nand some of them are more desirable than others. Given this, it is appropriate to con\u00adsider synthesis \ntasks where the synthesized implementation must not only meet a boolean speci.cation, but also be optimal \nwith re\u00adspect to a quantitative objective [3, 6]. A plausible approach to solve such synthesis problems \nis to sep\u00adarately handle the boolean and quantitative goals, for example by searching for candidates \nthat are locally optimal with respect to the quantitative criterion and then attempting to verify them \nagainst the boolean speci.cation. The disadvantage of this approach is that if the search for a function \nthat is good with respect to the quantita\u00adtive objective happens without regards to the subsequent veri.ca\u00adtion \nphase it may take a long time to .nd a solution that can be veri.ed. This suggests that a procedure for \nquantitative synthesis should aim to meet its boolean and quantitative objectives simul\u00adtaneously. The \nbene.ts of such an approach are corroborated by prior work on (boolean) synthesis [28, 34], which combines \nsyn\u00adthesis and veri.cation to make the overall process more tractable. In this paper, we offer such a \ncombined veri.cation and synthe\u00adsis procedure for the problem of synthesizing values for unknown program \nparameters. Speci.cally, we introduce smoothed proof search as a new tech\u00adnique to combine quantitative \nsynthesis and veri.cation. The key idea here is to reduce the synthesis problem to a sequence of un\u00adconstrained \noptimization problems where the objective function for each problem is a continuous approximation of \nthe boolean and quantitative objectives. As the sequence progresses, the approxi\u00admate objective gets \ncloser to the original objective, and in the limit the method .nds parameters that provably meet the \nboolean spec\u00adi.cation. At the same time, the continuity of the approximations lets us optimize them effectively \nusing local numerical techniques, which rely heavily on smoothness assumptions, and do poorly on the \ndiscontinuous functions that programs often represent.  double P (double x) { c := ??; if (x > c) { \ny := x + 1; } else { y := 10; } return y } while satisfying the safety invariant B : (c - 10 = y = c \n+ 10), and a quantitative speci.cation that states that the return value of the procedure should be as \nlow as possible. This is an example of a veri.ed parameter synthesis problem [25, 30, 32, 33]. The pro\u00adgrammer \nhas provided an implementation with missing numerical parameters also known as a sketch [30] and the \nsynthesis problem is to .nd values for these parameters such that the result\u00ading program satis.es the \ncombined Boolean and quantitative spec\u00adi.cation. The problem described above is not yet well de.ned, \nas there are different ways to interpret the optimality requirement. One interpretation is that the programmer \nwishes to minimize the worst\u00adcase behavior of the system; alternatively, Chatterjee et al. [6] have argued \nthat a more natural goal is to optimize the expected value of the output. This is potentially a harder \nproblem, because it requires knowledge of the distribution of its inputs, and it requires an analysis \ncapable of deriving the distribution of the outputs from this input distribution. In this paper, we focus \non this probabilistic view of the problem; speci.cally, we focus on problems where the input, say x, \nis drawn from a given probability distribution \u00b5x, and the quantitative speci.cation is that The expected \nreturn value of P on input x is minimal. Because the analysis is probabilistic, the boolean assertion \ncan also be generalized to a probabilistic one. This new assertion (call it .) is (c - 10 = x = c + 10) \nwith probability greater than or equal to a certain threshold .. Our approach to this problem is a re.nement \nof the follow\u00ading idea. Using existing ideas on probabilistic abstract interpreta\u00adtion [20], we can symbolically \nrepresent the input distribution \u00b5x of x, then compute an approximation PFc(\u00b5x) of the actual distri\u00adbution \nof outputs Pc(x) of the program on input x drawn from the distribution \u00b5x (these outputs depend on c; \nhence the subscript c in Pc). From PF(\u00b5x, c), we can compute a sound upper bound p on the probability \nwith which Pc(x) violates the assertion B and a real interval I such that the expectation of Pc(x) is \nguaranteed to fall within I. Given this mapping from c . (p, I ), our goal is to .nd a value of c that \nleads to low values of p as well as I. We can frame this as a single-objective optimization problem where \nthe goal is to .nd a c that minimizes sup(I) + P enalty(p, .), where sup(I) is the least upper bound \non I, P enalty(p, .) is a penalty function that is zero when p = ., and a large positive value (larger \nthan any upper bound on I) when p is larger than .. Minimizing this function gives us a value of c that \nis desirable according to the quantitative criterion while satisfying the probabilistic assertion .. \nNumerical search techniques like gradient descent or Nelder-Mead search [22] seem like the natural choice \nfor solving this op\u00adtimization problem, because even though they do not provide any guarantees on the \noptimality of the result, they are known to work well in practice when the function to optimize satis.es \ncertain con\u00adtinuity requirements. These techniques cannot be applied directly, though, because the results \nof abstract interpretation are highly dis\u00adcontinuous. To understand the source of the discontinuities, \ncon\u00adsider our example program from before. Let us consider an ab\u00adstract interpretation where, following \nprior work [20], probability distributions are approximated by structures that are essentially his\u00adtograms: \ndisjunctions of pairs (Ei, wi), where each Ei is a set of possible values for a random variable (a bin \nin the histogram), and wi is an upper bound on the measure concentrated in Ei (i.e. the Figure 1. Example \nof probabilistic abstraction probability that the value will fall in that bin). Fig. 1 depicts an ex\u00adample \nabstraction of a continuous distribution by such a structure. Now suppose the abstract state of x, right \nbefore the conditional if (x > c) in our example program, is as in Fig. 1. Note that if c is exactly \n0.5, the probability that x > c will be bounded from below by 0.23, but for any E > 0, making c = 0.5 \n+ E will change the lower bound on the probability to 0.02. This is because the abstract state tells \nus that the probability of falling in the range (0.5, 1.5] is 0.21, but the abstract state has lost the \ninformation about the exact probability of falling between 0.5 and 0.5 + E. This property of the abstract \ndomain makes the function c . (p, I ) highly discontinuous. Our approach overcomes this dif.culty via \na novel notion of smoothing for abstract interpretations. Instead of using the abstract transformer PFc(\u00b5x) \nto generate a target for optimization, we use a series of approximations to the abstract transformer \nthat are con\u00adtinuous in the analytical sense. Because of the continuity of these approximations, numerical \noptimization can be used to compute high-quality minima in objectives generated from them. We de.ne these \napproximations by .rst de.ning smooth analogs of the classic operators of abstract interpretation, such \nas join and widening. The approximations are neither abstractions or re.nements of the sound abstraction \nPFc in fact, they bear no resemblance to operations on abstract interpreters studied in the lit\u00aderature. \nNotably, each of them is an unsound abstraction. While this may sound like a violation of our stated \ngoals, it is not so. Each of our approximations is parameterized by a real value \u00df; in the limit as \u00df \napproaches zero, the approximations converge to PFc. There\u00adfore, by iteratively .nding local minima on \nobjectives generated from approximations parameterized by lower and lower values of \u00df, we can .nd parameters \nthat are satisfy our boolean speci.cation with maximal probability. We call the above strategy for meeting \na combination of boolean and quantitative synthesis goals smoothed proof search. We have implemented \nour algorithm in the form of a tool called FE R M AT, built on top of the SKET C H program synthesizer. \nWe have used FE RM AT to do veri.ed parameter synthesis on two bench\u00admarks from the embedded control \ndomain: a model of a thermostat and a model of an aircraft controller. Our experiments show that smoothing \nsigni.cantly improves the quality of parameters synthe\u00adsized through search, and that searching simultaneously \nwith re\u00adspect to the boolean and quantitative objectives gives better results than applying the two kinds \nof search in sequence. In summary, this paper makes the following contributions: We introduce smoothed \nproof search, a new way to reconcile boolean and quantitative reasoning in program synthesis. The essence \nof the idea is to reduce a combination of proof and opti\u00admization tasks to a sequence of smooth optimization \nproblems.  We present a concrete smoothed proof search algorithm for veri.ed parameter synthesis in \nprograms with probabilistic in\u00adputs. We prove several properties of our algorithm, including   (a) \nsoundness; and (b) the smoothness of the objectives that we generate for numerical optimization. We present \na prototype implementation of our algorithm, called FERMAT, and perform case studies on two benchmarks \nfrom the embedded control domain. The rest of the paper is organized as follows. In Section 2, we formulate \nour synthesis problem. In Section 3, we present smoothed proof search as well as a concrete algorithm \nbased on this strategy. Section 4 presents the FERMAT system and experimental results. Section 5 discusses \nrelated work; we conclude with some discussion in Section 6. Finally, we had to omit proofs for most \nof our theorems due to lack of space; these can be found in an online technical report [7]. 2. Problem \nformulation In this section, we formalize the veri.ed parameter synthesis prob\u00adlem. As outlined earlier, \nwe will be focusing on the probabilistic version of the problem where the goal is to meet the optimality \ncri\u00adterion on the average input. The key technical task of this section is the de.nition of the probabilistic \nsemantics. Measures To de.ne the semantics of our programs rigorously, we need some de.nitions from probability \ntheory. For brevity, we only give the most essential of these de.nitions. A more thorough treatment of \nthis background material can be found in a textbook such as Billingsley s [2]. De.nition 1 (Borel sets). \nA s-algebra s over Rn is a set of subsets of Rn that contains \u00d8, and is closed under complementation \nand countable union. The collection of Borel sets, denoted B, is the smallest s-algebra over Rn containing \nthe open sets. Examples of Borel sets include the set Rn , the set of all rational vectors, and the sets \nof real vectors satisfying conjunctions or disjunctions of polynomial inequalities (in practice, all \nsubsets of the reals of interest in program analysis). De.nition 2 (Measure). A (.nite, nonnegative) \nmeasure \u00b5 (over Rn) is a function \u00b5 : B . [0, +8) such that: (1) \u00b5(\u00d8) = 0, and (2) If (An)n.N is a countable \ncollection of disjoint subsets of Rn , o then \u00b5( n.N An) = n.N \u00b5(An). The total weight of \u00b5 is I\u00b5I = \n\u00b5(Rn). If I\u00b5I = 1, then \u00b5 is a probability measure; if I\u00b5I = 1, then \u00b5 is a subprobability measure. A \nmeasure \u00b5 over Rn is concentrated over a subset Y . Rn if \u00b5(Rn \\ Y ) = 0. The support supp(\u00b5) of a measure \n\u00b5 is the least closed set Y . Rn such that \u00b5 is concentrated on Y . Intuitively, if \u00b5 is a probability \nmeasure associated with a ran\u00addom variable x, then \u00b5(Y ) is the probability that x . Y . Non\u00adprobability \nmeasures \u00b5 formalize unnormalized probability dis\u00adtributions, where the probability of the certain event \ndoes not have to be 1. A function f : Rn . Rn is a measurable function if for all Borel sets Y . Rn , \nf-1(Y ) is also a Borel set. For measurable functions f : Rn . Rn and random variables x with measure \n\u00b5, we can de.ne the expectation E\u00b5[f(x)] of f(x) by the standard I Lebesgue integral: E\u00b5[f(x)] = f d\u00b5. \nAll the functions that we consider in this paper are measurable. Programs Now we de.ne the language (call \nit IMP) of programs that we want to synthesize. IMP is a core imperative language with standard control \nconstructs. Programs here are allowed to update n memory locations containing real values for a .xed \nbut arbitrary constant n; hence, the state of a program is described by a real vector of length n. Assignments \nin the program correspond to af.ne transformations applied to this vector. Let us .x a single variable \nx, ranging over Rn , that stores the state of a program. The syntax of Boolean expressions B and programs \nS in IMP are given by: B ::= tbv \u00b7 x + b0 > 0 S ::= skip | x := M \u00b7 x + c |if B then S1 else S2 |while \nB do S1 | S1; S2 where bv, c . Rn , b0 . R, M is a real matrix, and tbv denotes the transpose of bv. \nWe assign a probabilistic concrete semantics [ S] to each IMP program S (we use [ S] det whenever we \nneed to refer to the stan\u00addard non-probabilistic semantics). This semantics is de.ned as a transformation \non .nite measures \u00b5 (i.e. measures with I\u00b5I < 8). Speci.cally, [ S]](\u00b5) is the output probability measure \nof S when applied to an input probability measure \u00b5. The semantics of a boolean expression b is a function \n[ b] that maps the state vector to a Boolean, but abusing notation, we also use [ b] to denote the set \nof vectors v that satisfy b. We need some more notation. Given a matrix M and a set of vectors U . Rn \n, we de.ne M-1U = {v|Mv . U} to be the set of vectors that when multiplied times M produce a vector in \nU. Note that this operation is well de.ned even for non-invertible matrices. We also abuse notation by \nusing (U -a) to refer to the set {y - a|y . U}. The probabilistic semantics of loop-free programs is \nnow given by the following rules: [ skip]](\u00b5) = \u00b5 [ tbv \u00b7 x + b0 > 0]] = {x . Rn|tbv \u00b7 x + b0 > 0} [ \nx := Mx + c]](\u00b5) = .U.\u00b5(M-1(U - c)) [ S1; S2]](\u00b5) = [ S2]]([[S1]](\u00b5)) [ if b then S1 else S2]](\u00b5) = [ \nS1]](.U.\u00b5(U n [ b]])) +[[S2]](.U.\u00b5(U\\[ b]])) To give semantics to loops, let us de.ne an operation stepS,b(\u00b5) \n= n [ S]](.U.\u00b5(U n [ b]])). We use the notation stepS,b to refer to the composition of stepS,b n times, \nwith step0 being the identity S,b function. Now we de.ne: 8 n [ while b do S]](\u00b5)(U) = stepS,b(\u00b5)(U\\[ \nb]]). n=0 n The quantity stepS,b(\u00b5)(U \\[ b]]) corresponds to the probability that some initial state \nx will cause the loop to iterate exactly n times and after those n iterations, the resulting state belongs \nto the set U. For simplicity, in this paper we only consider programs S that terminate on almost every \ninput i.e., the set of inputs on which the program does not terminate is of measure 0. Example 1. Suppose \nwe are trying to analyze the program from the introduction after having replaced c with 0.5. if (x > \n0.5) { y := x + 1; } else { y := 10; } Now, suppose the input x is uniformly distributed over the range \n[0, 10). The distribution can be represented by a probability mea\u00adsure \u00b5(A) which for any set A produces \nthe probability that x . A. In particular, for any interval (a, b) with 0 < a < b < 10, b - a \u00b5((a, b)) \n= . 10 For any set A that does not intersect [0, 10), \u00b5(A) = 0. According to the semantic rules, the \ndistribution of the output y is given by the following function: \u00b5out = .U. \u00b5(M1 -1(U - 1) n [0.5, 8))+ \n\u00b5(M2 -1(U - 10) n (-8, 0.5)).  Now M1 -1(A) = A for any A, and since M2 is the zero matrix, M-1 2 (A) \n= R if 0 . A, and is the empty set otherwise. Thus, on the range (1.5, 2), we have \u00b5out((1.5, 2)) = \u00b5((0.5, \n1.0) n [0.5, 8)) + \u00b5(\u00d8 n (-8, 0.5)) = \u00b5((0.5, 1.0)) = 0.05 and on the range (9, 12), we have \u00b5out((9, \n12)) = \u00b5((8, 11) n [0.5, 8)) + \u00b5(Rn (-8, 0.5)) = \u00b5((8, 11)) + \u00b5((-8, 0.5)) = 0.25 i.e. the probability \nof the output being between 9 and 12 is 0.25, while the probability of the output being between 1.5 and \n2.0 is 0.05. Lemma 1 (Properties of concrete semantics). The concrete seman\u00adtics of IMP satis.es the \nfollowing properties. For all programs S, [ S]](\u00b51 + \u00b52) = [ S]](\u00b51) + [ S]](\u00b52) I\u00b51I = I[ S]](\u00b51)I Moreover, \n[ S]](\u00b5)(U ) = \u00b5([[S] -1 (U)), where [ \u00b7] stands for det det the usual deterministic semantics of programs. \nSketches A sketch is an IMP program with missing parameters. Formally, let H be a special name for a \nvariable storing an n\u00adtuple of (missing) control parameters. We de.ne an implementa\u00adtion sketch (or simply \na sketch) to be a term SH with the syntax t tb' B ::= bv \u00b7 x + v \u00b7 H + b0 > 0 SH ::= skip |x := M \u00b7 x \n+ M ' \u00b7 H + c |if B then S1H else S2H |while B do S1H | S1H ; S2H where bv, c, b'v . Rn , b0 . R, and \nM, M' are real matrices. By substituting H by a constant vector c in SH , we obtain an IMP program. We \ndenote this program by SH [H . c] or Sc. Note that as the sketch performs only linear operations in H, \nwe can treat the concatenation of H and x as a state vector; the sketch then becomes a standard IMP program \nS(x : H) on that extended vector. Assertions A (probabilistic) assertion for a program S is a pair . \n= (B; .), where B is a boolean expression in IMP and 0 = . = 1 is a constant. De.nition 3 (Satisfaction). \nA measure \u00b5 satis.es . = (B; .) if ' \u00b5([[B]]) = .. A program S satis.es . on the input \u00b5 if \u00b5= [ S]](\u00b5) \nsatis.es .. Intuitively, if S satis.es . under \u00b5, then the probability that the assertion B will hold \non termination of S is greater than or equal to .. Also, note that if . = 1, then . is a non-probabilistic \nassertion that is expected to be true for all inputs allowed by the distribution. For simpler notation, \nwe only allow assertions as postconditions in the formal exposition of our method. However, our method \neasily extends to requirements asserted at intermediate labels within a program, and such assertions \nare permitted in our implementation. Error value Our programs compute an error value, i.e. a real value \nre.ecting how close the behavior was to the ideal. In general, we assume that there is an error function \nErr(x) that computes the error value from the .nal state of the program. Usually, the error value will \njust be stored as one of the components of the state vector; for example, if the program is storing the \nerror value in the .rst component of the state vector, Err(x) = d0 \u00b7 x, where d0 is the Kronecker delta. \nParameter synthesis Now we de.ne the parameter synthesis problem that we solve. Problem 1 (Veri.ed parameter \nsynthesis). Given an implementa\u00adtion sketch P , an input measure \u00b5 (assumed to be of bounded sup\u00adport \nfor technical convenience), and a boolean requirement ., .nd a vector c . Rn such that: 1. [Boolean goal] \nSc = SH [H . c] satis.es . on input \u00b5. 2. [Quantitative goal] The expected error value produced by Sc \nis minimal. Formally, c = argminc F(c), where F(c) = E[ Sc] (\u00b5)[Err(x)] is the expected value of component \nzero of x according to the output distribution of Sc.  If we use Sc(x) as a shorthand for Err([[Sc] \ndet(x)), i.e. the function that maps an input to its error value, then it is easy to prove that E[ Sc] \n(\u00b5)[Err(x)] = E\u00b5[Sc(x)], so we will use the two notations interchangeably. Example 2. Let us go back \nto th e example in the introduction: if (x > c) { y := x + 1; } else { y := 10; } The Boolean goal can \nbe expressed as . : ((c - 10 = y = c + 10); 1.0). As in Example 1, let us assume that the input x is \ndistributed uniformly within [0, 10). The probability of passing the assertion at the end of the pro\u00adgram \nis equal to \u00b5out([c - 10, c + 10]), and the expected .nal value of y is E\u00b5out [y] (because our stated \ngoal is to minimize the output y, Err(y) is just the identity function). For this simple pro\u00adgram, both \nof these functions can be computed from the de.nition of \u00b5out. Using Lebesgue integration, we see that \nwhen 0 = c = 10 the expected value as a function of c is: (c + 1)2 y d\u00b5out = 5.05 + (c + 1) - 20 So, \nfor example, when c = 1, the expected value is 6.85, and when c = 9, the expected value is 10.05. From \nthis, we can see that in order to minimize the output y while preserving the invariant, we need to set \nc = 1. Any value of c lower than 1 will reduce the probability of satisfying the invariant below 1. On \nthe other hand, any value of c in (1, 10] will lead to a higher expected value of y by the above calculation, \nand if c > 10, then the output will be the constant 10. Example 3 (Thermostat). Let us now understand \nour problem statement using a real example a controller for a thermostat. The thermostat has two inputs: \na target temperature ltarget for the room, and the value lin of the outside temperature. These two inputs \nare probabilistic, because while we do not know what the outside or the target temperatures will be at \na given time, we can collect statistics from the local weather and user s preferences to determine an \nexpected distribution of these input values. The joint distribution \u00b5 on lin and ltarget is assumed to \nbe given. The output of the program is the difference between the real temperature and the target temperature \nover a period of time, and the goal is to design a thermostat that will minimize the expected value of \nthis error. A natural partial implementation for our controller1 is in Fig. 2. Here the placeholders \n??(c1,c2) stand for missing real-valued parameters; by using a placeholder like the above, the programmer \ncommunicates the additional insight that the parameter is likely to lie in the interval [c1, c2]. The \ncode captures the simple high-level insight that a thermostat is a system with two discrete modes: one \nwhere the heater it controls is off and one where the heater is on. When the temperature goes above a \ncertain threshold tOff, it is appropriate to turn off the heater; when the room temperature is below \na certain tOn, the heater must come back on. 1 This code is written in SKETCH [30] the language used \nin our implementation but is easily translated to IMP.  double thermostat(double lin, double ltarget) \n{ double h = ??(0,10); double tOn = ltarget + ??(-10,0); double tOff = ltarget + ??(0,10); double isOn \n= 0.0; double K = 0.1; double curL = lin; assert(tOn < tOff; 0.9); assert(h > 0; 0.9); assert(h < 20; \n0.9); for(int i = 0; i < 40; i = i + 1) { if(isOn > 0.5) { curL = curL + (h -K (curL -lin)); * if(curL \n> tOff) { isOn = 0.0; } } else { curL = curL -K (curL -lin); * if(curL < tOn) { isOn = 1.0; } } assert(curL \n< 120; 0.9); } Error = abs(curL -ltarget); return Error; } Figure 2. Sketch of a thermostat. abs is the \nabsolute value func\u00adtion. The synthesis problem is to .nd values for tOn and tOff, as well the heat h \ngiven off by the heater in each time step, such that the following two conditions are satis.ed. First, \nafter 40 steps the tem\u00adperature of the room should be as close to the target as possible; this is the \nError value computed by the sketch. Second, the values of the parameters must be such that if the inputs \nfollow a distribution \u00b5, then the controller provably satis.es each probabilistic assertion in the sketch \ne.g., the property that the temperature curL should be below 120. with probability > 0.9. 3. Smoothed \nproof search In this section, we describe the smoothed proof search approach to veri.ed parameter synthesis. \nOf the two goals in the statement of the problem, we view the boolean requirement as a minimum requirement \non the solutions, and guarantee that every solution satis.es it. However, the quantitative goal is met \napproximately using local optimization, and substantiated empirically. This choice is akin to how in \nmost program analyses, one guarantees soundness but leaves completeness as an empirical consideration. \nFormally, suppose we are given an instance of an optimal syn\u00adthesis problem (SH , ., \u00b5), where the components \nof the tuple have meanings as before. Let . = (B, .), and for any c . Rn , let Sc = SH [H . c]. Now, \nsuppose we have a way to compute both the expected error value at the end of the execution as well as \nthe probability that the execution value satis.es B, both as a function of c. F(c) = E[ Sc] (\u00b5)[Err(x)] \n.(c) = P[[[Sc]](\u00b5) satis.es B] The goal is to .nd a c that minimizes F(c) under the constraint that .(c) \n< .. We can also frame this as an unconstrained, single\u00adobjective optimization problem by introducing \na penalty term when .(c) = .. Speci.cally, such a problem can have the form: min (F(c) + P enalty(.(c), \n.)) . c where Penalty(p, .) is 0 for p = . and an arbitrarily large positive value for p > .. Our smoothed \nproof search algorithm addresses two challenges faced in solving the optimization problem above. The \n.rst chal\u00adlenge is that computing the true values of F and . is prohibitively expensive, so we need to \nhave sound approximations that can be computed ef.ciently but can still guarantee that the result does \nin\u00addeed satisfy the probability bound. Second, while local numerical search algorithms such as Nelder-Mead \nsimplex search are the only reasonable way of solving the problem, these algorithms Algorithm 1 Smoothed \nproof search 1. Initialize Inc to a random value. 2. Let \u00df0, \u00df1, . . . , \u00dfm be a series of values where \n\u00df0 is a heuris\u00adtically chosen real constant and \u00dfi = \u00df0 * .i for a constant 0 < . < 1, and \u00dfm is the \n.rst \u00dfi below a certain threshold E\u00df 3. For \u00df in \u00df0, \u00df1, . . . , \u00dfm:  (a) Obtain representations of \nF#(c) and .#(c). Let IF = F#(c) \u00df \u00df\u00df\u00df # and I\u00df . = .\u00df (c). (b) Set G := .(c).(sup(I\u00df F) + P enalty\u00df #(max(I\u00df \n.), .)). (c) Minimize G using local numerical search, starting from the initial point Inc. Let c * = \nargminc G(c) (d) Set Inc := c *  4. Verify that Sc * satis.es .. If this fact can be proved, then terminate; \nreport c * as the optimal parameter value. Otherwise, go to step 1. rely very strongly on the continuity \nof the objective function. Due to the presence of braching control constructs, this assumption does not \nhold in our setting. The key idea behind our algorithm is to derive a set of continu\u00adous approximations \nto F(c) and .(c). The approximations F# \u00df (c) and .# \u00df (c) are continuous but unsound approximations \nof F(c) and .(c) parameterized by value \u00df that controls the degree of ap\u00ad # proximation. Speci.cally, \nF\u00df maps each control parameter value to an interval I\u00df F , and .# \u00df maps each control parameter value \nto an interval I\u00df . . For values of \u00df > 0, the mappings F\u00df # and .\u00df # are continuous, and bigger values \nof \u00df will lead to smoother func\u00adtions that are easier to optimize numerically. In the limit as \u00df goes \nto zero, on the other hand, the intervals returned by the approxima\u00adtions converge to sound bounds over \nthe original functions F and .. In other words: Let lim\u00df.0 F# \u00df (c) = I0 F . Then F(c) . I0 F . # Let \nlim\u00df.0 .\u00df (c) = I0 . . Then .(c) . I0 . . Thus, bigger values of \u00df make numerical optimization easier, \nwhile small values of \u00df make the function closer to the sound but discon\u00adtinuous approximation we would \nlike to optimize. Finally, the function Penalty(p, .) is also a source of discon\u00adtinuity, so it is approximated \nby a smooth function Penalty# \u00df (p, .). # In particular, we use an approximation of the form Penalty\u00df \n(p, .) = sigmoid(p, ., \u00df), where sigmoid(p, ., \u00df) is a smooth sigmoid (S\u00adshaped) function that monotonically \nincreases in value with p, has a single in.ection point at p = ., and smoothly approaches the function \nPenalty(p, .) as \u00df . 0. We exploit these properties in our smoothed proof search algo\u00adrithm (Algorithm \n1). Note that, while the abstraction of the error function returns an interval, the algorithm optimizes \nthe supremum or least upper bound on this interval (i.e., if I\u00df F = (l\u00df F , h\u00df F), then we optimize hF \n\u00df ). However, in principle we could have also chosen to optimize a different real objective derived from \nthe interval. On the other hand, it is important that we optimize the upper bound sup I\u00df . on the probability \nof assertion failure, because our goal is to guarantee that the probability of error is below the threshold. \nThe check in step 4 of our algorithm is important because the bounds computed by approximation G in Step \n3 are not sound ap\u00adproximations: the interval I\u00dfF m may not bound the value of F(c),  .. . false otherwise. \nconverges to sound bounds. Thus, step 4 can be seen to be a limit of the iteration in Step 3. a .p b \n= # # Now we show how to compute F\u00df and .\u00df using abstract interpretation. In Section 3.1, we give a method \nto compute sound bounds for the expected value of a function on an input measure. It is important to \nnote a few properties about the partial order. First, note that the partial order is only de.ned when \nthe abstractThe procedure that computes sound bounds is discontinuous, so the parameter \u00df does not play \na role here. (However, the soundness of the procedure means that we can use it in the veri.cation step \nStep 4 in the algorithm.) Subsequently, in Section 3.2, we states share the same sets I and wi. In principle, \nit is possible to provide a more general partial order that also relates abstract states with different \nindex sets and weights, but for the purpose of our analysis, this partial order will suf.ce. The second \npoint topresent our method for smooth approximation of programs. note is the rationale behind the de.nition \nof .p. The main idea  3.1 Sound but discontinuous domain Our abstract interpretation for computing sound \n(but discontinu\u00adous) bounds on the expected output of a program builds on the work of Monniaux [20]. \nWe improve upon this work by leverag\u00ading an assumption of structured control .ow to handle conditionals \nmore precisely. Abstract states An abstract state in our domain is a tuple of the form A = (I, {wi}, \n{pi}, {Ei}). Here I is a set of indices; for each index i . I there is exactly one weight wi, one fraction \npi and one subset Ei of Rn . The meaning of each of these components is best understood by de.ning the \nconcretization function ., which maps abstract states to sets of sub-probability measures over Rn: is \nthat when pi . {0, 1}, it restricts the set of measures in the concretization, but if pi has a fractional \nvalue, it is inconsequential. Example 4. Consider abstract states A and B below: IA = {0} IB = {0} A \nB w= 0.5 w= 0.5 A: 0 B: 0 A B p0 = 1/2 p0 = 1/4 EA = [0, 2.5] EB = [0, 2.5] 0 0 In this case, both p \nA 0 and p B 0 are fractional, so the concretization of both abstract states is the same and hence A .p \nB even A though they have different values of pi. If p0 were equal to 1, the concretization of A would \nbe a subset of the concretization of B, B so A .p B would still hold. However, if p0 was to equal 1 or \n0, A B the partial order would only hold if p0 was also made equal to p0 . Abstraction of loop-free programs \nThe abstract semantics of loop-free programs is given by the following rules: .((I, {wi}, {pi}, {Ei})) \n= {\u00b5 | \u00b5 = \u00b5i . .i . I : supp(\u00b5i) . Ei . ||\u00b5i|| = wi i.I [ x := Mx + c]](I, {wi}, {pi}, {Ei})  . pi \n= 0 . \u00b5i = 0 . pi = 1 . ||\u00b5i|| = wi} = (I, {wi}, {pi}, {MEi + c}) [ S1; S2]](I, {wi}, {pi}, {Ei}) In \nother words, the measure can be decomposed into a sum = [ S2]]([[S1]](I, {wi}, {pi}, {Ei}). of component \nmeasures \u00b5i, where each of these components is concentrated in the set Ei. The values pi carry information \nabout [ if b then S1else S2]](I, {wi}, {pi}, {Ei}) abstraction precision and are one of the distinguishing \nfeatures of = [ S1]](I, {wi}, {pi b}, {Ei b}) 1 our abstract domain compared to that of Monniaux. Each \npi lies [ S2]](I, {wi}, {p \u00acb}, {E \u00acb}). between 0 and 1; when pi is 0 or 1, we know that the total weight \ni i o of the corresponding component \u00b5i is respectively 0 and the full Here weight (wi). An intermediate \nvalue means that we don t know the .. . 0 if [ b] n Ei = \u00d8 pi if Ei . [ b] pi/2 otherwise precise value \nof ||\u00b5i|| but we have a bound on it. p b As we saw in the introduction, when n = 1 and each Ei is i = \nan interval, the abstract state is essentially a histogram; each Ei corresponds to a bucket in the histogram, \nand the value wi bounds the total area of the ith bar in the histogram or if p = 1, wi gives the exact \narea of that bar. The abstract domain allows us to symbolically propagate this histogram through the \nprogram. As this histogram passes through branches, we lose certainty about the weight in any given bucket \nEi. To see why, suppose the branch condition b has an intersection with Ei. Given that we do not know \nhow the measure on Ei is distributed, we do not know if the weight on b n Ei is the total initial weight \non Ei. However, note that by the time the abstract interpretation reaches the end of the branch, this \nlost certainty is once again regained. This is because, by this point, all the paths into which Ei could \nhave been split within the branch-statement have been joined. Thus, we know that the total weight on \nEi at this point is the same as the initial weight on Ei. Formally, the partial order . over the abstract \nstates is de.ned as follows: (I, {wi}{pi}, {Ei}) . (I, {wi}, {qi}, {Fi}) . .i . I : pi .p qi . Ei . Fi \n\u00acb and pi is de.ned in an analogous way. The set Ei b is some superset of Ei n [ b] . The operator 1 \non abstract states is de.ned as follows: (I, {wi}, {p a i }, {Ei a}) 1 (I, {wi}, {p b i }, {Ei b}) = \nab ab (I, {wi}, {pi + pi }, {join(pi , Ei a , pi , Ei b)}) where join(p a i , Ei a , p b i , Ei b) = \n{x | (x . Ea . p a > 0) . (x . Eb . p b > 0)}. ii ii Finally, the notation MEi + c is used to describe \nthe set of points {Mx + c | x . Ei}. Note how the propagation of abstract states through a branch (say \nwith condition b) tracks precision information. If [ b] n Ei is either empty or equal to Ei, we have \nnot lost any precision by propagation through the branch condition. However, if these conditions not \nhold, then we have lost precision, and this is tracked by shrinking pi by half. Note also that the 1 \noperator ensures that we will regain this lost precision at the end of the branch. We observe that 1 \nis not actually a join operation in the tradi\u00ad b \u00acb b tional sense, because pi + pi = pi and we could \nhave pi .p pi .  We refer to this operation as a subjoin because it produces a more precise result than \nthe join. However, the result is still sound be\u00adcause of the relationship between the distributions from \nthe two branches as we prove in the appendix. The use of a sub-join op\u00aderation and the use of the values \npi to help track the precision of the approximation are the main distinguishing features between our \nmethod and prior work on probabilistic abstract interpretation by Monniaux [20]. We also observe that \n1 is de.ned only when for all i, pi a + p b i = 1. It so happens that at any step where the 1 operation \nis applied, this condition holds. Speci.cally, 1 is used only on abstract states computed from two conditional \nbranches. As abstract interpretation of assignments preserves the values of {pi}, the {pi} resulting \nfrom both branches will sum to the ones before the branch, which was already lower than 1. The rationale \nbehind the de.nition of the subjoin is illustrated by the following example. Example 5. Consider a simple \ncode fragment: if (x >= 0.5) { x = x + 10; } Now, suppose the abstract state before the if statement \nis (I = {0}, w0 = 1.0, p0 = 1, E0 = [0, 1]) That means that x will fall between 0 and 1, but the abstract \nstate has no information about the exact distribution of x in that range. Now, inside the conditional, \nthe abstract state is (I = {0}, w0 = 1.0, p0 = 1/2, E0 = [0.5, 1]) i.e. x is now between 0.5 and 1, but \nwe don t know the probability that the branch was taken; all we know is that it is bounded by 1. This \nuncertainty is re.ected by the fractional value of p0. After the branch, the new abstract state will \nbe: (I = {0}, w0 = 1.0, p0 = 1, E0 = [0, 0.5) . [10.5, 11]) Note that p0 is again 1, because even though \nthe probability of taking each side of the conditional is unknown, we do know that the probabilities \nadd up to w0, so after the two branches merge, we know that the probability of x . E0 is exactly w0. \nWhile loops. Let us now de.ne the abstract semantics of while\u00adloops. First we de.ne an abstract step \noperation: step((I, wi, pi, Ei)) = [ S]](I, wi, pi b , Ei b). The transformations (stepn)n.N generate \na sequence of abstract states, ((I, {wi}, {pi,n}, {Ei,n})), that are visited in succession in an abstract \nexecution. Now we have: [ while b do S]](I, {wi}, {pi}, {Ei}) = \u00acb (I, {wi}, {pi}, {\\((Ei,n)n.N)}) \u00acb \nwhere \\((Ei,n)n.N) is a superset of n.N Ei,n n [ \u00acb] . The con\u00adcrete de.nition of \\ relies on a widening \npolicy (see Section 3.2). We can prove the following properties of the abstract domain. (For proofs, \nsee the technical report version of the paper [7].) Theorem 1. Let S be any IMP program. For each abstract \nstate A and for \u00b5 . .(A), we have [ S]](\u00b5) . .([[S]](A)). Theorem 2. Consider an abstract state (I, {wi}, \n{pi}, {Ei}) such that for all i . I we have pi = 1, and \u00b5 is a probabil\u00adity measure in the abstract state \ns concretization. Then E\u00b5[xk] = o i.I sup(dkEi)wi, where dk is the function mapping x to its kth component \nxk, and sup(dkEi) is the supremum of the kth compo\u00adnent over the set Ei. Theorem 3. Let A be an event, \nand \u00b5 a probability measure in the concretization of an abstract state (I, {wi}, {pi}, {Ei}). Then o \nP\u00b5[A] = wi, where IA = {i | Ei n A= \u00d8}. i.IA The above theorems lead to a strategy for sound veri.cation \nof probabilistic assertions . = (B, .). Given an input measure \u00b5, let us abstract \u00b5 into an abstract \nstate A\u00b5, then use abstract interpretation to compute [ S]](A\u00b5) = (I, {wi}, {pi}, {Ei}). Let o us certify \nthe program as satisfying . if i.ID wi = ., where ID = {i | Ei n [ B] = \u00d8}. From the above theorems, \nthis strategy is sound i.e., a program certi.ed as satisfying . does, in fact, satisfy .. This strategy \nis used to implement Step 4 of the smoothed proof search algorithm (Algorithm 1). By the argument given \nabove, we have: Theorem 4 (Soundness). If Algorithm 1 returns a value c * of the missing parameters, \nthen the implementation Sc * satis.es the assertion .. Ellipsoid Domain: Representing sets of points. \nThe abstract do\u00admain described above assumes we have a representation of the sets Ei that can be manipulated \nef.ciently. Our algorithm represents these sets as ellipsoids, or n-dimensional generalizations of el\u00adlipses. \nThis choice is a matter of pragmatics rather than fundamen\u00adtals. The reason we use ellipsoids as opposed \nto other natural choices like polytopes is that they offer an attractive tradeoff be\u00adtween ef.ciency \nand precision. For instance, with ellipsoids, com\u00adputing volumes (an essential step for us) is inexpensive, \nwhereas for polytopes, volume computations are #P-hard. We note that ef.\u00adciency considerations are especially \nimportant in our setting, where an abstract interpretation is performed on every query from the top\u00adlevel \nnumerical search routine, and the total number of calls to the abstract interpreter can be in the hundreds/thousands. \nFormally, we represent each set Ei as a collection of N\u00addimensional open ellipsoids Ei = {Oi,j }. Each \nellipsoid is repre\u00adsented by a pair O = (M, t) of an invertible matrix and a vector. The pair represents \na set of points de.ned as follows: (M, t) = {x | .r. x = Mr + t . IrI = 1}. We also have a special non-ellipsoid \nelement T, standing for Rn . The abstract semantics requires the following operations on the sets Ei: \n(1) computing the image of set under an af.ne transfor\u00admation; (2) checking whether the intersection \nEi n [ b] for boolean tests b is empty, and computing the sets Ei b and Ei \u00acb , (3) the subjoin operation, \nand (4) the \\ operator for loops. Of these, af.ne transformations of ellipsoids can be performed exactly \nin most cases. The one exception is non-invertible assign\u00adments, which generate .at ellipsoids whose \naxes along some di\u00admensions equal zero. Our algorithm overapproximates such ellip\u00adsoids by ones where \neach axis is nonzero. For the special case when an ellipsoid equals T, the transformation returns T. \nFor testing intersections, suppose b equals tbv \u00b7 x + bo > 0. Therefore, [ b] n(M, t) is nonempty iff \n.r s.t. tbv(Mr +t)+bo > 0 . IrI = 1. A solution for r in the above equation will exist if and only if \nwe have ItMbvI + (tbv \u00b7 t + bo) > 0. By running this check, we can determine if the intersection is empty \nor not. As for the sets Ei b and Ei \u00acb , we could retain soundness by setting them both to Ei. However, \nin practice, we achieve higher precision by setting Ei b and Ei \u00acb to the minimum-volume enclosing ellipsoids \n(MVEEs) of the sets Ei n[ b] and Ei n[ \u00acb] , respectively. We can compute these MVEEs by symbolically \ntransforming Ei we skip the details. The subjoin operation is accomplished by simply concatenating the \nlists of ellipsoids from the two abstract states. If one of the arguments is T, then it returns T. Finally, \nthe \\ operator for loops is de.ned via loop unrolling. We de.ne the \\ operator in such a way that it \nis equivalent to replacing the loop by the unrolling of its n0 .rst iterations, and to return T in the \nabstract for the branch corresponding to non-termination in n0 iterations.  b) if (2 * x1 + x0 - 7 > \n0) x1 := x1 + 2 else x0 := x0 - 2  Figure 3. Effect of different statements on ellipsoid domain Fig. \n3 illustrates abstract interpretation using the above domain. Part (a) shows the way an assignment transforms \nan abstract state with two ellipsoids. Fig. 3-(b) shows the effect of an if-statement. The ellipsoid \nE2 that straddles the boundary is split into two parts, with each part translated by the assignment in \nthe corresponding branch. This means that at the join point, the set E2 now comprises two ellipsoids, \nwhile the sets E1 and E3 still have one each.  3.2 Continuous approximation The abstract domain described \nso far is sound but discontinuous: small changes to a program s inputs could lead to an arbitrarily large \nchange to the expected output. Discontinuities mostly come from ellipsoids appearing and disappearing \nfrom the sets Ei. For example, in program (b) on .gure Fig. 3, a small change to x0 that caused ellipsoid \n2 to fall entirely below the x + 2y > 7 line will cause ellipsoid 2 ' to suddenly vanish from .nal abstract \nstate. This will result in a discontinuity of sup(d0E2) relative to x0 and therefore also in the bound \ncomputed for E[x0]. This is the same effect that was illustrated in the introduction with a one dimensional \nexample where the ellipsoids become intervals. Now we give a domain called smooth ellipsoids that provides \na continuous, unsound approximation of the above domain. We call the abstract semantics under the smooth \nellipsoids domain the smooth semantics [ \u00b7] \u00df . As stated earlier, the approximation is parameterized \nby a value \u00df that controls the degree of smoothing. As \u00df approaches zero, the domain converges to the \nsound domain of Section 3.1. Compared to the original domain, the smooth ellipsoids do\u00admain now associates \nwith each ellipsoid in the set Ei a measure ai,j . [0, 1] that re.ects how close each ellipsoid is from \ndis\u00adappearing. Speci.cally, each Ei now corresponds to a multiset Ei = {(Oi,j , ai,j )}. The smooth semantics \n[ \u00b7] will modify Oi,j \u00df as before; the ai,j will be initialized to one for all ellipsoids and will be \nunaffected by assignments but modi.ed by branches. For example, the rule for if-statements will now be \nas follows: [ if b then S1else S2] (I, {wi}, {pi}, {(Oi,j , ai,j )}) = \u00df [ S1] (I, {wi}, {pi b}, {(Oi,j \n, .\u00df (Oi,j , b) * ai,j )}) \u00df \u00acb 1 [ S2] \u00df (I, {wi}, {pi }, {(Oi,j , .\u00df (Oi,j , \u00acb) * ai,j )}). The 1 \noperation at the end of the if-statement will be computed as before, by taking the union of the sets \nof ellipsoids for each Ei for which pi is not zero. As for .\u00df , it is a special continuous function. \nBecause the arguments of .\u00df are sets, its continuity needs to be de.ned with respect to a metric on sets. \nWe choose this metric to be the Hausdorff metric, de.ned below: De.nition 4 (Hausdorff distance). Let \nA and B be two non-empty subsets of Rn . The Hausdorff distance DH (A, B) between A and B is de.ned by \nDH (A, B) = inf {A . Br . B . Ar} r.R+ where Ar is de.ned as {x|.y . A : ||x-y|| = r}. In other words, \nthe distance between A and B is the smallest r such that if we draw a halo of width r around A, the halo \nwill contain B, and if we draw a halo of width r around B, the halo will contain A. Formally, the function \n.\u00df is a function with the following prop\u00aderties: .\u00df is continuous with respect to the Hausdorff distance. \n 0 if Oi,j n [ b] = \u00d8 .\u00df (Oi,j , b) = 1 if Oi,j . [ b] . As \u00df approaches zero, .\u00df should smoothly approximate \nthe following function: 0 if Oi,j n [ b] = \u00d8 .0(Oi,j , b) = 1 otherwise. Ox n [ b] . Oy n [ b] . .\u00df \n(Ox, b) = .\u00df(Oy, b)  For all invertible af.ne transformations f,  .\u00df(f(Ox), b . f -1) = .\u00df(Ox, b). \nIn other words, .\u00df is stable under af.ne transformation. (The last requirement is not needed by our proofs, \nbut expresses the fact that we do not want our abstraction to behave differently over programs that are \naf.ne transformations of each other.) The properties imply that if px is equal to zero in an abstract \nstate (I, {wi}, {pi}, {(Oi,j , ai,j )}), then all the ax,j will be equal to zero as well because the \ncondition under which pi becomes zero are the same as those under which .\u00df becomes zero. There are many \nfunctions that satisfy the above criteria for .\u00df . A natural choice, which we use in practice, is V \n(On[ b] ) min(1, ) if O is .nite f(\u00df)V (O) .\u00df (O, b) = 1 - f(\u00df) if O is the universal set where f(\u00df) \n= min(1/2, .\u00df) and . is a constant parameter. Here, V (S) stands for the n-dimensional volume of a subset \nS of Rn . Initial distribution A sketch Sc(x) takes two different kinds of inputs: x and c. The initial \ndistribution for inputs x is known and is given as part of the problem de.nition, but c is unknown. Previous \nwork on smooth interpretation [8] showed that as the search algorithms tries different values c i for \nparameter c, it can get better information about the function to be optimized by executing on a distribution \ncentered at c i . In our context, this means that the initial distribution must be a product between \nthe initial input distribution \u00b5 and a distribution \u00b5(ci,\u00df) centered at ci and with variance proportional \nto \u00df. Since we are interested in an abstraction of \u00b5 \u00d7 \u00b5(ci,\u00df), we need a sound product operation over \nabstract states. In general, this is de.ned as A\u00b5 \u00d7 A\u00b5(ci,\u00df) = (I, wi a , p a i , Ei a) \u00d7 (J, wj b , \np b j , Ej b) = b ab i (I \u00d7 J, wi a wj , pi pj , Ea \u00d7 Ej b). However, ellipsoids are not closed under \ncross product; e.g. in the one dimensional case, the product of two ellipsoids [-a, a] and [-b, b] is \na rectangle. Instead of overapproximating this rectangle with a bigger ellipsoid, we actually underapproximate \nit by the largest ellipsoid enclosed by the rectangle. This is unsound in general, but it becomes sound \nin the limit as \u00df approaches zero.  As for A\u00b5(ci,\u00df) , for our experiments, we use (ci,\u00df) A\u00b5(ci,\u00df) = \n({0}, {w0 = 1}, {p0 = 1}, {E0 }) (ci,\u00df) where E0 is the sphere centered at ci with radius \u00df. Continuity \nof [ \u00b7] \u00df Now we establish the continuity of our do\u00admain. For space reasons, we only offer a proof sketch \nof the central theorem behind this property. Full proofs are available in the tech\u00adnical report version \nof the paper [7]. In order to prove continuity, we .rst need to de.ne a dis\u00adtance metric D(Aa , Ab) between \ntwo abstract states Aa = aa bb (Ia , {wi }, {pi }, {Ei a}) and Ab = (Ib , {wj }, {pj }, {Ei b}), where \nthe sets E are represented as weighted sets of ellipsoids Ei x = {(Ox i,j )} as discussed earlier. i,j \n, ax De.nition 5 (Distance). We de.ne the distance to be 8 between two abstract states with different \nindex sets or different wi x . When x index sets and wi are identical, the distance D(Aa , Ab) between \ntwo abstract states is de.ned by the following equation: max min i,j , aab b D((Oa i,j ), (Oi,si(j), \nai,si(j)))i si j where the si-s are bijective functions. The distance between two weighted ellipsoids \nis de.ned in terms of the Hausdorff distance DH between ellipsoids. D((Oa , aa), (Ob , ab)) = min(DH \n(Oa , Ob) + |aa - ab|, max(aa , ab)). The de.nition assumes without loss of generality that match\u00ading \nEi are represented by the same number of ellipsoids. If this is not the case, we pad with extra ellipsoids \nwith a = 0. The choice of the extra ellipsoid does not affect the distance measure because when one of \nthe alphas, say aa equals zero, the distance D((Oa , aa), (Ob , ab)) always equals the other alpha ab \nirrespec\u00adtive of Oa . At a high-level, given two abstract states with matching index sets, the de.nition \nabove computes the distance for each index independently and returns the minimum over all of them. For \na given index, the distance function tries to produce the best match between ellipsoids in one state \nand ellipsoids in the other. For each pair of ellipsoids and their alphas, the distance is dictated by \nthe magnitude of the alphas when the ellipsoids are far apart, and by the distance between the ellipsoids \nwhen the ellipsoids are very close together. Our continuity theorem requires the introduction of an addi\u00adtional \ntechnical condition known as boundedness. De.nition 6 (Bounded states). Let B be an Euclidean ball; an \nabstract state is B-bounded if Oi,j . B for all .nite ellipsoids Oi,j with non-zero measure ai,j that \nare part of the abstract state. A set of abstract states is bounded if all the abstract states in the \nset are B-bounded for some Euclidian ball B. The boundedness condition in the de.nition of continuity \nis there because of the previously mentioned property that when dis\u00adtances between ellipsoids are large, \nthe distance metric is domi\u00adnated by alpha. This means that for any E it is possible to .nd states that \nare E-close to AE but whose ellipsoids are arbitrarily far and such states could violate the continuity \nproperty. Such states, ly\u00ading outside the B-ball, however, are not relevant from the point of view of \nsmoothed proof search, so this de.nition of continuity is suf.cient for us. Now we establish that the \nabstract semantic function [ \u00b7] \u00df is continuous over bounded sets. Theorem 5. For any ball B, any E and \nany B-bounded AE there exists a d such that for all B-bounded AF , D(AE , AF ) < d . D([[S] \u00df (AE), [ \nS] \u00df (AF )) < E. Also, the abstract semantics maps bounded sets to bounded sets. Proof. (Sketch). We \nonly prove the theorem for loop-free pro\u00adgrams. The proof is by induction on the execution of the abstract \ninterpretation. The base case corresponds to assignments; as assign\u00adments are linear, the property clearly \nholds for them. The interesting inductive case corresponds to conditionals. Let B be any euclidean ball, \nE any positive real, and (I, {wi}, {pi}, {Ei}) be any B-bounded abstract state. We have [ if b then S1 \nelse S2] (I, {wi}, {pi}, {Ei}) = \u00df [ S1] (I, {wi}, {pi b}, {Ei b}) 1 \u00df [ S2] (I, {wi}, {p \u00acb}, {E \u00acb}) \ni\u00df where Ei b i,j )b i,j )} from Ei = is de.ned as {((OE , .\u00df (Oi,j , b) * aE {(0E i,j )}. i,j , aE By \nthe induction hypothesis, [ S1] \u00df and [ S2] \u00df are continuous maps from bounded sets to bounded sets. \nSo we only need prove this property for 1 and the functions (I, {wi}, {pi}, {Ei}) . bY Y (I, {wi}, {p \n}, {Eb}), where b ' . {b, \u00acb}. i i Let us .rst focus on 1. The only possible source of discontinuity \ncomes from the fact that we only merge components with pi = 0. However, when pi = 0, every ai,j = 0, \nso distance between union with and without this component is 0. So it is equivalent to componentwise \nmultiset union, which is obviously continuous over the pairs of abstract states. Moreover, if both abstract \nstates are B1-bounded and B2-bounded, then resulting abstract states is B-bounded for any ball B enclosing \nboth B1 and B2. Since such a ball exists those properties are true for 1. Thus, we only need to prove \nthat the transformation (I, {wi}, {pi}, {Ei}) . (I, {wi}, {pi b}, {Ei b}) maps bounded sets to bounded \nsets and is continuous over them. The else branch case is symmetrical. The .rst property directly follows \nfrom properties of Minimum Volume Enclosing Ellipsoids (MVEEs). For a full-dimensional convex set S, \nn 1 MVEE(S) . S . MVEE(S). Since our re\u00adsulting ellipsoids are MVEEs of subsets of a common ball, they \nare included inside this ball scaled by a factor n around its center. As for the second property, we \nnote that the intersection op\u00aderation between a convex-set and a half-space is continuous with respect \nto the Hausdorff distance. Moreover, one can show that the function that computes MVEEs is continuous \nwith respect to Haus\u00addorff distance on full-dimensional sets, so Oi,j . Ob i,j is continu\u00adous on ellipsoids \nintersecting [ b] . Now, let us restrict to a distance d small enough such that any ellipsoid d-close \nto some OE i,j that intersects [ b] , also intersects [ b] . A value d satis.es this property if for \nevery Oi,j n [ b] , the furthest point of b hyperplane is at least d far from it, so such a d exists. \nWe then restrict this distance to be lower than one so index sets and weights must be identical. Let \n(I, {wi}, {qi}, {Fi}) be any B-bounded abstract state with distance lower than d from (I, {wi}, {pi}, \n{Ei}). By de.nition of distance, we have D((I, {wi}, {pi}, {Ei}), (I, {wi}, {qi}, {Fi})) = o max D((OE \ni,j ), (OF i,j )). i,j , aE i,j , aF i j Here we assume, without loss of generality, an indexing for \nsets Ei and Fi such that minimum over bijective functions are reached at  D((I, {wi}, {p b i }, {Ei \nb}), (I, {wi}, {qi b}, {Fi b})) = o maxi D(((OE i,j , b)), i,j )b , aE ((OF , aF i,j , b)). j i,j * .\u00df \n(OE i,j )b i,j * .\u00df(OF In the above, in order to simplify notation, (OE is de.ned i,j )b as any padding \nellipsoid when OE i,j do not intersect [ b] . This is justi.ed by corresponding aE i,j , b) being zero. \ni,j * .\u00df(OE To complete the proof (for the loop-free case), we only need to show how to construct a dg \nsuch that for any such B-bounded (I, {wi}, {qi}, {Fi}), D((I, {wi}, {pi}, {Ei}), (I, {wi}, {qi}, {Fi})) \n< dg . D((I, {wi}, {p b i }, {Ei b}), (I, {wi}, {qi b}, {Fi b})) < E. This construction is somewhat involved \nand hence we skip it. Inter\u00adested readers will .nd the details in the technical report version of the \npaper [7]. Smooth expectation and probability The measures ai,j are used to compute a smooth approximation \nof the expected value. Recall that a sound upper approximation of the expected error can be computed \nas follows: E[xk] = (sup(dkEi))wi. i.I In the smooth approximation of this expression, we use the following \nexpression in place of sup((dkEi)): E#(k, (I, {wi}, {pi}, {Ei})) = wsup\u00df (k, {(Oi,j , ai,j )})wi \u00df i.I \n The function wsup\u00df is de.ned as follows. First, let Si = [(bi,l, aJ)] be a list that contains the supremums \nand in.mums i,L l of every d2 kOi,j with their respective measures; i.e., bi,2*j is the supremum and \nbi,2*j+1 the in.mum of coordinate k of ellipsoid Oi,j and they are both associated with ai,j . The function \nwsup\u00df is de.ned in terms of Si as follows. o bi,l aJ * bi,l * e \u00df i,L l 2 wsup\u00df (k, Ei) = l o bi,l aJ \n* e \u00df i,L l 2 l Note that as \u00df approaches 8, the function reduces to a weighted average of ellipsoid \ncenters weighted by ai. In the limit as \u00df approaches zero, on the other hand, the function converges \nto the supremum. This can be seen by considering the equivalent formula o bi,l-bmax ai,L l J * bi,l * \ne \u00df 2 wsup\u00df(k, Ei) = l o bi,l-bmax aJ * e \u00df i,L l 2 l where bmax is the maximum of the bi,l, i.e the \nactual supremum. When \u00df is close to 0, all the exponential coef.cients will converge to zero except for \nthe ones where bi,l = bmax, so the result will converge to bmax. Note that the universals elements should \nhave special handling bi,l \u00df here. Instead of using bi,l * e factors as for other ellipsoids on the numerator, \nwe use f(ai,l), where f is an increasing continuous function with the properties that f(0) = 0 and f(1) \n= 8. On the bi,l \u00df denominator, e are removed for universal elements. A smooth approximation to an upper \nbound on the probability of an event, speci.ed as an af.ne boolean expression b, is de.ned in a similar \nway: o o P# \u00df ([[b]]) = wi * ai,j * .\u00df (Oi,j , b) i.I j From the de.nition of these bounds and from Theorem \n5, we have: Theorem 6. For each \u00df > 0, the expressions E# \u00df and P# \u00df are continuous over bounded sets \nof abstract states. This in turn implies the continuity requirement that we de\u00admanded in Section 3: Theorem \n7 (Continuity of F# \u00df and .# \u00df ). Assuming programs are abstracted using smooth ellipsoids and that the \nabstraction of the # initial distribution is B-bounded for some B, the functions F\u00df (c) and .# \u00df (c) \nin Algorithm 1 are continuous. Example 6. To illustrate the effect of a, consider the following 1D example \nwhere ellipsoids become intervals. Consider two abstract states that are relatively close to each other \nA1 = (I = {0, 1}, {w0 = 0.4, w1 = 0.6}, {p0 = 1.0, p1 = 1.0}, {E0 = ([0, 1], 1.0), E1 = ([2, 3], 1.0)}) \nA2 = (I = {0, 1}, {w0 = 0.4, w1 = 0.6}, {p0 = 1.0, p1 = 1.0}, {E0 = ([0, 0.99], 1.0), E1 = ([2, 3], 1.0)}) \nNow, consider the following code if (x > 0.99) { x = x + 5; } else { x = x -5; } In the original discontinuous \ndomain, the state at the end of the conditional would be: [ P ]](A1) = (I = {0, 1}, {w0 = 0.4, w1 = 0.6}, \n{p0 = 1.0, p1 = 1.0}, {E0 = [-5, -4.01] . (5.99, 6], E1 = [7, 8]}) [ P ]](A2) = (I = {0, 1}, {w0 = 0.4, \nw1 = 0.6}, {p0 = 1.0, p1 = 1.0}, {E0 = [-5, -4.01], E1 = [7, 8]}) That means that under A1, the upper \nbound on the expected value will be 0.4 * 6 + 0.6 * 8 = 7.2, whereas the under the slightly different \nA2, the upper bound on the expected value is now 0.4 * -4.1 + 0.6 * 8 = 3.16. By contrast, under the \ncontinuous domain using \u00df = 10, the abstract states at the end of the program will be: [ P ]](A1) = (I \n= {0, 1}, {w0 = 0.4, w1 = 0.6}, {p0 = 1.0, p1 = 1.0}, {E0 = {([-5, -4.01], 1), ((5.99, 6], 0.01)}, E1 \n= ([7, 8], 1.0)}) [ P ]](A2) = (I = {0, 1}, {w0 = 0.4, w1 = 0.6}, {p0 = 1.0, p1 = 1.0}, {E0 = ([-5, -4.01], \n1.0), E1 = ([7, 8], 1.0)}) This means that the smooth upper bound over the expected value for [ P ]](A1) \nwill now be -0.401+0.01*5.99*e 0.599+0.01*6*e 0.6 0.4 * 1.0*-5*e -0.5+1.0*-4.01*e 1.0*e-0.5+1.0*e -0.401+0.01*e0.599+0.01*e0.6 \n0.7+8*e 0.8 +0.6 * 7*e e0.7+e0.8 = 2.87 and for [ P ]](A2) it will now be -0.5 -0.401 0.8 +-4.01*e 0.7+8*e \n0.4 * -5*e e-0.5+e-0.401 + 0.6 * 7*e e0.7+e0.8 = 2.76 so whereas the original sound approximation was \ndiscontinuous, the smoothed approximation changes only slightly when we make a small change to the input \ndistribution. As \u00df decreases, however, the smooth approximation approaches the sound bound, so for example, \nwith \u00df = 1, the approximate bounds will be 7.02 and  2.92 respectively.  Conservative merges and widening \nOne problem with the do\u00admain presented so far is that the representation of each Ei as a set of ellipsoids \ncan potentially double in size after every if-statement. The partial order in the discontinuous domain \ngives us some lee\u00adway to de.ne less precise merge functions that prevent some of this blowup. For example, \nmultiple ellipsoids can be replaced by a sin\u00adgle one that cover all of them without losing soundness. \nIn the case of the smooth domain, however, such an operation can potentially introduce discontinuity. \nOur approach described in this section fol\u00adlows the same strategy we followed to achieve continuity in \nthe original semantics. Namely, we introduce a smooth join operation, and show that the abstract semantics \nusing the parameterized join are continuous. Moreover, as \u00df goes to zero (and every a converges to one), \nthe operation converges to a sound join operation. In order to de.ne join, we de.ne an operation wcover({(Oi, \nai)}). The function s input is a non-empty multiset of weighted ellipsoids. Each ellipsoid Oi = (Mi, \nci) is represented by a matrix-vector pair as described earlier. The output (Oout, aout) is a single \nweighted ellipsoid with the following properties : o aout = min( ai, 1) i ai = 1 . Oi . Oout. In order \nto de.ne wcover, we .rst de.ne a function wadjust which adjust the size and position of each ellipsoid \nbased on its e aici weight. The output Oi Y is de.ned as follows. Let cout = ie ai be i the center of \ngravity of ellipsoid centers. Then, YYY Y Oi = (ai * Mi, ai * ci + (1 - ai) * cout) where ai Y = ai . \nNote that the uniform center of gravity max ai of resulting center is now cout. The ellipsoid Oout produced \nby wcover is then the Minimum Volume Enclosing Ellipsoid (MVEE) of the ellipsoids Oi Y . The computation \nof MVEE is performed using an adaptation of an algorithm by Jambawalikar and Kumar [15]. Fig. 4 illustrates \nthe merge process. Here, consider the ellipsoids labeled 2, 2 ' , and 2 '' . For ellipsoids 2 ' and 2 \n'' , a < 1; therefore, during the merge they are shrunk to the small, purple ellipsoids. Ellipsoid 2 \ndoes not shrink as a = 1 for it. Now we compute the MVEE of 2, 2 ' , and 2 '' , leading to the dashed \nred ellipsoid. This is the output of the merge. A similar process applies to ellipsoids 1, 1 ' , and \n1 '' . The universal elements are handled differently: they are com\u00adbined in a single universal element, \nwith ai combined as before. Now, let us add to our language a statement ABSTRACT , whose concrete semantics \nare equivalent to skip and whose ab\u00adstract semantics is de.ned as follows: [ ABSTRACT ]]((I, {wi}, {pi}, \n{Ei})) = (I, {wi}, {pi}, {wcover(Ei)}). We can prove that [ ABSTRACT] satis.es the inductive hy\u00adpothesis \nof Theorem 5. Furthermore, this is obviously sound on the discontinuous domain. Theorem 8 (Continuity \nof conservative merge). [ ABSTRACT ] maps bounded set of abstract states to bounded sets and is contin\u00aduous \nover bounded set of abstract states. In that case, Theorem 5 is preserved even if we add the conser\u00advative \nmerge operation ABSTRACT to our language. Now we do the same for loops. To get loops to converge, we \nneed a widen\u00ading strategy. Our strategy is very simple. After a constant num\u00adber of iterations, we widen \nour representation to the universal ele\u00adment, then apply [ ABSTRACT] . To be precise, we replace every \nellipsoid representation by the universal element before applying [ ABSTRACT] . Figure 4. Merge process \nNote that this strategy is equivalent to peeling the .rst k itera\u00adtions of the loop and then replacing \nthe rest of the loop with the statement WIDEN (while b do S) followed by ABSTRACT . This transformation \npreserves the concrete semantics and is sound for the discontinuous abstract semantics. We show that \nit does not break the continuity of the smooth semantics by showing that: Theorem 9 (Continuity of widening). \n[ WIDEN (while b do S)]] is continuous over abstract states and maps bounded sets to bounded sets. 4. \nImplementation and evaluation We conducted two case studies using our implementation of FER-MAT. The \ncase studies both come from the embedded control do\u00admain, and include the thermostat controller introduced \nin Section 2, and a model of an aircraft collision avoidance maneuver [24]. FERMAT uses the SKETCH program \nsynthesis infrastructure [31] to parse sketches into an AST which is then translated into a C++ program \nthat implements the smooth abstract semantics described earlier. For numerical search, FERMAT uses the \nNelder-Mead sim\u00adplex search [22] available in GNU Scienti.c Library (GSL) as the underlying local optimization \nmethod. Our two case studies were designed to help answer the follow\u00ading questions: 1. Does our algorithm \nreally compute better-quality parameters (i.e., parameters that lead to a lower upper bounds on average\u00adcase \nerror) than those computed by regular numerical search? Note that the outcome of any local search routine \ndepends on the starting point of the search, and we cannot expect our algorithm to perform better than \nthe competing approach on all starting points. Instead, it is the distribution of the expected error \nvalue, across starting points, that should interest us. The question is whether this distribution skews \nto lower expected error values. 2. In practice, what are the highest-quality proofs that the al\u00adgorithm \ncan .nd?  Consider a probabilistic assertion (B; 1 - .), which states that B is violated with probability \n< . . As . becomes smaller, one would expect the task of .nding parameters that provably satisfy this \nassertion to get harder. The question is to .nd the lowest value of . (an upper bound on the probability \nof asser\u00adtion failure ) for which different synthesis algorithms can .nd a parameter meeting this proof \ngoal. Naturally, this bound de\u00adpends on the start point of the search. The question is whether the distribution \nof the bounds computed using our algorithm is better than the distribution one would get running a less \nsophis\u00adticated technique. 3. In our method, a search for optimal parameters is interleaved with a search \nfor a boolean proof. Is this really needed, or could boolean goal for these parameters?  For each of \nthe two case studies, we compared three different approaches for parameter synthesis: Smoothed Proof \nSearch is the algorithm described in this pa\u00adper, where the synthesizer is using smoothed numerical search \nto .nd parameters that allow it to jointly optimize the expected .tness and the probability of assertion \nfailure.  Nelder-Mead with Abstract Interpretation uses a standard Nelder-Mead numerical search to jointly \noptimize the expected .tness and the probability of assertion failure as computed by the non-smoothed \nabstract interpretation presented earlier.  Nelder-Mead with Sampling also tries to jointly optimize \nthe expected .tness and the probability of assertion failure, but computes these by running the program \non a .xed sample of inputs drawn from the input distribution.  Using each of these approaches, we solved \nthe parameter syn\u00adthesis problem for the two problems 80 different times from differ\u00adent random starting \npoints in order to get a representative sample of the distribution of solutions that each of these three \nmethods can produce. The results of these experiments are summarized in Fig\u00adures 5, 6, 7 and 8. The rest \nof this section describes each of the benchmarks individually and discusses the results. Thermostat Recall \nour thermostat example, where the goal is to shift the tem\u00adperature of a room from an initial temperature \nlin to a target tem\u00adperature ltarget, and the sketch to be completed is as in Fig. 2. Here, lin and target \nare both probabilistic inputs. The distribu\u00adtion of lin is trimodal and bell-shaped with modes centered \nat 30, 35, and 50 and spread \u00b13. The distribution of ltarget is unimodal and bell-shaped, with mean 75 \nand spread \u00b11. The parameters to be synthesized are the temperatures tOn and tOff at which the heater \nrespectively switches off and on, and the heat h released in a time step. Our safety property states \nthat tOn is lower than tOff with high probability, and sets limits on the temperature of the room. Note \nthat the code in the .gure permits variables of discrete types. This is syntactic sugar. When such a \nvariable depends on the inputs, we just cast it to a real. Otherwise, the compiler encodes it using control \n.ow for example, the variable i in Fig. 2 is eliminated by unrolling the main loop to a depth of 40. \nFig. 5 shows the cumulative distribution function for the ex\u00adpected value of the .tness function for \nthe thermostat example for each of the three methods above. For each of these methods, we computed the \nexpected value in two ways: a) for the lines labeled Sampled expectation we computed the expected .tness \nby run\u00adning the synthesized algorithms on a random sample of inputs. And b) for the lines labeled Proved \nexpectation we plotted the upper bound of the expected value as computed with abstract interpre\u00adtation. \nFig. 6, shows the probability of assertion failure as proved by abstract interpretation for the solutions \ngenerated by the three methods. Together these two graphs allow us to answer the three questions as they \napply to the thermostat benchmark. The results are surprising at .rst sight; Fig. 5 shows that Nelder-Mead \nwith sampling is able to produce parameters with better aver\u00adage .tness than any of the methods that \nrely on abstract interpreta\u00adtion, whether smoothed or not. However, while the parameters led to good \nbehavior in practice, the resulting implementations were dif.cult to analyze, leading to the huge gap \nbetween their empiri\u00adcally observed behavior and the probabilities that can be proved for these implementations. \nThis is reinforced by Fig. 6; for the meth\u00adods where the search used abstract interpretation, the proved \nprob\u00adability of assertion failure was close to zero for most instances; by contrast, of the implementations \ngenerated by Nelder-Mead there were 60 that had probabilities of failure greater than 2.5%, and a full \n10 that had probabilities of failure higher than 50 Of the two methods that use the results of abstract \ninterpreta\u00adtion, we .nd that smoothed numerical proof was able to produce better results both in terms \nof their empirically evaluated .tness as well as in the bounds on the expected .tness can prove. The \ndiffer\u00adences are not very big, but they are statistically signi.cant. Using the Wilcoxon signed-rank \ntest, we computed a p-value of 0.027 for the for the expectation upper bound determined empirically and \na p-value of less than 0.01 for the proved bounds respectively, sup\u00adporting the hypothesis that smoothing \nhelped us .nd better param\u00adeters. In the case of the probability of assertion failure, the differ\u00adence \nbetween smooth and non-smooth search was not statistically signi.cant (p-value of 0.25). So in short, \nwe were able to .nd good bounds for the probability of failure (Question 2), and the use of smoothing \nhad an effect on the .tness of the solutions we got, but not on the probability of assertion failure \n(Question 1). Aircraft collision avoidance In this problem, we want to synthesize parameters for an air\u00adplane \nthat performs maneuvers to avoid a collision with a sec\u00adond plane [24]. The controller has four control \nstates called CRUISE, LEFT, STRAIGHT, and RIGHT. Normally, our plane .ies in the CRUISE control state. \nIf it gets within a distance d(x1, y1, x2, y2) < criticalDist of the other plane, then it starts .ying \nleft (in the LEFT state) at an angle of 45., continu\u00ading for delay number of timesteps. Then it .ies \nSTRAIGHT for a while. After delay2 steps it turns RIGHT, comes back to its original course, and changes \nstate back to CRUISE (see Fig. 10). Our error value here is the total delay, as in an idealized setting, \nour airplane returns to its course immediately. Our safety assertions set a minimum distance between \nthe two planes, and ensure that the plane does not start the maneuver too early or too late. \n\t\t\t", "proc_id": "2535838", "abstract": "<p>We present a new technique for parameter synthesis under boolean and quantitative objectives. The input to the technique is a \"sketch\" --- a program with missing numerical parameters --- and a probabilistic assumption about the program's inputs. The goal is to automatically synthesize values for the parameters such that the resulting program satisfies: (1) a {boolean specification}, which states that the program must meet certain assertions, and (2) a {quantitative specification}, which assigns a real valued rating to every program and which the synthesizer is expected to optimize.</p> <p>Our method --- called <i>smoothed proof search</i> --- reduces this task to a sequence of unconstrained smooth optimization problems that are then solved numerically. By iteratively solving these problems, we obtain parameter values that get closer and closer to meeting the boolean specification; at the limit, we obtain values that provably meet the specification. The approximations are computed using a new notion of <i>smoothing</i> for program abstractions, where an abstract transformer is approximated by a function that is continuous according to a metric over abstract states.</p> <p>We present a prototype implementation of our synthesis procedure, and experimental results on two benchmarks from the embedded control domain. The experiments demonstrate the benefits of smoothed proof search over an approach that does not meet the boolean and quantitative synthesis goals simultaneously.</p>", "authors": [{"name": "Swarat Chaudhuri", "author_profile_id": "81309496839", "affiliation": "Rice University, Houston, TX, USA", "person_id": "P4383800", "email_address": "swarat@rice.edu", "orcid_id": ""}, {"name": "Martin Clochard", "author_profile_id": "86158990257", "affiliation": "ENS Paris and Universit&#233; Paris-Sud (LRI and Inria Saclay), Paris, France", "person_id": "P4383801", "email_address": "martin.clochard@lri.fr", "orcid_id": ""}, {"name": "Armando Solar-Lezama", "author_profile_id": "81100173160", "affiliation": "Massachusetts Institute of Technology, Cambridge, MA, USA", "person_id": "P4383802", "email_address": "asolar@csail.mit.edu", "orcid_id": ""}], "doi_number": "10.1145/2535838.2535859", "year": "2014", "article_id": "2535859", "conference": "POPL", "title": "Bridging boolean and quantitative synthesis using smoothed proof search", "url": "http://dl.acm.org/citation.cfm?id=2535859"}