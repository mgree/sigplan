{"article_publication_date": "01-08-2014", "fulltext": "\n Authenticated Data Structures, Generically Andrew Miller, Michael Hicks, Jonathan Katz, and Elaine Shi \nUniversity of Maryland, College Park, USA Abstract An authenticated data structure (ADS) is a data structure \nwhose operations can be carried out by an untrusted prover, the results of which a veri.er can ef.ciently \ncheck as authentic. This is done by having the prover produce a compact proof that the veri.er can check \nalong with each operation s result. ADSs thus support outsourcing data maintenance and processing tasks \nto untrusted servers without loss of integrity. Past work on ADSs has focused on particular data structures \n(or limited classes of data structures), one at a time, often with support only for particular operations. \nThis paper presents a generic method, using a simple exten\u00adsion to a ML-like functional programming language \nwe call . (lambda-auth), with which one can program authenticated oper\u00adations over any data structure \nde.ned by standard type construc\u00adtors, including recursive types, sums, and products. The program\u00admer \nwrites the data structure largely as usual and it is compiled to code to be run by the prover and veri.er. \nUsing a formalization of . we prove that all well-typed . programs result in code that is secure under \nthe standard cryptographic assumption of collision\u00adresistant hash functions. We have implemented . as \nan extension to the OCaml compiler, and have used it to produce authenticated versions of many interesting \ndata structures including binary search trees, red-black+ trees, skip lists, and more. Performance experi\u00adments \nshow that our approach is ef.cient, giving up little compared to the hand-optimized data structures developed \npreviously. Categories and Subject Descriptors D.3.3 [Programming Lan\u00adguages]: Language Constructs and \nFeatures Data types and struc\u00adtures General Terms Security, Programming Languages, Cryptogra\u00adphy 1. Introduction \nSuppose data provider would like to allow third parties to mirror its data, providing a query interface \nover it to clients. The data provider wants to assure clients that the mirrors will answer queries over \nthe data truthfully, even if they (or another party that compromises a mirror) have an incentive to lie. \nAs examples, the data provider might be providing stock market data, a certi.cate revocation list, the \nTor relay list, or the state of the current Bitcoin ledger [22]. Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. Copyrights for components of this work owned by others than the author(s) \nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. Request permissions from \npermissions@acm.org. POPL 14, January 22 24, 2014, San Diego, CA, USA. Copyright is held by the owner/author(s). \nPublication rights licensed to ACM. ACM 978-1-4503-2544-8/14/01. . . $15.00. http://dx.doi.org/10.1145/2535838.2535851 \n Such a scenario can be supported using authenticated data structures (ADS) [5, 24, 31]. ADS computations \ninvolve two roles, the prover and the veri.er. The mirror plays the role of the prover, storing the data \nof interest and answering queries about it. The client plays the role of the veri.er, posing queries \nto the prover and verifying that the returned results are authentic. At any point in time, the veri.er \nholds only a short digest that can be viewed as summarizing the current contents of the data; an authentic \ncopy of the digest is provided by the data owner. When the veri.er sends the prover a query, the prover \ncomputes the result and returns it along with a proof that the returned result is correct; both the proof \nand the time to produce it are linear in the time to compute the query result. The veri.er can attempt \nto verify the proof (in time linear in the size of the proof) using its current digest, and will accept \nthe returned result only if the proof veri.es. If the veri.er is also the data provider, the veri.er \nmay also update its data stored at the prover; in this case, the result is an updated digest and the \nproof shows that this updated digest was computed correctly. ADS computations have two properties. Correctness \nimplies that when both parties execute the protocol correctly, the proofs given by the prover verify \ncorrectly and the veri.er always receives the correct result. Security1 implies that a computationally \nbounded, malicious prover cannot fool the veri.er into accepting an incorrect result. Authenticated data \nstructures can be traced back to Merkle [18]; the well-known Merkle hash tree can be viewed as providing \nan authenticated version of a bounded-length array. More recently, au\u00adthenticated versions of data structures \nas diverse as sets [23, 27], dictionaries [1, 12], range trees [16], graphs [13], skip lists [11, 12], \nB-trees [21], hash trees [26], and more [15] have been proposed. In each of these cases, the design of \nthe data structure, the supporting operations, and how they can be proved authentic have been recon\u00adsidered \nfrom scratch, involving a new, potentially tricky proof of security. Arguably, this state of affairs \nhas hindered the advance\u00adment of new data-structure designs as previous ideas are not easily reused or \nreapplied. We believe that ADSs will make their way into systems more often if they become easier to \nbuild. This paper presents . (pronounced lambda auth ), a language for programming authenticated data \nstructures. . represents the .rst generic, language-based approach to building dynamic authen\u00adticated \ndata structures with provable guarantees. The key observa\u00adtion underlying . s design is that, whatever \nthe data structure or operation, the computations performed by the prover and veri.er can be made structurally \nthe same: the prover constructs the proof at key points when executing a query, and the veri.er checks \na proof by using it to replay the query, checking at each key point that the computation is self-consistent. \n. implements this idea using what we call authenticated types, written t , with coercions auth and unauth \nfor introducing and eliminating values of an authenticated type. Using standard func\u00ad 1 This property \nis sometimes called soundness but we eschew this term to avoid confusion with its standard usage in programming \nlanguages.  tional programming features, the programmer writes her ADS s datatype de.nition and its \ncorresponding operations (e.g., queries and updates) to use authenticated types. For example, as we show \nlater in the paper, the programmer could write an ef.cient authen\u00adticated binary search tree using the \n(OCaml-style) type de.nition type bst = Tip | Bin of bst \u00d7 int \u00d7 bst along with es\u00adsentially standard \nroutines for querying and insertion. Then, given such a program, the . compiler produces code for both \na prover and a veri.er that will produce or con.rm, respectively, a proof of the correct execution of \nthe corresponding operation. Proofs con\u00adsist of a stream of what we call shallow projections of the data \nthe prover visits while running its routine: the prover s code adds to this stream at each unauth call, \nwhile the veri.er s code draws from the stream at the corresponding call, checking for consistency. We \ngive a more detailed overview of how this approach works, and how authenticated types are represented, \nin Section 2. Importantly, as we show in Sections 3 and 4, any well-typed program written in . compiles \nto a prover and veri.er which are correct and secure, where security holds under the standard cryptographic \nassumption of collision-resistant hash functions. 2 . provides two key bene.ts over prior work. First, \nit is ex\u00adtremely .exible. We can use . to implement any dynamic data structure, both queries and updates, \nexpressible using ML-style data types (involving sums, products, and recursive types). Our theoretical \ndevelopment, though not our implementation, also sup\u00adports authenticated functions. Previous work by \nMartel et al. [17] can also be used to build DAG-oriented ADSs, but it supports only queries and not \n(incremental) updates, requires the data structure have a single root, and does not support authenticated \nfunctions. . s .exibility does not compromise its performance. To the best of our knowledge the asymptotic \nperformance of every prior ADS construction from the literature based on collision-resistant hash\u00ading \ncan be matched by . . We have implemented an optimizing . compiler as an extension to the OCaml compiler \n(described in Section 5), and using it we have implemented Merkle trees, au\u00adthenticated binary search \ntrees, red-black+ trees, skip lists, and pla\u00adnar separator trees, as well as improvements to standard \nBitcoin data structures. Experiments described in Section 6 con.rm the ex\u00adpected asymptotic performance \nof . ADSs, show the bene.t of the two compiler optimizations we implemented (which exploit space/\u00adtime \ntradeoffs), and demonstrate that the performance of . ADSs is competitive with hand-rolled versions. \n. s second main bene.t is ease of use. We .nd that it is rela\u00adtively simple to construct an ADS using \n. : just write the standard data structure in a purely functional style, and sprinkle in authenti\u00adcated \ntypes; we give a .avor for this in the next section. Pleasantly, there is no need for the ADS designer \nto prove anything: Assuming the resulting program type checks, the programmer is assured that the produced \nprover and veri.er code enjoy both correctness and security. By contrast, Martel et al. [17] provide \nno such support; programmers must write and check their implementations manu\u00adally. . ADSs can be freely \ncomposed and customized just as one might expect with normal data structures, a fact which we hope will \nmake them more readily deployable. All of this is in contrast to the state of practice with ADSs today, \nsummarized in Section 7, which tends to favor hand-rolled versions that are hard to build, customize, \nand compose. In summary, this paper makes the following contributions: 1. We present . , a purely functional \nlanguage in which one can write a rich array of authenticated data structures using a novel feature we \ncall authenticated types. 2 Informally, hash is collision-resistant if it is computationally infeasible \nto .nd distinct inputs x, x' such that hash(x) = hash(x'). We treat this more formally in Section 4.4. \n Figure 1. A Merkle tree and proof p for fetch(2) describing the highlighted path (with bold edge and \nnode outlines). 2. We formalize the semantics and type rules for . and prove that all well-typed . programs \nproduce ADS protocols that are both correct and secure. 3. We have implemented . as an extension to \nthe OCaml com\u00adpiler3 and used it to program a variety of existing and new ADSs, showing good asymptotic \nperformance that is compet\u00aditive with hand-rolled implementations.  2. Overview This section presents \nan overview of our approach. We begin by describing Merkle trees, the canonical example of an authenticated \ndata structure. Then we give a .avor for . by showing how we can use it to implement Merkle trees. We \nconclude with a discussion of the .exibility and ease-of-use bene.ts of using . to write ef.cient authenticated \ndata structures. 2.1 Background: Merkle trees The canonical example of an ADS is a Merkle tree [19], \nwhich is the authenticated version of a full binary tree where data is stored at the leaves but not the \ninterior nodes. A Merkle tree of height h can represent an array of n = 2h-1 elements, x0, ..., xn-1. \nEach leaf node is coupled with a digest that consists of the hash of the associated element, while each \ninternal node contains a digest that is the hash of the concatenation of the digests of its two children. \nA depiction of a Merkle tree for h = 3 is given in Figure 1. Each leaf is associated with a string str0, \nstr1, etc. Each node is numbered according to its position in the tree, with x, y indicating x as the \nrow and y as the column. The canonical Merkle-tree query fetches the value xi at index i . [0, n - 1]. \nWhen thus queried, the prover (call it P ) returns the value xi along with the set of digests p needed \nto compute the root digest. The veri.er (call it V ) keeps a copy of the root digest itself, and checks \nthe proof by recomputing this digest from the proof to make sure the two match. Figure 1 shows the proof \np for a fetch at position i = 2 (i.e., the leaf at position N 0, 2). It consists of three elements in \nsequence, the string str2, the hash h7, and the hash h2; these are labeled with the salient nodes of \nthe tree that they relate to. Veri.cation proceeds bottom up: V computes the hash of str2, which is h6, \nand concatenates that with the hash h7 provided in p. It then concatenates these two and takes the hash \nto compute what should be the digest for node N1, 1, i.e., h3. Then it concatenates h2, the hash for \nN1, 0 provided in p, with its computed digest for N1, 1 and hashes the result. It then con.rms that this \ncomputed digest equals h1, the digest it stores for the whole tree. Performance analysis. Because the \ntree is perfectly balanced, the size of the proof is always log2 n; additionally the computational cost \nfor each of P and V is log2 n. The overall size of the data structure stored by P is O(n), whereas V \nat no point requires more than a constant amount of storage or memory. In particular, V only stores a \nconstant-sized digest of the tree between fetch operations, 3 The full open-source code for our implementation \nis available at the following URL: http://www.cs.umd.edu/~amiller/gpads/  type tree = Tip of string \n| Bin of tree \u00d7 tree type bit = L | R let rec fetch (idx:bit list) (t: tree) : string = match idx, unauth \nt with | [], Tip a . a | L :: idx, Bin(l, ) . fetch idx l | R :: idx, Bin( ,r) . fetch idx r Figure \n2. Merkle trees in . . The tree is assumed to be complete, i.e., with a power-of-two number of leaves. \nand because V processes each (constant-sized) hash in order, it can discard it immediately after it is \nread. For this reason, we often refer to p as a proof stream. Security analysis. As described in the \nIntroduction, we are inter\u00adested in two properties of this scheme. Correctness says that when P executes \na query f over a tree t correctly, then V gets the same result as it would have if it had just computed \nf (t) normally. The second property, security, says that a computationally bounded, cheating prover P \n* cannot cause V to accept an incorrect answer. The basis of this property is the use of collision-resistant \nhashes: we can show that if P * can cause V to accept an incorrect answer then the proof returned by \nP * will yield a collision. We state these properties precisely, in the context of . , in Section 4. \n 2.2 Introducing . , a language for programming ADSs The Merkle tree veri.cation procedure was carefully \ndesigned with the properties of the underlying data structure in mind. In particular, there can be but \none path from the root to a given leaf, and from this path we can determine digests suf.cient to recompute \nthe root digest. The question is: how might we generalize this approach to arbitrary data structures \nt involving arbitrary computations f? We designed . as a solution to this problem. . is a completely \nstandard, purely functional programming language extended with authenticated types t , along with coer\u00adcions \nauth and unauth, which have type .a.a . a (for intro\u00adducing authenticated values) and type .a. a . a \n(for eliminat\u00ading authenticated values), respectively. A function f using authen\u00adticated types is compiled \nto variations fP and fV for the prover and veri.er, respectively. Data of type t stored at the prover \nis like a normal value of type t but augmented with digests, while data of type t stored at the veri.er \nis simply a compact digest. The auth/unauth coercions at the prover facilitate proof genera\u00adtion, while \nat the veri.er they check a provided proof. In short, . s design exploits the observation that proof \ngeneration and proof veri.cation can be made structurally identical essentially by piggy\u00adbacking them \non top of the ideal computation of f(t). Example. As an illustration, Figure 2 shows a version of Merkle \ntrees written in our OCaml-based . implementation. The type tree is simply a binary tree with strings \nstored at the leaves. The fetch function takes an index expressed as a list of bits, which is interpreted \nas a path through the tree, with L bits directing the traversal to the left, and R bits directing it \nright. The function returns the string associated with the Tip that is eventually reached. Notice that \nsince the argument t has type tree, the function must call unauth t to coerce it to a tree to be matched \nagainst (we give a use of auth in Section 2.3). Interpretation of authenticated types. All standard constructs \nhave the usual semantics in both fP and fV , but authenticated types are interpreted differently. Prover \nFor fP , values of type t consist of pairs (h, v) where v has type t and h is its digest, i.e., a hash \nof the shallow pro-Figure 3. A . Merkle tree t at the prover (of type tree from Figure 2) and proof stream \np for query fetch t [R; L]. Hashes of relevant shallow projections are given in the lower right. jection \nof v. The shallow projection of a value is just the value itself for all values of type t that do not \nconsist of any authen\u00adticated types t0, while the shallow projection of an authenti\u00adcated value (h, v) \nis just the digest h (the formal de.nition is in Figure 9). Looking at the de.nition of type tree in \nthe .g\u00adure, we can see that recursive references to the tree in the Bin case are authenticated. As such, \nthe prover s representation is just as described in the previous subsection: each node of the tree has \nthe form Bin((h1, v1), (h2, v2)), which consists of the left subtree v1 and its digest h1, and the right \nsubtree v2 and its digest h2. Each digest consists of the hash of the shallow projection of its respective \ntree. So, if v1 was a leaf Tip(s), the shallow projection is just Tip(s) itself, and thus h1 is the hash \nof Tip(s). On the other hand, suppose v1 was a node Bin((h11, v11), (h12, v12)). Then Bin(h11, h12) is \nthis node s shallow projection, and h1 is its digest. Veri.er For fV , values of type t consist solely \nof the digest h of some value of type t . As such, for our example, while the prover maintains the entire \ntree data structure, the veri.er only keeps the digest of the root. In general, values in fV are the \nshallow projections of their corresponding values in fP ; we de.ne this notion formally in the next section. \nTurning to the coercions, for both the prover and veri.er the auth v coercion computes the hash h of \nthe shallow projection of v; for the prover, this hash is paired with v while the veri.er retains only \nh itself. The interesting part is the semantics of unauth. For the prover, unauth is called with (h, \nv) and it simply returns v. In addition, it computes the shallow projection of v and adds it to the proof \np, which is just a list of such shallow projections. We often refer to p as a proof stream to emphasize \nthe list structure. For the veri.er, unauth takes a hash h and compares it to the hash of the element \ns at the head of the proof stream, which should be a shallow projection of type t. If all is well, this \nelement is the one the Prover put there and so the hashes will match and the coercion returns s. Otherwise \nthere is a problem and veri.cation fails. Example Merkle-tree query. Figure 3 depicts the prover s ver\u00adsion \nof an object of type tree corresponding to the Merkle tree from Figure 1. These trees are structurally \nsimilar but not identical; in particular, notice that a node s digest is stored with the pointer to that \nnode, rather than at the node itself. Suppose the prover ex\u00adecutes the query (fetch [R; L] t), which \ncorresponds to the query from Section 2.1. The .gure also depicts the proof stream p it pro\u00adduces, along \nwith the hashes of shallow projections of relevant tree elements. The .rst thing the prover will execute \nis unauth t, which returns the pointer to the .rst node, and stores its shallow projec\u00adtion Bin(h2,h3) \nin the proof stream notice that this is the same as the pointed-to node but the sub-tree pointers have \nbeen dropped. Execution continues to the third case of the match, which recur\u00adsively calls (fetch [L] \nr), where r is bound to the authenticated value (h3, v) such that v is the right subtree. The prover \nthen invokes unauth on this pair, returning v and adding Bin(h6,h7) to the proof stream. This time we \ntake the second case of the match, recursing on (h6, Tip(str2 )), so the call to unauth returns Tip(str2 \n) and adds its shallow projection (Tip(str2 ) itself) to the proof stream. Execution concludes with str2 \nas the .nal result while the .nal proof stream p consists of three elements, representing the three nodes \nvisited.  The veri.er begins with the proof stream p and just the digest of t, which is h1. It then \nruns (fetch [R; L] t) using its version of the code. It .rst executes unauth h1, which compares h1 to \nthe hash of the .rst element s0 of the proof stream, which is Bin(h2,h3). The hashes match, as per the \nequations given in the lower right of the .gure, and thus execution continues using s0. Execution proceeds \nto the third case of the match, recursively calling fetch with [L] and h3. This time, calling unauth \nh3 results in comparing h3 to the hash of the second element in the proof stream, which is Bin(h6,h7), \nand once again the hashes match and the proof stream element is returned. The second branch of the match \n.res, so the recursive call passes [] and h6. Finally, unauth h6 compares h6 to the hash of the .nal \nelement of the proof stream, Tip(str2 ), which is returned as the hashes match. Thus execution concludes \nwith the .nal result as str2 . As all hash checks succeeded, the veri.er has con.rmed the prover s execution \nis correct. Analysis. . Merkle trees are asymptotically as ef.cient as the originals, and as secure. \nAs before, the veri.er maintains only the constant-sized digest between queries, and the size of the \nfetch proof and the time to generate and verify it is O(log2 n): the proof stream consists of one (constant-size) \nshallow projection for each recursive call to fetch. The argument for security once again rests on collision-resistant \nhashes, though . veri.cation checks the root digest top-down rather than bottom-up. Our proof stream \nhas some redundancy (it contains hashes h2, h3, h6, and h7, whereas in Figure 1 the proof contains only \nh2 and h7) but this is only a constant factor and can be optimized away (cf. Section 5.2).  2.3 Discussion: \nBene.ts of . The primary bene.t of writing ADSs in . over prior approaches is .exibility and ease of \nuse. . can support essentially any com\u00adputation over a DAG-oriented data structure that is expressed \nas a functional program. Moreover, as proved in Section 4, writing an ADS in . ensures it is both correct \nand secure; there is no need for a designer to make a new argument for each new data struc\u00adture. As far \nas we are aware, . can be used to implement any previously proposed ADS based on collision-resistant \nhashing. As described in Section 6, so far we have successfully implemented Merkle trees and authenticated \nversions of binary search trees, red\u00adblack+ trees [24], skip lists [29], and variations of the Bitcoin \nblock chain [22], all of which enjoy asymptotically identical, or better, performance than their specially-designed \ncounterparts. Support for updates. Martel et al. [17] also previously proposed a general-purpose scheme \nthat supports ADSs based on DAGs. In principle, their scheme could also support the above-mentioned data \nstructures, but only for query computations, not updates. By contrast, updates are completely natural \nin . . For example, the function update in Figure 4 updates a Merkle tree. The veri.er could submit a \nrequest to the prover to run (update [R; L] t str4 ). The prover will produce a proof stream p for the \noperation along with a new authenticated tree t ' that contains the modi.cation, and which shares much \nof the structure of the original tree t, as per standard functional programming style. The prover can \nthen update its root to now be t ' and then send the veri.er the result of the execution, which is the \ndigest portion of t ' and the proof stream let rec update (idx:bit list) (t: tree) (newval:string) : \ntree = match idx, unauth t with | [], Tip . auth(Tip newval) | L::idx , Bin(l,r) . auth(Bin(update idx \nl newval, r)) | R::idx , Bin(l,r) . auth(Bin(l, update idx r newval)) let update cps (idx:bit list) (t: \ntree) (newval:string) : tree = let rec update (k : ( tree . tree)) idx t x : tree = match idx, unauth \nt with | [], Tip . (unauth k) (auth(Tip x)) | L :: idx , Bin(l,r) . update (auth(fun t . auth(Bin(t,r)))) \nidx l x | R :: idx , Bin(l,r) . update (auth(fun t . auth(Bin(l,t)))) idx r x in update (auth(fun t . \nt)) idx t newval type stack = E | SL of stack \u00d7 tree | SR of stack \u00d7 tree let update stk (idx:bit list) \n(t: tree) (newval:string) : tree = let rec build idx t (s:stack) : tree \u00d7 stack = match idx, unauth t \nwith | [], Tip . auth(Tip newval), s | L::idx , Bin(l,r) . build idx l (SL(auth s, r)) | R::idx , Bin(l,r) \n. build idx r (SL(auth s, l)) in let rec apply (child: tree, s:stack) : tree = match s with | E . child \n| SL(s, r) . apply (auth(Bin(child, r)), unauth s) | SR(s, l) . apply (auth(Bin(l, child)), unauth s) \nin apply (build idx t E) Figure 4. Functions for updating a Merkle tree in . . p. The veri.er can then \nuse p in the usual way to verify that (the digest of) t ' is indeed the right result and then update \nits local root.4 Controlling performance. The fact that . is a general-purpose programming language means \nthat it affords substantial .exibility to the ADS designer in customizing an ADS design to her needs. \nAs one possible customization, the designer might refactor op\u00aderations to better control space usage. \nConsider the update func\u00adtion once again. While the proof stream contributes only a constant space overhead, \nsince the veri.er can discard each element after it is read, we observe that executing update will require \nO(log n) stack space, since the function is not tail recursive. One way to eliminate this overhead is \nto rewrite update in continuation-passing style (CPS) such that the continuation itself is authenticated, \nas for the function update cps given in the middle of Figure 4. As such, recursive uses of nested continuations \nwill be replaced with a hash, effectively bounding the depth of the stack encoded in the continu\u00adation. \nTo the best of our knowledge, no prior work has considered authenticated closures. Another way to achieve \nthe same effect, but perhaps less elegantly, is to use an explicit authenticated stack as is done by \nupdate stk given at the bottom of the .gure. The designer could also tune performance by adjusting the \nde.nition of the data structure itself. For example, we could have de.ned Merkle trees instead as follows: \ntype tree = Tip of string | Bin of (tree \u00d7 tree) In this case, we are only hashing nodes, and will never \nhash tips. This de.nition makes more sense when the hash of the Tip is larger 4 In general, the prover \nwill return the shallow projection of the result of a computation back to the veri.er; when the result \nis a normal value the prover will thus return the value itself (as with the result in our (fetch [R; \nL] t) example query).  Types t ::= 1 | t1 . t2 | t1 + t2 | t1 \u00d7 t2 | \u00b5a.t | a | t Values v ::= () | \nx | .x.e | rec x..y.e | inj1 v | inj2 v | (v1, v2) | roll v Exprs e ::= v | let x = e1 in e2 | v1 v2 \n| case v v0 v1 | prj1 v | prj2 v | unroll v | auth v | unauth v Figure 5. Syntax for types and terms \nthan the representation of Tip itself, e.g., if the tree stored integers instead of strings. As another \nvariation, we might imagine de.ning a tree that only optionally authenticates its children: type tree \n= | Tip of string | Bin of tree \u00d7 tree | AuthBin of (tree \u00d7 tree) Then the tree might go several levels \nusing Bin before using Au\u00adthBin. This design thus increases the constant factor on asymptotic space usage, \nbut may reduce proving/veri.cation time. All of these customizations are possible, and easy to experiment \nwith, thanks to the fact that . is a general-purpose programming language. However, this .exibility cuts \nboth ways: there is nothing (at the moment) stopping the programmer from producing a subop\u00adtimal design. \nAs an extreme example, the programmer could write type tree = Tip of string | Bin of tree \u00d7 tree i.e., \nwithout any use of authenticated types! This design will be secure and correct, as with every . program, \nbut will effectively require the veri.er to maintain the entire tree, not simply a digest. Fortunately, \nthere is a simple rule of thumb that may have already become evident to the reader by this point: the \ndata-structure type de.nition should authenticate recursive references, thus aiming for shallow projec\u00adtions \nto be constant-sized. We leave to interesting future work the task of automating the transformation of \na -free type de.nition to an ef.cient authenticated one. 3. . : A Language with Authenticated Types This \nsection formalizes . , our language for writing computations over authenticated data structures. We present \nthe syntax, typing rules, and operational semantics for . programs. The next section proves that . computations \nproduce correct and secure results. 3.1 Syntax Figure 5 presents the syntax for . . Other than authenticated \ntypes t , the type language is entirely standard, consisting of the unit type 1, function types t1 . \nt2, sum types t1 + t2, product types t1 \u00d7 t2, recursive types \u00b5a.t , and variable types a arising from \nthese. In this syntax, our authenticated tree type de.ned in Figure 2 would be written \u00b5a.string + ( \na \u00d7 a), where string would itself be encoded, e.g., as a list of Peano-style integers. Our formal language \ndoes not include parametric polymorphism for simplicity, but adding it would present no dif.culties. \nThe language does not support references because mutations would risk invalidating hashes for t values. \nIn particular, given an authenticated value (h, v) where v is a reference, a mutation via v may invalidate \nh. Terms (values v and expressions e) are in administrative normal form [7] to keep the semantics simple. \nIn this form, the grammar forces us to write let x = e1 in let y = e2 in x y instead of the more familiar \ne1 e2, for example. In addition to variables x, the term language includes functions .x.e and function \napplication v1 v2; sum-type values inj1 v and inj2 v which are eliminated by case v v0 v1, where v0 and \nv1 are expected to be functions; G f v : t1 G f v : t2 G f inj1 v : t1 + t2 G f inj2 v : t1 + t2 G f \nv : t1 + t2 G f v1 : t1 . t G f v2 : t2 . t G f case v v1 v2 : t G f v : t G f v : t G f auth v : t G \nf unauth v : t Figure 6. Selected typing rules products (v1, v2) eliminated by expressions prj1 v and \nprj2 v; values of recursive type introduced via roll v and eliminated by unroll v; and .nally .xpoints \nrec x..y.e for de.ning recursive functions (where inside of .y.e references to x refer to the function \nitself). Authenticated types t are introduced by coercion auth and eliminated by unauth. 3.2 Typing \nThe typing judgment for . programs is the usual one, written G f e : t. It states that expression e has \ntype t under environment G, where G is a map from variables x to types t. Typing rules for most constructs \nare standard. Selected rules are given in Figure 6.  3.3 Operational semantics In practice, our compiler \ntakes a program like the one in Figure 2 and outputs versions to be run by the prover and the veri.er. \nIn our formalization, we de.ne distinct semantics for the same program, as determined by an execution \nmode m, where m = P for the prover s execution, and m = V for the veri.er s. We also de.ne a mode I for \nthe Ideal case, representing a computation that happens in the normal way, ignoring authenticated types; \nthis is needed for stating the security and correctness properties. We de.ne a small-step operational \nsemantics of the form \u00ab p, e \u00bb .m \u00ab p ' , e ' \u00bb, where m is the mode and p is the proof stream, which \nis a list of shallow projections s. This can be read: An expression e coupled with a proof stream p can \nevaluate one step in mode m to produce an expression e ' and an updated proof stream p ' . We de.ne \u00ab \np, e \u00bb .i \u00ab p ' , e ' \u00bb to be the transitive m multi-step application of the single-step relation; it \nstates that e evaluates, in i steps, to e ' in mode m, starting with proof stream p and .nishing with \np '. The proof stream is produced in mode P , so p is a pre.x of p ' in this mode. The stream is consumed \nin mode V , and thus p ' is a suf.x of p. The proof stream is ignored in mode I. We use the operator \n@ to denote the concatenation of two proof streams, treating @ as associative with the empty stream [] \nas the identity. We write [s] as the singleton stream containing element s. The rules for standard language \nfeatures are identical in all three modes, and are standard. They are de.ned in the top portion of Fig\u00adure \n7, and we discuss them brie.y in order. The rule for function application, (.x.e) v, substitutes v for \nx in e this substitution is written e[v\\x]. Application of a recursive function is similar: when the \nfunction (rec x..y.e) is on the left-hand side of an application, we substitute x in the function body \ne with the recursive function itself. Let-binding is used to sequence computations, either evaluat\u00ading \nthe bound expression e1 one step or else, if this expression is a value v1, substituting that value for \nx in the body e2. The semantics of case depends on whether it is given inj1 v or inj2 v; in the former \ncase we substitute v in the .rst lambda term (the true branch ), else we substitute it in the second \n( false ) one. Projection from a pair (v1, v2) produces v1 for prj1 and v2 for prj2. Finally, the recursive \ntype coercions unroll and roll nullify each other.  \u00ab p, (.x.e) v \u00bb .m \u00ab p, e[v\\x] \u00bb \u00ab p, (rec x..y.e) \nv \u00bb .m \u00ab p, (.y.e ' ) v \u00bb where e ' = e[(rec x..y.e)\\x] \u00ab p, let x = v1 in e2 \u00bb .m \u00ab p, e2[v1\\x] \u00bb \u00ab \np, case (inj1 v)(.x.e1)(.x.e2) \u00bb .m \u00ab p, e1[v\\x] \u00bb \u00ab p, case (inj2 v)(.x.e1)(.x.e2) \u00bb .m \u00ab p, e2[v\\x] \n\u00bb \u00ab p, prj1 (v1, v2) \u00bb .m \u00ab p, v1 \u00bb \u00ab p, prj2 (v1, v2) \u00bb .m \u00ab p, v2 \u00bb \u00ab p, unroll (roll v) \u00bb .m \u00ab p, \nv \u00bb \u00ab p, e1 \u00bb .m \u00ab p ' , e 1 ' \u00bb \u00ab p, let x = e1 in e2 \u00bb .m \u00ab p ' , let x = e1 ' in e2 \u00bb \u00ab p, e \u00bb .i \n\u00ab p ' , e ' \u00bb m ' ' '' '' \u00ab p ,e \u00bb .m \u00ab p ,e \u00bb \u00ab p, e \u00bb .0 \u00ab p, e \u00bb '' '' m \u00ab p, e \u00bb .i+1 \u00ab p ,e \u00bb m \nFigure 7. Standard single-step and multi-step operational rules \u00ab p, auth v \u00bb .I \u00ab p, v \u00bb \u00ab p, unauth \nv \u00bb .I \u00ab p, v \u00bb \u00ab p, auth v \u00bb \u00ab p, unauth (h, v) \u00bb \u00ab p, auth v \u00bb .P .P .V \u00ab p, (hash ([v]), v) \u00bb \u00ab p \n@ [ ([v]) ], v \u00bb \u00ab p, hash v \u00bb hash s0 = h \u00ab [s0] @ p, unauth h \u00bb .V \u00ab p, s0 \u00bb where v ::= . . . | \nh | (h, v) Figure 8. Operational rules for authenticated values ([()]) = () ([x]) = x ([(h, v)]) = h \n([.x.e]) = .x.([e]) ([auth v]) = auth ([v]) ([unauth v]) = unauth ([v]) ([(v1, v2)]) = (([v1]), ([v2])) \n([prji v]) = prji ([v]) ([roll v]) = roll ([v]) ([unroll v]) = unroll ([v]) ([rec x..y.e]) = rec x.([.y.e]) \n([inji v]) = inji ([v]) ([case v v0 v1]) = case ([v]) ([v0]) ([v1]) ([let x = e1 in e2]) = let x = ([e1]) \nin ([e2]) Figure 9. Shallow projection of an expression e, written ([e]) The rules for the multi-step \nrelation are given at the bottom of Figure 7, and are also standard. The operational rules for authenticated \nvalues are given in Fig\u00adure 8. For mode I, authenticated values of type t are merely val\u00adues of type \nt and the auth/unauth operations are no-ops. For mode P , values of type t are implemented as a pair \n(h, v) of a hash h and a value v (of type t). As shown in the auth rule, the hash is computed by applying \na hash function hash over the shal\u00adlow projection of v, written ([v]). We do not formalize the semantics \nof hash explicitly; in practice it can be implemented by serializ\u00ading the value it is given and hashing \nthat using a collision-resistant hash function.5 The shallow projection operation is de.ned in Fig\u00ad 5 \nFor functions .x.e, serialization involves pretty-printing the function s code such that alpha-equivalent \nfunctions will have the same hash value. We discuss implementing authenticated functions more in Section \n5.3. ure 9. It is essentially a fold over the structure of the term, preserv\u00ading that structure in every \ncase but that of values (h, v): here we simply drop the value v and retain the hash h. Another interesting \ncase is functions .x.e: we recursively descend into e to translate any (h, v) values that appear there. \nSuch values will not appear in source programs, but they can arise via substitution under lambdas. Returning \nto Figure 8, the mode-P semantics of unauth (h, v) is to strip off the hash, returning v, while adding \nthe shallow projec\u00adtion of v to the end of the proof stream. Finally, for mode V the representation of \nt is the hash h of a value of type t. The auth rule constructs this representation, while the unauth \nrule checks that the hash value matches the shallow projection at the head of the proof stream. 4. Metatheory \nWe want to show that well-typed . programs will (a) produce correct results that is, results that all \nthree modes agree on or else (b) a malicious prover has been able to .nd a hash collision, which by assumption \nis computationally dif.cult. We call property (a) correctness and property (b) security. In this section \nwe state and prove these two properties. 4.1 Type Soundness To begin, we want to prove that . s design \nis sensible in that the ideal semantics is sound (and entirely ordinary). We can prove the standard type \nsoundness lemma about the ideal mode s semantics. Lemma 1 (Type Soundness). If G f e : t, then either \ne is a value, or there exists e ' and i > 0 such that \u00ab [], e \u00bb .i I \u00ab [], e ' \u00bb and G f e ' : t . Proof. \nThe proof is completely standard, using progress and preser\u00advation lemmas, and inducting on \u00ab [], e \u00bb \n.i I \u00ab [], e ' \u00bb.  4.2 Agreement Now we must de.ne what we mean when we say that the different execution \nmodes agree on their results it cannot be that these results are syntactically equal because each mode \ninterprets authen\u00adticated values differently. For example, consider the update func\u00adtion from Figure \n4. In the ideal setting, this function will return a normal tree v because t values are the same as those \nof type t , the tree v will contain no digests. On the other hand, the prover will return a value (h, \nvP ), where h is the digest of vP . For the same insertion on the same tree, the results v and (h, vP \n) in I and P modes, respectively, should agree without being equal: v will just be a normal tree, while \nvP will contain digests but the elements and sub-trees, excepting the digests, should be the same. And, \nrun\u00adning the insertion at the veri.er will return a digest h, which should match the digest in the prover \ns returned value (h, vP ). We formalize this connection as a three-way type-indexed rela\u00adtion G f e eP \neV : t, given in Figure 10, which states: in envi\u00adronment G, ideal expression e, prover expression eP \n, and veri.er expression eV all agree at type t . In every case but that of authen\u00adticated values (the \nlast rule), agreement follows syntactic structure of the terms, and the shape of each rule matches that \nof the standard type rules. The rule for authenticated values formalizes the intuition given above; it \nstates that G f v (h, vP ) h : t holds when (a) the digest h of both the prover and veri.er is the same; \n(b) this digest is the hash of the shallow projection of the prover s value vP ; (c) the prover s value \nvP agrees with the ideal value v. Now we prove some useful facts about terms in agreement. Lemma 2 (Agreement). \nSuppose G f e eP eV : t. Then 1. ([eP ]) = eV . ''' ' 2. G f e e e : t implies that e = eP and eV = eV \n. PV P  G f () () () : 1 G(x) = t G f x x x : t G, x:t1 f e eP eV : t2 G f (.x.e) (.x.eP ) (.x.eV ) \n: t1 . t2 G f v1 v1P v1V : t1 . t2 G f v2 v2P v2V : t1 G f (v1 v2) (v1P v2P ) (v1V v2V ) : t2 G f e1 \ne1P e1V : t1 G, x:t1 f e2 e2P e2V : t2 G, x:t1 . t2 f (.y.e) (.y.eP ) (.y.eV ) : t1 . t2 G f (let x = \ne1 in e2) (let x = e1P in e2P ) (let x = e1V in e2V ) : t2 G f (rec x..y.e) (rec x..y.eP ) (rec x..y.eV \n) : t1 . t2 G f v vP vV : t1 G f v vP vV : t2 G f (inj1 v) (inj1 vP ) (inj1 vV ) : t1 + t2 G f (inj2 \nv) (inj2 vP ) (inj2 vV ) : t1 + t2 G f v vP vV : t1 + t2 G f vP v1P v1V : t1 . t G f vV v1V v2V : t2 \n. t G f v1 v1P v1V : t1 G f v2 v2P v2V : t2 G f (case v v1 v2) (case vP v1P v2P ) (case vV v1V v2V ) \n: t G f (v1, v2) (v1P , v2P ) (v1V , v2V ) : t1 \u00d7 t2 G f v vP vV : t1 \u00d7 t2 G f v vP vV : t1 \u00d7 t2 G f \nv vP vV : t [\u00b5a.t \\a] G f (prj1v) (prj1 vP ) (prj1 vV ) : t1 G f (prj2 v) (prj2 vP ) (prj2 vV ) : t2 \nG f (roll v) (roll vP ) (roll vV ) : \u00b5a.t G f v vP vV : \u00b5a.t G f v vP vV : t G f (unroll v) (unroll \nvP ) (unroll vV ) : t [\u00b5a.t \\a] G f (auth v) (auth vP ) (auth vV ) : t G f v vP vV : t f v vP ([vP ]) \n: t hash ([vP ]) = h G f (unauth v) (unauth vP ) (unauth vV ) : t G f v (h, vP ) h : t Figure 10. Agreement \nrelation: de.nes those expressions that agree (i.e., that are morally, if not syntactically, the same) \nin the Ideal, Prover, and Veri.er modes. The most interesting rule is the last one, while the rest are \nthree-way versions of the standard type rules. 3. G f e : t 4. Either e, eP , and eV are all values, \nor none of them are.  Proof. By induction on G f e eP eV : t . The .rst part shows the agreement relation \nis intimately con\u00adnected to the shallow projection operator a prover s term only ever agrees with a veri.er \ns term when the latter is the shallow pro\u00adjection of the former. Moreover, we prove for any given ideal \nterm e, there is at most one pair of terms eP and eV that agree with it under a given environment G and \ntype t, that agreement implies e is well-typed, and that values only agree with other values. Client \nand server agree. In a client/server application scenario, a query/update sent by the client will reference \nthe data structure stored at the server using a free variable, e.g., the t in the query fetch t 4. To \nrun this query on the server, we substitute the prover s representation for t, while to verify the result \nat the client, we substitute t s digest. These representations should agree. The fol\u00adlowing lemma states \nthat, given an expression e containing free variables with authenticated types, substituting authenticated \nval\u00adues that agree for the free variables of e produces versions eI , eP , and eV that also agree. Lemma \n3. Given the following: 1. G f e : t where e contains no values of type t 2. For all xi . domain(G), \n (a) G(xi) = ti for some ti (b) f vi (hi, vP i ) hi : ti for some (hi, vi) and vP i   3. eP = e[(h1, \nvP 1)\\x1]...[(hn, vP n )\\xn] eV = e[h1\\x1]...[hn\\xn] eI = e[v1\\x1]...[vn\\xn] Then f eI eP eV : t. The \nproof of this lemma follows from straightforward applica\u00adtion of the following substitution lemma: Lemma \n4 (Substitution). If G, x:t ' f e eP eV : t and f v vP vV : t ', then G f (e[v\\x]) (eP [vP \\x]) (eV [vV \n\\x]) : t. Proof. The proof is by induction on G, x:t ' f e eP eV : t . The only interesting case is when \nG, x:t ' f v ' P ) (h, v ' h : t . The '' ' empty environment in the premise f v vP ([vP ]) : t ensures \n' ' that v and vP contain no variables, so the substitution will be the identity and the result follows \nby assumption.  4.3 Correctness and Security Now we can state and prove our main theorem, Theorem 1, \nwhich encapsulates the two properties of interest, correctness and secu\u00adrity. For both properties, we \nstart with the assumption that terms e, eP , and eV agree (which will be the case at the start of evalu\u00adating \na query/update as per Lemma 3). The ideal-mode evaluation represents the speci.cation of correctness: \nif e can evaluate to e ' in ideal mode in i steps, then the veri.er, when consuming the proof stream \np produced by the prover s evaluation of eP , should evalu\u00adate to some eV ' which (along with the prover \ns resulting term eP ' ) agrees with e '. On the other hand, if the veri.er does not consume p but rather \nsome other, adversarially chosen stream pA that does not contain p as a pre.x (e.g., because the server \nis behaving ma\u00adliciously or incorrectly), then the only way the veri.er can accept an incorrect result \nis if the adversary has found a hash collision. That is, the consumed stream pA contains an element s \n that corre\u00adsponds to an element s in p such that s but hash s = hash s = s .  As discussed further \nin Section 4.4, this implies the standard cryp\u00adtographic notion of security for this setting if hash \nis collision\u00adresistant. Here is the theorem, stated formally: Theorem 1. Suppose that f e eP eV : t . \nCorrectness: If \u00ab [], e \u00bb .i I \u00ab [], e ' \u00bb then there exist eP ' , eV ' , p such that \u00ab [], eP \u00bb .i \u00ab \np, e ' \u00bb P P \u00ab p, eV \u00bb .i \u00ab [], e ' \u00bb V V '' ' f e eP eV : t Security: If \u00ab pA, eV \u00bb .i V \u00ab p ' , e ' \n\u00bb then V 1. there exist e ' , eP ' , p, such that \u00ab [], e \u00bb .i I \u00ab [], e ' \u00bb  \u00ab [], eP \u00bb .i \u00ab [] @ \np, e ' \u00bb  P P pA = p @ p ' '' ' f e eP eV : t 2. or else there exist j = i, eP ' , p0, s and s such \nthat ' \u00ab [], eP \u00bb .j \u00ab [] @ p0 @ [s], e \u00bb P P pA = p0 @ [s ] @ p '  s = s but hash s = hash s . \n The proof is by induction on the length i of the multi-step derivations, relying on two lemmas about \nthe Correctness and Se\u00adcurity of single-step evaluation, which we present next. Lemma 5 (Correctness). \nIf f e eP eV : t and \u00ab [], e \u00bb .I \u00ab ' '' [], e \u00bb then there exist eP , eV , and p such that for all p \n' , pp '' ' 1. f e eP eV : t 2. \u00ab pp, eP \u00bb .P \u00ab pp @ p, e ' \u00bb  P 3. \u00ab p @ p ' , eV \u00bb .V \u00ab p ' , e V \n' \u00bb. Proof. By induction on f e eP eV : t. Most cases are straight\u00adforward, and follow by application \nof the Substitution lemma. The two interesting cases deal with authenticated computations: Suppose e, \neP , and eV are auth v, auth vP and auth vV , respectively. Each can take a step in its respective mode, \npro\u00adducing v, (hash ([vP ]), vP ), and hash vV , respectively, leaving the proof stream unchanged (i.e., \np = []). Now we must prove f v (hash ([vP ]), vP ) hash vV : t, which in turn requires proving f v vP \n([vP ]) : t and hash ([vP ]) = hash vV . Both are the consequence of Lemma 2.1 and f e eP eV : t .  \nSuppose e, eP , and eV are unauth v, unauth vP and unauth vV , respectively. By inversion on f e eP eV \n: t we know that f v (h, vP ) h : t and by inversion on this we know f v vP ([vP ]) : t and h = hash([vP \n]). We can set p = [([vP ])], and then each term can take a step in its respective mode to v, vP , and \n([vP ]), which agree by Lemma 2.1.  Finally, we demonstrate that a veri.er term that begins in agree\u00adment \nand takes a step remains in agreement unless an adversary has managed to .nd a hash collision. Lemma \n6 (Security). Given the following: f e eP eV : t  \u00ab pA, eV \u00bb .V \u00ab p ' , e V ' \u00bb  then there exist \ne ' , eP ' , and p such that for all pp, \u00ab [], e \u00bb .I \u00ab [], e ' \u00bb  \u00ab pp, eP \u00bb .P \u00ab pp @ p, e ' \u00bb  \nP and either '' ' 1. f e eP eV : t and pA = p @ p ', or else 2. there exists a pair s and s such that \np = [s] and pA = [s ] @ p ' with s = s but hash s = hash s . Proof. By induction on f e eP eV : t . \nSince eV is not a value, we know from Lemma 2.4 that neither are e or eP , so we can always introduce \ne ' and eP ' . Most cases are straightforward because '' ' evaluation yields p = [] and pA = p ', and \nf e eP eV : t can be obtained directly from inversion on f e eP eV : t . The remaining cases are for \nlet binding and unauth. The former follows by induction. For the latter we have e, eP , and eV are unauth \nv, unauth vP and unauth vV , respectively. Since these terms agree by assumption, we know that vP (h, \nv ' = P ) and ' ' vV = h = hash([vP ]) for some vP . From the stepping rule for ' .P , we know p = [([vP \n])]. Then there are three possible outcomes depending on pA: 1. pA = [], or pA = [s ] @ p ' and hash \ns = h, in which case \u00ab pA, eV \u00bb is stuck and we have a contradiction ' '' 2. pA = [([vP ])] @ p ' and \neV = ([vP ]), from which '' ' f e eP eV : t follows directly ' ' 3. pA = [s ] @ p ' and ([vP ]) = s , \nbut hash ([vP ]) = hash s . Although the Security property guarantees that the ideal com\u00adputation can \nalways take as many steps as the veri.er (in particular, the veri.er cannot run forever if the ideal \ncomputation terminates), we would also like to show that ideal computation can take as many steps as \nthe prover. Remark 1. Suppose f e eP eV : t and .i ' ' \u00ab pp, eP \u00bb \u00ab pp @ p, e ' \u00bb. Then there exists \ne , e PP V ''' ' such that f e e e : t , \u00ab [], e \u00bb .i \u00ab [], e \u00bb, and PV I \u00ab p, eV \u00bb .i \u00ab [], e ' \u00bb. V \nV Proof. This follows from straightforward induction on derivation length i and f e eP eV : t , applying \nLemmas 2 and 5.  4.4 Cryptographic Security In the cryptographic security de.nition for a .xed ADS protocol, \n(e.g., as per Papamanthou et al. [25]), somewhat informally, there is an attacker who is assumed able \nto control the interaction be\u00adtween an honest prover and veri.er. The attacker may specify a se\u00adquence \nof operations ( queries ) q1, . . . , qt that the veri.er poses to the prover. For each such query, the \nprover generates and sends a proof to the veri.er; both parties update their local state as ap\u00adpropriate. \nFinally, the attacker speci.es a query qt+1 along with an adversarially generated proof string pA; the \nattacker succeeds if pA causes the veri.er to output an incorrect result for the given query. The ADS \nis parameterized by a security parameter k which we may identify with the output length of the hash function \nbeing used. The ADS is secure if no attacker running in polynomial time (in k) succeeds with non-negligible \nprobability. Security is proven by contradiction with the collision-resistance of an appropriately chosen \nhash function. To translate the standard cryptographic notion to our setting, we must address three technicalities. \nFirst, we must provide a notion of programs and inputs, such that the ADS is speci.ed by an arbitrary \n. program, and the adversary is allowed to choose the inputs. Second, in order to show contradiction \nwith collision-resistance, we must de.ne a speci.c procedure by which the hash function is instantiated \nafter the ADS program and the adversary are .xed. Finally, we must relate the number of reduction steps \ntaken by a . program to a number of steps taken by a Turing machine. We then claim that the reduction \nargument in Theorem 1 implies that this security de.nition holds for every . program.  Inputs. We can \ntreat the free variables in an open . expression as program inputs. In our running example, for instance, \nthe ex\u00adpression fetch idx t has idx and t as free variables. The adversary chooses the inputs by computing \nwell-typed and in-agreement val\u00adues to substitute for each of the free variables. Choosing the hash function. \nOur language is parameterized by an arbitrary hash function, which we have assumed is collision\u00adresistant. \nHowever, to be precise, collision-resistance is only de\u00ad.ned formally for a family of hash functions \nrather than some .xed hash function (see Katz and Lindell [14]). That is, collision\u00adresistance is de.ned \naccording to the following game: First, take an arbitrary adversary that runs in polynomial-time given \na security parameter k. Next, choose hash randomly from a family of func\u00adtions, and give the adversary \na description of hash as input. The family of hash functions is collision-resistant if the the adversary \noutputs a collision in hash with negligible probability in k. The following game captures this notion \nin the context of . : 1. Let e be an arbitrary well-typed . program specifying the data structure being \nsupported, and let A be an arbitrary adversary that runs in polynomial-time (in k). 2. Choose hash at \nrandom from a collision-resistant family of k\u00adbit hash functions, and then compile eP and eV . 3. A \nsucceeds if, given k and hash as input, it outputs in\u00adagreement values to substitute for the free variables \nof e, eP , and eV , and a proof stream pA, such that after some polyno\u00admial of steps i, the veri.er outputs \nan incorrect answer; i.e., a value eV ' such that \u00ab pA, eV \u00bb .i A, e ' \u00bb for some  V \u00ab p ' V '' ' p \n' A, but there is no e , eP such that \u00ab [], e \u00bb .i I \u00ab [], e \u00bb '' ' and f e eP eV : t . Note that the \ngame begins with an arbitrary well-typed . program e, before the hash function has been chosen. Although \n. is parameterized by hash, the ideal terms are invariant to the choice of hash function, so we can .x \ne and G f e : t before choosing hash. However, the prover and veri.er terms eP and eV may actually contain \ndigests, so we must instantiate hash before compiling eP and eV . If A succeeds, then by Theorem 1 we \ncan evaluate eP and eV (on pA) for j = i steps, and extract the collision s and s . Thus, it only remains \nfor us to show that evaluation of eV and eP also takes polynomial time, and then we can obtain from A \na polynomial-time collision-.nding algorithm with the same success probability. Polynomial-time execution. \nIt is well known that standard lambda-calculus evaluation and Turing-machine execution are polynomially \nequivalent [4]; that is, a lambda-calculus interpreter implemented as a Turing machine can simulate i \nlambda-calculus evaluation steps in O(poly(i)) Turing-machine steps. The only nonstandard terms in . \nare auth and unauth, and each involves at most one hash computation during evaluation. The time to com\u00adpute \na hash is proportional to the size of the serialized shallow projection, which depends on the hash output \nlength k. Therefore, if an ideal program e takes i steps to reach a value, a Turing ma\u00adchine can simulate \nthe execution of e in O(poly(i)) steps and the corresponding eP and eV in O(poly(ik)) steps. Since we \nassume i is bounded by O(poly(k)), the entire evaluation is O(poly(k)). 5. Implementation This section \ndescribes our prototype extension to the OCaml com\u00adpiler for supporting authenticated types. We discuss \nbasic compila\u00adtion,6 two optimizations we implement, and current limitations. 6 Our technique for extending \nthe OCaml compiler is based on a 2012 blog post by Jun Furuse: https://bitbucket.org/camlspotter/ compiler-libs-hack \n 5.1 Compilation The compilation process works as follows. The programmer writes an OCaml program p like \nthat of Figure 2 that contains uses of authenticated types. The code will link against the ADS module, \nwhose signature declares a as abstract7 and declares the (poly\u00admorphic) types of the auth and unauth \ncoercions. Program p is then passed to our extended compiler which, depending on a command-line mode \n.ag, replaces each application of auth and unauth it .nds with a call to a prover-or veri.er-speci.c \nimple\u00admentation; the resulting code is linked with the ADS module. This module, given in Figure 11, de.nes \ntype a as either a digest (just the hash, represented as a string), or as a pair of the hash and a value \nof type a. The next four functions de.ne the prover s and veri.er s versions of auth and unauth, respectively; \nthe calls to auth and unauth will be replaced by calls to these functions instead. We can see that their \ncode largely matches the operational rules given in Figure 8, where the proof stream from the rules is \nimplemented as OCaml channels, prf output and prf input. The one departure is that auth prover and unauth \nprover addition\u00adally take a function shallow that is invoked to perform the shal\u00adlow projection operation. \nThis operation is needed because OCaml does not provide a generic method for folding/mapping over the \nstructure of a term. As such, our compiler generates type-speci.c shallow projection functions where \nneeded, and includes them in the replaced calls to auth and unauth. The type of the shallow projection \noperator is determined by the concrete type inferred at each auth/unauth call. For example, the unauth \nin let x : int = unauth y is inferred to have type int . int. Therefore, we need a shallow projection \noperation of type int . int (which is just the identity). The generated code will refer to the ADS module \ns shallow function, shown at the bottom of the .gure, for handling (nested) authenticated values. Library \nfunctions are provided to enable the programmer to ma\u00adnipulate the proof and veri.cation streams, for \nexample by writ\u00ading/reading to a .le or a socket, or performing multiple authenti\u00adcated operations with \nseparate proofs in a single execution. Figure 12 shows the result of compiling a variant of authenti\u00adcated \nbinary search trees. The top of the .gure is the code provided by the programmer. Compilation will replace \nthe call to auth with a call to auth bst1 and the call to unauth with a call to unauth bst. These functions \nare de.ned at the bottom of the .gure, and employ the needed, type-speci.c shallow projection operations. \nThe hash function referenced in Figure 11 is polymorphic, having type .a.a . string. It is implemented \nby .rst serializing the argument and then hashing it using SHA1 (which is widely used as a collision-resistant \nhash function). For serialization, we use OCaml s default serializer imple\u00admented in the Marshal module. \nThis choice has an implication for security: the worst-case cost to compute the hash of a mali\u00adcious \nstring is bounded only by the representation of an integer in OCaml, either 32 or 64 bits, depending \non the OS. We used the no-sharing option for the Marshal module to guarantee that any two equal objects \nhave equal serializations.8 7 Type a is written in ASCII as a authtype, but we continue writing a for \nconsistency. 8 It may be the case that two terms of different types have equal serializa\u00adtions using \nMarshal; however, since we only interpret serialized values ac\u00adcording to known static types (no polymorphism), \nit would take a collision at the same type to harm security. In our formalism, which is essentially dynamically \ntyped, we assume serialization (encased in the abstract hash function) is bijective.  type a = | Digest \nof string (* the digest *) | Prover of string \u00d7 a let auth prover (shallow: a . a) (v:a) : a = Prover(hash \n(shallow v), v) let unauth prover (shallow: a . a) (v: a) : a = let Prover( ,x) = v in to channel !prf \noutput (shallow x); let auth veri.er (v:a) : a = Digest(hash v) let unauth veri.er (v: a) : a = let Digest(h) \n= v in let y = from channel !prf input in assert h = hash y; y let shallow (Prover(h, ): a) : a = Digest(h) \nFigure 11. The implementation of type constructor and the Prover and Veri.er s unauth and auth coercions. \n(* User-provided code *) type bst = Tip | Bin of bst \u00d7 int \u00d7 bst | AuthBin of (bst \u00d7 int \u00d7 bst) let is \nempty (t: bst) : bool = (unauth t = Tip) let mk leaf (x:int) : bst = AuthBin(auth(Tip, x, Tip)) (* Generated \nProver code *) let rec shallow bst : bst . bst = function | Tip . Tip | Bin (x, y, z) . Bin(shallow \nx, y, shallow z) | AuthBin (x) . AuthBin (shallow bst1 x) and shallow bst1 : bst \u00d7 int \u00d7 bst . bst \u00d7 \nint \u00d7 bst = function (x, y, z) . (shallow bst x, y, shallow bst z) let unauth bst = unauth prover shallow \nbst let auth bst1 = auth prover shallow bst1 Figure 12. Example types and generated code (for prover) \n 5.2 Optimizations Our compiler implements two optimizations that reduce the size of the proof stream, \nreuse buffering, and suspended disbelief. Reuse buffering. We can reduce the size of the proof stream, \nand speed up proving/veri.cation, when we anticipate that the same elements may appear in the proof stream \nmore than once. For example, a client may submit a batch of operations to the server that end up re-traversing \nmany of the nodes of the ADS. The client could cache the shallow projections of these elements locally \ninstead of reading them from the proof stream multiple times. This optimization requires modifying the \nunauth and auth functionality; the modi.cation is simlar for both prover and veri\u00ad.er. A counter is incremented \neach time auth or unauth is called. Each party maintains two data structures: LRU-Map, a mapping from \nauth/unauth counter values to shallow projections, indicat\u00ading the least-recently-used ordering, and \nDigest-Map, a mapping from digests to auth/unauth counter values; collectively Digest-Map and LRU-Map \nare referred to as the cache, as they contain corresponding elements. When unauth is called, if the digest \nex\u00adists in Digest-Map, the prover omits (resp., veri.er fetches from the cache) the corresponding shallow \nprojection, then updates the counter value associated with it in the cache; otherwise, the prover appends \nit to (resp., veri.er reads it from) the proof stream and adds it to the cache. If the size of the cache \nexceeds the parameter, then the least recently used element (the smallest key in LRU-Map) is removed. \nThe proof generation/checking/size bene.ts come at the cost of having to store the cache. Suspending \ndisbelief. This optimization eliminates redundancy in shallow projections that contain hashes computable \nfrom nested shallow projections appearing subsequently in the proof stream. This idea is implicit in \nthe veri.cation procedure for Merkle trees (Section 2.1). We can approximate the optimization for arbitrary \ndata structures in . by modifying unauth (for both the prover and veri.er) to use a buffer to suspend \ndisbelief. For the prover, the goal is to decide which digests in a shallow projection can safely be \nomitted, which are those that correspond to nodes that will be visited during subsequent calls to unauth. \nTo achieve this, we extend the representation for a values: type a = ... | Susp of string \u00d7 a \u00d7 bool \nref | Sentinel Each time unauth is called, the shallow projection is com\u00adputed differently: each immediate \nchild, Prover(d,a), would or\u00addinarily be replaced with Digest(d) but is instead replaced with Susp(d,a,.ag), \nwhere .ag is a fresh mutable .ag (initially false) that indicates whether the digest can be omitted. \nWhen one of these children is accessed by unauth the corresponding .ag is set. Rather than writing the \nshallow projection immediately to the proof stream, it is appended to a queue. The queue is .ushed when \nexecu\u00adtion reaches a programmer-inserted insist annotation. This is a hint that belief need no longer \nbe suspended; its placement has no ef\u00adfect on security but it is best used at the end of a distinct operation. \nBefore a queue element is added to the proof stream, occurrences of Susp(d,a,.ag) are (functionally) \nreplaced with Sentinel when !.ag is true, and replaced with Digest(d) when !.ag is false. When the veri.er \nencounters a shallow projection object in the proof stream containing Sentinel values, its digest cannot \nbe computed immediately so the object is stored in a set referred to as the suspended-disbelief buffer. \nIf unauth is subsequently called on an immediate child of a node in this buffer, even if the shallow \nprojection is available in the proof stream, the root hash is unknown so it cannot be immediately validated \neither. Thus we extend the a representation again with a new tag, Suspension. type a = ... | Suspension \nof string ref \u00d7 (unit . unit) For every object placed in the buffer, each immediate Sentinel is replaced \nwith a Suspension containing a callback closure and a mutable reference (initially empty) optionally \ncontaining a hash. When a leaf node is accessed, the Suspension reference is updated with the actual \ndigest of the leaf, and the callback is invoked. The callback encapsulates a pointer to the parent node, \nand checks if all immediate Suspension children have been populated with digests. If so, the callback \nremoves the node from the buffer, computes the node s digest, and takes one of two actions: if the reference \nalready contains a digest, then the two are compared for equality; if not, then the reference is updated \nwith the computed digest, and the callback closure is invoked. Thus validation propagates upwards from \nthe leaves to the root. A caveat of this optimization is that it exposes the veri.er to potential resource \nexhaustion attacks, as (potentially in.nite) computation is performed on untrusted data before it is \nvalidated. A solution would be to bound the number of steps the program should take before the buffer \nis cleared. Another caveat is that this optimization requires additional storage on the veri.er in contrast \nto the original Merkle tree optimization.  5.3 Supporting full OCaml Our compiler prototype supports \nauthenticating the OCaml equiv\u00adalent of the type language given in Figure 5 with the exception of function \ntypes. This support has been suf.cient to program a vari\u00adety of interesting data structures, as described \nin the next section. To implement authenticated functions requires that we be able to perform the shallow \nprojection of a lambda term. Our formal\u00adism does this by folding over the syntax of the lambda term s \nbody to .nd authenticated values (h, v) and replace them with values h. In an implementation this operation \nis tantamount to transform\u00ading a closure s environment. We could do this quite naturally using Siskind \nand Pearlmutter s map-closure operator [30], but unfor\u00adtunately (as they point out) it is not clear how \nto implement this operator in a statically typed language, since the compiler cannot, in general, know \nthe types of a given closure s environment vari\u00adables. We could imagine storing type information with \nthe closure (e.g., Crary et al s [3] term representations for types) in support of a generic, run-time \nshallow projection operation as per the formal\u00adism. In the meantime, the most natural use of authenticated \nclosures we have found is to support shallow CPS transformations; we can use an explicit stack to the \nsame effect, as shown in Figure 4. Among other OCaml features not yet supported, the most desir\u00adable \nis authenticated polymorphic types. Similarly to closure envi\u00adronments, the compiler cannot know types \nneeded to perform shal\u00adlow projection if a value given to auth and unauth is polymor\u00adphic, then its type \nis determined by how type variables are instan\u00adtiated at a particular call-site. Once again, a generic \nshallow pro\u00adjection operator as per our formalism (and easily implemented in a dynamically typed language) \nwould .t the bill. We could imag\u00adine requiring that auth and unauth each take an additional type parameter; \nin most cases it could be statically determined, but to support polymorphism it could be passed as an \nargument, e.g., to the polymorphic function containing the auth/unauth call. 6. Evaluation To demonstrate \nthe effectiveness and generality of our language and compiler, we have implemented a variety of ADSs. \nWe ana\u00adlyze their performance and con.rm it empirically with benchmarks for selected algorithms. Our \nbenchmarks were conducted using an Amazon EC2 m1.xlarge instance (an Intel E5645 2.4GHz proces\u00adsor, with \n16GB of RAM). All data structures were stored in RAM. Complete code is given in our extended technical \nreport [20]. Merkle trees. Our version of Merkle trees was given in Figure 2. As Merkle trees are the \nmost common authenticated data structure, and are readily implemented, we compared the running time of \nour compiled veri.er routine to hand-written implementations in OCaml and in C (see Figure 13(c)). The \nbenchmark consists of 10,000 random accesses to trees of height h for h . [5, 19]. Each array element \nis a 1024 byte string; thus the largest tree contains approximately 250, 000 elements and stores approximately \n250 MB of data in total. Compared to the hand-optimized version in C, the program generated by our compiler \nis slower by only a factor of two; the hand-written OCaml code is about 30% slower than the C program. \nPro.ling with gprof reveals that substantial overhead is due to the Marshal serialization routine used \nby our compiler; the hand-written OCaml code avoids this serialization by concatenating the child digests \ndirectly. Red-black+ Trees. A red-black+ tree is a self-balancing binary tree the + indicates that internal \nnodes only store keys, and the values are stored only in the leaves. This data structure is appropri\u00adate \nfor a (updatable) dictionary. We consider authenticated search trees to be the second oldest authenticated \ndata structure, proposed by Naor and Nissim [24] to implement certi.cate revocation lists. Our results \nare asymptotically equivalent: the storage cost to the prover for the entire data structure is O(n), \nwhile the computation cost per operation for both prover and veri.er is O(log n); the size of the proof \nstream is also O(log n). Note that we also implement an authenticated version of normal binary search \ntrees, too, and these also have the expected performance. In Figure 13(a), we show the empirical runtime \nperformance of the authenticated red-black+ tree for both the prover (P ) and veri\u00ad.er (V ) modes, as \nwell the ideal mode with the annotations and unauth/auth commands erased, to show the overall computational \noverhead of authentication. The benchmark consists of 100, 000 random insertions into a random tree containing \n2k elements, for each k . [4, 21]. P runs approximately 25% faster than V ; this is because V computes \na hash during both unauth and auth in\u00adstructions whereas P only computes a hash during auth. Accord\u00ading \nto pro.ler analysis (using gprof), V spends 55% of its time in the SHA1 hash routine and 30% in (de)serialization \nroutines; P spends 28% of its time computing SHA1, 30% performing se\u00adrialization and 22% in garbage collection. \nThe overhead of P is approximately a factor of 100 compared to the ordinary data struc\u00adture. We omit \nsimilar benchmarks for our other algorithms as the results are similar. We measured the largest amount \nof memory allocated by OCaml during this benchmark as shown in Figure 13(b). This illus\u00adtrates the key \nadvantage of an authenticated data structure scheme: while P incurs space overhead by a factor of 3 vs \nthe Ideal mode, the space requirement of the V is effectively constant. Finally, we used this benchmark \nto evaluate the effectiveness of our two compiler optimizations on proof size (see Figure 13(d)). For \na binary tree, the suspended-disbelief buffer results in a proof\u00adsize reduction of almost 50%, since \nonly one of the left or right child digests must be transmitted for each node. The reuse cache is most \neffective when the tree is small and mostly .ts in the cache; thus since the cache-size parameter in \nour benchmark is 1000, the proof is nearly empty up to trees of height 9. However, because the benchmark \nconsists of random queries, the leaves and nodes toward the bottom are accessed almost uniformly at random, \nso only a constant number of nodes near the root are read from the cache each query. The cache would \nbe more bene.cial in applications where some nodes were accessed much more frequently. We only implemented \nthe two optimizations separately; combining the two is left as future work. Skip Lists. Skip lists [29] \nare randomized data structures provid\u00ading similar performance (in expectation) to binary search trees.9 \nOur results are asymptotically equivalent to previous work on au\u00adthenticated skip lists [12]: the storage \ncost to P for the entire data structure is O(log n), where n is the number of elements inserted; the \nexpected computational cost to P and V as well as the size of the proof stream is O(log n), but O(n) \nin the worst case. Planar Separator Trees. Planar separator trees (PSTs) are data structures that can \nbe used to ef.ciently query the distance of the shortest path between two vertices in a planar graph \n(e.g., many road maps) [6]. A separator of a graph is a collection of vertices inducing a binary partition \non the graph, such that any path from a vertex in one partition to a vertex in the other partition must \npass through a vertex in the separator. A consequence of the planar sepa\u00adrator theorem is that every \nplanar graph has a separator that is small 9 Random algorithms can be used in . as long as P and V both \nuse the same pseudorandom function and seed.  v (O( n) where n is the number of vertices) yet induces \na balanced partition (both partitions have at least n 3 elements); a search struc\u00adture can be built over \nthe graph by recursively constructing separa\u00adtors for each partition. While the na\u00a8ive solution of storing \nthe short\u00adest distance between every pair of vertices requires O(n 2) storage, the planar separator tree \nrequires only O(n 2 3 ) space. The shortest v distance between any two points can be computed in O( n \nlog n) time using this data structure. A potential application of an authen\u00adticated planar separator \ntree is for a mobile device user to query a service provider for travel directions, along with a proof \nthat the response is actually the shortest path (rather than, e.g., one that routes the user out of their \nway past billboards for which the ser\u00advice provider might receive a pro.t). Using our authenticated com\u00adpiler, \nthe proof size and computation cost for P and V is also v O( n log n). We include this primarily as an \nexample of a data structure that has not been treated as an ADS in prior work, but is straightforward \nto authenticate using our framework. Bitcoin. Bitcoin [22] is a peer-to-peer network implementing a virtual \ncurrency; it features an authenticated data structure called the blockchain, which represents a history \nof transactions. A global ledger can be computed from the blockchain, which, abstractly speaking, contains \na set of currently valid coins. A valid transaction removes a past coin from the ledger and adds a new \none (assigned to the recipient of the coin). The current Bitcoin data structure suffers from two drawbacks: \n1) a miner (veri.er) needs to maintain an entire copy of the global ledger to ef.ciently perform validation \nof transactions, which may become unscalable as the number of coins increases; and 2) at install time, \na new client needs to download the entire transaction history and perform a linear computation (in the \nsize of the block chain) to construct the ledger even when it trusts the root digest. These drawbacks \ncan be resolved if we build the ledger (as an authenticated set) into the block chain data structure. \nWe have done this in our language by composing the blockchain data struc\u00adture with a ledger consisting \nof our authenticated red-black+ tree, thereby reducing client storage to O(log M), where M bounds the \nnumber of coins in the ledger. Full details are given our supplemen\u00adtal technical report [20]. 7. Related \nWork As mentioned earlier, authenticated data structure research has had a .urry of results [1, 12, 15, \n16, 19, 23] from the cryptography com\u00admunity, proposing authenticated versions of set (non)-membership, \ndictionaries, range queries, certain graph queries, B-trees, etc. To the best of our knowledge, no one \nhas offered a general authenticated data structure implementation for generic programs. Those closest \nwork is by Martel et. al. [16], which proposes a method for designing authenticated data structures for \na class of data structures referred to as search DAGs. Their model is lim\u00adited to static data structures, \ni.e., it does not support updates, which are supported by . . Our approach is also easier to use, since \nthe programmer writes largely standard (purely functional) implemen\u00adtations of data structures and their \noperations, and the compiler generates the prover/veri.er code; in their approach, the task of designing \nand implementing ADS still must be done by hand. Our programmatically generated ADS implementations have \nperformance competitive with known customized ADS construc\u00adtions based on collision-resistant hashes. \nWe note, however, that while most are, not all known ADS constructions are based on col\u00adlision resistant \nhash functions. For example, bilinear-group based ADS constructions exist for set operations [27]. Using \nalternative algebraic primitives other than collision resistant hashes can some\u00adtimes yield asymptotically \nbetter ADS constructions. (a) Running time (b) Memory usage (c) our . compiler vs hand-(d) proof size \nwith optional opti\u00adoptimized code mizations Figure 13. Empirical performance evaluation results. For \n100,000 insertions into a red-black+ tree, (a) running time for Prover, Veri\u00ad.er, and Ideal; (b) memory \nusage (heap size). (c) Running time for fetch operation in a balanced merkle tree, for the program gener\u00adated \nby our compiler, hand-written OCaml code, and hand-written C code; For 100,000 random insertions in a \nbinary search tree, (d) the effect of two optional optimizations on proof stream size, com\u00adpared with \ntwo optional optimizations: a reuse-cache (of size 1000) and the belief-suspension buffer. Beyond the \noptimizations we have implemented (see Section 5.2), there are other known optimizations that we have \nnot an in\u00adcluded. An example is the technique of commutative hashing due to Goodrich et al. [12] which \nreduces the proof size when it is irrel\u00adevant which (of possibly several) child nodes are traversed. \nWe be\u00adlieve it is likely that optimizations for speci.c data structures could be incorporated generally \ninto our compiler. Other optimizations lie further outside our model; an example is a line of work begin\u00adning \nwith Merkle s original paper [2, 18] in which the stored data is not arbitrary, but is instead generated \nalgorithmically (e.g., us\u00ading a pseudo-random number generator). In this case, the prover s storage costs \ncan be signi.cantly reduced by recomputing data on the .y rather than storing it. In our performance \nevaluation we con\u00adsider memory usage and running time; however some work in au\u00adthenticated data structures \n[16, 21] considers I/O ef.ciency, another practical characteristic. Veri.ed computation [9] and succinct \nnon-interactive argu\u00adments of knowledge (SNARKs) [10, 28] can also yield asymp\u00adtotically better protocols \nfor ensuring integrity of outsourced com\u00adputation (e.g., with O(1) amount of client computation other \nthan reading the input and output). However, while theoretically at\u00adtractive, known veri.ed computation \nschemes and SNARKs are orders of magnitude more expensive than constructions based on collision-resistant \nhashes in practice [28] partly due to the use of heavyweight cryptographic primitives such as fully homomorphic \nencryption.  ZQL [8] is a language for writing veri.ed computations over hidden inputs; this is achieved \nby compiling programs to custom zero-knowledge protocols. Thus, unlike . , ZQL provides correct\u00adness, \nsecurity, and privacy. However, this comes at the price of a more limited language, e.g., ZQL does not \nsupport branching or higher-order functions generally. In addition, ZQL s absolute per\u00adformance is much \nworse due to the use of more heavyweight cryp\u00adtography. 8. Conclusions We have presented . , the .rst \nprogramming language for authen\u00adticated data structures (ADS). We have formally proven that ev\u00adery well-typed \n. program compiles to a secure protocol, and we have implemented . as a simple compiler extension to \nOCaml so that a programmer can easily derive an authenticated data structure from any ordinary one. The \nprotocols generated by our compiler are competitive with the state-of-the-art in hand-rolled ADSs. We \nbelieve this work is long past-due. ADS are a 30-year-old technique in cryptography, and yet researchers \nhave overlooked the simple connection between ADSs encapsulated in our notion of authenticated types. \nWe plan to extend our language to be more expressive, and to include more ef.cient techniques based on \nad\u00advanced cryptographic primitives. We hope our work encourages ADS adoption in future secure computing \ninfrastructure. Acknowledgments We thank Zooko and the Tahoe-LAFS team for several conversations that \ninspired our approach, and Nikhil Swamy and the anonymous reviewers for invaluable comments on drafts \nof this paper. This research was sponsored in part by NSF grant CNS-1111599, and by the US Army Research \nLaboratory and the UK Ministry of Defence under Agreement Number W911NF\u00ad06-3-0001. The views and conclusions \ncontained in this document are those of the authors and should not be interpreted as repre\u00adsenting the \nof.cial policies, either expressed or implied, of the US Army Research Laboratory, the U.S. Government, \nthe UK Ministry of Defense, or the UK Government. The US and UK Governments are authorized to reproduce \nand distribute reprints for Government purposes notwithstanding any copyright notation hereon. References \n[1] A. Anagnostopoulos, M. T. Goodrich, and R. Tamassia. Persistent authenticated dictionaries and their \napplications. In Proc. ISC, pages 379 393, London, UK, UK, 2001. Springer-Verlag. [2] P. Berman, M. Karpinski, \nand Y. Nekrich. Optimal trade-off for Merkle tree traversal. Theor. Comput. Sci., 372(1):26 36, Mar. \n2007. [3] K. Crary, S. Weirich, and G. Morrisett. Intensional polymorphism in type-erasure semantics. \nJournal of Functional Programming, 12(6), 2002. [4] U. Dal Lago and S. Martini. An invariant cost model \nfor the lambda calculus. In Logical Approaches to Computational Barriers, pages 105 114. Springer, 2006. \n[5] P. Devanbu, M. Gertz, C. Martel, and S. G. Stubblebine. Authentic third-party data publication. In \nData and Application Security, pages 101 112. Springer, 2002. [6] R. Duan. Planar separator theorem and \nits applications. lecture slides, Advanced Graph Algorithms, Summer 2012. max planck insti\u00adtut informatik. \nhttp://www.mpi-inf.mpg.de/departments/d1/ teaching/ss12/AdvancedGraphAlgorithms/Slides10.pdf. [7] C. \nFlanagan, A. Sabry, B. F. Duba, and M. Felleisen. The essence of compiling with continuations. In Proc. \nPLDI, 1993. [8] C. Fournet, M. Kohlweiss, G. Danezis, and Z. Luo. ZQL: A compiler for privacy-preserving \ndata processing. In USENIX Security, 2013. [9] R. Gennaro, C. Gentry, and B. Parno. Non-interactive veri.able \ncom\u00adputing: Outsourcing computation to untrusted workers. In CRYPTO 2010, pages 465 482. Springer, 2010. \n[10] R. Gennaro, C. Gentry, B. Parno, and M. Raykova. Quadratic span pro\u00adgrams and succinct NIZKs without \nPCPs. Cryptology ePrint Archive, Report 2012/215, 2012. http://eprint.iacr.org/. [11] M. T. Goodrich, \nC. Papamanthou, and R. Tamassia. On the cost of persistence and authentication in skip lists. In Proc. \nIntl. Workshop on Experimental Algorithms, volume 4525 of LNCS, pages 94 107. Springer, 2007. [12] M. \nT. Goodrich, R. Tamassia, and A. Schwerin. Implementation of an authenticated dictionary with skip lists \nand commutative hashing. In Proc. DARPA Information Survivability Conference and Exposition II (DISCEX \nII), pages 68 82, 2001. [13] M. T. Goodrich, R. Tamassia, and N. Triandopoulos. Ef.cient au\u00adthenticated \ndata structures for graph connectivity and geometric search problems. Algorithmica, 60(3):505 552, 2011. \n[14] J. Katz and Y. Lindell. Introduction to Modern Cryptography. Chap\u00adman &#38; Hall/CRC Press, 2007. \n[15] F. Li, K. Yi, M. Hadjieleftheriou, and G. Kollios. Proof-infused streams: Enabling authentication \nof sliding window queries on streams. In VLDB, pages 147 158, 2007. [16] C. Martel, G. Nuckolls, P. Devanbu, \nM. Gertz, A. Kwong, and S. Stub\u00adblebine. A general model for authentic data publication, 2001. Available \nfrom http://www.cs.ucdavis.edu/~devanbu/files/ model-paper.pdf. [17] C. Martel, G. Nuckolls, P. Devanbu, \nM. Gertz, A. Kwong, and S. G. Stubblebine. A General Model for Authenticated Data Structures. Algorithmica, \n39(1):21 41, Jan. 2004. [18] R. C. Merkle. Secure communications over insecure channels. Com\u00admunications \nof the ACM, 21(4):294 299, Apr. 1978. [19] R. C. Merkle. A certi.ed digital signature. In G. Brassard, \neditor, Proc. CRYPTO 89, volume 435 of LNCS, pages 218 238. Springer-Verlag, 1989. [20] A. Miller, M. \nHicks, J. Katz, and E. Shi. Full version: Authenticated data structures, generically. http://www.cs.umd.edu/~amiller/ \ngpads-full.pdf, Jan. 2014. [21] E. Mykletun, M. Narasimha, and G. Tsudik. Authentication and integrity \nin outsourced databases. Trans. Storage, 2(2):107 138, 2006. [22] S. Nakamoto. Bitcoin: A peer-to-peer \nelectronic cash system. Techni\u00adcal report, unpublished, 2009. [23] M. Naor and K. Nissim. Certi.cate \nrevocation and certi.cate update. In Proc. USENIX, pages 217 228, Berkeley, 1998. [24] M. Naor and K. \nNissim. Certi.cate revocation and certi.cate update. IEEE J. on Sel. Areas Commun., 18(4):561 570, 2000. \n[25] C. Papamanthou and R. Tamassia. Time and space ef.cient algorithms for two-party authenticated data \nstructures. In Information and Com\u00admunications Security, pages 1 15. Springer, 2007. [26] C. Papamanthou, \nR. Tamassia, and N. Triandopoulos. Authenticated hash tables. In Proc. ACM Conference on Computer and \nCommunica\u00adtions Security (CCS), pages 437 448. ACM, October 2008. [27] C. Papamanthou, R. Tamassia, and \nN. Triandopoulos. Optimal veri\u00ad.cation of operations on dynamic sets. In CRYPTO, pages 91 110, 2011. \n[28] B. Parno, C. Gentry, J. Howell, and M. Raykova. Pinocchio: Nearly practical veri.able computation. \nIn Proc. IEEE SSP, 2013. [29] W. Pugh. Skip lists: a probabilistic alternative to balanced trees. Communications \nof the ACM, 33(6):668 676, 1990. [30] J. M. Siskind and B. A. Pearlmutter. First-class nonstandard interpre\u00adtations \nby opening closures. In POPL, 2007. [31] R. Tamassia. Authenticated data structures. In 11th Annual European \nSymposium on Algorithms, Sept. 2003.    \n\t\t\t", "proc_id": "2535838", "abstract": "<p>An authenticated data structure (ADS) is a data structure whose operations can be carried out by an untrusted <i>prover</i>, the results of which a <i>verifier</i> can efficiently check as authentic. This is done by having the prover produce a compact proof that the verifier can check along with each operation's result. ADSs thus support outsourcing data maintenance and processing tasks to untrusted servers without loss of integrity. Past work on ADSs has focused on particular data structures (or limited classes of data structures), one at a time, often with support only for particular operations.</p> <p>This paper presents a generic method, using a simple extension to a ML-like functional programming language we call &#955;&#8226; (lambda-auth), with which one can program authenticated operations over any data structure defined by standard type constructors, including recursive types, sums, and products. The programmer writes the data structure largely as usual and it is compiled to code to be run by the prover and verifier. Using a formalization of &#955;&#8226; we prove that all well-typed &#955;&#8226; programs result in code that is secure under the standard cryptographic assumption of collision-resistant hash functions. We have implemented &#955;&#8226; as an extension to the OCaml compiler, and have used it to produce authenticated versions of many interesting data structures including binary search trees, red-black+ trees, skip lists, and more. Performance experiments show that our approach is efficient, giving up little compared to the hand-optimized data structures developed previously.</p>", "authors": [{"name": "Andrew Miller", "author_profile_id": "86159184057", "affiliation": "University of Maryland, College Park, MD, USA", "person_id": "P4383864", "email_address": "amiller@cs.umd.edu", "orcid_id": ""}, {"name": "Michael Hicks", "author_profile_id": "81100060959", "affiliation": "University of Maryland, College Park, MD, USA", "person_id": "P4383865", "email_address": "mwh@cs.umd.edu", "orcid_id": ""}, {"name": "Jonathan Katz", "author_profile_id": "81100411790", "affiliation": "University of Maryland, College Park, MD, USA", "person_id": "P4383866", "email_address": "jkatz@cs.umd.edu", "orcid_id": ""}, {"name": "Elaine Shi", "author_profile_id": "81554302756", "affiliation": "University of Maryland, College Park, MD, USA", "person_id": "P4383867", "email_address": "elaine@cs.umd.edu", "orcid_id": ""}], "doi_number": "10.1145/2535838.2535851", "year": "2014", "article_id": "2535851", "conference": "POPL", "title": "Authenticated data structures, generically", "url": "http://dl.acm.org/citation.cfm?id=2535851"}