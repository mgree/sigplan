{"article_publication_date": "01-08-2014", "fulltext": "\n Fissile Type Analysis: Modular Checking of Almost Everywhere Invariants Devin Coughlin Bor-Yuh Evan \nChang University of Colorado Boulder {devin.coughlin,evan.chang}@colorado.edu Abstract We present a \ngeneric analysis approach to the imperative relation\u00adship update problem, in which destructive updates \ntemporarily vio\u00adlate a global invariant of interest. Such invariants can be conveniently and concisely \nspeci.ed with dependent re.nement types, which are ef.cient to check .ow-insensitively. Unfortunately, \nwhile traditional .ow-insensitive type checking is fast, it is inapplicable when the desired invariants \ncan be temporarily broken. To overcome this lim\u00aditation, past works have directly ratcheted up the complexity \nof the type analysis and associated type invariants, leading to inef.\u00adcient analysis and verbose speci.cations. \nIn contrast, we propose a generic lifting of modular re.nement type analyses with a symbolic analysis \nto ef.ciently and effectively check concise invariants that hold almost everywhere. The result is an \nef.cient, highly modular .ow-insensitive type analysis to optimistically check the preserva\u00adtion of global \nrelationship invariants that can fall back to a precise, disjunctive symbolic analysis when the optimistic \nassumption is vio\u00adlated. This technique permits programmers to temporarily break and then re-establish \nrelationship invariants a .exibility that is crucial for checking relationships in real-world, imperative \nlanguages. A signi.cant challenge is selectively violating the global type consis\u00adtency invariant over \nheap locations, which we achieve via almost type-consistent heaps. To evaluate our approach, we have \nencoded the problem of verifying the safety of re.ective method calls in dynamic languages as a re.nement \ntype checking problem. Our analysis is capable of validating re.ective call safety at interactive speeds \non commonly-used Objective-C libraries and applications. Categories and Subject Descriptors F.3.1 [Logics \nand Meanings of Programs]: Specifying and Verifying and Reasoning about Pro\u00adgrams Keywords almost everywhere \ninvariants; dependent re.nement types; almost type-consistent heaps; re.ection; Objective-C 1. Introduction \nModular veri.cation of just about any interesting property of pro\u00adgrams requires the speci.cation and \ninference of invariants. One particularly rich mechanism for specifying such invariants is depen- Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. Copyrights for components of this work owned \nby others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, \nor republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. Request permissions from permissions@acm.org. POPL 14, January 22 24, 2014, San Diego, CA, USA. \nCopyright is held by the owner/author(s). Publication rights licensed to ACM. ACM 978-1-4503-2544-8/14/01. \n. . $15.00. http://dx.doi.org/10.1145/2535838.2535855 dent re.nement types [38], which have been applied \nextensively to, for example, checking array bounds [12, 31, 32, 37]. Re.nement types are compelling because \nthey permit the speci.cation of rela\u00adtionships in a type system framework that naturally admits modular \nchecking. For example, a modular re.nement type system can relate an array with an in-bounds index or \na memory location with the lock that serializes access to it. A less well-studied problem that also falls \ninto a re.nement type framework is modularly verifying the safety of re.ective method call in dynamic \nlanguages. Re.ective method call is a dynamic language feature that enables programmers to invoke a method \nvia a run-time string value called a selector. In many languages, these calls have become commonplace \nin libraries as a mechanism to decouple client and framework code. Yet while they are powerful and convenient, \nre.ective method calls introduce a new kind of run-time error: the method named by the selector may not \nexist. Our key observation about modularly verifying re.ective call safety is that the essential property \nto capture and track through the program is the relationship between a responder (the object on which \nthe method is invoked) and a valid selector. In particular, the veri.er does not need to determine the \nactual string value as long as it can ensure that the responds-to relationship between the object and \nthe selector holds at the re.ective call site. This observation is crucial because the point where this \nrelationship invariant is established and where the selector is known (usually in client code) is likely \nfar removed from the point where the re.ective call is performed and at which the invariant is relied \nupon (usually in framework code). The imperative relationship update problem. A signi.cant chal\u00adlenge \nin checking relationship invariants in dynamic, imperative programming languages is reasoning precisely \nabout destructive up\u00addates of related storage locations, such as local variables on the stack and object \n.elds on the heap. To illustrate this issue, consider an object o with an (object) invariant specifying \na relationship between two .elds o.f and o.g. For example, o.f could point to an object that should respond \nto a selector stored in o.g. We can then use this invariant to show that a re.ective method call on o.f \nusing selector o.g is safe. Again, there are many other interesting properties that require speci.cation \nof relationships (e.g., o.f is an array with an in-bounds index stored in o.g, or o.f is a monitor object \nguarded by the lock stored in o.g). Now consider a call o.updateRelation(p) to a simple method updateRelation \nthat updates .elds o.f and o.g with the corre\u00adsponding .elds from the argument p: def updateRelation(x) \n= O self.f = x.f; @ self.g = x.g; @ where three program points O to @ are marked explicitly. Suppose \nthat .elds p.f and p.g of object p have the corresponding rela\u00adtionship with each other as those .elds \nof o (e.g., p.f responds to p.g). Then it is clear that after a call to o.updateRelation(p),  the relationship \ninvariant between o.f and o.g should still hold. This property seems obvious, but two issues make it \nchallenging to verify: (1) a standard, .ow-insensitive type analysis by itself is in\u00adsuf.cient and (2) \nsound symbolic reasoning about potential aliasing requires an expensive disjunctive analysis. Issue 1 \narises because the .rst assignment violates the type re.nement on self.f. In our re.ective call safety \nexample, after the assignment, the new self.f (holding the value passed in x.f) might not respond to \nthe old self.g. Switching the order of assignments does not help: then after the .rst assignment, the \nold self.f might not respond to the new self.g. Problems arising from imperative relationship updates \nhave been studied in the context of array bounds checking [12, 32, 37]. To deal with Issue 1, these type \nsystems either require simultaneous relationship updates [12] or drop .ow-insensitivity altogether and \nmove to a .ow-sensitive treatment of typing [32, 37]. In contrast to a .ow-insensitive invariant, the \ntype of a location in a .ow-sensitive treatment is not .xed globally and is permitted to vary. We argue \nthat for the relationship update problem, computing new types at every program point is overly pessimistic. \nAlthough the ideal .ow-insensitive type invariant imposed by the re.nement on the self.f .eld is broken \nat program point @, it is restored almost immediately at point @. While the blocks of code between violations \nand restorations (e.g., points O to @) require at least .ow-sensitivity, a fast .ow-insensitive analysis \ncan still be effective in checking that the relationship invariant is preserved everywhere else. Issue \n2 arises in the above example because we must reason about (potentially) two concrete objects: the object \npointed to by self and the (possibly same) object pointed to by x. While this code satis.es the desired \nproperty regardless of whether or not self and x are aliases, the analysis must consider both cases. \nConsider a slight variant where, for example, an assignment self.f = null occurs before point O. A sound \nanalysis must detect a bug in this variant (when self and cb are aliases). Prior approaches (e.g., [1, \n2, 18, 32]) enable strong updates in some situations by reasoning about concrete objects one-at-a-time. \nWhile one-at-a-time reasoning is sound, it is insuf.ciently precise for even this unextraordinary example. \nIn particular, a disjunctive analysis (e.g., a path-sensitive analysis) must reason about two cases: \n(1) where there is one concrete object self and x are aliases and (2) where there are two objects self \nand x are not aliases.  We also argue that directly augmenting a type system to han\u00addle temporary invariant \nviolations or other .ow-analysis issues is overly speci.c. The imperative relationship update problem \napplies to checking just about any property that requires relational invari\u00adants. In contrast to the \naforementioned works, the essence of our approach is to mix a property-speci.c re.nement type system \nwith a generic, symbolic .ow analysis to handle temporary violations of the type invariant. The symbolic \nanalysis performs execution-based reasoning and decouples issues like .ow-and path-sensitivity from the \nparticular type abstraction of interest. Fissile type analysis. We propose flow-insensitive storage location \n(FI S S I LE) type analysis a framework for enriching a dependent re\u00ad.nement type system to tolerate \ntemporary violations via a generic, symbolic, separation logic-based, .ow analysis. The result is an \nanalysis that soundly checks a type invariant that holds almost every\u00adwhere. When the fast, .ow-insensitive \nanalysis detects an invariant violation, FI S SI L E type analysis splits the type environment (which \nrelates storage locations to storage locations) into two components: (1) relationships between symbolic \nvalues (i.e., re.nement types lifted to values) and (2) the locations where those values are stored (i.e., \na symbolic memory). The symbolic analysis permits bounded violation of the storage location property \nand takes over until the type invariant is restored, at which point the fast .ow-insensitive analysis \nresumes. As illustrated in the above example, we must sup\u00adport bounded relationship violations not only \namong local variables but also among a number of heap locations. Supporting bounded violations of heap \nlocations is a signi.cant challenge. When applied to relationships that hold almost everywhere, FI S-S \nI LE type analysis addresses the imperative relationship update prob\u00adlem while still maintaining two \nkey bene.ts of .ow-insensitivity: 1. It is nearly as fast as a .ow-insensitive analysis (5,000 to 38,000 \nlines of code per second see Section 4), since it begins with the optimistic assumption that the invariant \nholds everywhere and then only has to reason precisely about the relatively few program locations in \nwhich any relationships are violated. 2. It permits the vast majority (99.95%) of method type signatures \nto be .ow-insensitive. Flow-insensitive type signatures do not need to specify the effect of the method \non the heap. Contrast this to a modular, .ow-sensitive analysis that has summaries specifying the effects \non all methods, in essence, to rule out the pessimistic assumption that any callee could violate the \ninvariant.  In summary, we make the following contributions: We describe the F I SSIL E type analysis \nframework for intertwined fast type and precise symbolic analysis of almost .ow-insensitive storage location \nproperties and instantiate it to check re.ective call safety. Our framework is built on the observation \nthat .ow\u00adinsensitive type invariants on mutable storage locations really serve two roles: specifying \nfacts about the values stored in them and constraining what values are allowed to be stored in them. \nWe de.ne two generic operations to handoff between the type and symbolic analyses that essentially either \ndecouples or relinks these roles (Section 3.2).  We introduce the notion of almost type-consistent heaps \nthat (at the concrete level) splits the overall heap into two regions: one explicit region where locations \nare permitted to be type inconsistent and one implicit region where locations are type consistent up \nto encountering a location that is potentially in\u00adconsistent. We then de.ne type-consistent materialization \nand summarization operations that permit transitioning an arbitrary number of locations with any connectivity \nrelation between the two regions. With materialized locations, we thus enable strong update reasoning \nin our disjunctive symbolic analysis. These capabilities are critical for supporting bounded relationship \nvio\u00adlations among an arbitrarily bounded number of heap locations (Sections 2.2, 3.3, and 3.4).  A key \nchallenge in verifying re-establishment of violated re\u00ad.nement relationships is that the code that breaks \na relationship may be in one module while the storage for that relationship is in another. We introduce \nsymbolic summaries that enable pro\u00adgrammers to specify encapsulated relationship storage and thus retain \nmodular checking for cross-module bounded violations (Sections 2.3 and 3.5).  We evaluate the effectiveness \nof our approach to checking re.ective call safety on a suite of Objective-C libraries and applications \nand on code snippets posted by inexperienced developers on public forums (Section 4).  2. Overview In \nthis section, we present an example that illustrates the main challenges in permitting temporary violations \nof type consistency, particularly with respect to heap-allocated objects. Our examples are drawn from \nverifying re.ective call safety in real-world Objective-C code, which require such temporary violations \nto be able to use simple, global type invariants. Objective-C, like C++, is an object\u00adoriented layer \non top of C that adds classes and methods. We will describe its syntax as needed.  1 @interface Button \n2 -(void)drawState:(String * . lin { Up , Down } . )state { 3 String *m = ... 4 CustomImage *image = \n... 5 m = [\"draw\" append:state]; 6 [image setDelegate:self selector:m]; 7 [image draw]; 8 } 9 -(void)drawUp \n{ ... } 10 -(void)drawDown { ... } 11 @end 12 @interface CustomImage { 13 Object * delegate; String \n*selector; 14 } 15 -(void)setDelegate:(Object * 16 selector:(String *)s {  17 self->delegate = d; 18 \nself->selector = s; 19 } 20 -(void)draw { [self->delegate performSelector:self->selector]}; } 21 @end \n Figure 1. Verifying re.ective call safety requires knowing responds\u00adto relationships between delegates \nand selectors. The example in Figure 1, adapted from the ShortcutRecorder library, demonstrates how programmers \nuse re.ective method call to avoid boilerplate code and to decouple components. Ignore the annotations \nin double parentheses for now these denote our additions to the language of types. The Button class (lines \n1 11) contains a drawState: method (lines 2 8) that draws the button as either up or down, according \nto whether the caller passes the string \"Up\" or \"Down\" as the state argument. A class is de.ned within \n@interface...@end blocks; an instance method de.nition begins with -. Methods are de.ned and called using \nin.x notation (Smalltalk-inspired syntax). For example, the code at line 6 calls the setDelegate:selector: \nmethod on the image object with self as the .rst argument and m as the second. This call is analogous \nto image->setDelegateSelector(self,m) in C++. Now, a Button object draws itself by using the CustomImage \nto call either drawUp or drawDown. The CustomImage sets up a drawing context and re.ectively calls the \npassed in selector on the passed in delegate at line 20 the delegate and selector pair form, in essence, \na callback. This syntax [o performSelector:s] for re.ective call in Objective-C is analogous to o.send(s) \nin Ruby, getattr(o,s)() in Python, and o[s]() in JavaScript. In this case, the delegate is set to the \nButton object itself, and the selector is constructed by appending the passed in state string to the \nstring constant \"draw\" (lines 5 6). Constructing the selector dynamically reduces boilerplate by avoiding, \nfor example, a series of if statements inspecting the state variable. Using re.ection for callbacks also \nimproves decoupling CustomImage is agnostic to the identity of the delegate. This delegate idiom is one \ncommon way responder-selector pairs arise in Objective-C and other dynamic languages. The use of re.ection \nin this example comes at a cost: while the Objective-C type system statically checks that directly called \nmethods exist, it cannot do so for re.ective calls these are only checked at run time. In this work we \npresent an analysis that enables modular static checking of re.ective call safety while still maintaining \nthe bene.ts of reduced boilerplate. To prove that the program is re.ection-safe, we use re.nement types \n[19, 20, 31] to ensure that the responder does, in fact, respond to the selector. To see how these responds-to \nrelationships arise, consider the re.ective call at line 20. It will throw a run-time error if the receiver \ndoes not have a method with the name speci.ed in the argument conversely, to be safe, it is suf.cient \nthat self->delegate re\u00adsponds to self->selector. There is an unexpressed invariant that requires that \nfor every instance of CustomImage, the object stored in the delegate .eld must respond to the selector \nstored in the selector .eld. We capture this invariant by applying the respondsTo selector().void re.nement \nto the delegate .eld at line 13. This re.nement expresses the desired relationship between the delegate \n.eld and the selector .eld. The method signa\u00adture ().void states that the selector .eld holds the name \nof a method that takes zero parameters with return type void. This ex\u00adpresses an intuitive invariant \nthat, unfortunately, does not quite hold everywhere. Still, our framework is capable of using this almost \neverywhere invariant to check that the required relationships hold when needed we revisit this point \nin Section 2.1. Working backward, we see that the setDelegate:selector: method updates the delegate and \nselector .elds with the values passed as parameters this demonstrates the need, in a modular analysis, \nfor respondsTo re.nements to apply to parameters as well as .elds. We annotate parameter d to require \nthat it responds to s. Any time the method is called, the .rst argument must respond to the second. Thus \nat the call to setDelegate:selector: at line 6, we must ensure that self responds to m. In the caller \n(i.e., the client of CustomImage), we know a precise type, Button, for the .rst argument (whereas from \nthe callee s point of view it is merely Object). This means we know that, from the caller s point of \nview, the delegate will respond to the selector if the selector is a method on Button so if we limit \nthe values m can take on to either \"drawUp\" or \"drawDown\" the respondsTo re.nement in the callee will \nbe satis.ed. We write in for the re.nement that limits strings to one of a set of string constants (i.e., \na union of singletons). For simplicity in presentation, our only re.nement for string invariants is in, \nalthough more complex string reasoning is possible. 2.1 Insuf.cient: Flow-Insensitive Typing of Re.nements \nRestricting values stored in variables, parameters, and .elds with respondsTo relationships and in re.nements \ncaptures the essential invariants needed to verify re.ective call safety. Here, we show why a .ow-insensitive \ntype analysis with these re.nements is insuf.cient in the presence of imperative updates. We focus on \nthe most interesting case: updates to .elds of heap-allocated objects. Re.nement types {v : B | R(v)} \nconsist of two components: the base type B, which comes from the underlying type system, and the (optional) \nre.nement formula R, which add restrictions on the value v beyond those imposed by the base type. As \na notational convenience, we write them without the bound variable and assume the bound variable is used \nas the .rst argument of all atomic relations, writing for example, Int l= 0 instead of {v : Int | v = \n0}. Subtyping with re.nement types. We assume the re.nement type system of interest comes equipped with \na subtyping judgment G f T1 <: T2 that is a static over-approximation of semantic in\u00adclusion (i.e., under \na context G, the concretization of type T1 is contained in the concretization of T2). As an example, \nwe consider informally subtyping with the respondsTo and the in re.nements for re.ective call safety. \nFor in re.nements, this is straightforward: an in-re.ned string is a subtype of another string if the \npossible con\u00adstant values permitted by the .rst are a subset of those required by the second. The situation \nfor subtyping the respondsTo re.nement is complicated by the fact that a relationship re.nement can refer \nto the contents of related storage locations. Consider the Button * type in the drawState: method. The \ntype environment, G, limits the local variable m to hold either \"drawUp\" or\"drawDown\" . Since Button \n* is a subtype of Object * in the base Objective-C type system and Button has both a drawUp and a drawDown \nmethod, Button * is a subtype of Object * l respondsTo m in this envi\u00adronment. If, for example, G(m) \ninstead had re.nement in{ Fred }the above subtyping relationship would not hold. Note that for pre\u00adsentation \nwe have elided the method type on the respondsTo here; we do so whenever it is not relevant to the discussion. \n Type checking .eld assignments. We check .eld assignments .ow-insensitively with a weakest-preconditions \nbased approach similar to the Deputy type system [12] (although extended to handle subtyping). Here, \nwe focus on why .ow-insensitive typing raises an alarm after the .eld assignment self->delegate = d at \nline 17 (see Section 3 for more details on how checking proceeds). To check this assignment, we .rst \naugment the type environment with fresh locals representing the .elds of the assigned-to object and then \ncheck the assignment as if it were a local update. Conceptually we temporarily bring .eld storage locations \ninto scope and give them local names. Let this augmented type environment be Ga = G[d : Object * l respondsTo \ns] [delegate : Object * l respondsTo selector] for some G and where we explicitly show the two respondsTo \nre.nements (for presentation, we use the .eld names as the fresh locals). Checking the assignment, we \nend up with the subtyping check Ga f Ga(d) <: Ga(delegate), which expresses the invariant that the relationship \nbetween delegate and selector should be preserved across this assignment. Note that while this subtyping \ncheck is what is prescribed for assignment in a standard, non\u00addependent type system, the weakest-preconditions \nbased approach ensures that this same check is also required (and thus also fails) for the next line \n(line 18) where selector is updated. Although these two assignments are each unsafe in isolation, considered \nin combination, they are safe. The .rst assignment breaks the invariant that the delegate .eld should \nrespond to selector, but the second restores it. These temporary violations cannot be tolerated by a \n.ow\u00adinsensitive type analysis because, in imperative languages, .ow\u00adinsensitive types on storage locations \nreally perform two duties. First, they express facts about values: any value read from a variable with \ntype respondsTo m can be assumed to respond to the value stored in location m. But second, they express \nconstraints on muta\u00adble storage: for the fact to universally hold, the type system must disallow any \nwrite to that variable of a value that does not respond to m. These constraints are .ne for standard \ntypes but are problematic for relationships that are established or updated in multiple steps.  2.2 \nTolerating Violation of Relationship Re.nements As we previewed in Section 1, we argue that moving to \na .ow\u00adsensitive treatment of typing is too pessimistic. A .ow-sensitive type analysis drops the global \nconstraints on mutable storage locations that enable concise speci.cation. Instead it focuses on tracking \nfacts on values as they .ow through the program, which then require more verbose summaries. Other possible \nalternatives are to change the programming language to disallow temporary violations (e.g., by requiring \nsimultaneous updates) or to somehow generalize the type invariant to capture the temporary violations \nof the simpler invariant; we argue that these approaches are too speci.c. Our work is motivated by the \nobservation that although program\u00admers do sometimes violate re.nement relationships, most of the time \nthese relationships hold they are almost .ow-insensitive. To set up our notion of almost type-consistent \nheaps, we .rst make explicit a standard notion of type-consistency. De.nition 1 (Type-Consistency). A \nstorage location is type\u00adconsistent if the values stored in it and all locations in its reach\u00adable heap \nconform to the requirements imposed by their .ow\u00adinsensitive re.nement type annotations. Thus, a storage \nlocation is type-inconsistent if either the value stored in it immediately without pointer dereferences \nviolates a type constraint or there is a type-inconsistent location transitively in its reachable heap. \nWe distinguish these two cases of immediately type-inconsistent versus only transitively type-inconsistent. \nIn this work we rely on two premises about how programmers violate re.nement relationships over storage \nlocations on the heap: Premise 1 All of the heap is type-consistent most of the time. Premise 2 Most \nof the heap is not immediately type-inconsistent all of the time. In other words, only a few locations \nare responsible for breaking the global type invariant at any time. Following Premise 1, we apply type \nanalysis when the heap is type\u00adconsistent and switch to symbolic analysis when the type invariant is \nviolated. Under this premise, these periods of violation are bounded in execution and short enough that \nthe path explosion from precise symbolic analysis is manageable. To enable the intertwining of a type \nand a symbolic analysis, we require two conceptually inverse operations, symbolization and typei.cation, \nthat are applied when switching between the two kinds of analyses. Symbolization splits a type environment \nG (which expresses relationship constraints between storage locations) into a symbolic fact map GMand \na symbolic memory M . The fact map expresses relationships between symbolic values (i.e., re.nement types \nlifted to the symbolic domain) and the memory indicates where those values are stored (symbolic local \nvariables and heap). So, for example, splitting a type environment G with [d : Object * l respondsTos] \nwill result in a fact map GMwith fact [vM1 : Object * l respondsTo vM2] and a memory M which maps d to \nvM1 and s to vM2. Here vM1 and vM2 are arbitrary symbolic names for values initially stored in d and \ns upon symbolization. In order for a symbolization to be sound, the symbolized fact map must be no stronger \nthan the original type environment. A type environment G is not directly comparable to a symbolic fact \nmap GM, so we capture the required relationship with a subtyping under substitution judgment G <:. -1 \nGMthat, in essence, converts the symbolic fact map to a type environment before performing the comparison. \nWe perform this conversion with a substitution . -1 , constructed from the symbolic memory, that maps \nsymbolic values to the local variables that store them. Typei.cation fuses GMand M back into a type environment \nG. In this case, the type environment under the forward memory substitution must be no stronger than \nthe fact map: GM<:. G. We describe these relations fully in Section 3.3. Premise 2 is at the core of \nour approach to soundly handling temporary type violations on heap locations. The key idea is a view \nof the heap as being made up of two separate regions: (a) a small number of individual locations that \nare allowed to be immediately type-inconsistent and (b) an almost type-consistent region consisting of \n(fully) type-consistent or only transitively type\u00adinconsistent locations, which we illustrate intuitively \nbelow: In the illustration, the dark node represents one location that is immediately type-inconsistent, \nwhile the light rectangle around it represents the almost type-consistent region. Note that there may \nbe pointers (shown as arrows) to the this location where such objects are not type-consistent but only \ntransitively type-inconsistent. In the analysis, the locations in the almost type-consistent region are \nsummarized and represented by an atomic assertion okheap, while the possibly immediately type-inconsistent \nlocations are materialized and explicitly given in the symbolic memory M . During symbolic analysis, \nwe can materialize explicit storage locations from the almost type-consistent region okheap and thus \nupdate them to hold values that do not match their expected types (i.e., to become immediately type-inconsistent). \nWhen the materi\u00adalized storage is again consistent with its expected types, we can summarize it back \ninto okheap. When the heap consists entirely of okheap, we know that the entire heap is fully type-consistent \nand we can return to type checking. Given this mechanism, we can easily allow for more than one materialization \nat a time as long as we account for possible aliasing with already materialized locations Premise 2 suggests \nthat this explosion is also manageable. As an aside, we see okheap as a specialization of separating \nimplication --from separation logic [30] for type-consistency. Materializing from okheap corresponds \nto removing a location from its concretiza\u00adtion and introducing an implication awaiting type-consistency \nof the location (intuitively, the hole in the above illustration). Summarizing into okheap corresponds \nto putting a location into its concretization and eliminating an implication (see Section 3.3).  2.3 \nModular Checking and Symbolic Summaries Flow-insensitive type signatures are effective for achieving \nmethod\u00adlevel modularity, but they do not summarize the effect that a method has on the heap. Such heap \neffect summaries are needed when the code that breaks and restores a relationship invariant is spread \nbetween multiple methods. Consider again the temporary invariant violation at line 17 in Figure 1, but \nsuppose that instead of updating the delegate and selector .elds directly, the programmer used the accessor \nidiom with setDelegate: and setSelector: methods: 17 [self setDelegate:d]; 18 [self setSelector:s]; Each \nof these methods in isolation break the relationship invariant, but they are safe when used in combination. \nFlow-insensitive type signatures specify neither alias information nor the effect of the method on the \nheap a richer speci.cation is needed to check such cross-method relationship violations. Rather than \ncomplicate the type analysis with .ow-sensitive method type signatures or effect annotations, we enrich \nthe sym\u00adbolic analysis with the ability to summarize methods via pre-and post-conditions describing the \nstructure of the heap (in separation logic [30]). For example, the symbolic summary for the setDele\u00adgate: \nmethod with a parameter named p would have input heap self . {delegate : -} and output heap self . {delegate \n: p}. This summary says that (1) regardless of its contents on method entry, on method exit the delegate \n.eld contains the passed in the parameter and (2) the method does not touch any .elds other than delegate. \nWhen symbolically executing the caller of one of these methods, we can modularly apply the summary, as \nlong we ensure conformance to the summary when checking the method body (Section 3.5). Uniquely, we need \nsymbolic method summaries only as a rare escape hatch because of an intertwined approach: within symbolic \nanalysis, we can apply a nested type analysis with a different local type invariant. This enables using \n.ow-insensitive method types within symbolic analysis and other ways to leverage symbolic reasoning outside \nof the type system (see Section 3.5). On one hand, .ow-insensitive type signatures are imprecise but \nsimple to express and fast to check. On the other, symbolic method summaries can precisely describe method \nheap effects but are complex to express and slow to check. We therefore can obtain the same precision \nas a fully symbolic analysis but still take advantage of the simpler, more ef.cient type analysis where \nthe global type invariant holds. In contrast to .ow-sensitive approaches (e.g., [32]), we do not need \nheap effect summaries for all methods but rather only for those very few (0.05%) that leave a relationship \ninvariant violated. 3. Storage Type and Symbolic Value Analysis In this section, we provide an example-driven \ndescription of how FI S SI LE type analysis intertwines .ow-insensitive type analysis and path-sensitive \nsymbolic analysis to modularly check re.nement relationships between storage locations. For reference, \nwe give the full details of the type and symbolic analyses in our TR [13]; here we focus on the core \ncontributions of our framework and illustrate them via an instantiation to check re.ective call safety. \nPreliminaries: Syntax of language and types. We describe FI S-SILE type analysis over a core imperative \nprogramming language of expressions e with objects and re.ective method call. For presentation purposes, \nwe have only three types of values: unit, strings, and objects. We assume disjoint syntactic classes \nof identi\u00ad.ers for program variables x,y,z, .eld names f , method names m, and parameter names p, as \nwell as a distinguished identi\u00ad.er self that stands for the receiver object in methods. Pro\u00adgram expressions \ninclude literals for unit (), strings c, objects {var f : T = e,def m(p : Tp) : Bret[S] = e}. The var \ndeclarations specify mutable .elds f of types T , and the def declarations describe methods m with parameters \np of types Tp and with return type Bret. The return type is a base type, which does not itself have re.nements \n(but could have re.nements on its .elds in the case of an object base type). An overline stands for a \nsequence of items. Methods can also be optionally annotated with symbolic summaries S, which we revisit \nin Section 3.5. Objects are heap allocated. Local variable binding let x : T = e1 in e2 binds a local \nvariable x of type T initialized to the value of e1 whose scope is e2. We include one string operation \nfor illustration: string append x1 @ x2. Then, we have reads of locals x and .elds x. f , writes to .elds \nx. f := y, basic control structures for sequencing e1;e2 and branching e1 . e2. For presentation, we \nuse non-deterministic branching, as the guard condition of an if-then-else expression has no effect on \n.ow-insensitive type checking and can be re.ected in the symbolic analysis in the usual way (i.e., by \nstrengthening the symbolic state with the guard condition). Finally, we have two method call forms: one \nfor direct calls z.m(x) and one for re.ective calls z.[y](x). A call allocates an activation record for \nthe receiver object z and parameters x; it then dispatches with the direct name m or the re.ective selector \ny. Types T are a base type B for either unit Unit, strings Str, or objects {var f : Tf , def m(p : Tp).Bret} \nwith a set of re.nements R, which are interpreted conjunctively. The framework is parametrized by the \nlanguage of re.nements R needed to specify the invariants of interest, and re.nements should be parametric \nwith respect to the syntactic class of identi.ers .. We decorate with a superscript RL , RF, or RS when \nwe want to emphasize or make clear over which syntactic class of identi.ers the re.nement ranges: locals \nx, .elds f , or symbolic values vM(see Section 3.2), respectively. Because types include re.nements, \ntypes are parametrized as well, written T L , T F, or T S, as are type environments G. 3.1 Instantiation: \nThe Re.ection Checking Type Re.nement To verify re.ective call safety, we have seen that the key property \nis the respondsTo .(p : Tp).Bret re.nement that says an object must respond to the value named by . with \nthe given method type. As a symbolic fact, it says that an object must respond to the value named by \n.. But as a type invariant on storage locations, the re.nement also constrains both the storage location \non which the re.nement is applied and the storage location named by . to hold a responder and a correspondingly \nvalid selector for it. We also need some re.nements on string values, such as the union of singletons: \n in {c1, . . . , cn} which says the value is one of the following (string) literals c1, . . . , cn. To \ntype expressions, we use the standard typing judgment form G f e : T that says in a type environment \nG, expression e has type T . A type environment G is a .nite map from identi.ers to types, which we view \nas the types assigned to program variables (i.e., GL f e : T L for emphasis). The standard typing judgment \nform emphasizes that G is a .ow-insensitive invariant.  T-R E FL E C T I V E -M E T H O D -CA L L G(z) \n= {\u00b7\u00b7\u00b7} l respondsTo y(p : Tp).Bret G <:[p:x,self:z] p : Tp,self : G(z) G f z.[y](x) : Bret l SU B -OB \nJ -RE S P O N D S TO-RE FL G f G(x) <: Str l in {c1, . . . , cn}.i.1..n B has a method named ci with \nsignature (p : Tp).Bret G f B l \u00b7\u00b7\u00b7 <: B l respondsTo x(p : Tp).Bret Figure 2. Flow-insensitive typing \nfor re.ective method calls. The respondsTo re.nement is checked on re.ective dispatch. We provide the \nfull type system for re.ective call safety in our TR [13] here we focus on the rules needed to check \nre.ective calls given the desired type invariant (Figure 2). The T-RE FL E C T I V E -ME T H O D -CA \nL L rule for checking a re.ective method is itself not complicated: we require that the responder object \nz has a re.nement guaranteeing that it responds to the selector y with method type sig\u00adnature (p : Tp).Bret. \nThe arguments to call are checked against the speci.ed types of the parameters via G <:[p:x,self:z] p \n: Tp,self : G(z). We write G <:. G' as the lifting of subtyping to type environments under a substitution \n. from variables on the right to variables on the left. The type of the call is then the return base \ntype of the method (as expected) without any re.nements Bret l. The respondsTo re.nement is introduced \nvia subtyping. The subtyping judgment G f T <: T ' says that in typing environment G, type T implies \ntype T '. The SU B -O B J -RE S P O N D S TO-RE FL sub\u00adtyping rule combines information from base object \ntypes and the environment to introduce respondsTo. This rule says that for any location x that is one \nof a set of selector strings c1, . . . , cn, then any object of base type B with methods of the appropriate \nsignature for all c1, . . . , cn responds to the method named by x with that signature. We also have \nsubtyping rules expressing component-wise implica\u00adtion of re.nements, conjunctive weakening of the set \nof re.nements, and disjunctive weakening of in re.nements. For our purposes, it does not matter how subtyping \nis checked as long as it is a sound approximation of semantic subtyping. We could, for example, use an \nSMT solver as in Liquid Types [31] and also replace the type rules for string operations with an off-the-shelf \nstring solver. Another Instantiation: Typing for array re.nements. The F I S S I L E type analysis framework \nis parametrized by the language of re.ne\u00adments and a decision procedure for semantic inclusion. To provide \ncontext for our approach, we sketch another instantiation that checks array-bounds safety a property \nconsidered by many prior works with a few re.nements and rules. Suppose we augment our program\u00adming language \nto include array allocation and array access and add two re.nements: (1) hasLength, which indicates that \nan array has the speci.ed (non-zero) length and (2) indexedBy, which indicates that the speci.ed index \nis a valid index for the array that is, that the index is in bounds. When analyzing an array access e[x], \nwe check that x is a valid index into the array e by requiring that e s type has the re.nement indexedBy \nx. We introduce this re.nement via subtyping with the following rule, which says that x is a valid index \nfor an array of length y if the environment G restricts x and y such that x = 0 and x < y: [G] fSMT x \n= 0 . x < y G f B l hasLength y <: B l indexedBy x We verify that this condition holds by encoding the \nenvironment into a linear arithmetic formula (written [G]) and checking entailment with an SMT solver \n(written as the judgment f1 fSMT f2 for formulas f1 and f2). Here we map meta-variables x and y in the \ntyping judgment to logical variables of the same name in the SMT entailment checking judgment. SM::= \n(GM, HM) symbolic states M E ::= \u00b7 | EM[x : vM] symbolic environments MM H ::= emp | aM: o | HM1 -H2 \n| okheap symbolic heaps M G ::= \u00b7 | GM[vM: T S] symbolic facts MM P ::= S . vM| PM1 . PM2 | false symbolic \npaths o ::= emp | f : vM| o 1 -o 2 symbolic objects vM,aM,xM, yM,Mz symbolic values Figure 3. The symbolic \nanalysis state splits type environments into types lifted to values and the locations where values are \nstored.  3.2 Symbolic Analysis State and Handoff The type analysis is ef.cient but coarse. It is .ow-insensitive \nconstraining all storage locations to be a .xed type and the heap to be always in a consistent state. \nWhen these constraints hold, we get a simple and fast analysis. When they are temporarily violated, our \noverall analysis can switch to a path-sensitive symbolic analysis that continues until the constraints \nagain hold. We now walk through a modi.ed version of the example from Section 2 to describe the key components \nof this switch: (1) we describe our symbolic analysis state and how we convert ( sym\u00adbolize ) a type \nenvironment to a symbolic state; (2) we describe type-consistent materialization and summarization from \nthe almost type-consistent heap in Section 3.3; (3) we describe the proofs of soundness for handoff, \nmaterialization/summarization, and our overall analysis in Section 3.4; and (4) we explore the interaction \nbetween modular symbolic analysis and the almost type-consistent heap in Section 3.5. Symbolic analysis \nstate. In the symbolic analysis, we split a type environment G into a symbolic environment EMand a symbolic \nstate SM(Figure 3). A symbolic environment EMprovides variable context: it maps variables to symbolic \nvalues vMthat represent their values. A symbolic state SMconsists of two components: a symbolic fact \ncontext GM, mapping symbolic values to the facts (symbolic types) known about them and a symbolic heap \nHM. A symbolic heap HMcontains a partially-materialized sub-heap that maps addresses ( aM) to symbolic \nobjects ( o ), which are themselves maps from .eld names ( f ) to symbolic values. We write symbolic \nobjects and heaps using the separating conjunction -notation borrowed from separation logic [30] to state \nthat we refer to disjoint storage locations. Symbolic values vMcorrespond to existential, logic variables. \nFor clarity, we often use aMto express a symbolic value that is an address and similarly use xM,yM,Mz \nfor values stored in the corresponding program variables x, y, z. Relationship re.nements in GMare expressed \nin terms of types lifted to symbolic values (T S) that is, the re.nements state relationship facts between \nvalues and not storage locations (like the re.nements in G for typing). Our overall analysis state is \na symbolic path set PM, which is a disjunctive set of singleton paths SM. xM. A singleton path is a pair \nof a symbolic state and a symbolic value corresponding to the return state and value, respectively. The \nsymbolic heap HMenables treating heap locations much like stack locations, capturing relationships in \nthe symbolic context GM, though certainly more care is required with the heap due to aliasing. A symbolic \nheap HMcan be empty emp, a single materialized object aM: o with base address aMand .elds given by o \n, or a separating conjunction of sub-heaps HM1 -HM2. Lastly and most importantly, a sub-heap can be okheap, \nwhich represents an arbitrary but almost type-consistent heap. This formula essentially grants permission \nto materialize from the almost type-consistent heap and, as discussed in Section 2.2, is the key mechanism \nfor soundly transitioning between the type and symbolic analyses. Handoff from type checking to symbolic \nexecution. Consider the formal language version of the callback example from Section 2.2:  T-SY M -HA \nN D O FF ------. G symbolize GM,EMEMf {GM,okheap}e{(GMi,okheap) . xMi}i ----. GMi,EMtypeify G GMi f \nGMi(xMi) <: T [EM] for all i G f e : T C -STAC K -S Y M B O L I Z E C-O B J E C T-S Y M B O L I Z E EMis \n1-1 G <:EM-1 GMGF = .eldtypes(B) o is 1-1 GF <:o -1 GM ------. ------. G symbolize GM,EMB symbolize GM,o \nM-MAT E R I A L I Z E SM= GM, HMokheap . HMaM./dom(HM) ------. MG.elds MMGM.elds G(aM) = B l \u00b7\u00b7\u00b7 B symbolize \nM,o G' = G, . . -------. SMmaterialize .GM' ,(HM-aM: o).SM|M. a=yMyM.mayaliasSM(aM) SY M -W R I T E -F \nI E L D EMf {GM, HM}x. f := y{GM,HMEM(x) :HM(EM(x))[ f : EM(y)]. EM(y)} M-S U M M A R I Z E ----. okheap \n. HMGM(aM) = B l \u00b7\u00b7\u00b7 GM,o typeify B -------. GM,(HM-aM: o) summarize GM, HM C-OB J E C T-T Y P E I F \nY SU B -TY P E S -FAC T S M G <:o .eldtypes(B) G f G(. -1(xM)) <: T S[. -1] for all xM: T S . GM ----. \nGM,o typeify B G <:. -1 GM C -STAC K -TY P E I F Y SU B -FAC T S -TY P E S MM G <:EMG G f GM(. (x)) <: \nT [. ] for all x : T . G ----. M GM,EMtypeify G G <:. G Figure 4. Selected rules demonstrating how FI \nSS ILE type analysis switches to a symbolic analysis to tolerate bounded violations. 1 { var del: {} \nl respondsTo sel, var sel: Str, 2 def update(d: {} l respondsTo s, s: Str): Unit = 3 self.del := d; 4 \nself.sel := s } Here the update method updates the del and sel .elds in sequence. Recall that the assignment \nat line 3 breaks the type invariant and the assignment at line 4 restores it. We illustrate the core \noperations (Figure 4) behind FI SS I L E type analysis by walking through this example. When checking \nthis method, the type analysis will produce a .ow-insensitive type error for the assignment at line 3 \nand so will switch to symbolic execution. To do so, it will (1) symbolize a suitable symbolic analysis \nstate from the type environment, (2) symbolically execute the two .eld writes, and (3) attempt to typeify \nthe resultant symbolic analysis state back to the original type environment. If this succeeds, then the \ntype analysis can continue. The T-SY M -HA N D O FF rule formalizes this process. It says the type checker \ncan switch to the symbolic analysis to check an expression e in a type environment G by creating ( symbolizing \n) a symbolic state representing G and symbolically executing e in that state. The judgment form EMf {SM}e{PM} \nsays that in the context of a given symbolic local variable environment EMand with a symbolic state SMon \ninput, expression e symbolically evaluates to a disjunction of state-value pairs PMon output. Here the \ninput facts and environment ------. are obtained from G (via the G symbolize GM,EMjudgment form), while \nthe input heap is initialized to a fully type-consistent heap okheap. After symbolic execution, the resultant \nsymbolic state must be consistent with ( typeify to ) the original G, and the symbolic facts about the \nresulting symbolic value must be consistent with the inferred type T of the expression. Note that here \nwe lift the subtyping judgment \u00b7 f \u00b7 <: \u00b7 to symbolic types in the expected way. Here T [. ] converts \nthe standard type T to a symbolic type (fact) T S with a substitution . that replaces all variable references \nin T s re.nements with symbolic values. Both the initially symbolized heap and the .nally typei.ed heap \nmust consist solely of okheap the heap is assumed consistent on entry and must be restored on exit. The \nkey aspect of this handoff is that although the symbolic execution is free to violate any of the .ow-insensitive \nconstraints imposed by G, it must restore them to return to type checking. We will discuss restoration \nin detail later .rst we describe symbolization. Symbolizing type environments to symbolic states. Symboliza\u00adtion \nsplits a type environment G (which expresses type constraints on local variables) into a symbolic fact \nmap GM(expressing facts about symbolic values) and a symbolic local variable state EM(ex\u00adpressing where \nthose values are stored). For example, consider the type environment above at line 3, immediately before \nthe .rst write: G = [d : {} l respondsTo s][s : Str][self : TImage] where TImage = {var del : {} l respondsTo \nsel,var sel : Str}. We can symbolize this environment to create a symbolic environment where EM= [d : \nMs][self : eHere we have created fresh d][s : Mself]. symbolic names to represent the values stored on \nthe stack: Md is the name of the value stored in local d, Ms in local s, etc. These symbolic values represent \nconcrete values from a type environment in which the storage location re.nement relationships hold, so \nwe can safely assume that values initially stored in those locations have the equivalent relationships, \nexpressed as lifted types: GM= [Md : {} l respondsTo Ms][Ms : Str][s self : TImage] Note that the re.nement \non Md refers to symbolic value Ms and not storage location s, but that the re.nements on the types of \nthe .elds of the base type of s self s fact TImage still refer to (.eld) storage locations. These .eld \nre.nements on the base object type are, in essence, a promise that if any explicit storage for those \n.elds is later materialized, it must be consistent with TImage when summarized back into okheap. We formalize \ntype environment symbolization in rule C-S TAC K -SY M B O L I Z E, which captures the requirement that \nthe symbolized state must over-approximate the original type environment. We note that EM-1 forms a substitution \nmap from symbolic values to local variable names and require that the symbolized fact map GMunder that \nsubstitution be an over-approximate environment of the original type environment G (rule SU B -TY P E \nS -FAC T S). In essence, any assumptions that the symbolic analysis initially makes about the symbolic \nfacts must also hold in original type environment. That EMis one-to-one ensures that the inverse exists \nbut more importantly encodes the requirement that the newly symbolized environment makes no assumptions \nabout aliasing between values stored on the stack in local variables. Note that when symbolizing a local \nvariable with type B l RL in a type environment, we do not lift the base type B to the symbolic domain \nnor do we create storage for any of B s .elds. That is, re.nements on the .elds of an object base type \nremain re.nements over .elds, expressing both facts about the .eld contents and constraints on those \nstorage locations. This interpretation is what permits materialized, immediately type-inconsistent objects \nto point back into okheap (i.e., the almost type-consistent region). As we detail next, with this interpretation, \nour analysis materializes storage for objects from okheap on demand, which is not only more ef.cient \nbut is required in the presence of recursion.  3.3 Materialization from Type-Consistent Heaps Returning \nto the callback example, recall that the analysis has sym\u00adbolized a state corresponding to the type environment \nimmediately before line 3. A symbolic heap HMconsists of two separate regions: (1) the materialized heap, \na precise region with explicit storage that supports strong updates and allows .eld values to differ \nfrom their declared types (i.e., permits immediate type-inconsistency) and (2) the okheap, a summarized \nregion in which all locations are either type-consistent or only transitively type-inconsistent. In a \nnewly symbolized analysis state, HMconsists of solely okheap. Before the .eld write at line 3 can proceed, \nthe analysis must .rst materialize storage for the TImage object pointed to by e  self to get: Me H \n= okheap -self . {del : esel}del,sel : s and a new fact map GMthat contains the additional facts: e del \n: {} l respondsTo sel and e esel : Str. We formalize type-consistent materialization with the C-O B J \nE C T-SY M B O L I Z E and M -MAT E R I A L I Z E rules. Creating symbolic storage for an object type \nis very similar to symbolizing a type environment. As rule C-O B J E C T-S Y M B O L I Z E de.nes, the \nanalysis can symbolize a type B to a symbolic object o (mapping .eld names to fresh symbolic values) \nand a fact map GM(facts about those values) if the assumed facts about the values are no stronger than \nthose guaranteed by the object s .eld types. Once the analysis has symbolized an object, it adds the \nnew object storage to the explicit heap and facts about the fresh symbolic values to the fact map in \nrule M-MAT E R I A L I Z E. For the symbolic analysis to perform strong updates, it must maintain the \nkey invariant that any two objects storage locations in the explicit heap are de.nitely separate. When \nmaterializing an arbitrary object, the evaluator must consider whether any of the already materialized \nobjects aliases with the newly materialized object and case split on these possibilities. The split is \nrequired because any two distinct symbolic values may in fact represent the same concrete value. In M-M \nAT E R I A L I Z E, for any input state SMin which the heap contains okheap, the symbolic analysis is \nfree to materialize the object stored at a symbolic address aMfrom the type-consistent heap. For the \ncase where the materialized symbolic address does not alias any address already on the explicit heap, \nwe symbolize a new symbolic object o with fresh symbolic values as described above from the base type \nof aM. In the case where the address may alias some address yMon the materialized heap, we must assert \nthat aM= yM. We write SM|Mfor any sound constraining of SM a=yM with the equality (we implement it by \nsubstituting one name for the other and applying a meet n in the symbolic facts GM). We also leave unspeci.ed \nthe mayaliasSM(aM) that should soundly yield the set of addresses that may-alias aM; our implementation \nuses a type-based check to rule out simple non-aliases. This rule is quite general. It permits an arbitrary \nnumber of loca\u00adtions to be immediately type-inconsistent without any constraints on connectivity, ownership, \nor non-aliasing. To simplify the formal\u00adization of type-consistent materialization, we restrict relations \nex\u00adpressed by re.nements in the heap to be among .elds within objects. Relations between .elds are captured \nbecause all of .elds of the object are symbolized at the same time (see C-OB J E C T-SY M B O L I Z E). \nSupporting cross-object relations would merely require material\u00adizing multiple objects while disjunctively \nconsidering all possible aliasing relationships and then symbolizing their .elds simultane\u00adously within \neach con.guration. It would also be possible to just materialize the .elds corresponding to the speci.c \nrelationships that we wish to violate by using a .eld-split model [26, 28] of objects. Symbolic execution. \nWith the symbolization and materialization complete, the analysis now executes the .eld writes at lines \n3 and 4. The SY M -W R I T E -FI E L D rule describes symbolic execution of writing the value of a local \nvariable y to a .eld f of a base address x. It requires that the object at the base address EM(x) already \nbe materialized and updates the appropriate .eld in the symbolic heap HM. We give the rest of our symbolic \nexecutions rules in our TR [13] they are as expected. Unlike traditional symbolic analysis, our mixed \napproach can soundly ensure termination by falling back to type checking. In practice, we switch to types \nat the end of loop bodies to cut back edges and cut recursion with method summaries. Summarizing symbolic \nobjects back into types. After execution of the .eld writes, the symbolic heap at line 4 is: Me H = okheap \n-self . {del : Md,sel : Ms}. That is, the .elds now contain the values passed in as parameters. But recall \nthat GM(M= {} l respondsTo MG( e= TImage. d) s and Mself) In this state, the value stored in .eld del \nagain responds to the value stored in .eld sel the .ow-insensitive type invariant (TImage) promised by \nMself) again holds and thus the object can be safely G( e summarized back into the okheap. We describe \nthis process in rule M-SU M M A R I Z E, which says that a symbolic address aMpointing to a materialized \nobject o can be summarized (i.e., removed from the explicit heap) if the object is consistent with (i.e., \ncan be typei.ed to) the base type required of the address in the fact map. Typeifying a symbolic object \no to an object type B (rule C-O B J E C T-TY P E I F Y) is analogous to symbolization except that it \ngoes in the other direction. We require that the symbolic fact map be over-approximated by the .eld types \nof B, nicely converting it to the symbolic domain using o as the substitution. Note that o does not need \nto be one-to-one; the observation that this constraint is irrelevant for typei.cation captures that types \nare agnostic to aliasing. Once all materialized objects have been summarized (and thus HM= okheap), the \nchecker can end the handoff to symbolic analysis and resume type checking (back to rule T-SY M -H A N \nD O FF) as long as the symbolic locals are consistent with the original G for all symbolic paths (rule \nC -S TAC K -TY P E I F Y) and the returned symbolic values have facts consistent with the return type \nof the expression.  3.4 Concretization and Soundness An important concern for materialization and summarization \nis whether information is transferred soundly between the type analy\u00adsis and the symbolic analysis (i.e., \nwe have a sound reduced prod\u00aduct [15]). In particular, materialization pulls information from the heap \ntype invariant on demand during symbolic execution and then permits temporary violations of the global \nheap invariant in some locations. We take an abstract interpretation-based approach [14] to soundness, \nwhich is critical for expressing almost type-consistent heaps and connecting the soundness of type checking \nwith the soundness of symbolic analysis. In this section, we describe, via concretization, the different \nmeanings of object types and their asso\u00adciated reachable heaps in the two analyses. Further, we present \nthe properties of these concretizations that are key to proving soundness of handoff and materialization/summarization \nand also state a theo\u00adrem of intertwined analysis soundness. We provide complete con\u00adcretization functions \nand a full proof of soundness in our TR [13]. Concretization. A concrete state consists of a concrete \nenviron\u00adment E, mapping variables x to values v, and a concrete heap H, which is a .nite map from addresses \na to concrete objects o bundled with their allocated base types B. We overload -to indicate both the \ndisjoint heap union of two concrete subheaps and the separating conjunction of two static symbolic subheaps. \nConcretization functions give meaning to abstract constructs by describing how they constrain the set \nof possible values and states. As is standard, we write . for concretization and overload it for all \nconstructs, except base types and .eld types. Object base types and .eld types, crucially, have different \nmeanings in the type domain and symbolic domain. To disambiguate, we write .(B) for concretization in \nthe type analysis and .M(B) for the symbolic analysis. Concretization in the type analysis. In the type \nanalysis, the concretization of an object type is fairly standard: it constrains  .. Hmat (a) = (o,B) \nand C for all methods m exists o where . . . exists o where H(a) = (o,B) and C for all methods m . . \nM.(B) . . . . . . . . o(m) . .(B,(p : Tp).Bret) and  (Hok ,Hmat ,a) o(m) . .(B,(p : Tp).Bret) and @ \nfor all .elds f (H,o,o( f )) . .(Tf F). .(B) (H,a) . . @ for all .elds f f . dom(o) and if a . dom(Hok) \nthen (H, o, o( f )) . .M(Tf F). . . . ..  . .. . .  . . (H,v) . .M(B) and(H,v) . .(B) and .(B l RF \n\u00b7\u00b7\u00b7 ,RF 1 , n ,RF n (Hok ) ) , Hmat for all re.nements Ri (H, o, v) (a) Types domain (b) Symbolic domain \nM , v) for all re.nements Ri \u00b7\u00b7\u00b7 .(B l RF 1 , ...... (H,o,v) . .(RF i ) Hok Hmat -, o, v) . .(RF i ) \n( M M Figure 5. Concretization of an object base type B = {var f : Tf , def m(p : Tp).Bret} in the types \nand symbolic domains. In the symbolic domain, values stored in the .elds of an object in Hok must not \nbe immediately type-inconsistent; values stored in the .elds of an object in Hmat are not constrained. \nThe shaded region highlights the key difference between the concretizations. not only the value but also \nthe entire heap reachable from that object. of the full heap into Hok and Hmat . Crucially, this de.nition \nof As we show in Figure 5a, the concretization .(B) of an object type concretization permits pointers \nfrom Hok to Hmat and vice-versa. B = {var f : Tf , def m(p : Tp).Bret} yields a set of pairs of heaps \nNote that regardless of which heap an object resides in, its method and values (addresses). The concretization \nrequires that the address implementations are still constrained by their signatures. S) of a symbolic \nstate MH) with S = (GM, The concretization .(EM,point to an object o which C has suitable method implementations \n(i.e., constrained by the concretization of the method signature respect to a symbolic environment EMyields \na environment-heap pair (E,H). There must exist a valuation V : SymVal . Values mapping symbolic values \nto concrete values and a partitioning of the heap = Hok (p : Tp).Bret on an object of type B) for each \nmethod m in the object type and @ has suitable .eld values for each declared .eld M agree upon. Symbolic \nfact maps GMand heaps HMboth concretize to a Hmat such that the concretizations of EM, H G, and HMallf \nof type Tf F . We adorn the type with its storage class, F, to make - clear that it is a .eld type dependent \non other .elds. set of valuation-heap-heap tuples where emp in the symbolic heapThe key property of concretization \nin the type domain is that M the concretization of a .eld type T F = B l RF \u00b7\u00b7\u00b7 ,RF is mutually requires \nboth Hok and Hmat be empty whereas okheap requires that 1 , n inductively de.ned with that for base types \nand thus constrains the Hmat be empty but Hok can be any heap. The singleton heap formula entire heap \nreachable from that .eld, in addition to the other .elds concretizes to a singleton in Hmat and -is the \nheap disjoint union of the object. This concretization yields a heap-object-value triple in both Hok \nand Hmat A symbolic path is a disjunction of singleton S . M paths PM=x; its concretization is similar \nto that of a symbolicwhere the heap and value are constrained by the concretization of the state, except \nthat it yields a triple (E,H,v) where V (xM) = v. Soundness. The soundness of FISSILE type analysis and \nin base type and the entire triple is constrained by the concretization of each of the .eld re.nements \nRF i . Because these re.nements are dependent re.nements, they may constrain other .elds of the object \nparticular of handoff and materialization/summarization dependsin addition to the value of the .eld in \nquestion. For example, a on the following key properties of concretization.heap-object-value triple in \nthe concretization of a .eld re.nement At handoff, the analysis requires that the explicitly materializedrespondsTo \ng would constrain the g .eld of the object to store heap be empty. The following lemma states that under \nthose condi\u00ada string with name m that is a valid method for the (potentially different) object pointed \nto by the value. The concretization of a tions (i.e., when the entire heap is Hok), the meaning of base \ntypes type environment .(G) is a set of concrete environment-heap (E,H) in the symbolic domain is the \nsame as the meaning of base types in pairs where the values stored in local variables are consistent \nwith the type domain: the declared types and reachable heaps from the type bindings in G.   Lemma \n1 (Equivalence of Typed and Symbolic Base Types). \u00b7,v) . .M(B) .(B) =(H,(H,v) Concretization in the symbolic \nanalysis. In contrast to the type analysis, in the symbolic world part of the heap may be explicitly \nmaterialized and thus immediately type-inconsistent, leaving the We rely on this result to show that \nthat the T-SYM-HANDOFF and SYM-TYPE-HANDOFF (Section 3.5) rules are sound. To show soundness of the M-MATERIALIZE \nrule, we rely on a property about the meaning of base types in the symbolic domain: Lemma 2 (Type-Consistent \nMaterialization for Types). If (Hok -a : (oa,Ba),Hmat , v) . .M(B) then (Hok ,Hmat -a : (oa,Ba),v) . \n.M(B). This lemma considers a value v of type B and a heap containing an object oa of allocated type \nBa stored at address a (informally, a is in v s reachable heap, otherwise it is uninteresting). If there \nis one concretization of B where a is in the almost type-consistent heap Hok , then the con.guration \nwith a moved to the materialized Hmat is also in its concretization. In essence, moving the storage for \na to the materialized heap will not cause the type of v to change from the perspective of the symbolic \nanalysis. rest of the heap almost type-consistent. To capture this difference, the symbolic concretization \nof an object type yields two heaps: Hok and Hmat , corresponding to a non-deterministic choice of which \nobjects are in the almost type-consistent heap and which objects are materialized and thus may have .eld \nvalues differing from their declared types. We write .M(B) here to emphasize concretization of base types \nin the symbolic domain. The shaded region of Figure 5b illustrates the key difference: in the symbolic \ndomain, an object s .elds are only constrained by the concretization of the .eld types if the object \nis in Hok . If the object is in Hmat , the .elds are guaranteed to exist, but the values stored in them \nare not constrained. Because concretization of object types is de.ned inductively, the concretization \ncan opt out of type constraints for the reachable subheap at each .eld dereference, depending on the \npartitioning  SYM-TYPE-HANDOFF ----. ------. GM,EMtypeify G G f e : T G symbolize GM' , EMMz ./dom(GM' \n) M E f {GM,okheap}e{GM' [Mz : T [EM]],okheap . Mz} SYM-METHOD-CALL-SUMMARY ret (p)[h/h ' ] : p= summary(GM(EM(x)),m) \nMHfr\\. h H f h \u00ae M. = . h t [p : EM(y)] MM E f {GM,H}x.m(y) {GM, (HMfr -h ' [. ]) . . (pret))} Figure \n6. Symbolic execution rules to switch to the typed analysis and to apply symbolic summaries. A related \nlemma describes summarization: Lemma 3 (Soundness of Type-Consistent Summarization for - --. States). \nIf GM,o typeify B and okheap . HMand GM(aM) = B l \u00b7\u00b7\u00b7 then for all EMwe have .(EM,(GM,HM-aM: o)) . .(EM,(GM,HM)) \n. That is, if the symbolic execution determines that a materialized symbolic object is not immediately \ntype inconsistent, then it can summarize the symbolic storage for that object back into okheap (rule \nM-SUMMARIZE) without unsoundly dropping concrete states. We rely on the above lemmas to prove soundness \nof the inter\u00adtwined analysis: Theorem 1. FISSILE Type Analysis is sound. That is, if E f [H]e[r] then \n' 1. If GL f e : T L and (E, H) . .(GL) then r = H' . v where ' (E,H' ) . .(GL) and (E, H ,v ' ) . .(T \nL); and M' 2. If EMf {SM}e{PM} and (E,H) . .(EM,S) then r = H' . v where (E,H' ,v ' ) . .(EM, PM). This \nis a fairly standard statement of soundness of for both analyses. Here, E f [H]e [r] says that in a concrete \nenvironment E and with a concrete heap H, an expression e big-step evaluates to a result r. For types, \nif the initial concrete state is described by the static type environment and the expression type checks, \nthen the expression evaluates to a heap-value pair (that is, not to an error) where the .nal state still \nconforms to the type environment and the value conforms to the static type. Similarly, the symbolic analysis \nsoundly over-approximates the concrete execution and rules out a faulting error. The proof proceeds by \ninduction on the derivation of concrete execution and covers an additional judgment form describing generalized \npath-to-path symbolic analysis we provide full details in our TR [13].  3.5 Fully-Intertwined Type-Symbolic \nAnalysis As described in Section 3.3, the type analysis can hand off checking of an expression to the \nsymbolic analysis. We also would like to perform the opposite handoff from symbolic to type (i.e., apply \ntype analysis within symbolic analysis). For example, we would like do this handoff when we encounter \na method call during symbolic analysis to enable modular analysis with only type speci.cations. Fortunately, \nwe can employ the same consistency mechanisms to allow handoff in the other direction, that is, to switch \nfrom symbolic analysis to type checking (rule SYM-TYPE-HANDOFF in Figure 6). The key constraint is that \nthe entire heap must be fully type-consistent (okheap). In general, this requirement means summarization \nshould have been applied so that no locations are materialized. The entire state is checked type consistent \nvia typeify to G before type checking, and then symbolic analysis can resume by symbolize -ing a new \nsymbolic state from G and adding an assumption from the type of the expression. Suppose this symbolic \nanalysis is the context of an outer .ow\u00adinsensitive type analysis. Observe that type environment G is \nderived solely from the current symbolic execution state and could be more precise than the outer .ow-insensitive \ninvariant. A common scenario is to leverage symbolic reasoning about guard conditions in an if but switch \nto type analysis inside the if body with a stronger invariant without needing to the make any changes \nto the type analysis (cf. occurrence typing [35]). For the re.ective call safety client, the checked \ndelegate idiom is quite common where a re.ective call is performed after checking if an object responds \nto a particular string respondsToSelector: in Objective-C. Symbolic summaries for cross-module bounded \nviolations. On the other hand, we have seen a handful of cases where a further preci\u00adsion re.nement is \nneeded: when programmers break relationship re.nements across module boundaries, such as when they abstract \nthe heap with getters and setters. To see how this is a problem, con\u00adsider the slightly modi.ed version \nof the update function in which the direct .eld access is replaced the following setter functions: 1 \ndef setDel(d)[del : -/del : d] : - = self.del := d 2 def setSel(s)[sel : -/sel : s] : - = self.sel := \ns This small change exacerbates the problem of checking relation\u00adship re.nement safety because now the \ninvariant violation crosses module (function) boundaries and thus cannot go to a fully type\u00adconsistent \nheap on method call. To support this scenario, we enable the programmer to supply additional checked \nannotations, symbolic method summaries of the form (p)[h/h' ] : pret , that permit symbolic checking \nacross module boundaries. Here p is a sequence of method parameter names, h and h' are summaries of the \ninput heap and output heap respectively, and pret speci.es the method return value. The input summary \ngives the form of the part of the heap the method will operate upon (the footprint) and gives names to \nthe values stored in the .elds of the input heap. The output summary gives the form of the heap after \nthe method has .nished executing, in terms of the names given in the input heap and the parameters. For \nexample, the method summary annotation at line 1 says that whatever the del .eld stores before setDel \nis called, after the method is executed the .eld stores the value from the d parameter. Since the method \nis a setter, the return value is irrelevant. The annotation for setSel is analogous. Applying the summary \nfor setDel leaves the heap in an inconsistent state, but then the summary for setSel restores it. With \nthese annotations, checking the calls to the setters is analo\u00adgous to checking the .eld writes as before, \nexcept that rather than applying the symbolic transfer function for .eld writes, we apply the method \nsummary. We formalize this in the SYM-METHOD-CALL-SUMMARY rule in Figure 6. The auxiliary function summary(T,m) \nlooks up the summary of a method m on a static type T . The judg\u00adment HMf h \u00ae HMfr\\. h splits the heap \nHMinto a footprint (speci.ed by h) and the left-over frame (HMfr) that the method is guaranteed not to \ntouch. This frame inference also produces a symbolic map . h that captures the symbolic variables that \nthe parameters in the h match to during the splitting. We then apply this map (combined with the mapping \nfrom parameter names to the symbolic values passed in as parameters) to the output summary h' to get \nthe footprint on method exit and add it back to the frame to get the entire heap on method exit. We also \nconsult this map . to look up the value returned as speci.ed by the summary. We write t for disjoint \nunion of maps where the result is unde.ned if the union is not a map. The frame in\u00adference is a simple \napplication of subtraction [3] but makes this rule quite .exible. The developer can choose to refuse \naccess to okheap in a symbolic summary (as above) to provide a stronger guarantee to the method s callers \nor request it to get a stronger assumption for checking the method implementation. We note that the particular \nkind of symbolic summary that we describe above (essentially, standard pre-/post-conditions in separation \nlogic) is not the most interesting point. Other symbolic analysis techniques could be applied, such as \ncontext-sensitive, non\u00admodular reasoning. Rather, we argue that the interest lies in that heavier-weight \nsymbolic analysis machinery can be applied when needed without the cost of applying it everywhere, all \nthe time.  Checking Method Implementations. For modular checking, we type check each method implementation \nseparately according to its type signature (as is standard). We guarantee that the implementation of \na symbolically-summarized method conforms to its summary with our symbolic analysis infrastructure, although \nthe summary checking technique is orthogonal to that for checking relationship re.nements. One could \nsubstitute a different approach (e.g. abstract interpretation or interactive proofs) if desired. 4. Case \nStudy: Checking Re.ective Call Safety We implemented our FI S S ILE type analysis approach to checking \nalmost .ow-insensitive invariants in a prototype method re.ection safety checker for Objective-C. We \nevaluate our prototype, a plugin to the clang static analyzer, by investigating the following questions: \nWhat is the increased type annotation cost for checking re.ection safety? How much does the mixed F ISS \nI LE approach improve preci\u00adsion? Do our premises about how programmers violate relationships hold in \npractice? Is our intertwined almost type analysis as fast as we hope? We also discuss a bug found by \nour tool surprising in a mature application. The bug .x that we proposed was accepted by the application \ndeveloper. Table 1 describes our prototype s performance on a benchmark suite of 6 libraries and 3 large \napplications. The OmniFrwks are noteworthy because they are very large and have been in continuous development \nsince 1997. The fact that our tool can run on them provides evidence for the kind of real world Objective-C \nthat we can handle something that would be challenging for a purely symbolic analysis. We discuss these \nresults throughout the rest of this section. The developer cost to add modular re.ection checking. To \nseed potential type errors, we .rst annotated the re.ection requirements on 76 system library functions \n(i.e., with respondsTo re.nements). These are requirements imposed by the system API enriched to check \nfor method re.ection errors. Then, for each benchmark we report the total number of developer annotations \nrequired, as well as the average number required per re.ective call site, to give an indication of how \nmuch work it would be for developers to mod\u00adularly check their use of re.ection (column Total Annotations \n). All annotations are checked they emit a static type error if their requirements are not met. Based \non this column, we observe that our benchmarks fall into three categories, depending on how they use \nre.ection. Clients of re.ective APIs, such as Sparkle and ZipKit, have a very low (essentially zero) \nannotation burden. In contrast, benchmarks that expose re.ective interfaces, such as SCRecorder and OAuth \nhave a higher annotation burden. This is perhaps not surprising, since annotations are the mechanism \nthrough which inter\u00adfaces expose requirements to clients. In the middle are those that use re.ection \nin both ways: parts of OmniFrwks do expose a re.ective API, but they also use internal re.ection quite \nsigni.cantly. Our application benchmarks also fall in this category: they are structured into modular \napplication frameworks and a core application client. Over our entire benchmark suite we .nd that we \nneed 0.10 annotations and 0.01 symbolic summaries per re.ective callsite (row Combined, columns Total \nAnnotations and Symbolic Annotations ). In other words, on average, the programmer should expect to write \none annotation for every 10 uses of re.ection and a single symbolic heap effect summary for every 100 \nuses of re.ection. Importantly, note that almost all of annotations are extremely lightweight re.nement \nannotations, like respondsTo only 0.05% of methods required a symbolic summary. Even there, the summaries \nwere very simple because they were on leaf methods, such as setters. This overall low annotation burden \nhighlights a key bene.t of our optimistic mostly .ow-insensitive approach: whenever the re.ection relationship \nis preserved .ow-insensitively, no method summary is needed. Contrast this to a modular .ow\u00adsensitive \napproach where a summary is needed on all methods to describe their potential effects on re.ection-related \n.elds. Improved precision. We veri.ed re.ection safety on our bench\u00admarks using two con.gurations: a \ncompletely .ow-insensitive anal\u00adysis (no switching) and our mixed FI S SI LE approach. We then com\u00adpared \nthe number of static type errors reported by each (columns FI Type Errors and FIS S I LE Type Errors \n). F I S S IL E type analysis sometimes signi.cantly reduces the number of static type alarms (e.g., \nASIHTTP) and by 29% in our combined benchmark suite. The number of FI S S I L E static type alarms ranges \nfrom 0 (for SCRecorder and ZipKit) to 74 (for OmniFrwks, our most chal\u00adlenging benchmark). Pessimistically \nviewing our tool as a post\u00addevelopment analysis, we manually triaged all the reported static type errors \nto determine if they could manifest at run-time as true bugs (see discussion on bugs below) or otherwise \nare false alarms due to static over-approximation. The single biggest source of false alarms were re.ection \ncalls on objects pulled from collection classes. Retro.tting Objective-C s underlying type system for \nparametric polymorphism (like, what has been for Java with generics) would di\u00adrectly improve precision \nfor this case. At the same time, as discussed below, the ef.ciency of F I SSI L E makes it feasible to \ninstead consider it as a development-time type checker where a small number code rewritings or cast insertions \nare not unreasonable (especially if most casts would go away altogether with generic types). Premises. \nWe designed FIS S I L E type analysis around two core premises (Section 2.2): (1) that most of the program \ncan be checked .ow-insensitively and (2) that even when a .ow-insensitive rela\u00adtionship between heap \nstorage locations is violated, most other relationships on the heap remain intact. As Table 1 shows, \nthe num\u00ad ber of times the analysis switches to symbolic execution and back (column Successful Symbolic \nSections ) is quite low, even for large programs Premise 1 appears to hold empirically. The maximum number \nof simultaneous materializations (column Max. Mats.) is also low Premise 2 holds as well empirically. \nNote that we need more than the single materialization that would be possible with a non-disjunctive \n.ow-sensitive analysis. Modular re.ection checking at interactive speeds. Our two core premises hold, \nenabling FI S S I L E type analysis to soundly verify almost everywhere invariants quickly. Analysis \ntimes range from less than a second for our smaller (around 1,000 lines of code) benchmarks to around \n9 seconds (for our largest, about 180,000 lines of code). These results (column Analysis Time ) include \nonly the time to run our analysis: they do not include parsing or clang s base type checker. Our goal \nwith these measurements is to determine the additional compile-time penalty a developer would incur when \nadding our analysis to her existing work-.ow. Expressed as a rate (thousands of lines of code per second), \nour analysis ranges from about 5 kloc/s to around 38 kloc/s, with a weighted average of 23.0 kloc/s. \nIn general, the larger benchmarks show a faster rate because they amortize the high cost of checking \nsystem headers (which are typically more than 100 kloc) over larger compilation units. Finding bugs. \nWhen running our tool on the Vienna benchmark, we found a real re.ection bug in a mature application: \nNSNotificationCenter *nc = [NSNotificationCenter defaultCenter]; [nc addObserver:self selector:\"autoCollapseFolder\" \nname:\"MA_Notify_AutoCollapseFolder\" object:nil]; Here an object registers interest in being noti.ed whenever \nany code in the project auto-collapses a folder. This noti.cation takes the form of a re.ective callback: \nthe autoCollapseFolder method of self will be called. Unfortunately, self has no such method. Our  Benchmark \nLines Re.. Methods Total Symbolic Check FI FI S S I L E Successful Max. Analysis Time of Call Annotations \n/ Annotations / Sites Type Type Errors Symbolic Mats. (Rate) Code Sites Per Re.. Site Per Re.. Site Errors \n(% Reduced) Sections OAuth 1248 7 92 5 / 0.71 0 / 0.00 11 7 2 (-71%) 7 1 0.24s ( 5.3 kloc/s) SCRecorder \n2716 12 200 9 / 0.75 4 / 0.33 15 2 0 (-100%) 2 2 0.28s (10.8 kloc/s) ZipKit 3301 28 165 0 / 0.00 0 / \n0.00 28 0 0 ( ) 0 0 0.10s (33.0 kloc/s) Sparkle 5290 40 320 0 / 0.00 0 / 0.00 40 4 1 (-75%) 3 1 0.67s \n( 7.9 kloc/s) ASIHTTP 13565 68 707 2 / 0.03 2 / 0.03 68 50 10 (-80%) 59 2 0.50s (27.2 kloc/s) OmniFrwks \n160769 192 7611 49 / 0.26 2 / 0.01 259 82 74 (-10%) 9 1 4.25s (37.8 kloc/s) Vienna 37348 186 2261 24 \n/ 0.13 4 / 0.02 207 59 38 (-36%) 28 2 2.79s (13.4 kloc/s) Skim 60211 207 3010 7 / 0.03 0 / 0.00 212 43 \n43 (\u00ad0%) 0 0 2.49s (24.1 kloc/s) Adium 176632 587 8723 40 / 0.07 0 / 0.00 648 87 70 (-20%) 17 1 8.79s \n(20.1 kloc/s) Combined 461080 1327 23089 136 / 0.10 12 / 0.01 1488 334 238 (-29%) 125 2 20.09s (23.0 \nkloc/s) Table 1. The Lines of Code count includes project headers but excludes comments and whitespace; \nMethods indicates the total number of methods; Re.. Call Sites gives the number of calls to system library \nmethods that perform re.ection, either directly or as part of some other operation; Total Annotations \nlists the total number of annotations and the average number of annotations required per re.ective callsite; \nSymbolic Annotations lists gives the number of symbolic summaries required; Check Sites gives the number \nof program sites where some annotation was checked; FI Type Errors indicates the number of check sites \nwhere a .ow-insensitive type analysis produces a type error; FI S S I L E Type Errors indicates the number \nof check sites where we emit a static type error and the corresponding percent reduction from the .ow-insensitive \napproach; Successful Symbolic Sections gives the number of times our analysis successfully switched from \ntype checking to symbolic execution and back again; Max. Mats. gives the maximum number of materialized \nobjects ever present in the explicit heap (this includes unsuccessful symbolic sections); and Analysis \nTime indicates the speed of our analysis on each benchmark, in both absolute terms and in lines of code \nper second. Our benchmarks include OAuth, which performs OAuth Consumer authentication; SCRecorder, which \nrecords custom keyboard shortcuts and is the source of our motivating example in Section 2; ZipKit, which \nreads and writes compressed archives; Sparkle, a widely-used automatic updater; ASIHTTP, which performs \nweb services calls; and the OmniFrwks, which provide base functionality to the widely used OmniGraf.e \napplication; Vienna, an RSS newsreader; Skim, a PDF reader; and Adium, an instant message chat client. \nThe Combined row treats all of the benchmarks together as a combined workload. Experiments were performed \non a 4-core 2.6 GHz Intel Core i7 laptop with 16GB of RAM running OS X 10.8.2. We used clang 3.2 (trunk \n165236) compiled in Release+Asserts mode to perform the analysis and xcodebuild 4.6/4H127 to drive the \nbuild. analysis detects this error and issues an alarm. We reported the bug to the developers; they acknowledged \nit as a bug and .xed it (see https://github.com/ViennaRSS/vienna-rss/pull/85). Our tool was also useful \nin .nding bugs in beginner Objective-C code. We used it to statically detect run-time errors in 12 code \nsnippets culled from mailing lists and discussion forums. These novice re.ective errors fell into three \ndifferent categories: (1) typos in selector names, (2) intending to re.ectively call a method with a \nselector stored in a variable but instead passing in a constant selector with the name of the variable, \nand (3) passing the wrong responder into a re.ective call, typically a .eld of self instead of self itself. \nThese results show that our tool can statically detect a common class of novice errors; they provide \nevidence in favor of including re.ective call checking with FI S S IL E type analysis in the compiler. \n5. Related Work Dependent re.nement types [20, 38] enable programmers to restrict types based on the \nvalue of program expressions and thus rule out certain classes of run-time errors, such as out-of-bounds \narray ac\u00adcesses. Extending dependent types to imperative languages [34, 37] has generally led to .ow-sensitive \ntype systems because mutation may change the value of a variable referred to in a type. The high burden \nthat .ow-sensitive type annotations impose on the programmer motivates sophisticated inference schemes \n[31], of which CSO LVE [32] is perhaps the closest work to ours. In con\u00ad trast to CSO LV E, which performs \n.ow-sensitive checking of in\u00adferred .ow-sensitive types with at most one materialization, we use path-sensitive \nchecking of .ow-insensitive annotations [12] and support arbitrary materialization with a disjunctive \nsymbolic analysis, as opposed to proving non-aliasing for one materializa\u00adtion (e.g., [1, 2, 18]). DJS \n[11] checks dependent re.nements in JavaScript, including the safety of dynamic .eld accesses a prob\u00adlem \nsimilar to re.ective method call safety but supports only single materialization and employs a .ow-sensitive \nheap. There has been a recent explosion in techniques (e.g., [7, 22]) that have signi.cantly improved \nthe effectiveness of symbolic execution. The SMPP approach [24] leverages SMT technology combined with \nabstract interpretation on path programs to lift a symbolic-execution based technique to exhaustive veri.cation. \nThis technique can be seen as applying a .xed one level of analysis switching between a top-level symbolic \nexecutor and an abstract interpreter for loops. Our approach of switching between type checking and symbolic \nexecution is similar to the MI X system [25] for simple types. A signi.cant difference is that our approach \nenables the symbolic executor to leverage the heap-consistency invariant enforced by the type analysis \nthrough a type-consistent materialization operation, which is critical for our rich re.nement relationship \ninvariants, whereas the symbolic and type analyses in MIX interact minimally with respect to the heap. \nThe notion of temporary violations of an invariant is also reminiscent of the large body of work on object \ninvariants (see [17] for an overview). We remark on two perspective differences that make FIS S I L E \ncomplementary to this work. First, the points where the invariant is assumed and where they may be violated \nis not based on the program structure (e.g., inside a method or not) but instead is based on the analysis \nbeing applied (i.e., type or symbolic). Second, the symbolic analysis takes a more global view of the \nheap and decides speci.cally which objects may violate the global type invariant. Issues like reentrancy \nand multi-object invariants are not as salient in FI SS IL E, but are possible at the cost of separate \nsymbolic summaries or more expensive, disjunctive analysis in certain complex situations. On materialized \nheap locations, our symbolic analysis works over separation logic [3, 30] formulas. We de.ne an on-demand \nmaterialization [33] that is universal in separation-logic based analyzers [4, 9, 16]. However, our materialization \noperator pulls out heap cells that are summarized and validated independently using a re.nement type \nanalysis. Bi-abductive shape analyses [8, 23] are modular analyses that try to infer a symbolic summary \nfor each method. Our analysis is modular using a fast, .ow-insensitive type analysis with few uses of \nsymbolic summaries. Bi-abduction and our technique could complement each other nicely in that (1) we \ndo not require symbolic summaries on all methods only those that violate type consistency across method \nboundaries and (2) bi-abduction could be applied to generate candidate symbolic summaries. Most prior \nwork on re.ection analysis has focused on whole\u00adprogram resolution: determining, at a re.ective site, \nwhat method is called (either statically [6, 10, 36] or dynamically [5, 21]).  We address the problem \nof modular static checking of re.ective call safety: ensuring that the receiver responds to the selector, \nin languages with imperative update. Politz et al. [29] describe a type system that modularly checks \nre.ection safety by combining occurrence typing [35] with .rst-class member names speci.ed by string \npatterns. In contrast, we treat the responds-to relationship as .rst-class (i.e., we permit the user \nto specify it with a dependent re.nement), allowing us to (1) check relationships between mutable .elds \nand (2) express that an object responds to two completely unknown (i.e. potentially identical) selectors. \nLivshits et al. [27] assume re.ection safety and leverage this assumption to improve precision of callgraph \nconstruction. 6. Conclusion We have described FI SS I L E type analysis, which intertwines fast type \nanalysis over storage locations and precise symbolic analysis over values to ef.ciently, effectively, \nand modularly prove relation\u00adship properties. We have evaluated FIS S I L E using an interesting safety \nproperty re.ective method call safety. The key technical enabler for our analysis is materialization \nfrom an almost type\u00adconsistent heap. On a benchmark suite consisting of commonly-used Objective-C libraries \n(6) and applications (3), we .nd that our ap\u00adproach is capable of .nding con.rmed bugs in both production \nand beginner code. It has a balanced annotation burden that is negligible for clients of re.ection and \nmoderate (up to 0.75 annotations per re.ective call site) for re.ective interfaces. FI SS I L E type \nanalysis starts with the optimistic assumption that global .ow-insensitive relationship invariants hold \nalmost everywhere it only has to use precise and expensive reasoning for those few program locations \nthat violate a relationship. Contrast this to traditional modular .ow-sensitive analyses, which require \nall methods to specify their effect on the heap to rule out the pessimistic assumption that relationship \ninvariants could be violated anywhere. Our approach permits the vast majority (99.95%) of methods to \navoid any annotations related to heap effects. Checking most of the program .ow-insensitively allows \nF I S S ILE to validate re.ective method call safety at interactive speeds (5 to 38 kloc/s with an overall \nrate of 23.0 kloc/s over our benchmark suite). Acknowledgments We thank Sriram Sankaranarayanan, Amer \nDiwan, Jeremy Siek, the CUPLV group, and Ranjit Jhala for insightful discussions, as well as the anonymous \nreviewers for their helpful comments. This material is based upon work supported by the National Science \nFoundation under Grant Nos. CCF-1218208 and CCF-1055066. References [1] A. Ahmed, M. Fluet, and G. Morrisett. \nL3: A linear language with locations. Fundam. Inform., 77(4), 2007. [2] A. Aiken, J. S. Foster, J. Kodumal, \nand T. Terauchi. Checking and inferring local non-aliasing. In PLDI, 2003. [3] J. Berdine, C. Calcagno, \nand P. W. O Hearn. Symbolic execution with separation logic. In APLAS, 2005. [4] J. Berdine, C. Calcagno, \nB. Cook, D. Distefano, P. W. O Hearn, T. Wies, and H. Yang. Shape analysis for composite data structures. \nIn CAV, 2007. [5] E. Bodden, A. Sewe, J. Sinschek, H. Oueslati, and M. Mezini. Taming Re.ection: Aiding \nstatic analysis in the presence of re.ection and custom class loaders. In ICSE, 2011. [6] M. Braux and \nJ. Noy\u00b4 e. Towards partially evaluating re.ection in Java. In PEPM, 2000. [7] C. Cadar, D. Dunbar, and \nD. R. Engler. KLEE: Unassisted and automatic generation of high-coverage tests for complex systems programs. \nIn OSDI, 2008. [8] C. Calcagno, D. Distefano, P. W. O Hearn, and H. Yang. Compositional shape analysis \nby means of bi-abduction. In POPL, 2009. [9] B.-Y. E. Chang and X. Rival. Relational inductive shape \nanalysis. In POPL, 2008. [10] A. S. Christensen, A. M\u00f8ller, and M. I. Schwartzbach. Precise analysis \nof string expressions. In SAS, 2003. [11] R. Chugh, D. Herman, and R. Jhala. Dependent types for JavaScript. \nIn OOPSLA, 2012. [12] J. Condit, M. Harren, Z. R. Anderson, D. Gay, and G. C. Necula. Dependent types \nfor low-level programming. In ESOP, 2007. [13] D. Coughlin and B.-Y. E. Chang. Fissile Type Analysis: \nModular checking of almost everywhere invariants (extended version), 2013. [14] P. Cousot and R. Cousot. \nAbstract interpretation: A uni.ed lattice model for static analysis of programs by construction or approximation \nof .xpoints. In POPL, 1977. [15] P. Cousot and R. Cousot. Systematic design of program analysis frameworks. \nIn POPL, 1979. [16] D. Distefano, P. W. O Hearn, and H. Yang. A local shape analysis based on separation \nlogic. In TACAS, 2006. [17] S. Drossopoulou, A. Francalanza, P. M \u00a8uller, and A. J. Summers. A uni.ed \nframework for veri.cation techniques for object invariants. In ECOOP, 2008. [18] M. F\u00a8ahndrich and R. \nDeLine. Adoption and focus: Practical linear types for imperative programming. In PLDI, 2002. [19] C. \nFlanagan. Hybrid type checking. In POPL, 2006. [20] T. Freeman and F. Pfenning. Re.nement types for ML. \nIn PLDI, 1991. [21] M. Furr, J.-h. D. An, and J. S. Foster. Pro.le-guided static typing for dynamic scripting \nlanguages. In OOPSLA, 2009. [22] P. Godefroid, N. Klarlund, and K. Sen. DART: Directed automated random \ntesting. In PLDI, 2005. [23] B. S. Gulavani, S. Chakraborty, G. Ramalingam, and A. V. Nori. Bottom-up \nshape analysis. In SAS, 2009. [24] W. R. Harris, S. Sankaranarayanan, F. Ivancic, and A. Gupta. Program \nanalysis via satis.ability modulo path programs. In POPL, 2010. [25] Y. P. Khoo, B.-Y. E. Chang, and \nJ. S. Foster. Mixing type checking and symbolic execution. In PLDI, 2010. [26] V. Laviron, B.-Y. E. Chang, \nand X. Rival. Separating shape graphs. In ESOP, 2010. [27] B. Livshits, J. Whaley, and M. S. Lam. Re.ection \nanalysis for Java. In APLAS, 2005. [28] M. J. Parkinson. Local Reasoning for Java. PhD thesis, University \nof Cambridge, Computer Laboratory, 2005. [29] J. G. Politz, A. Guha, and S. Krishnamurthi. Semantics \nand types for objects with .rst-class member names. In FOOL, 2012. [30] J. C. Reynolds. Separation logic: \nA logic for shared mutable data structures. In LICS, 2002. [31] P. M. Rondon, M. Kawaguchi, and R. Jhala. \nLiquid types. In PLDI, 2008. [32] P. M. Rondon, M. Kawaguchi, and R. Jhala. Low-level liquid types. In \nPOPL, 2010. [33] M. Sagiv, T. Reps, and R. Wilhelm. Solving shape-analysis problems in languages with \ndestructive updating. ACM Trans. Program. Lang. Syst., 20(1), 1998. [34] R. Tate, J. Chen, and C. Hawblitzel. \nInferable object-oriented typed assembly language. In PLDI, 2010. [35] S. Tobin-Hochstadt and M. Felleisen. \nThe design and implementation of Typed Scheme. In POPL, 2008. [36] O. Tripp, M. Pistoia, S. J. Fink, \nM. Sridharan, and O. Weisman. TAJ: Effective taint analysis of web applications. In PLDI, 2009. [37] \nH. Xi. Imperative programming with dependent types. In LICS, 2000. [38] H. Xi and F. Pfenning. Dependent \ntypes in practical programming. In POPL, 1999.   \n\t\t\t", "proc_id": "2535838", "abstract": "<p>We present a generic analysis approach to the <i>imperative relationship update problem</i>, in which destructive updates temporarily violate a global invariant of interest. Such invariants can be conveniently and concisely specified with dependent refinement types, which are efficient to check flow-insensitively. Unfortunately, while traditional flow-insensitive type checking is fast, it is inapplicable when the desired invariants can be temporarily broken. To overcome this limitation, past works have directly ratcheted up the complexity of the type analysis and associated type invariants, leading to inefficient analysis and verbose specifications. In contrast, we propose a <i>generic lifting</i> of modular refinement type analyses with a symbolic analysis to efficiently and effectively check concise invariants that hold <i>almost everywhere</i>. The result is an efficient, highly modular flow-insensitive type analysis to <i>optimistically</i> check the preservation of global relationship invariants that can fall back to a precise, disjunctive symbolic analysis when the optimistic assumption is violated. This technique permits programmers to temporarily break and then re-establish relationship invariants--a flexibility that is crucial for checking relationships in real-world, imperative languages. A significant challenge is selectively violating the global type consistency invariant over heap locations, which we achieve via <i>almost type-consistent heaps</i>. To evaluate our approach, we have encoded the problem of verifying the safety of reflective method calls in dynamic languages as a refinement type checking problem. Our analysis is capable of validating reflective call safety at interactive speeds on commonly-used Objective-C libraries and applications.</p>", "authors": [{"name": "Devin Coughlin", "author_profile_id": "81442593521", "affiliation": "University of Colorado Boulder, Boulder, CO, USA", "person_id": "P4383750", "email_address": "devin.coughlin@colorado.edu", "orcid_id": ""}, {"name": "Bor-Yuh Evan Chang", "author_profile_id": "81464662824", "affiliation": "University of Colorado Boulder, Boulder, CO, USA", "person_id": "P4383751", "email_address": "evan.chang@colorado.edu", "orcid_id": ""}], "doi_number": "10.1145/2535838.2535855", "year": "2014", "article_id": "2535855", "conference": "POPL", "title": "Fissile type analysis: modular checking of almost everywhere invariants", "url": "http://dl.acm.org/citation.cfm?id=2535855"}