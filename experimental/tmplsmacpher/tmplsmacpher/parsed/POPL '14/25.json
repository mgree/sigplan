{"article_publication_date": "01-08-2014", "fulltext": "\n On Coinductive Equivalences for Higher-Order Probabilistic Functional Programs Ugo Dal Lago Davide \nSangiorgi Universit` a di Bologna &#38; INRIA {dallago,sangio}@cs.unibo.it Abstract We study bisimulation \nand context equivalence in a probabilistic .-calculus. The contributions of this paper are threefold. \nFirstly we show a technique for proving congruence of probabilistic ap\u00adplicative bisimilarity. While \nthe technique follows Howe s method, some of the technicalities are quite different, relying on non-trivial \ndisentangling properties for sets of real numbers. Secondly we show that, while bisimilarity is in general \nstrictly .ner than context equivalence, coincidence between the two relations is attained on pure .-terms. \nThe resulting equality is that induced by Levy-Longo trees, generally accepted as the .nest extensional \nequivalence on pure .-terms under a lazy regime. Finally, we derive a coinductive characterisation of \ncontext equivalence on the whole probabilistic language, via an extension in which terms akin to distributions \nmay appear in redex position. Another motivation for the extension is that its operational semantics \nallows us to experiment with a different congruence technique, namely that of logical bisimilarity. Categories \nand Subject Descriptors F.3.1 [Logics and Mean\u00ading of Programs]: Specifying and Verifying and Reasoning \nabout Programs logics of programs; F.3.2 [Logics and Meaning of Pro\u00adgrams]: Semantics of Programming \nLanguages operational seman\u00adtics. General Terms Theory Keywords Bisimulation; Probabilistic Lambda Calculus; \nCoinduc\u00adtion; Howe s Technique. 1. Introduction Probabilistic models are more and more pervasive. Not \nonly are they a formidable tool when dealing with uncertainty and incomplete information, but they sometimes \nare a necessity rather than an option, like in computational cryptography (where, e.g., secure public \nkey encryption schemes need to be probabilistic [17]). A nice way to deal computationally with probabilistic \nmodels is to allow probabilistic choice as a primitive when designing algorithms, this way switching \nfrom usual, deterministic computation to a new paradigm, called probabilistic computation. Examples of \napplication areas in which Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page. \nCopyrights for components of this work owned by others than ACM must be honored. Abstracting with credit \nis permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. Request permissions from permissions@acm.org. POPL 14, January \n22 24, 2014, San Diego, CA, USA. Copyright c &#38;#169; 2014 ACM 978-1-4503-2544-8/14/01. . . $15.00. \nhttp://dx.doi.org/10.1145/2535838.2535872 Michele Alberti Institut de Math\u00b4 ematiques de Luminy CNRS \n&#38; Universit\u00b4 e d Aix-Marseille michele.alberti@univ-amu.fr probabilistic computation has proved to \nbe useful include natural language processing [29], robotics [44], computer vision [8], and machine learning \n[33]. This new form of computation, of course, needs to be available to programmers to be accessible. \nAnd indeed, various probabilistic programming languages have been introduced in the last years, span\u00adning \nfrom abstract ones [24, 32, 37] to more concrete ones [18, 34], being inspired by various programming \nparadigms like imperative, functional or even object oriented. A quite common scheme consists in endowing \nany deterministic language with one or more primitives for probabilistic choice, like binary probabilistic \nchoice or primitives for distributions. One class of languages that cope well with probabilistic com\u00adputation \nare functional languages. Indeed, viewing algorithms as functions allows a smooth integration of distributions \ninto the play\u00adground, itself nicely re.ected at the level of types through mon\u00adads [20, 37]. As a matter \nof fact, many existing probabilistic pro\u00adgramming languages [18, 34] are designed around the .-calculus \nor one of its incarnations, like Scheme. The focus of this paper are operational techniques for under\u00adstanding \nand reasoning about program equality in higher-order prob\u00adabilistic languages. Checking computer programs \nfor equivalence is a crucial, but challenging, problem. Equivalence between two programs generally means \nthat the programs should behave in the same manner under any context. Speci.cally, two .-terms are con\u00adtext \nequivalent if they have the same convergence behavior (i.e., they do or do not terminate) in any possible \ncontext. Finding effective methods for context equivalence proofs is particularly challenging in higher-order \nlanguages. Bisimulation has emerged as a very powerful operational method for proving equivalence of \nprograms in various kinds of languages, due to the associated coinductive proof method. To be useful, \nthe behavioral relation resulting from bisimulation bisimilarity should be a congruence, and should \nalso be sound with respect to context equivalence. Bisimulation has been transplanted onto higher-order \nlanguages by Abramsky [1]. This version of bisim\u00adulation, called applicative bisimulation has received \nconsiderable attention [19, 27, 28, 35, 36, 39]. In short, two functions M and N are applicative bisimilar \nwhen their applications M P and N P are applicative bisimilar for any argument P . Often, checking a \ngiven notion of bisimulation to be a con\u00adgruence in higher-order languages is nontrivial. In the case \nof ap\u00adplicative bisimilarity, congruence proofs usually rely on Howe s method [22]. Other forms of bisimulation \nhave been proposed, such as environmental bisimulation and logical bisimulation [25, 41, 42], with the \ngoal of relieving the burden of the proof of congruence, and of accommodating language extensions. In \nthis work, we consider the pure .-calculus extended with a probabilistic choice operator. Context equivalence \nof two terms means that they have the same probability of convergence in all con\u00adtexts. The objective \nof the paper is to understand context equivalence and bisimulation in this paradigmatic probabilistic \nhigher-order lan\u00adguage, called ...  The paper contains three main technical contributions. The .rst \nis a proof of congruence for probabilistic applicative bisimilarity along the lines of Howe s method. \nThis technique consists in de.ning, for every relation on terms R, its Howe s lifting RH . The construction, \nessentially by de.nition, ensures that the relation obtained by lifting bisimilarity is a congruence; \nthe latter is then proved to be itself a bisimulation, therefore coinciding with applicative bisimilarity. \nDe.nitionally, probabilistic applicative bisimulation is obtained by setting up a labelled Markov chain \non top of .-terms, then adapting to it the coinductive scheme introduced by Larsen and Skou in a .rst-order \nsetting [26]. In the proof of congruence, the construction (\u00b7)H closely re.ects analogous constructions \nfor nondeterministic extensions of the .-calculus. The novelties are in the technical details for proving \nthat the resulting relation is a bisimulation: in particular our proof of the so-called Key Lemma an \nessential ingredient in Howe s method relies on non-trivial disentangling properties for sets of real \nnumbers, these properties themselves proved by modeling the problem as a .ow network and then apply the \nMax-.ow Min-cut Theorem. The congruence of applicative bisimilarity yields soundness with respect to \ncontext equivalence as an easy corollary. Completeness, however, fails: applicative bisimilarity is proved \nto be .ner. A subtle aspect is also the late vs. early formulation of bisimilarity; with a choice operator \nthe two versions are semantically different; our construction crucially relies on the late style. In \nour second main technical contribution we show that the presence of higher-order functions and probabilistic \nchoice in contexts gives context equivalence and applicative bisimilarity maximal discriminating power \non pure .-terms. We do so by proving that, on pure .-terms, both context equivalence and applicative \nbisimilarity coincide with the Levy-Longo tree equality, which equates terms with the same Levy-Longo \ntree (brie.y LLT), and is generally accepted as the .nest extensional equivalence on pure .-terms under \na lazy regime. The result is in sharp contrast with what happens under a nondeterministic interpretation \nof choice (or in the absence of choice), where context equivalence is coarser than LLT equality. Our \nthird main contribution is a coinductive characterisation of probabilistic context equivalence on the \nwhole language .. (as opposed to the subset of pure .-terms). We obtain this result by set\u00adting a bisimulation \ngame on an extension of .. in which weighted formal sums terms akin to distributions may appear in \nredex position. Thinking of distributions as sets of terms, the construction reminds us of the reduction \nof nondeterministic to deterministic automata. The technical details are however quite different, because \nwe are in a higher-order language and therefore once more we are faced with the congruence problem \nfor bisimulation, and because formal sums may contain an in.nite number of terms. For the proof of congruence \nof bisimulation in this extended language, we have experimented the technique of logical bisimulation. \nIn this method (and in the related method of environmental bisimu\u00adlation), the clauses of applicative \nbisimulation are modi.ed so to allow the standard congruence argument for bisimulations in .rst\u00adorder \nlanguages, where the bisimulation method itself is exploited to establish that the closure of the bisimilarity \nunder contexts is again a bisimulation. Logical bisimilarities have two key elements. First, bisimilar \nfunctions may be tested with bisimilar (rather than identical) arguments (more precisely, the arguments \nshould be in the context closure of the bisimulation; the use of contexts is nec\u00adessary for soundness). \nSecondly, the transition system should be small-step, deterministic (or at least con.uent), and the bisimulation \ngame should also be played on internal moves. In our probabilistic setting, the ordinary logical bisimulation \ngame has to be modi.ed substantially. Formal sums represent possible evolutions of running terms, hence \nthey should appear in redex position only (allowing them anywhere would complicate matters considerably). \nThe obli\u00adgation of redex position for certain terms is in contrast with the basic schema of logical bisimulation, \nin which related terms can be used as arguments to bisimilar functions and can therefore end up in arbitrary \npositions. We solve this problem by moving to coupled logical bisimulations, where a bisimulation is \nformed by a pair of relations, one on ..-terms, the other on terms extended with formal sums. The bisimulation \ngame is played on both relations, but only the .rst relation is used to assemble input arguments for \nfunctions. Another delicate point is the meaning of internal transitions for formal sums. In logical \nbisimilarity the transition system should be small-step; and formal sums should evolve into values in \na .nite number of steps, even if the number of terms composing the formal sum is in.nite. We satisfy \nthese requirements by de.ning the transition system for extended terms on top of that for ..-terms. The \nproof of congruence of coupled logical bisimilarity also exploits an up-to distribution bisimulation \nproof technique. In the paper we adopt call-by-name evaluation. The results on applicative bisimilarity \ncan be transported onto call-by-value; in contrast, transporting the other results is more problematic, \nand we leave it for future work. See Section 6 for more details. An extended version of this paper is \navailable [10]. 1.1 Further Related Work Research on (higher-order) probabilistic functional languages \nhave, so far, mainly focused on either new programming constructs, or denotational semantics, or applications. \nThe underlying operational theory, which in the ordinary .-calculus is known to be very rich, has remained \nso far largely unexplored. In this section, we give some pointers to the relevant literature on probabilistic \n.-calculi, without any hope of being exhaustive. Various probabilistic .-calculi have been proposed, \nstarting from the pioneering work by Saheb-Djahromi [38], followed by more advanced studies by Jones \nand Plotkin [24]. Both these works are mainly focused on denotational semantics. More recently, there \nhas been a revamp on this line of work, with the introduction of adequate (and sometimes also fully-abstract) \ndenotational models for probabilistic variations of PCF [11, 16]. There is also another thread of research \nin which various languages derived from the .\u00adcalculus are given types in monadic style, allowing this \nway to nicely model concrete problems like Bayesian inference and probability models arising in robotics \n[20, 32, 37]; these works however, do not study operationally based theories of program equivalence. \nNondeterministic extensions of the .-calculus have been anal\u00adysed in typed calculi [3, 27, 43] as well \nas in untyped calculi [6, 13, 23, 30]. The emphasis in all these works is mainly domain-theoretic. Apart \nfrom [30], all cited authors closely follow the testing the\u00adory [12], in its modalities may or must, \nseparately or together. Ong s approach [30] inherits both testing and bisimulation elements. Our de.nition \nof applicative bisimulation follows Larsen and Skou s scheme [26] for fully-probabilistic systems. Many \nother forms of probabilistic bisimulation have been introduced in the liter\u00adature, but their greater \ncomplexity is usually due to the presence of both nondeterministic and probabilistic behaviors, or to \ncontinuous probability distributions. See surveys such as [5, 21, 31]. Contextual characterisations of \nLLT equality include [7], in a .-calculus with multiplicities in which deadlock is observable, and [15], \nin a .-calculus with choice, parallel composition, and both call-by-name and call-by-value applications. \nSee [14] for a survey on observational characterisations of .-calculus trees.  2. Preliminaries 2.1 \nA Pure, Untyped, Probabilistic Lambda Calculus Let X = {x, y, . . .} be a denumerable set of variables. \nThe set .. of term expressions, or terms is de.ned as follows: M, N, L ::= x | .x.M | MN | M . N, where \nx . X. The only non-standard operator in .. is probabilistic choice: M . N is a term which is meant to \nbehave as either M or N, each with probability 1 2 . A more general construct M .p N where p is any (computable) \nreal number from [0, 1], is derivable, given the universality of the .-calculus (see, e.g., [9]). The \nset of free variables of a term M is indicated as FV(M) and is de.ned as usual. Given a .nite set of \nvariables x . X, ..(x) denotes the set of terms whose free variables are among the ones in x. A term \nM is closed if FV(M) = \u00d8 or, equivalently, if M . ..(\u00d8). The (capture-avoiding) substitution of N for \nthe free occurrences of x in M is denoted M{N/x}. We sometimes use the identity term def def I = .x.x, \nthe projector K = .x..y.x, and the purely divergent def term O = (.x.xx)(.x.xx). Terms are now given \na call-by-name semantics following [9]. A term is a value if it is a closed .-abstraction. We call V.. \nthe set of all values. Values are ranged over by metavariables like V, W, X. Closed terms evaluates not \nto a single value, but to a (partial) value distribution, that is, a function D : V.. . R[0,1] such m \nthat D(V ) = 1. Distributions do not necessarily sum to V .V.. 1, so to model the possibility of (probabilistic) \ndivergence. Given a value distribution D, its support S(D) is the subset of V.. whose elements are values \nto which D attributes positive probability. Value distributions ordered pointwise form both a lower semilattice \nand an .CPO: limits of .-chains always exist. Given a value distribution m m D, its sum D is D(V ). V \n.V.. The call-by-name semantics of a closed term M is a value distribution [ M] de.ned in one of the \nways explained in [9]. We recall this now, though only brie.y for lack of space. The .rst step consists \nin de.ning a formal system deriving .nite lower approximations to the semantics of M. Big-step approximation \nsemantics, as an example, derives judgments in the form M . D, where M is a term and D is a value distribution \nof .nite support (see Figure 1). Small-step approximation semantics can be de.ned similarly, and derives \njudgments in the form M . D. Noticeably, big-step and small-step can simulate each other, i.e. if M . \nD, then M . E where E = D, and vice versa [9]. In the second step, [ M] , called the semantics of M, \nis set as the least upper bound of distributions obtained in either of the two ways: def [ M] = sup D \n= sup D. M.D M.D Notice that the above is well-de.ned because for every M , the set of all distributions \nD such that M . D is directed, and thus its least upper bound is a value distribution because of .-completeness. \ndef EXAMPLE 2.1. Consider the term M = I . (K . O). We have M . D, where D(I) = 2 1 and D(V ) is 0 elsewhere, \nas well as M . \u00d8, where \u00d8 is the empty distribution. The distribution [ M] assigns 1 2 to I and 1 4 to \nK. The semantics of terms satis.es some useful equations, such as: LEMMA 2.2. [ M . N] = 1 2 [ M] + 1 \n2 [ N ] . We are interested in context equivalence in this probabilistic setting. Typically, in a qualitative \nscenario as the (non)deterministic one, terms are considered context equivalent if they both converge \nor diverge. Here, we need to take into account quantitative information. expone f n = (f n) (+) (expone \nf n+1) exptwo f = (\\x -> f x) (+) (exptwo (\\x -> f (x+1))) expthree k f n = foldp k n f (expthree (expone \nid k) f) foldp 0 n f g = g n foldp m n f g = (f n) (+) (foldp (m-1) (n+1) f g) Figure 2. Three Higher-Order \nFunctions DEFINITION 2.3 (Context Preorder and Equivalence). The expres\u00ad m sion M.p stands for [ M] = \np, i.e., the term M converges with probability p. The context preorder =. stipulates M=.N if C[M ].p \nimplies C[N].q with p = q, for every closing context C. The equivalence induced by =. is probabilistic \ncontext equivalence, denoted as ... REMARK 2.4 (Types, Open Terms). The results in this paper are stated \nfor an untyped language. Adapting them to a simply-typed language is straightforward; we use integers, \nbooleans and recur\u00adsion in examples. Moreover, while the results are often stated for closed terms only, \nthey can be generalized to open terms in the expected manner. In the paper, context equivalences and \npreorders are de.ned on open terms; (bi)similarities are de.ned on closed terms and it is then intended \nthat they are extended to open terms by requiring the usual closure under substitutions. EXAMPLE 2.5. \nWe give some basic examples of higher-order prob\u00adabilistic programs, which we will analyse using the \ncoinductive techniques we introduce later in this paper. Consider the functions expone, exptwo, and expthree \nfrom Figure 2. They are written in a Haskell-like language extended with probabilistic choice, but can \nalso be seen as terms in a (typed) probabilistic .-calculus with integers and recursion akin to ... Term \nexpone takes a function f and a natural number n in input, then it proceeds by tossing a fair coin (captured \nhere by the binary in.x operator (+)) and, depend\u00ading on the outcome of the toss, either calls f on n, \nor recursively calls itself on f and n+1. When fed with, e.g., the identity and the natural number 1, \nthe program expone evaluates to the geometric distribution assigning probability 21 n to any positive \nnatural number n. A similar effect can be obtained by exptwo, which only takes f in input, then modifying \nit along the evaluation. The function expthree is more complicated, at least apparently. To understand \nits behavior, one should .rst look at the auxiliary function foldp. If m and n are two natural numbers \nand f and g are two functions, foldp m n f g call-by-name reduces to the following expression: (f n) \n(+) ((f n+1) (+) ... ((f n+m-1) (+) (g n+m))). The term expthree works by forwarding its three arguments \nto foldp. The fourth argument is a recursive call to expthree where, however, k is replaced by any number \ngreater or equal to it, chosen according to a geometric distribution. The functions above can all be \nexpressed in .., using .xed-point combinators. As we will see soon, expone, exptwo, and expthree k are \ncontext equivalent whenever k is a natural number.  2.2 Probabilistic Bisimulation In this section we \nrecall the de.nition and a few basic notions of bisimulation for labelled Markov chains, following Larsen \nand Skou [26]. In Section 3 we will then adapt this form of bisimilarity to the probabilistic .-calculus \n.. by combining it with Abramsky s applicative bisimilarity. DEFINITION 2.6. A labelled Markov chain \nis a triple (S, L, P) such that: S is a countable set of states;  L is set of labels;   M . D {P \n{N/x} . EP,N }.x.P .S(D) M . D N . E bt bv m ba 1 bs M . \u00d8 V . {V } MN . D(.x.P ) \u00b7 EP,N M . N . 1 \u00b7 \nD + \u00b7 E .x.P .S(D) 22 Figure 1. Big-step call-by-name approximation semantics for ... P is a transition \nprobability matrix, i.e. a function P : S\u00d7L\u00d7S . R[0,1] such that the following normalization condition \nholds: .e . L..s . S. P(s, e, S) = 1 m where, as usual P(s, e, X) stands for t.X P(s, e, t) when\u00adever \nX . S. If R is an equivalence relation on S, S/R denotes the quotient of S modulo R, i.e., the set of \nall equivalence classes of S modulo R. Given any binary relation R, its re.exive and transitive closure \nis denoted as R * . DEFINITION 2.7. Given a labelled Markov chain (S, L, P), a probabilistic bisimulation \nis an equivalence relation R on S such that (s, t) . R implies that for every e . L and for every E . \nS/R, P(s, e, E) = P(t, e, E). Note that a probabilistic bisimulation has to be, by de.nition, an equivalence \nrelation. This means that, in principle, we are not allowed to de.ne probabilistic bisimilarity simply \nas the union of all probabilistic bisimulations. As a matter of fact, given R, T two equivalence relations, \nR . T is not necessarily an equivalence relation. The following is a standard way to overcome the problem: \nLEMMA 2.8. If {Ri}i.I , is a collection of probabilistic bisimula\u00adtions, then also their re.exive and \ntransitive closure ( i.I Ri) * is a probabilistic bisimulation. Lemma 2.8 allows us to de.ne the largest \nprobabilistic bisimulation, def called probabilistic bisimilarity. It is ~= {R | R is a probabilis\u00adtic \nbisimulation}. Indeed, by Lemma 2.8, (~) * is a probabilistic bisimulation too; we now claim that ~ = \n(~) * . The inclusion ~ . (~) * is obvious. The other way around, ~. (~) * , follows by (~) * being a \nprobabilistic bisimulation and hence included in ~. In the notion of a probabilistic simulation, preorders \nplay the role of equivalence relations: given a labelled Markov chain (S, L, P), a probabilistic simulation \nis a preorder relation R on S such that (s, t) . R implies that for every e . L and for every X . S, \nP(s, e, X) = P(t, e, R(X)), where as usual R(X) stands for the R-closure of X, namely the set {y . S \n| . x . X. x R y}. Lemma 2.8 holds for probabilistic simulations, and as a consequence, we are allowed \nto de.ne similarity simply as ; def {R | R is a = probabilistic simulation}. Any symmetric probabilistic \nsimulation is a probabilistic bisim\u00adulation. Contrary to the nondeterministic case, however, simulation \nequivalence coincides with bisimulation: PROPOSITION 2.9. ~ coincides with ; n ;op. For technical reasons \nthat will become apparent soon, it is conve\u00adnient to consider Markov chains in which the state space \nis parti\u00adtioned into disjoint sets, in such a way that comparing states com\u00ading from different components \nis not possible. Remember that the disjoint union Xi of a family of sets {Xi}i.I is de.ned as i.I {(a, \ni) | i . I . a . Xi}. If the set of states S of a labelled Markov chain is a disjoint union i.I Xi, one \nwants that (bi)simulation relations only compare elements coming from the same Xi, i.e. (a, i)R(b, j) \nimplies i = j. In this case, we say that the underlying labelled Markov chain is multisorted. 3. Probabilistic \nApplicative Bisimulation and Howe s technique In this section, notions of similarity and bisimilarity \nfor .. are introduced, in the spirit of Abramsky s work on applicative bisim\u00adulation [1]. De.nitionally, \nthis consists in seeing .. s operational semantics as a labelled Markov chain, then giving the Larsen \nand Skou s notion of (bi)simulation for it. States will be terms, while labels will be of two kinds: \none can either evaluate a term, obtaining (a distribution of) values, or apply a term to a value. The \nresulting bisimulation (probabilistic applicative bisimula\u00adtion) will be shown to be a congruence, thus \nincluded in probabilistic context equivalence. This will be done by a non-trivial generaliza\u00adtion of \nHowe s technique [22], which is a well-known methodology to get congruence results in presence of higher-order \nfunctions, but which has not been applied to probabilistic calculi so far. Formalizing probabilistic \napplicative bisimulation requires some care. As usual, two values .x.M and .x.N are de.ned to be bisimilar \nif for every L, M{L/x} and N{L/x} are themselves bisimilar. But how if we rather want to compare two \narbitrary closed terms M and N? The simplest solution consists in following Larsen and Skou and stipulate \nthat every equivalence class of V.. modulo bisimulation is attributed the same measure by both [ M] and \n[ N] . Values are thus treated in two different ways (they are both terms and values), and this is the \nreason why each of them corresponds to two states in the underlying Markov chain. DEFINITION 3.1. .. \ncan be seen as a multisorted labelled Markov chain (..(\u00d8) l V.., ..(\u00d8) l {t }, P.) that we denote with \n... Labels are either closed terms, which model parameter passing, or t , that models evaluation. Please \nobserve that the states of the labelled Markov chain we have just de.ned are elements of the disjoint \nunion ..(\u00d8) l V... Two distinct states correspond to the same value V , and to avoid ambiguities, we \ncall the second one (i.e. the one coming from V..) a distinguished value. When we want to insist on the \nfact that a value .x.M is distinguished, we indicate it with .x.M . We de.ne the transition probability \nmatrix P. as follows: For every term M and for every distinguished value .x.N, def P.(M, t, .x.N) = [ \nM]](.x.N); For every term M and for every distinguished value .x.N, def P.(.x.N, M, N{M/x}) = 1; In all \nother cases, P. returns 0. Terms seen as states only interact with the environment by perform\u00ading t, \nwhile distinguished values only take other closed terms as parameters. Simulation and bisimulation relations \ncan be de.ned for .. as for any labelled Markov chain. Even if, strictly speaking, these are binary relations \non ..(\u00d8) l V.., we often see them just as their restrictions to ..(\u00d8). Formally, a probabilistic applicative \nbisimulation (a PAB) is simply a probabilistic bisimulation on ... This way one can de.ne probabilistic \napplicative bisimilarity, which is denoted ~. Similarly for probabilistic applicative simulation (PAS) \nand probabilistic applicative similarity, denoted ;. REMARK 3.2 (Early vs. Late). Technically, the distinction \nbetween terms and values in De.nition 3.1 means that our bisimulation is in  late style. In bisimulations \nfor value-passing concurrent languages, late indicates the explicit manipulation of functions in the \nclause for input actions: functions are chosen .rst, and only later, the input value received is taken \ninto account [40]. Late-style is used in contraposition to early style, where the order of quanti.ers \nis exchanged, so that the choice of functions may depend on the speci.c input value received. In our \nsetting, adopting an early style N would mean having transitions such as .x.M -. M{N/x}, and then setting \nup a probabilistic bisimulation on top of the resulting transition system. We leave for future work a \nstudy of the comparison between the two styles. In this paper, we stick to the late style because easier \nto deal with, especially under Howe s technique. Previous works on applicative bisimulation for nondeterministic \nfunctions also focus on the late approach [30, 36]. REMARK 3.3. De.ning applicative bisimulation in \nterms of multi\u00adsorted labelled Markov chains has the advantage of recasting the de.nition in a familiar \nframework; most importantly, this formu\u00adlation will be useful when dealing with Howe s method. To spell \nout the explicit operational details of the de.nition, a probabilistic applicative bisimulation can be \nseen as an equivalence relation R . ..(\u00d8) \u00d7 ..(\u00d8) such that whenever M R N: 1. [ M]](E n V..) = [ N]](E \nn V..), for any equivalence class E of R (that is, the probability of reaching a value in E is the same \nfor the two terms); 2. if M and N are values, say .x.P and .x.Q, then P {L/x} R  Q{L/x}, for all L \n. ..(\u00d8). The special treatment of values, in Clause 2., motivates the use of multisorted labelled Markov \nchains in De.nition 3.1. Terms with the same semantics are indistinguishable: LEMMA 3.4. The binary \nrelation R = {(M, N) . ..(\u00d8) \u00d7 ..(\u00d8) s.t. [ M] = [ N] } {(V, V ) . V.. \u00d7 V..} is a PAB. Conversely, knowing \nthat two terms M and N are (bi)similar means knowing quite a lot about their convergence probability: \n m LEMMA 3.5 (Adequacy of Bisimulation). If M ~ N, then [ M] = m mm [ N] . Moreover, if M ; N , then \n[ M] = [ N] . EXAMPLE 3.6. The semantics of the terms: def M = ((.x.(x . x)) . (.x.x)) . O; def N = O \n. (.x.Ix); differ, as for every value V , we have: will not give all the details. The main idea consists \nin de.ning a way to turn an arbitrary relation R on (possibly open) terms to another one, RH , in such \na way that, if R satis.es a few simple conditions, then RH is a (pre)congruence including R. The key \nstep, then, is to prove that RH is indeed a (bi)simulation. In view of Proposition 2.9, considering similarity \nsuf.ces here. It is here convenient to work with generalizations of relations called ..-relations, i.e. \nsets of triples in the form (x, M, N), where M, N . ..(x). Thus if a relation has the pair (M, N) with \nM, N . ..(x), then the corresponding ..-relation will include (x, M, N). (Recall that applicative (bi)similarity \nis extended to open terms by considering all closing substitutions.) Given any ..-relation R, we write \nx f M R N if (x, M, N) . R. A .. \u00adrelation R is said to be compatible iff the four conditions below hold: \n(Com1) .x . PFIN(X), x . x: x f x R x, (Com2) .x . PFIN(X),.x . X - x,.M, N . ..(x . {x}): x . {x} f \nM R N . x f .x.M R .x.N, (Com3) .x . PFIN(X),.M, N, L, P . ..(x): x f M R N . x f L R P . x f ML R NP \n, (Com4) .x . PFIN(X),.M, N, L, P . ..(x): x f M R N . x f L R P . x f M . L R N . P . The notions of \nan equivalence relation and of a preorder can be straightforwardly generalized to ..-relations, and any \ncompatible ..-relation that is an equivalence relation (respectively, a preorder) is said to be a congruence \n(respectively, a precongruence). If bisimilarity is a congruence, then C[M] is bisimilar to C[N] whenever \nM ~ N and C is a context. In other words, terms can be replaced by equivalent ones in any context. This \nis a crucial sanity-check any notion of equivalence is expected to pass. It is well-known that proving \nbisimulation to be a congruence may be nontrivial when the underlying language contains higher\u00adorder \nfunctions. This is also the case here. Proving (Com1), (Com2) and (Com4) just by inspecting the operational \nsemantics of the involved terms is indeed possible, but the method fails for (Com3), when the involved \ncontexts contain applications. We thus need to introduce nontrivial technical tools. Actually, the Howe \ns lifting of any ..-relation R is the relation RH de.ned by the rules in Figure 3. The reader familiar \nwith Howe s method should have a sense of dej\u00b4` a vu here: indeed, this is the same de.nition one .nds \nin the realm of nondeterministic .\u00adcalculi. The language of terms, after all, is the same. This facilitates \nthe .rst part of the proof. Indeed, one already knows that if R is a preorder, then RH is compatible, \nclosed under term-substitution and includes R, since all these properties are already known (see, e.g. \n[36]) and only depend on the shape of terms and not on their if V is .x.(x . x) or .x.x; operational \nsemantics. For the reader s convenience, all these proofs 1 4 [ M]](V ) = 0 otherwise; can be found in \n[10]. Something is missing, however, before we can 1 2 0 if V is .x.Ix; conclude that ;H is a precongruence, \nnamely transitivity. We also otherwise. follow Howe here and consider the transitive closure (;H )+ , \nwhich [ N]](V ) = Nonetheless, we can prove M ~ N. Indeed, .x.(x . x) ~ .x.x ~ .x.Ix because, for every \nL . ..(\u00d8), the three terms L, L . L and IL all have the same semantics, i.e., [ L] . Now, consider any \nequivalence class E of distinguished values modulo ~. If E includes the three distinguished values above, \nthen 1 P.(M, t, E) =[ M]](V ) = =[ N]](V ) = P.(N, t, E). 2 V .E V .E Otherwise, P.(M, t, E) = 0 = P.(N, \nt, E). 3.1 Probabilistic Applicative Bisimulation is a Congruence In this section, we prove that probabilistic \napplicative bisimulation is indeed a congruence, and that its non-symmetric sibling is a precongruence. \nThe structure of the proof follows Howe [22], so we is a preorder by construction. This is just the .rst \nhalf of the story: we also need to prove that (;H )+ is a simulation. As we already know it is a preorder, \nthe following lemma gives us the missing bit: LEMMA 3.7 (Key Lemma). If M ;H N, then for every X . ..(x) \nit holds that [ M]](.x.X) = [ N]](.x.(;H (X))). The proof of this lemma is delicate and is discussed \nin the next section. From the lemma, using a standard argument we derive the needed substitutivity results, \nand ultimately the most important result of this section. THEOREM 3.8. On ..-terms, ; is a precongruence \nand ~ is a congruence.  x . {x} f M RH L x f .x.L R N x /. x x f x R M (How1) (How2) x f x RH M x f \n.x.M RH N x f M RH P x f N RH Q x f P Q R L x f M RH P x f N RH Q x f P . Q R L (How3) (How4) x f MN \nRH L x f M . N RH L Figure 3. Howe s Lifting for ... 3.2 Proof of the Key Lemma Proving the Key Lemma \n3.7 turns out to be much more dif.cult than for deterministic or nondeterministic cases. In particular, \nthe case when M is an application relies on another technical lemma we are now going to give, which itself \ncan be proved by tools from linear programming. The combinatorial problem we will face while proving \nthe Key Lemma can actually be decontextualized and understood indepen\u00addently. Suppose we have n = 3 non-disjoint \nsets X1, X2, X3 whose elements are labelled with real numbers. As an example, we could be in a situation \nlike the one in Figure 4(a) (where for the sake of simplicity only the labels are indicated). We .x three \nreal numbers def def def 5 3 5 p1 = , p2 = , p3 = . It is routine to check that for every 64 16 64 I \n. {1, 2, 3} it holds that  pi = || Xi||, i.I i.I where ||X|| is the sum of the labels of the elements \nof X. Let us observe that it is of course possible to turn the three sets X1, X2, X3 into three disjoint \nsets Y1, Y2 and Y3 where each Yi contains (copies of) the elements of Xi whose labels, however, are obtained \nby splitting the ones of the original elements. Examples of those sets are in Figure 4(b): if you superpose \nthe three sets, you obtain the Venn diagram we started from. Quite remarkably, however, the examples \nfrom Figure 4 have an additional property, namely that for every i . {1, 2, 3} it holds that pi = ||Yi||. \nWe now show that .nding sets satisfying the properties above is always possible, even when n is arbitrary. \nSuppose p1, . . . , pn . R[0,1], and suppose that for each I . {1, . . . , n} a real number rI . R[0,1] \nis de.ned such that for m m every such I it holds that pi = rJ = 1. Then i.I JnI= \u00d8 ({pi}1=i=n, {rI }I.{1,...,n}) \nis said to be a probability assignment for {1, . . . , n}. Is it always possible to disentangle probability \nassignments? The answer is positive. def LEMMA 3.9 (Disentangling Probability Assignments). Let P = ({pi}1=i=n, \n{rI }I.{1,...,n}) be a probability assignment. Then for every nonempty I . {1, . . . , n} and for every \nk . I there is sk,I . R[0,1] such that the following conditions all hold: m 1. for every I, it holds \nthat k.I sk,I = 1; m 2. for every k . {1, . . . , n}, it holds that pk = sk,I \u00b7 rI . k.I Proof. Any probability \nassignment P can be seen as a .ow net\u00adwork, where nodes are the nonempty subsets of {1, . . . , n}, plus \na distinguished source s and target t. Edges, then, go from s to each singleton {i} (with capacity pi), \nfrom every nonempty I to I . {i} . {1, . . . , n} whenever i /. I (with capacity 1) and from every such \nI to t (with capacity rI ). The thesis, then, is easily proved m equivalent to showing that such a net \nsupports a .ow of value pi. And, indeed, the fact that this is the value of the maximum .ow from s to \nt can be proved via the Max-Flow Min-Cut Theorem. D REMARK 3.10. Throughout the following proof we will \nimplicitly use a routine result stating that M ; N implies [ M]](.x.X) = [ N]](.x.;(X)), for every X \n. ..(x). The property needed by the latter is precisely the reason why we have formulated .. as a multisorted \nlabelled Markov chain: ;(.x.X) consists of distinguished values only, and is nothing but .x.;(X). Proof. \n[of Lemma 3.7] This is equivalent to proving that if M ;H N , then for every X . ..(x) the following \nimplica\u00adtion holds: if M . D, then D(.x.X) = [ N]](.x.(;H (X))). This is an induction on the structure \nof the proof of M . D. Some interesting cases follow: If M is a value .x.L and D(.x.L) = 1, then the \nproof of M ;H N necessarily ends as follows: {x} f L ;H P \u00d8 f .x.P ; N \u00d8 f .x.L ;H N Let X be any subset \nof ..(x). Now, if L . X, then D(.x.X) = 0 and the inequality trivially holds. If, on the contrary, L \n. X, then P . ;H (X). Consider ; (P ), the set of terms that are in relation with P via ;. We have that \nfor every Q . ; (P ), both {x} f L ;H P and {x} f P ; Q hold, and as a consequence {x} f L ;H Q does \n(this is a consequence of a property of (\u00b7)H , see [10]). In other words, ; (P ) . ;H (X). But then, \n[ N]](.x.;H (X)) = [ N]](.x. ; (P )) = [ .x.P ]](.x.P ) = 1. If M is an application LP , then M . D is \nobtained as follows: L . F {Q{P/x} . HQ,P }Q,P m LP . Q F(.x.Q) \u00b7 HQ,P Moreover, the proof of \u00d8 f M ;H \nN must end as follows: \u00d8 f L ;H R \u00d8 f P ;H S \u00d8 f RS ; N \u00d8 f LP ;H N Now, since L . F and \u00d8 f L ;H R, \nby induction hypothesis we get that for every Y . ..(x) it holds that F (.x.Y ) = [ R]](.x.;H (Y )). \nLet us now take a look at the distribution D = F (.x.Q) \u00b7 HQ,P . Q Since F is a .nite distribution, the \nsum above is actually the sum of .nitely many summands. Let the support S(F) of F be {.x.Q1, . . . , \n.x.Qn}. It is now time to put the above into a form that is amenable to treatment by Lemma 3.9. Let us \nconsider the n sets ;H (Q1), . . . , ;H (Qn); to each term U in them we can associate the probability \n[ R]](.x.U). We are then in the scope of Lemma 3.9, since by induction hypothesis we know that for every \nY . ..(x), F (.x.Y ) = [ R]](.x.;H (Y )). We can then conclude that for every  U . ;H ({Q1, . . . , \nQn}) = ;H (Qi) 1=i=n  (a) (b) Figure 4. Disentangling Sets there are n real numbers rU,R , . . . , \nrU,R such that: 1 n  U,R ;H [ R]](.x.U) = ri . U . (Qi); 1=i=n 1=i=n F (.x.Qi) = ri U,R . 1 = i = n. \nU.;H (Qi) So, we can conclude that . . U,R \u00b7 HQi,P . . D = ri 1=i=n U.;H (Qi) = rU,R \u00b7 HQi,P . i 1=i=n \nU.;H (Qi) Now, whenever Qi;H U and P ;H S, it follows that Qi{P/x};H U{S/x}. We can then apply the inductive \nhypoth\u00adesis to the n derivations of Qi{P/x} . HQi,P , obtaining that, for every X . ..(x), U,R D(.x.X) \n=r\u00b7 [ U{S/x}]](.x.;H (X)) i 1=i=nU.;H (Qi) U,R = r\u00b7 [ U{S/x}]](.x.;H (X)) i 1=i=n U.;H ({Q1,...,Qn}) \n U,R = r\u00b7 [ U{S/x}]](.x.;H (X)) i 1=i=n U.;H ({Q1,...,Qn}) . . U,R .. = r\u00b7 [ U{S/x}]](.x.;H (X)) i U.;H \n({Q1,...,Qn}) 1=i=n =[ R]](.x.U) \u00b7 [ U{S/x}]](.x.;H (X)) U.;H ({Q1,...,Qn}) =[ R]](.x.U) \u00b7 [ U{S/x}]](.x.;H \n(X)) U...(x) = [ RS]](.x.;H (X)) = [ N]](.x. ; ((;H )(X))) = [ N]](.x.;H (X)), which is the thesis. This \nconcludes the proof. D  3.3 Relating Applicative Bisimulation and Context Equivalence The congruence \nof applicative bisimilarity yields the inclusion in context equivalence. THEOREM 3.11. For all M, N . \n.., M ~ N implies M .N. The converse inclusion fails. A counterexample is described in the following. \ndef def EXAMPLE 3.12. For M = .x.L.P and N = (.x.L).(.x.P ) (where L is .y.O and P is .y..z.O), we have \nM ; N, hence M ~ N, but M .N. We prove that the above two terms are context equivalent by means of CIU-equivalence. \nThis is a relation that can be shown to coincide with context equivalence by a Context Lemma, itself \nproved by the Howe s technique. More details are in [10]. See also Section 7. EXAMPLE 3.13. We consider \nagain the programs from Exam\u00adple 2.5. Terms expone and exptwo only differ because the former performs \nall probabilistic choices on natural numbers obtained by applying a function to its argument, while in \nthe latter choices are done at the functional level, and the argument to those functions is provided \nonly at a later stage. As a consequence, the two terms are not applicative bisimilar, and the reason \nis akin to that for the inequality of the terms in Example 3.12. In contrast, the bisimilarity between \nexpone and expthree k, where k is any natural number, intuitively holds because both expone and expthree \nk evaluate to a single term when fed with a function, while they start evolving in a genuinely probabilistic \nway only after the second argument is provided. At that point, the two functions evolve in very different \nways, but their semantics (in the sense of Section 2) is the same (cf., Lemma 3.4). As a bisimulation \none can use the equivalence generated by the relation  {(expone, expthree k)}. {(M, N ) | [ M] = [ N] \n} k .{(.n.B{L/f}, .n.C{L/f})} L using B and C for the body of expone and expthree respectively. 4. The \nDiscriminating Power of Probabilistic Contexts We show here that applicative bisimilarity and context \nequivalence collapse if the tested terms are pure, deterministic, .-terms. In other words, if the probabilistic \nchoices are brought into the terms only through the inputs supplied to the tested functions, applicative \nbisim\u00adilarity and context equivalence yield exactly the same discriminating power. To show this, we prove \nthat, on pure .-terms, both relations coincide with the Levy-Longo tree equality, which equates terms \nwith the same Levy-Longo tree (brie.y LLT) [14]. LLT s are the lazy variant of B\u00a8 ohm Trees (brie.y BT), \nthe most popular tree structure in the .-calculus. BT s only correctly express the computational content \nof .-terms in a strong regime, while they fail to do so in the lazy one. For instance, the term .x.O \nand O, as both unsolvable [4], have identical BT s, but in a lazy regime we would always distinguish \nbetween them; hence they have different LLT s. The Levy-Longo tree of M, LT (M), is def coinductively \nconstructed as follows: LT (M) = .x1. . . . xn..  def if M is an unsolvable of order n; LT (M) = T if \nM is an unsolvable of order 8; .nally if M has principal head normal form .x1. . . . xn.yM1 . . . Mm, \nthen LT (M) is a tree with root .x1. . . . xn.y and with LT (M1), . . . , LT (Mm) as subtrees. Being \nde.ned coinductively, LLT s can of course be in.nite. We write M =LL N iff LT (M) = LT (N). def EXAMPLE \n4.1. Let . be an unsolvable of order 8 such as . = (.x..y.(xx))(.x..y.(xx)), and consider the terms def \ndef M = .x.(x(.y.(x.Oy)).); N = .x.(x(x.O).). These terms have been used to prove non-full-abstraction \nresults in a canonical model for the lazy .-calculus by Abramsky and Ong [2]. For this, they show that \nin the model the convergence test is de.nable (this operator, when it receives an argument, would return \nthe identity function if the supplied argument is conver\u00adgent, and would diverge otherwise). The convergence \ntest, \\, can distinguish between the two terms, as M\\ reduces to an abstrac\u00adtion, whereas N\\ diverges. \nHowever, no pure .-term can make the same distinction. The two terms also have different LL trees: LT \n(M) = .x.x LT (N) = .x.x AA A  .y.x Tx T AA A  T . y T . Although in .., as in ., the convergence test \noperator is not de\u00ad.nable, M and N can be separated using probabilities by running them in a context \nC that would feed O . .z..u.z as argument; then C[M]. 1 whereas C[N]. 1 . n LEMMA 4.3. Suppose M = LL \nN for some n, and let {x1, . . . , xr}be the free variables in M, N. Then there are integers mx1 , . \n. . , mxr and k, and permutator functions fx1 , . . . , fxr such that, for all m > k, there are closed \nterms Rm such that the following holds: if M{fx1 (m + mx1 )/x1} . . . {fxr (m + mxr )/xr}Rm.r and N{fx1 \n(m + mx1 )/x1} . . . {fxr (m + mxr )/xr}Rm.s , then r = s. n The proof goes by induction on the least \nn such that M = LL N. The fact the B\u00a8 ohm-out technique actually works implies that the discriminating \npower of probabilistic contexts is at least as strong as the one of LLT s. COROLLARY 4.4. For M, N . \n., M .N implies M =LL N. To show that LLT equality is included in probabilistic applicative bisimilarity, \nwe proceed as follows. First we de.ne a re.nement of the latter, essentially one in which we observe \nall probabilistic choices. As a consequence, the underlying bisimulation game may ignore probabilities. \nThe obtained notion of equivalence is strictly .ner than probabilistic applicative bisimilarity. The \nadvantage of the re.nement is that both the inclusion of LLT equality in the re.nement, and the inclusion \nof the latter in probabilistic applicative bisimilarity turn out to be relatively easy to prove. A direct \nproof of the inclusion of LLT equality in probabilistic applicative bisimilarity would have been harder, \nas it would have required extending the notion of a Levy-Longo tree to .., then reasoning on substitution \nclosures of such trees. The de.nition below relies on two notions of reduction: M -.p N means that M \ncall-by-name reduces to N in one step with probability p. (As a matter of fact, p can be either 1 or \n1 2 .) Then =. is obtained by composing -. zero or more times (and multiplying the corresponding real \nnumbers). 4 2 DEFINITION 4.5. A relation R . ..(\u00d8) \u00d7 ..(\u00d8) is a strict EXAMPLE 4.2. Abramsky s canonical \nmodel is itself coarser than applicative bisimulation whenever M R N impliesdef def LLT equality. For \ninstance, the terms M = .x.xx and N = 1. if M -.1 P , then N =.1 Q and P R Q; 2. if M -. 1 P , then N \n=. 1 Q and P R Q;.x.(x.y.(xy)), have different LLT s but are equal in Abramsky s 2 2 model (and hence \nequal for context equivalence in .). They are 3. if M = .x.P , then N =.1 .x.Q and P {L/x} R Q{L/x} \nseparated by context equivalence in .., for instance using the for all L . ..(\u00d8); def 4. the converse \nof 1., 2. and 3.. [\u00b7](I . O), since C[M]. whereas C[N]. context C = 11 . 2 4 We already know that on \nfull .., applicative bisimilarity (~) implies context equivalence ( .). Hence, to prove that on pure \nStrict applicative bisimilarity is the union of all strict applicative bisimulations. If two terms have \nthe same LLT, then passing them the same .-terms the two equivalences collapse to LLT equality (=LL), \nit suf.ces to prove that, for those pure terms, . implies =LL, and that =LL implies ~. The .rst implication \nis obtained by a variation on the B\u00a8 ohm-out argument M . .. produces exactly the same choice structure: \nintuitively, whenever the .rst term .nds (a copy of) M in head position, also the second will .nd M. \ntechnique, a powerful methodology for separation results in the .-calculus, often employed in proofs \nabout local structure charac\u00adterisation theorems of .-models. For this we exploit an inductive characterisation \nof LLT equality via strati.cation approximants. The n n-approximant (for n = 1), written = LL, is essentially \nobtained by observing a tree only up-to level n. The key Lemma 4.3 shows that any difference on the trees \nof two .-terms within level n can be observed by a suitable context of the probabilistic .-calculus. \nWe write lM as an abbreviation for the term O . M. We denote by Qn, n > 0, the term .x1. . . . .xn.xnx1x2 \n\u00b7 \u00b7 \u00b7 xn-1. This is usually called the B\u00a8ohm permutators ohm permutator of degree n. B\u00a8play a key role \nin the B\u00a8 ohm-out technique. A variant of them, the l-permutators, play a pivotal role in Lemma 4.3 below. \nA term M . .. is a l-permutator of degree n if either M = Qn or there exists 0 = r < n such that M = \n.x1. . . . .xr. l .xr+1 \u00b7 \u00b7 \u00b7 .xn.xnx1 \u00b7 \u00b7 \u00b7 xn-1 . A function f from the positive integers to .-terms \nis a l-permutator function if, for all n, f(n) is a l-permutator of degree n. LEMMA 4.6. If M =LL N then \nM R N, for some strict applica\u00adtive bisimulation R. Terms which are strict applicative bisimilar cannot \nbe distinguished by applicative bisimilarity proper, since the requirements induced by the latter are \nless strict than the ones the former imposes: LEMMA 4.7. Strict applicative bisimilarity is included \nin applica\u00adtive bisimilarity. Since we now know that for pure, deterministic .-terms, = LL is included \nin ~ (by Lemma 4.6 and Lemma 4.7), that ~ is included in . (by Theorem 3.11) and that the latter is included \nin = LL (Corollary 4.4), we can conclude: COROLLARY 4.8. The relations =LL, ~, and . coincide in .. 5. \nCoupled Logical Bisimulation In this section we derive a coinductive characterisation of probabilis\u00adtic \ncontext equivalence on the whole language .. (as opposed to the subset of sum-free .-terms as in Section \n4). For this, we need to  ss M . N (M, 1 2 ) + (N, 1 2 ) [ Mi] = Di spc .x.M (.x.M, 1) sl Si(Mi, pi) \nSi(Di, pi) E F sp sa ZM Z M EM F M Figure 5. Reduction Rules for .FS . manipulate formal weighted sums. \nThus we work with an extension of .. in which such weighted sums may appear in redex position. An advantage \nof having formal sums is that the transition system on the extended language can be small-step and deterministic \n any closed term that is not a value will have exactly one possible internal transition. This will make \nit possible to pursue the logical bisimulation method, in which the congruence of bisimilarity is proved \nusing a standard induction argument over all contexts. The re.nement of the method handling probabilities, \ncalled coupled logical bisimulation, uses pairs of relations, as we need to distinguish between ordinary \nterms and terms possibly containing formal sums. We preferred to follow logical bisimulations rather \nthen environ\u00admental bisimulations because the former admit a simpler de.nition (in the latter, each pair \nof terms is enriched with an environment, that is, an extra set of pairs of terms). Moreover it is unclear \nwhat environments should be when one also considers formal sums. We leave this for future work. Formal \nsums are a tool for representing the behaviour of running .. terms. Thus, on terms with formal sums, \nonly the results for closed terms interest us. However, the characterization of contextual equivalence \nin .. as coupled logical bisimulation also holds on open terms. 5.1 Notation and Terminology We write \n.FS for the extension of .. in which formal sums may . appear in redex position. Terms of .FS are de.ned \nas follows (M, N . being ..-terms): E, F ::= EM | Si.I (Mi, pi) | M . N | .x.M. In a formal sum Si.I \n(Mi, pi), I is a countable (possibly empty) m set of indices such that i.I pi = 1. We use + for binary \nformal sums. Formal sums are ranged over by metavariables like H, K. When each Mi is a value (i.e., an \nabstraction) then Si.I (Mi, pi) is a (formally summed) value; such values are ranged over by Z, Y, X. \nIf H = Si.I (Mi, pi) and K = Sj.J (Mj , pj ) where I and J are disjoint, then H . K abbreviates Sr.I.J \n(Mr, p2 r ). Similarly, if for every j . J Hj is Si.I (Mi,j , pi,j ), then Sj (Hj , pj ) stands for S(i,j)(Mi,j \n, pi,j \u00b7 pj ). For H = Si(Mi, pi) we write S(H) for the m real number i pi. If Z = Si(.x.Mi, pi), then \nZ N stands for Si(Mi{N/x}, pi). The set of closed terms is .FS . (\u00d8). Any partial value distribution \nD (in the sense of Section 2) can be seen as the formal sum SV .V.. (V, D(V )). Similarly, any formal \nsum H = Si.I (Mi, pi) can be mapped to the distribution m i.I pi \u00b7 [ Mi] , that we indicate with [ H] \n. Reduction between .FS terms, written E F , is de.ned by . the rules in Figure 5; these rules are given \non top of the operational semantics for .. as de.ned in Section 2, which is invoked in the premise of \nrule spc (if there is a i with Mi not a value). The reduction relation is deterministic and strongly \nnormalizing. We use for its re.exive and transitive closure. Lemma 5.1 shows the agreement between the \nnew reduction relation and the original one. LEMMA 5.1. For all M . ..(\u00d8) there is a value Z such that \nM Z and [ M] = [ Z] . Proof. One .rst show that for all E there is n such that E n Z. Then one reasons \nwith a double induction: an induction on n, and a transition induction, exploiting the determinism of \n. D  5.2 Context Equivalence and Bisimulation In .FS . certain terms (i.e., formal sums) may only appear \nin redex position; ordinary terms (i.e., terms in ..), by contrast, may appear in arbitrary position. \nWhen extending context equivalence to .FS . we therefore have to distinguish these two cases. Moreover, \nas our main objective is the characterisation of context equivalence in .., we set a somewhat constrained \ncontext equivalence in .FS in which . contexts may not contain formal sums (thus the .FS contexts are \n. the same as the .. contexts). We call these simple .FS contexts, . whereas we call general .FS context \nan unconstrained context, i.e., . a .FS . term in which the hole [\u00b7] may appear in any places where a \nterm from .. was expected including within a formal sum. (Later we will see that allowing general contexts \ndoes not affect the resulting context equivalence.) Terms possibly containing formal sums are tested \nin evaluation contexts, i.e., contexts of the form [\u00b7]M. We write Eip if E Z and S(Z) = p (recall that \nZ is unique, for a given E). DEFINITION 5.2 (Context Equivalence in .FS ..-terms . ). Two M and N are \ncontext equivalent in .FS FS N, . , written M . if for all (closing) simple .FS contexts C, we have C[M]ip \niff . C[N]ip. Two .FS . -terms E and F are evaluation-context equiva\u00adlent, written E .FS F , if for all \n(closing) .FS evaluation contexts . . C, we have C[E]ip iff C[F ]ip. In virtue of Lemma 5.1, context \nequivalence in .. coincides with context equivalence in .FS . . We now introduce a bisimulation that \nyields a coinductive characterisation of context equivalence (and also of evaluation\u00adcontext equivalence). \nA coupled relation is a pair (V, E) where: .FS . (\u00d8) \u00d7 .FS V . ..(\u00d8) \u00d7 ..(\u00d8), E . . (\u00d8), and V . E. Intuitively, \nwe place in V the pairs of terms that should be preserved by all contexts, and in E those that should \nbe preserved by evaluation contexts. For a coupled relation R = (V, E) we write R1 for V and R2 for E. \nThe union of coupled relations is de.ned componentwise: e.g., if R and S are coupled relations, then \nthe coupled relation def def R . S has (R . S)1 = R1 . S1 and (R . S)2 = R2 . S2. If V is a relation \non .., then VC is the context closure of V in .., i.e., the set of all (closed) terms of the form (C[M], \nC[N]) where C is a multi-hole .. context and M V N. DEFINITION 5.3. A coupled relation R is a coupled \nlogical bisim\u00adulation if whenever E R2 F we have: 1. if E D, then F G, where D R2 G; 2. if E is a formally \nsummed value, then F  Y with S(E) = S(Y ), and for all M RC 1 N we have (E M) R2 (Y N); 3. the converse \nof 1. and 2.. Coupled logical bisimilarity, , is the union of all coupled logical bisimulations (hence \n1 is the union of the .rst component of all coupled logical bisimulations, and similarly for 2). In a \ncoupled bisimulation (R1, R2), the bisimulation game is only played on the pairs in R2. However, the \n.rst relation R1 is relevant, as inputs for tested functions are built using R1 (Clause 2. of De.nition \n5.3). Actually, also the pairs in R1 are tested, because in any coupled relations it must be R1 . R2. \nThe values produced by the bisimulation game for coupled bisimulation on R2 are formal sums (not plain \n.-terms), and this is why we do not require them to be in R1: formal sums should only appear in redex \nposition, but  terms in R1 can be used as arguments to bisimilar functions and can therefore end up \nin arbitrary positions. We will see below another aspect of the relevance of R1: the proof technique \nof logical bisimulation only allows us to prove substitutivity of the bisimilarity in arbitrary contexts \nfor the pairs of terms in R1. For pairs in R2 but not in R1 the proof technique only allows us to derive \npreservation in evaluation contexts. In the proof of congruence of coupled logical bisimilarity we will \npush as many terms as possible into the .rst relation, i.e., the .rst relation will be as large as possible. \nHowever, in proofs of bisimilarity for concrete terms, the .rst relation may be very small, possibly \na singleton or even empty. Then the bisimulation clauses become similar to those of applicative bisimulation \n(as inputs of tested function are almost identical). Summing up, in coupled logical bisimulation the \nuse of two relations gives us more .exibility than in ordinary logical bisimulation: depending on the \nneeds, we can tune the size of the .rst relation. It is possible that some of the above aspects of coupled \nlogical bisimilarity be speci.c to call-by\u00ad name, and that the call-by-value version would require non-trivial \nmodi.cations. RE M AR K 5.4. In a coupled logical bisimulation, the .rst relation is used to construct \nthe inputs for the tested functions (the formally summed values produced in the bisimulation game for \nthe second relation). Therefore, such .rst relation may be thought of as a global environment global \nbecause it is the same for each pair of terms on which the bisimulation game is played. As a consequence, \ncoupled logical bisimulation remains quite different from environmental bisimulation [42], where the \nenvironment for constructing inputs is local to each pair of tested terms. Coupled logical bisimulation \nfollows ordinary logical bisimulation [41], in which there is only one global environment; in ordinary \nlogical bisimulation, however, the global environment coincides with the set of tested terms. The similarity \nwith logical bisimulation is also revealed by non-monotonicity of the associated functional (in contrast, \nthe functional associated to environmental bisimulation is monotone); see Remark 5.11. As an example \nof use of coupled logical bisimulation, we revisit the counterexample 3.12 to the completeness of applicative \nbisimilarity with respect to contextual equivalence. EX A M P L E 5.5. We consider the terms of Example \n3.12 and show that they are in 1, hence also in . (contextual equivalence of ..), by Corollary 5.9 and \nFS = .. Recall that the terms . def def are M = .x.(L . P ) and N = (.x.L) . (.x.P ) for def def L = \n.z.O and P = .y..z.O. We set R1 to contain only (M, N ) (this is the pair that interests us), and R2 \nto contain the pairs (M, N ), ((M, 1), (.x.L, 1 ) + (.x.P, 1 )), ((L + P, 1), (L, 1 ) + 22 2 (P, 1 )), \nand a set of pairs with identical components, namely 2 1 11 ((L, 1 ) + (P, 1 ), (L, 1 ) + (P, 1 )), ((O, \n) + (.u.O, ), (O, ) + 2222 2 22 1 1111 (.u.O, )), ((.u.O, ), (.u.O, )), ((O, ), (O, )), (\u00d8, \u00d8), where \n2 2222 \u00d8 is the empty formal sum. Thus (R1, R2) is a coupled logical bisim\u00adulation. The main challenge \ntowards the goal of relating coupled logical bisimilarity and context equivalence is the substitutivity \nof bisimu\u00adlation. We establish the latter exploiting some up-to techniques for bisimulation. We only \ngive the de.nitions of the techniques, omit\u00adting the statements about their soundness. The .rst up-to \ntechnique allows us to drop the bisimulation game on silent actions: DE FI NI TI O N 5.6 (Big-Step Bisimulation). \nA coupled relation R is a big-step coupled logical bisimulation if whenever E R2 F , the following holds: \nif E Z then F Y with S(Z) = S(Y ), and for all M RC 1 N we have (Z M) R2 (Y N). In the reduction , \ncomputation is performed at the level of formal sums; and this is re.ected, in coupled bisimulation, \nby the application of values to formal sums only. The following up-to technique allows computation, and \napplication of input values, also with ordinary terms. In the de.nition, we extract a formal sum from \na term E in .FS using the function D(\u00b7) inductively as follows: . def D(E M ) = Si(MiM, pi) whenever \nD(E) = Si(Mi, pi); def def D(M) = (M, 1); D(H) = H. DE FIN I T I ON 5.7. A coupled relation R is a bisimulation \nup-to for\u00admal sums if, whenever E R2 F , then either (one of the bisimulation clauses of De.nition 5.3 \napplies), or (E , F . .. and one of the following clauses applies): 1. E D with D(D) = (M, 1 ) + (N, \n1 ), and F G with 2 2 D(G) = (L, 1 ) + (P, 1 ), M R2 L, and N R2 P ; 2 2 2. E = .x.M and F = .x.N, and \nfor all P RC 1 Q we have M{P/x} R2 N{Q/x}; 3. E = (.x.M )P M and F = (.x.N)QN, and M{P/x}M R2 N{Q/x}N. \nAccording to De.nition 5.7, in the bisimulation game for a coupled relation, given a pair (E, F ) . R2, \nwe can either choose to follow the bisimulation game in the original De.nition 5.3; or, if E and F do \nnot contain formal sums, we can try one of the new clauses above. The advantage of the .rst new clause \nis that it allows us to make a split on the derivatives of the original terms. The advantage of the other \ntwo new clauses is that they allow us to directly handle the given .-terms, without using the operational \nrules of Figure 5 and therefore without introducing formal sums. def To understand the .rst clause, suppose \nE = (M . N)L and def def F = P . Q. We have E ((M, 1 ) + (N, 1 ))L = G with 2 2 def D(G) = (M L, 1 ) \n+ (N L, 1 ), and F (P, 1 ) + (Q, 1 ) = H, 22 22 with D(H) = H, and it is suf.cient now to ensure (M L) \nR2 P , and (N L) R2 Q. Using the above proof technique, we can prove the necessary substitutivity property \nfor bisimulation. The use of up-to techniques, and the way bisimulation is de.ned (in particular the \npresence of a clause for t-steps and the possibility of using the pairs in the bisimulation itself to \nconstruct inputs for functions), make it possible to use a standard argument by induction over contexts. \nLEM M A 5.8. If R is a bisimulation then the context closure S with def RC S1 = 1 ; def = R2 . RC . {(EM, \nF N) s.t. E R2 F and Mi RC S21 1 Ni}; is a bisimulation up-to formal sums. Using Lemma 5.8 we can prove \nthe inclusion in context equivalence. CO RO LLARY 5.9. If M 1 N then M FS N. Moreover, if . E 2 F then \nE FS F . . The converse of Corollary 5.9 is proved exploiting a few simple FS FS properties of . (e.g., \nits transitivity, the inclusion . . ). FS FS TH E O R E M 5.10. We have . 1, and . 2. . . It also holds \nthat coupled logical bisimilarity is preserved by the formal sum construct; i.e., Mi 1 Ni for each i \n. I implies Si.I (Mi, pi) 2 Si.I (Ni, pi). As a consequence, context equiv\u00adalence de.ned on general .FS \ncontexts is the same as that set on . simple contexts (De.nition 5.2). REMA R K 5.11. The functional \ninduced by coupled logical bisim\u00adulation is not monotone. For instance, if V . W , then a pair of terms \nmay satisfy the bisimulation clauses on (V, E), for some E, but not on (W, E), because the input for \nfunctions may be taken from the larger relation W. (Recall that coupled relations are pairs of relations. \nHence operations on coupled relations, such as union and inclusion, are de.ned component-wise.) However, \nCorollary 5.9 and Theorem 5.10 tell us that there is indeed a largest bisimulation,  FS FS namely the \npair ( . , . ). With logical (as well as environmental) bisimulations, up-to tech\u00adniques are particularly \nimportant to relieve the burden of proving concrete equalities. A powerful up-to technique in higher-order \nlanguages is up-to contexts. We present a form of up-to contexts combined with the big-step version of \nlogical bisimilarity. Below, for a relation R on .., we write RCFS for the closure of the relation under \ngeneral (closing) .FS contexts. . DE FI NI TI O N 5.12. A coupled relation R is a big-step coupled logical \nbisimulation up-to contexts if whenever E R2 F , the following holds: if E Z then F Y with S(Z) = S(Y \n), and for all M RC 1 N, we have (Z M) RCFS 1 (Y N). For the soundness proof, we .rst derive the soundness \nof a small\u00adstep up-to context technique, whose proof, in turn, is similar to that of Lemma 5.8 (the up-to-formal-sums \ntechnique of De.nition 5.7 already allows some context manipulation; we need this technique for the proof \nof the up-to-contexts technique). EX A M P L E 5.13. We have seen that the terms expone and exptwo of \nExample 2.5 are not applicative bisimilar. We can show that they are context equivalent, by proving that \nthey are coupled bisimilar. We sketch a proof of this, in which we employ the up-to technique def from \nDe.nition 5.12. We use the coupled relation R in which R1 = def {(expone, exptwo)}, and R2 = 1 R1 . {(AM \n, BN ) | M RC N} def def where AM = .n.((M n) . (expone M (n + 1))), and BN = (.x.N x) . (exptwo (.x.N(x \n+ 1))). This is a big-step coupled logical bisimulation up-to contexts. The interesting part is the matching \nargument for the terms AM , BN ; upon receiving an argument m they yield the summed values Si(M(m + 1), \npi) and Si(N(m + 1), pi) (for some pi s), and these are in RCFS 1 . 6. Beyond Call-by-Name Reduction \nSo far, we have studied the problem of giving sound (and some\u00adtime complete) coinductive methods for \nprogram equivalence in a probabilistic .-calculus endowed with call-by-name reduction. One may wonder \nwhether what we have obtained can be adapted to other notions of reduction, and in particular to call-by-value \nreduction (e.g., the call-by-value operational semantics of .. from [9]). Since our construction of a \nlabelled Markov chain for .. is somehow independent on the underlying operational semantics, de.ning \na call-by-value probabilistic applicative bisimulation is effortless. The proofs of congruence of the \nbisimilarity and its soundness can also be transplanted to call-by-value. When we restrict our attention \nto pure .-terms, as we do in Section 4, we are strongly relying on call-by-name evaluation: LLT s only \nre.ect term equivalence in a call-by-name lazy regime. We leave the task of generalizing the results \nto eager evaluation to future work, but we conjecture that, in that setting, probabilistic choice alone \ndoes not give contexts the same discriminating power as probabilistic bisimulation. Similarly we have \nnot investigated the call-by-value version of coupled logical bisimilarity, as our current proofs rely \non the appearance of formal sums only in redex position, a constraint that would probably have to be \nlifted for call-by-value. 7. A Comparison with Nondeterminism Syntactically, .. is identical to an eponymous \nlanguage introduced by de Liguoro and Piperno [13]. The semantics we present here, however, is quantitative, \nand this has of course a great impact on context equivalence. While in a nondeterministic setting what \none observes is the possibility of converging (or of diverging, or both), terms with different convergence \nprobabilities are considered dif\u00adferent in an essential way here. Actually, nondeterministic context \nequivalence and probabilistic context equivalence are incomparable. As an example of terms that are context \nequivalent in the must sense but not probabilistically, we can take I . (I . O) and I . O. Con\u00adversely, \nI is probabilistically equivalent to any term M that reduces to I . M (which can be de.ned using .xed-point \ncombinators), while I and M are not equivalent in the must sense, since the latter can diverge (the divergence \nis irrelevant probabilistically because it has probability zero). May context equivalence, in contrast, \nis coarser than probabilistic context equivalence. Despite the differences, the two semantics have similarities. \nAnalogously to what happens in nondeterministic .-calculi, ap\u00adplicative bisimulation and context equivalence \ndo not coincide in the probabilistic setting, at least if call-by-name is considered. The counterexamples \nto full abstraction are much more complicated in call-by-value .-calculi [27], and cannot be easily adapted \nto the probabilistic setting. 8. Conclusions This is the .rst paper in which bisimulation techniques \nfor program equivalence are shown to be applicable to probabilistic .-calculi. On the one hand, Abramsky \ns idea of seeing interaction as application is shown to be amenable to a probabilistic treatment, giving \nrise to a congruence relation that is sound for context equivalence. Completeness, however, fails: the \nway probabilistic applicative bisimulation is de.ned allows one to distinguish terms that are context \nequivalent, but which behave differently as for when choices and interactions are performed. On the other, \na notion of coupled logical bisimulation is introduced and proved to precisely characterise context equivalence \nfor ... Along the way, applicative bisimilarity is proved to coincide with context equivalence on pure \n.-terms, yielding the Levy-Longo tree equality. The crucial difference between the two main bisimulations \nstudied in the paper is not the style (applicative vis-` a-vis logical), but rather the fact that while \napplicative bisimulation insists on relating only individual terms, coupled logical bisimulation is more \n.exible and allows us to relate formal sums (which we may think as distributions). This also explains \nwhy we need distinct reduction rules for the two bisimulations. See examples 3.12 and 5.5. While not \ncomplete, applicative bisimulation, as it stands, is simpler to use than coupled logical bisimulation. \nMoreover it is a natural form of bisimulation, and it should be interesting trying to transport the techniques \nfor handling it onto variants or extensions of the language. Topics for future work abound some have \nalready been hinted at in earlier sections. Among the most interesting ones, one can mention the transport \nof applicative bisimulation onto the language .FS . . We conjecture that the resulting relation would \ncoincide with coupled logical bisimilarity and context equivalence, but going through Howe s technique \nseems more dif.cult than for .., given the in.nitary nature of formal sums and their con.nement to redex \npositions. Also interesting would be a more effective notion of equivalence: even if the two introduced \nnotions of bisimulation avoid universal quanti.cations over all possible contexts, they refer to an essen\u00adtially \nin.nitary operational semantics in which the meaning of a term is obtained as the least upper bound of \nall its .nite approx\u00adimations. Would it be possible to de.ne bisimulation in terms of approximations \nwithout getting too .ne grained? Bisimulations in the style of logical bisimulation (or environ\u00admental \nbisimulation) are known to require up-to techniques in order to avoid tedious equality proofs on concrete \nterms. In the paper we have introduced some up-to techniques for coupled logical bisimi\u00adlarity, but additional \ntechniques would be useful. Up-to techniques could also be developed for applicative bisimilarity.  \nMore in the long-run, we would like to develop sound operational techniques for so-called computational \nindistinguishability, a key notion in modern cryptography. Computational indistinguishability is de.ned \nsimilarly to context equivalence; the context is however required to work within appropriate resource \nbounds, while the two terms can have different observable behaviors (although with negligible probability). \nWe see this work as a very .rst step in this direction: complexity bounds are not yet there, but probabilistic \nbehaviour, an essential ingredient, is correctly taken into account. Acknowledgments The authors would \nlike to thank the anonymous referees for the many interesting comments. This work is partially supported \nby the ANR project 12IS02001 PACE , and the project MIUR PRIN 2010LHT4KM CINA . References [1] S. Abramsky. \nThe Lazy .-Calculus. In D. Turner, editor, Research Topics in Functional Programming, pages 65 117. Addison \nWesley, 1990. [2] S. Abramsky and C.-H. L. Ong. Full abstraction in the lazy lambda calculus. Inf. Comput., \n105(2):159 267, 1993. [3] E. Astesiano and G. Costa. Distributive semantics for nondeterministic typed \nlambda-calculi. Theor. Comput. Sci., 32:121 156, 1984. [4] H. P. Barendregt. The Lambda Calculus Its \nSyntax and Semantics, volume 103 of Studies in Logic and the Foundations of Mathematics. North-Holland, \n1984. [5] M. Bernardo, R. De Nicola, and M. Loreti. A uniform framework for modeling nondeterministic, \nprobabilistic, stochastic, or mixed processes and their behavioral equivalences. Inf. Comput., 225:29 \n82, 2013. [6] G. Boudol. Lambda-calculi for (strict) parallel functions. Inf. Comput., 108(1):51 127, \n1994. [7] G. Boudol and C. Laneve. The discriminating power of the .-calculus with multiplicities. Inf. \nComput., 126(1):83 102, 1996. [8] D. Comaniciu, V. Ramesh, and P. Meer. Kernel-based object tracking. \nIEEE Trans. on Pattern Analysis and Machine Intelligence,, 25(5): 564 577, 2003. [9] U. Dal Lago and \nM. Zorzi. Probabilistic operational semantics for the lambda calculus. RAIRO -Theor. Inf. and Applic., \n46(3):413 450, 2012. [10] U. Dal Lago, D. Sangiorgi, and M. Alberti. On coinductive equivalences for \nprobabilistic higher-order functional programs (long version). Available at http://arxiv.org/abs/1311.1722, \n2013. [11] V. Danos and R. Harmer. Probabilistic game semantics. ACM Trans. Comput. Log., 3(3):359 382, \n2002. [12] R. De Nicola and M. Hennessy. Testing equivalences for processes. Theor. Comput. Sci., 34:83 \n133, 1984. [13] U. de Liguoro and A. Piperno. Non deterministic extensions of untyped lambda-calculus. \nInf. Comput., 122(2):149 177, 1995. [14] M. Dezani-Ciancaglini and E. Giovannetti. From bohm s theorem \nto observational equivalences: an informal account. Electr. Notes Theor. Comput. Sci., 50(2):83 116, \n2001. [15] M. Dezani-Ciancaglini, J. Tiuryn, and P. Urzyczyn. Discrimination by parallel observers: The \nalgorithm. Inf. Comput., 150(2):153 186, 1999. [16] T. Ehrhard, M. Pagani, and C. Tasson. The computational \nmeaning of probabilistic coherence spaces. In LICS, pages 87 96, 2011. [17] S. Goldwasser and S. Micali. \nProbabilistic encryption. J. Comput. Syst. Sci., 28(2):270 299, 1984. [18] N. D. Goodman. The principles \nand practice of probabilistic programming. In POPL, pages 399 402, 2013. [19] A. D. Gordon. Bisimilarity \nas a theory of functional programming. Electr. Notes Theor. Comput. Sci., 1:232 252, 1995. [20] A. D. \nGordon, M. Aizatulin, J. Borgstr \u00a8om, G. Claret, T. Graepel, A. V. Nori, S. K. Rajamani, and C. V. Russo. \nA model-learner pattern for bayesian reasoning. In POPL, pages 403 416, 2013. [21] M. Hennessy. Exploring \nprobabilistic bisimulations, part I. Formal Asp. Comput., 24(4-6):749 768, 2012. [22] D. J. Howe. Proving \ncongruence of bisimulation in functional programming languages. Inf. Comput., 124(2):103 112, 1996. [23] \nR. Jagadeesan and P. Panangaden. A domain-theoretic model for a higher-order process calculus. In ICALP, \npages 181 194, 1990. [24] C. Jones and G. D. Plotkin. A probabilistic powerdomain of evaluations. In \nLICS, pages 186 195, 1989. [25] V. Koutavas, P. B. Levy, and E. Sumii. From applicative to environmental \nbisimulation. Electr. Notes Theor. Comput. Sci., 276: 215 235, 2011. [26] K. G. Larsen and A. Skou. Bisimulation \nthrough probabilistic testing. Inf. Comput., 94(1):1 28, 1991. [27] S. B. Lassen. Relational Reasoning \nabout Functions and Nondetermin\u00adism. PhD thesis, University of Aarhus, 1998. [28] S. Lenglet, A. Schmitt, \nand J.-B. Stefani. Howe s method for calculi with passivation. In CONCUR, pages 448 462, 2009. [29] C. \nD. Manning and H. Sch \u00a8utze. Foundations of statistical natural language processing, volume 999. MIT \nPress, 1999. [30] C.-H. L. Ong. Non-determinism in a functional setting. In LICS, pages 275 286, 1993. \n[31] P. Panangaden. Labelled Markov Processes. Imperial College Press, 2009. [32] S. Park, F. Pfenning, \nand S. Thrun. A probabilistic language based on sampling functions. ACM Trans. Program. Lang. Syst., \n31(1), 2008. [33] J. Pearl. Probabilistic reasoning in intelligent systems: networks of plausible inference. \nMorgan Kaufmann, 1988. [34] A. Pfeffer. IBAL: A probabilistic rational programming language. In IJCAI, \npages 733 740. Morgan Kaufmann, 2001. [35] A. M. Pitts. Operationally-based theories of program equivalence. \nIn Semantics and Logics of Computation, pages 241 298. Cambridge University Press, 1997. [36] A. M. Pitts. \nHowe s method for higher-order languages. In D. Sangiorgi and J. Rutten, editors, Advanced Topics in \nBisimulation and Coinduction, pages 197 232. Cambridge University Press, 2011. [37] N. Ramsey and A. \nPfeffer. Stochastic lambda calculus and monads of probability distributions. In POPL, pages 154 165, \n2002. [38] N. Saheb-Djahromi. Probabilistic LCF. In MFCS, volume 64 of LNCS, pages 442 451, 1978. [39] \nD. Sands. From SOS rules to proof principles: An operational metatheory for functional languages. In \nPOPL, pages 428 441, 1997. [40] D. Sangiorgi and D. Walker. The pi-Calculus a theory of mobile processes. \nCambridge University Press, 2001. [41] D. Sangiorgi, N. Kobayashi, and E. Sumii. Logical bisimulations \nand functional languages. In FSEN, volume 4767 of LNCS, pages 364 379, 2007. [42] D. Sangiorgi, N. Kobayashi, \nand E. Sumii. Environmental bisimulations for higher-order languages. ACM Trans. Program. Lang. Syst., \n33(1):5, 2011. [43] K. Sieber. Call-by-value and nondeterminism. In TLCA, volume 664 of LNCS, pages 376 \n390, 1993. [44] S. Thrun. Robotic mapping: A survey. Exploring arti.cial intelligence in the new millennium, \npages 1 35, 2002.    \n\t\t\t", "proc_id": "2535838", "abstract": "<p>We study bisimulation and context equivalence in a probabilistic lambda-calculus. The contributions of this paper are threefold. Firstly we show a technique for proving congruence of probabilistic applicative bisimilarity. While the technique follows Howe's method, some of the technicalities are quite different, relying on non-trivial \"disentangling\" properties for sets of real numbers. Secondly we show that, while bisimilarity is in general strictly finer than context equivalence, coincidence between the two relations is attained on pure lambda-terms. The resulting equality is that induced by Levy-Longo trees, generally accepted as the finest extensional equivalence on pure lambda-terms under a lazy regime. Finally, we derive a coinductive characterisation of context equivalence on the whole probabilistic language, via an extension in which terms akin to distributions may appear in redex position. Another motivation for the extension is that its operational semantics allows us to experiment with a different congruence technique, namely that of logical bisimilarity.</p>", "authors": [{"name": "Ugo Dal Lago", "author_profile_id": "81100620235", "affiliation": "Universit&#224; di Bologna &#38; INRIA, Bologna, Italy", "person_id": "P4383827", "email_address": "dallago@cs.unibo.it", "orcid_id": ""}, {"name": "Davide Sangiorgi", "author_profile_id": "81100628842", "affiliation": "Universit&#224; di Bologna &#38; INRIA, Bologna, Italy", "person_id": "P4383828", "email_address": "sangio@cs.unibo.it", "orcid_id": ""}, {"name": "Michele Alberti", "author_profile_id": "86158893957", "affiliation": "CNRS &#38; Universit&#233; d'Aix-Marseille, Marseille, France", "person_id": "P4383829", "email_address": "michele.alberti@univ-amu.fr", "orcid_id": ""}], "doi_number": "10.1145/2535838.2535872", "year": "2014", "article_id": "2535872", "conference": "POPL", "title": "On coinductive equivalences for higher-order probabilistic functional programs", "url": "http://dl.acm.org/citation.cfm?id=2535872"}