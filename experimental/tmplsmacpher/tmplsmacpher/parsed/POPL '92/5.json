{"article_publication_date": "02-01-1992", "fulltext": "\n Optimally Profiling and Tracing Programs THOMAS BALL JAMES R. LARUS tom@cs.wise.edu larus@cs.wise.edu \nComputer Sciences Department University of Wisconsin Madison 1210 W. Dayton St. Madison, WI 53706 USA \nABSTRACT 1. INTRODUCTION This paper presents algorithms for inserting monitoring This paper presents \ntwo algorithms for inserting monitoring code to profile and trace programs. These algorithms code to \nprofile and trace programs. These algorithms greatly reduce the cost of measuring programs. Profiling \ngreatly reduce the cost of measuring programs. Profiling, counts the number of times each basic block \nin a program which counts the number of times each basic block in a executes and has a variety of applications. \nInstruction program executes, is widely used to measure instruction set traces are the basis for trace-driven \nsimulation and analysis, utilization of computers, identify program bottlenecks, and and are also used \nin trace-driven debugging. estimate program execution times for code optimiza\u00ad tion [2, 4,5, 10, 12,13, \n113]. Instruction braces are the basis The profiling algorithm chooses a placement of counters for trace-driven \nsimulation and analysis and are also used that is optimized-and frequently optimal with respect to in \ntrace-driven debugging [8, 11, 19]. the expected or measured execution frequency of each basic block \nand branch in the program. The tracing algo-Our goal is an exact basic block profile or trace-as rithm \ninstruments a program to obtain a subsequence of the opposed to the Unix p-of command, which samples \nthe basic block trace-whose length is optimized with respect program counter during program execution. \nThis paper to the program s execution from which the entire trace shows how to significantly reduce the \ncost of exact can be efficiently regenerated, profiling and tracing with: Both algorithms have been implemented \nand produce a (1) an algorithm to instrument a program for profiling substantial improvement over previous \napproaches. The that chooses a placement of counters that is profiling algorithm reduces the number of \ncounters by a optimized and frequently optimal-with respect to factor of two and the number of counter \nincrements by up the expected or measured execution frequency of to a factor of four. The tracing algorithm \nreduces the file each basic block and branch in the program; size and overhead of an already highly optimized \ntracing (2) an algorithm to instrument a program to obtain a system by 20-4070. subsequence of the basic \nblock trace-whose length is optimized with respect to the program s This work was supportedin part by \nthe National ScienceFoundationunder grsnt execution-from which an entire trace can be CCR-8958530and \nby the Wisconsin Alumni Research Foundation. efficiently regenerated. Both algorithms have been implemented \nand substan\u00adtially improve performance over previous approaches. Each atgorithm consists of two parts. \nThe first chooses points in a program at which to insert profiling or tracing code. The second uses the \nresults from the program s exe\u00adcution to derive a complete profile or trace. The algorithms for profiling \nand tracin,g programs are based on the well- Permission to copy without feo atl or part of thk material \nis granted known maximum spanning tree algorithm, applied to the provided that the copies am not made \nor distributed for direct program s control-flow graph [21]. commercial advantage, the ACM copyright \nnotice and the title of the publication and its date appear, and notice is given that copying is by In \nthe control-flow graph representation of a program, permission of the Association for Computing Machinery. \nTo cQpyother\u00ad where a vertex represents a basic block of instructions and wise , or to republish, requires \na fee and/or specific permission. an edge represents passage of contrcd between blocks, @ 1992 ACM 089791 \nAt53-8/92/0001/0059 $1.50 instrumentation code can be placed on vertices, edges, or some combination \nof the two. This work shows that for both profiling and tracing, it is better to place instrumenta\u00adtion \ncode solely on edges. The algorithms optimize placement of profiling and trac\u00ading code with respect to \na weighing that assigns a nonne\u00adgative value to each edge in the control-flow graph. The cost of profiling \nor tracing a set of edges is proportional to the sum of the weights of the edges. Weighings can be obtained \neither by empirical measurement (i.e., profiling) or a heuristic estimation. Our results show that a \nsimple edge frequency heuristic is accurate in predicting areas of low execution frequency at which to \nplace instrumentation code. The algorithms choose edges for instrumentation based on the control-flow \nof a program and a weighting. They are applicable to any control-flow graph the graphs need not be reducible. \nThe algorithms do not make use of other semantic information that could be derived from the pro\u00adgram \ntext (i.e., via constant propagation). While there exist unstructured control-flow graphs for which the \nalgorithms do not find an optimal placement, they optimize placements for a large class of well-structured \ncontrol-flow graphs. This paper has seven sections. The next section provides background material on \ncontrol-flow graphs, weighings, and spanning trees. Section 3 shows how to efficiently profile programs \nand Section 4 describes how to efficiently trace programs. Section 5 presents results on the perfor\u00admance \nof the profiling and tracing algorithms. Section 6 reviews related work and Section 7 summarizes the \npaper and describes future work. 2. BACKGROUND A control-flow graph (CFG) is a rooted directed graph \nG = (V, E) with a special vertex EXIT (distinct from the root vertex) that corresponds to a program in \nthe following way: each vertex in V represents a basic block of ins@uc\u00adtions and each edge in E represents \nthe transfer of control from one basic block to another. The root vertex represents the first basic block \nto execute and EXIT the last. There is a directed path from the root to every vertex and a directed path \nfrom every vertex to EXIT. Finally, for the profiling algorithm, it is convenient to insert an edge EXIT \n-+root to make the CFG strongly connected. This edge does not correspond to an actual flow of control \nand is not instru\u00admented. A vertex p is a predicate if there are distinct vertices a and b such that \np~a and p~b. All weighings W of a CFG G assign a nonnegative value to every edge subject to Kirchoff \ns law of conservation of flow: for each vertex v, the sum of the weights of edges with target v (the \nincoming edges of v) must be equal to the sum of the weights of edges with source v (the outgoing edges \nof v). The weight of a vertex is simply the sum of the weights of its incoming (or outgoing) edges. If \nW is a weighting of CFG G, then for a set of edges and vertices pl from CFG G, cost(G, pl, W) is the \nsum of the weights on the edges and vertices in pl. An execution EX of a CFG is a directed path that \nbegins with the root vertex and ends with EXIT in which EXIT appears exactly once (we also refer to an \nexecution as the sequence of vertices from such a directed path). The fre\u00adquency of a vertex v or edge \ne in an execution EX is the number of times that v or e appears in EX. If a vertex or edge does not appear \nin EX, its frequency is zero. How\u00adever, for any execution, the frequency of the edge EXIT--woot is defined \nto be 1. The edge frequencies for any execution (or set of execu\u00adtions) of a CFG constitute a weighting \nof the CFG. Con\u00adversely, a heuristically chosen weighting can summarize many different executions. A \nspanning tree of a directed graph G is a subgraph G = (V , E ), where V = V and E G E, such that for \nevery pair of vertices (v,w) in G there is a unique path (not necessarily directed) in G that links v \nto w. A maximum spanning tree G of graph G with weighting W is a span\u00adning tree such that cost(G, E , \nW) is maximized. Maximum spanning trees can be computed efficiently by a variety of algorithms [21]. \nFigure 1 illustrates these definitions. The first graph is the CFG of the program shown this graph has \nbeen given a weighting. The second graph is a maximum spanning tree of the first graph. Note that any \nvertex in the spanning tree can serve as a root and that the direction of the edges in the tree is unimportant. \nFor example, vertices C and EXIT are connected by the path C~P~EXIT. 3. PROGRAM PROFILING In order to \ndetermine how many times each basic block in a program executes, the program can be instrumented with \ncounting code. The simplest approach places a counter at every basic block (pixie and other instrumentation \ntools use this method [20]). There are two drawbacks to such an approach: (1) too many counters are used \nand (2) the total number of increments during an execution is larger than necessary. while P do ifQ \nthen A else B fi if I? then break fi c od P 105 Q  1 m ) Figure 1. A program, its CFG with a weighting, \nand a maximum sp~w W-The edw Exfl+p is ne~ed so fiat fie f10w e~ua\u00adtions for the root vertex (P) and \nEXIT are consistent. Thk edge does not correspond to an actuai flow of control and is not instru\u00admented. \nLet pl be a subset of the edges and/or vertices from CFG G. The set pl solves the vertex frequency problem \nfor CFG G, denoted VFreq(G,pl), iff the frequency of each vertex in any execution of G can be deduced \nsolely from the CFG G and the frequencies of the edges and vertices h pl. The set pl contains those edges \nand vertices whose frequencies are directly measured by counters. To reduce the cost of profiling (i.e., \nthe number of counter increments), these counters should be placed in areas of low execution fre\u00adquency. \nThat is, pl should solve VFreg(G,pl) and mhtimize cost(G, pl, W) for a weighting W. Such a pl is referred \nto as an optimal solution to VFreq (G,p/) (with respect to weighting W). Similarly, a set pl solves the \nedge frequency problem for CFG G, denoted -EFreq(G,pQ, iff the frequency of each edge in any execution \nof G can be deduced solely from the CFG G and the frequencies of the edges and vertices in pl. A solution \nto the edge frequency problem obviously yields a solution to the vertex frequency problem by simply sum\u00adming \nthe frequencies of the incoming or outgoing edges of each vertex. To limit the number of permutations \nof these problems, pl is restricted to be a set of edges (epl) or a set of vertices (vpl). Section 3.2 \nshows that mixed placements (edges and vertices) are never better than pure edge solutions. We study \nthe problems of VFreq (G ,epl), VFreq (G, vpl), and EFreq(G,epl), with the goal of optimally solving \nVFreq(G,p/). Since there are CFGS for which there are no vpl solutions to the edge frequency problem, \nEFreq(G,vpl) is not considered [15]. This section presents three results: (a) EFreq(G,epl) VFr,cq(G,vpl) \nA h V,Freq(G,epl) (b) EFreq(G,epl) = VFreq(G,epl) ~ VFreq(G,vpl) Figure 2. Case (a) shows the relationship \nbetween the costs of th~ optimal solutions of the three frequency problems for general CFGS. Case (b) \nshows the relationship when G is restricted to CFGS constructed from whiie loops, if-then-eise conditionals, \nand begin-end blocks. (1) an algorithm to optimally solve EFreq(G,epO (2) a comparison of the optimal \nsolutions to VFreq(G,epl), VFreq(G,vpl), and EFreq(G,epl). Case (a) of Figure 2 summarizes the relationship \nbetween these three problems (3) a proof that an optimal solution to EFreq(G,epl) is also au optimal \nsolution to VFreq (G,epl) for a large class of structured CFGS  3.1. The Edge-Frequency/Edge-Placement \nProblem To solve EFreq(G,epl), it is clearly sufficient to place a counter on the outgoing edges of each \npredicate vertex. However, this placement uses too many counters. From a well-known result in network \nprogramming, it follows that an edge-counter placement epl solves EFreq(G,epl) ifjf (E-ep/) contains \nno (Ipossibly undirected) cycle [6]. Since a spanning tree of a CIFG represents a maximum size subset \nof edges without a cycle, it follows that epl is a minimum size solution to EFreq(G,epl) iff E epl is \na spanning tree of G. Thus, the minimum number of counters necessary to solve EFreq(G, ep/) is IEI (IVI \n 1). To see how such a placement solves the edge frequency problem, consider a CFG G and a set epl such \nthat E epl is a spanning tree of G. Let each edge e in epl have an asso\u00adciated counter that is initially \nset to () and is incremented once each time e executes. If v is a leaf in the spanning tree (pick any \nvertex as the root), then all but one of the edges incident to v must be in epl. Since the edge frequen\u00adcies \nfor an execution satisfy Kirchoff s law, the unmeas\u00adured edge s frequency is uniquely determined by the \nflow equation for v and the known frequencies of the other incoming and outgoing edges of v. The remaining \nedges with unknown frequency still form a tree, so this process can be repeated until the frequencies \nof all edges in E epl are uniquely determined. If E epl is not a spanning tree of G (i.e., there is a \ncycle, possibly undirected, in E epl), it can be shown that whenever the frequencies of edges in epl \nare fixed, there is more than one solution to the system of flow equations< Any of the well-known maximum \nspanning tree algo\u00adrithms described by Tarjan [21] will produce the maximum spanning tree of G with respect \nto weighting IV. The edges that are not in the spanning tree solve EFreq (G,epl) and minimize cost(G, \nepl, W). Case (a) of Figure 3 illustrates this process. The dotted edges in the CFG are the edges in \nepl. The other edges are in E epi and form a spanning tree of the CFG. The edge frequencies are those \nfor the execution shown. The meas\u00adured frequencies are underlined. Let vertex P be the root of the spanning \ntree. Vertex Q is a leaf in the spanning tree and has flow equation (P ~ Q = Q ~A + Q +B). Since the \nfrequencies for P -+Q and Q -+A are known, we can sub\u00adstitute them into this equation and derive the \nfrequency for Q +B. Once the frequency for Q ~B is known, the fre\u00adquency for B -+R can be derived from \nthe flow equation for B, and so on. Execution: PQARC PQBRC PQBR EXIT P 3 QQ ~~1 AB 2 I2 R 2C ~ @ EXIT \n(a) (b) Figure 3. Solving EFreq(G,epl) using the spanning tree. The dotted edges are in epl ~d the remaining \nedges (E epl) form a spanning tree of the CFG. The frequency of each edge in the exe\u00adcution is shown \nand the measured frequencies are underlined. For the weighting given in Figure 1, the epl in case (a) \nis not optimal (minimal) but the epl in case (b) is optimal. For the weighting W given in Figure 1, the \nepl solution in case (a) of Figure 3 has cost(G, epl, W) = 16.75 and cost(G, E epl, W) = 36.75. However, \nas case (b) of Fig\u00adure 3 shows, there is an epl solution with cost(G, epl, W) = 11.5. This spanning tree \nhas cost(G, E epl, W) = 42. For this example, the epl placement of case (a) is suboptimal for any weighting. \nAlthough profiling has been described in terms of a sin\u00adgle CFG, the algorithm requires few changes to \ndeal with multi-procedure programs. The pre-execution spanning tree algorithm and post-execution propagation \nof edge frequencies are simply applied to each procedure separately. However, two problems can arise: \n(1) If there is a CFG G with a directed path from root to EXIT that contains no edge in epl (which can \noccur only if EXIT--w-oot is in epl), then there is a possible execution that increments no counter (since \nthe edge EXIT -+root is never traversed). Thus, it will be impossible to determine the exact count information \nfor edges in G. To ensure that no such path arises, the maximum spanning tree algorithm can be seeded \nwith the edge EXIT--woot. In fact, for any CFG and weighting, there is always a maximum spanning tree \nthat includes the edge EXIT--w-oot. The derived count for the edge EXIT-+root represents the number of \ntimes the procedure G executed. (2) The simple extension for multi-procedure profiling will determine \nthe correct frequencies only if interprocedural control-flow occurs via procedure call and return and \neach call eventually has a corresponding return, statically\u00addeterminable interprocedural jumps also can \nbe handled in our framework. However, dynamically-computed interpro\u00adcedural jumps (e.g., setjmp/longjmp) \ncan cause problems. The common case of the call to the exit procedure that ter\u00adminates execution illustrates \nthis problem. In this case, the  information on the activation stack at program termination is sufficient \nto correct the count error. Figure 4 describes this problem and a solution. Execution: PQBRC PQA(calltoexit) \n Figure 4. The first CFG executes the path shown and calls the exit routine at vertex A, which terminates \nthe program. If the measured counts (underlined) are propagated to the sparming tree edges, incorrect \nvalues are computed. The second graph shows how this problem is solved. At program termination, the edge \nA --XXZT is added and given count 1 to model the early termina\u00adtion of this procedure. After this edge \nhas been added, the counts will be computed correctly. One such edge must be added for each active procedure \non the stack at program termination, 3.2. Comparing the Three Frequency Problems This section examines \nthe relationships between the optimal solutions to VFreq (G,epl), VFreq (G,vp/), and EFreq(G,ep/) for \ngeneral CFGS, as summarized in case (a) of Figure 2. We first consider why VFreq(G,epl), VFreq (G,vpi), \nand EFreq(G,epl) are the most interesting problems to study. Suppose that a set pl contains a mix of \nvertices and edges and optimally solves VFreq (G,pl) or EFreq (G,pl) for CFG G with weighting W. For \nany vertex v in pl, v s counter can be pushed off of v onto each outgoing edge of v, resulting in placement \npi . Since the cost of a vertex is equal to the sum of the costs of its outgoing edges, and some of v \ns outgoing edges may be in pl, cost(G, pi , W) < cost(G, pl, W).l Furthermore, pl clearly solves the \nsame problem as pl since no vertex or edge frequency informa\u00adtion is lost in going from pl to pi . Thus, \nfor any CFG G and weighting W, a mixed solution to one of the prob\u00adlems can never be better than an optimal \nepl solution to the same problem. It follows directly from this argument that for any CFG G and weighting \nW, an optimal solution to VFreq(G,vpl) is never better than an optimal solution to VFreq(G,epl). An example \nwhere EFreq(G,epl) (and thus VFreq(G,epO) betters VFreq (G,vpl) is discussed later. Since any solution \nto EFreq (G,epl) must also solve VFreq(G,epl), it is clear that an optimal solution to EFreq(G,epl) can \nnever be better than an optimal solution to VFreq(G,epO for a given CFG and weighting. As Fig\u00adure 5 illustrates, \nthere are cases where an optimal solution to VFreq(G,epl) is better than an optimal solution to EFreq(G,epl). \nThe only examples that we have encoun\u00adtered in which VFreq(G,ep/) betters EFreq(G,epl) exhibit unstructured \ncontrol-flow such as found in Figure 5. For the CFG in Figure 1, the optimal solution to EFreq(G,epl) \nis also an optimal solution to VFreq(G,epl). Section 3.3 describes a class of graphs for which an optimal \nsolution to EFreq(G,ep/) is an optimrd solution to VFreq(G,epl). Finally, in comparing EFreq(G,epl) and \nVFreq(G,vpl) (for general CFGS), there are examples in which one is better than the other and vice versa. \nCase(b) of Figure 5 can be easily modified to show an example where VFreq(G,vp/) is better than EFreq(G,ep/): \nsimply consider Placing counters atong edges instead of on vertices may require insertion of jumps in \naddition ~Q .o.n!irig code, whi.h is not mfkted in o.. cost metric, Se-= S.+= for an exceltent discussion \nof the problem of optimizing jumps in addition to count\u00ading cede [17]. Cost = 2*2 + 3*6 =22 cost = 44 \n1 + 2+2+ 3 4 = 20 J4J4 4 22 J> 11 3311 33 J 333 [~ 46 (a) (b) Figure 5. An example of a CFG and a weighting \nfor which an op\u00adtirnat solution to VFreq (G, epl) is better than an optimal solution to EFreq(G,epl). \nThe dotted edges are in epl. Case (a) shows an optimal solution to EFreq (G, epl ). The edges in E ep/ \nform a maximum spanning tree of the graph. The, lower cost epl place\u00adment in case (b) does not solve \nEFreq (G, epl) (as there is a cycle in E -epl) but does solve VFreq (G, epl ). To see this, note that \nthe count for each checked edge is uniquely determined by the counts for the dotted edges md that this \nyields enough edge counts to determine the count for every vertex. The counts of the four edges in the \ninner cycle are not uniquely determined. each black dot as a vertex in its own right and split the dot\u00adted \nedge into two edges. The dots constitute the set vpl and solve VFreq (G,vpl) with cost 20. The optimal \nsolution to EFreq(G,ep/) for this graph still has cost 22. There are many examples of structured CFGS \nwhere EFreq(G,epl) is preferable to VFreq (G,vpl). Consider the CFG in Figure 1 again. The vertex frequencies \nin this graph are related by the equations Q = R = A + B and EXIT = (P +R) (C +Q ). From these equations \nand the weighting in Figure 1, it turns out that the optimal solution to VFreq(G,vp/) is ( ,4, B, C, \nEXIT }, with a cost of 21.5. The optimal solution to EFreq (G,epl) has cost 11.5. By instrumenting edges \ninstead of vertices, there is greater freedom to pick and. choose lower cost points (IEI as opposed to \nIll). 3.3. Optimality Revisited The previous section points out that the optimal way to solve VFreq(G,pl) \nis to optimally solve VFreq (G,epl). Unfortunately, VFreq (G,epl) is a hard problem to solve optimally \n! We have made some progress towards under\u00adstanding this problem but have no efficient algorithm or proof \nof intractability for it yet. However, we believe that for most CFGS encountered in practice, an optimal \nsolution to EFreq(G,epl) will provide an optimal (or near-optimal) solution to VFreq (G, epl). This section \ndescribes a class of CFGS for which an optimal solution to EFreq (G,epl) is also an optimal solution \nto VFreq(G,epl). The class of CFGS generated by while loops, if-then-else conditionals, and begin-end \nblocks is properly contained in this class. Definition. A diamond consists of two simple directed paths \n(a path is simple if no vertex appears in it more than once) PTHa = pjaj ... +Z and PTHb = pjb-)  +-Z \nsuch that p and z are the only vertices common to both PTH. and PTHb . THEOREM 3.1, If epl solves VFreq \n(G,epl), then E epl contains no diamond or directed cycle. PROOF. If E epl contains a diamond or a directed \ncycle, then it is possible to find two executions of G such that the frequency of each edge in epl is \nthe same in both execu\u00adtions, and where there is a vertex v with a different fre\u00ad quency in each execution. \nSince epl does not distinguish these two different executions, epl cannot solve VFreq(G,epl). D COROLLARY \n3.2. For any CFG G with weighting W, an optimal epl solution to VFreq (G,epl) can never cost less than \na minimal cost epl such that E epl contains no directed cycle or diamond. Consider the CFG in Figure \n1 and any simple cycle (a cycle with N vertices is simple if N 1 of the vertices in the path representing \nthe cycle are unique) in the graph. The cycle need not be directed. Each such cycle is either a directed \ncycle or a diamond. Let G* represent all CFGS in which the only simple cycles are directed cycles or \ndia\u00admonds. For any CFG G in G * with weighting W, the fol\u00adlowing two statements are equivalent: (1) epl \nis a minimal cost set of edges such that E-epl contains no directed cycles or diamonds. (2) E-epl is \na maximum spanning tree,  Corollary 3.2, together with this result, implies that for any CFG G in G* \nwith weighting W, an optimal solution to VFreq(G,epl) can never be better than an optimal solution to \nEFreq (G, epl). Therefore, for this class of CFGS, an optimal solution to EFreq (G, epl) is an optimal \nsolution to VFreq(G,epl). The class of graphs G* contains many examples of CFGS with multiple exit loops \n(such as in Figure 1), CFGS that require gotos, and even some irreducible graphs. The largest subset \nof structured CFGS contained in G * are those CFGS generated by while loops, if-then-else conditionals, \nand begin-end blocks. However, in general, CFGS gen\u00aderated by programs with repeat loops or breaks are \nnot always members of G *. To date, we have not found any examples of CFGS gen\u00aderated by structured programs \nwith multi-exit loops for which VFreq(G, ep/) betters EFreq(G, epl), Further work is required to find \nother classes of CFGS for which the optimal solutions to these problems are the same. 4. PROGRAM TRACING \nJust as a program can be instrumented to record basic block execution frequency, it also can be instrumented \nto record the sequence of basic blocks executed. The tracing prob\u00adlem is to record enough information \nabout a program s exe\u00adcution to be able to reproduce the entire execution. A straightforward way to solve \nthis problem is to instrument each basic block so that it writes a unique mark (witness) to a trace file \nwhenever it executes. In this case, the trace file need only be read to regenerate the execution. A more \nefficient method is to write a witness only at basic blocks that are targets of predicates [8]. Assuming \nthat there is a standard representation for witnesses (i.e., a byte, half-word, or word per witness), \nthe tracing problem can be solved with significantly less time and storage overhead than either solution \nby writing witnesses when edges are traversed (not when vertices are executed) and carefully choosing \nthe edges that write witnesses. Section 4.1 formalizes the trace problem for single-procedure progmms. \nSection 4.2 considers the com\u00adplications introduced by multi-procedure programs. 4.1, Single-Procedure \nTracing In this section, assume that basic blocks do not contain any calls and that the extra edge EXIT-+roor \nis not included in the CFG. The set of instrumented edges in the CFG is denoted by epl. In this application, \nwhenever an edge in epl is traversed, a witness to that edge s execution is written to a trace file. \nNo two edges in epl generate the same witness. The statement of the tracing problem relies on the following \ndefinitions: Definition. A path in CFG G is witness-free with respect to a set of edges epl iff no edge \nin the path is in epl. Definition. Given a CFG G, a set of edges epl, and edge p~q where p is a predicate, \nthe witness set (to vertex q) for predicate p is: = { u, v, EOF } and witness (P,B) = { u, v }. The \nexecu- Execution: P A c P B A c P B c EXIT AA AA Trace: t U v EOF P witness(p, A) = { t } t witness(p, \nB) = { u, v ] AB u witness(B,A) = { u } v witness(B, C)= { v } c @ witness(C, P) = { t, u, v } hwitness(C, \nEXIT) = { EOF } EXIT Figure 6. Example of a traced function. Vertices P, B, and C are predicates. The \nwitnesses are shown by dots along edges. For the execution shown, the traced generated is (t, U, V, EOF). \nThe wit\u00adness EOF is always the last witness in a trace. The execution can be reconstructed from rhe trace \nusing the witness sets to guide which branches to take. witness (G, epl, p, q) = ( w I p~q e epl (and \nwrites witness w) } u ( w I x +y c epl (and writes witness w) and 3 witness-free path p+q+ oc -+x ) u \n( EOF I 3 witness-free path p -+q ~ . s . -+EXZT ) Figure 6 illustrates the above definitions. Let us \nexamine how the execution in Figure 6 can be regenerated from its trace. Re-execution starts at predicate \nP, the root vertex. To determine the successor of P, we read witness t from the trace, which is a member \nof witness (P,A ) but not of witness (P,B). Therefore, A is the next vertex in the execution. Vertex \nC follows A in the execution as it is the sole successor of A. Since the edge that produced witness t(P-+A) \nhas been traversed already, we read the next witness from the trace. Witness u is a member of wifness \n(C,P ) but not witness (C, EXIT), so ver\u00adtex P follows C. At vertex P, witness u is still valid (since \nthe edge B -+A has not been traversed yet) and determines B as P s successor. Continuing in this manner, \nthe original execution can be reconstructed. If a witness w is a member of both witness (G, epl, p, a) \nand witness (G, epl, p, b), where a # b, then two different executions of G generate the same trace file, \nwhich makes regeneration based solely on the control-flow and trace information impossible. For example, \nin Figure 6, if the edge P ~A does not generate a witness, then witness (P,A) tions (P, A, C, P, B, C, \nEX17) and (P, B, C, EXIT) both generate the trace (v, IEOF). This motivates our definition of the tracing \nproblem: Definition. A set of edges, epl, solves the tracing problem for CFG G, denoted Trace (G,epl), \niff for each predicate p in G with successors q 1, .... q~, for all pairs (qi, qj) such that i #j, witness \n(G, epl, p, qi) n witness (G, epl, p, qj) = 0 A witness placement epl and an execution EX determine \na trace as follows: let trace_record(EX, epl) = (w ~, .... WJ II EOF, where wi is the witness generated \nby the i h edge in EX that is a member of epl. Given the CFG G, a set of edges epl that solves Trace \n(G,epl), and trace_record(EX, epl), the algorithm in Figure 7 regenerates the execution EX. The following \ntheorem captures the correetrte ss of this algorithm: THEOREM 4.1. If epl solves Trace (G,epl) then \nfor any exe\u00adcution EX of G , the call regenerate(G, epl, trace_record(EX, epl)) outputs the execution \nEX. ~OOF. Omitted. See [1] for details. El procedure regenerate(G: CFG; epl: set of witness edges; trace: \nfile of witnesses ) declare pc, newpc: vertices; wil: wimess; begin pc:= root-vertex(G); wi~:= NULL; \nOutput; do if not IsPrwticate(pc) then newpc := successor(G, pc); if wit = NULL and pc--mewpc ~ epl then \nwit := read(trace) fi etse if wit = NULL then wit:= read(trace) ti rmvpc := q such that wit G witness \n(G, epl, pc, q) 6 i~pc~newpc G epl then wit := NULL ti pc := newpc; Output; until (pc = EXIT ) end Figure \n7. Algorithm for regenerating an execution from a trace. The following theorem shows that epl solves \nTrace (G,epl) exactly when the set of edges E epl contains no diamond or directed cycle. This result \nimplies that any epl that solves EFreq(G,epl) also solves Trace(G,ep/). Therefore, if the set of edges \nT is a maximum spanning tree of G, epl = E T solves Trace (G,epl). Also, Theorem 3.1 implies that any \nepl that solves VFreq (G,epl) solves Trace (G,epl). THEOREM 4.2, The set E epl, where E represents the \nedges of CFG G and epl c E, contains no directed cycles or diamonds iff epl solves Trace (G,epl). ~OOF. \nOmitted. See [1] for details. D Solving Trace (G, epl) so that cost(G,ep/, IV) is minim\u00adized (where W \nis a weighting) is an NP-complete prob\u00adlem [14]. The reduction is similar to that used to show the Unconnected \nSubgraph problem is NP-complete [9], but is complicated by the fact that a weighting satisfies Kirchoff \ns flow law. However, for any CFG G in G*, an optimal solution to EFreq (G, epl) is an optimal solution \nto Trace (G,epl).   4.2. Multi-Procedure Tracing Unfortunately, tracing does not extend as easily to \nmultiple procedures as does profiling. There are several complica\u00adtions that we illustrate with the CFG \nin Figure 6. Suppose that basic block B contains a call to procedure X and execu\u00adtions proceeds from \nP to B, where procedure X is called. After procedure X returns, suppose that C executes. This call creates \nproblems for the regeneration process since the witnesses generated by procedure X, possibly an enormous \nnumber of them, precede the witness v in the trace file. In order to determine which branch of predicate \nP to take, the witnesses generated by procedure X must be buf\u00adfered or witness set information must be \npropagated inter\u00adprocedurally. The first solution is impractical because there is no bound on the number \nof witnesses that may have to be buffered. The second solution eliminates the possibil\u00adity of separate \ninstrumentation and is complicated by multi\u00adple calls to the same procedure and by calls to unknown procedures. \nFurthermore, if witness numbers are reused in different procedures, which greatly reduces the amount \nof storage needed per witness, then the second approach becomes even more complicated. The solution presented \nin this section places blocking witnesses that prevent all predicates in a CFG from see\u00ading a basic block \nthat contains a call site or from seeing the EXIT vertex in that CFG. This ensures that whenever the \nregenerator is in CFG G and reads a witness to deter\u00admine which branch of a predicate to take, the witness \nis guaranteed to have been generated by an edge in G.2 Definition, The set epl has the blocking property \nfor CFG G iff there is no predicate p in G such that there is a witness-free path from p to the EXIT \nvertex or a vertex containing a call. Definition. The set ( epl ~, .... epl~ ) solves the tracing problem \nfor a set of CFGS ( G ~, .... GM ) iff, for all i, epli solves Trace (Gi, epli) and epli has the blocking \nproperty for Gi. The regeneration algorithm in Figure 7 need only be modified to maintain a stack of \ncurrently active procedures: when the algorithm encounters a call vertex, it pushes the current CFG name \nand pc value onto the stack and starts executing the callee; when the algorithm encounters an EXIT vertex, \nit pops the stack and continues executing the caller from the point of the call. An easy way to ensure \nthat epl has the blocking property is to include each incoming edge to a call or EXIT vertex in epl. \nFigure 8 illustrates the reasons why this approach is sulmptimal. These problems can be solved by placing \nblocking witnesses as far away as possible from the ver\u00adtices that they are meant to block. Consider \na call vertex v and any directed path from a predicate p to v such that no vertex between p and v in \nthe path is a predicate. For any weighting of G, placing a blocking witness on the outgoing edge of predicate \np in each such path has cost equal to placing a blocking witness on each incoming edge to v (since no \nvertex between p and visa predicate). However, placing blocking witnesses as far away as possible from \nv ensures that no blocking witnesses are redundant. Further\u00admore, placing the blocking witnesses in this \nfashion increases the likelihood that they solve Trace (G,ep/), In general, it is not always the case \nthat a blocking wit\u00adness placement will solve Trace (G, ep/). Therefore, com\u00adputing epl becomes a two \nstep process: (1) place the block\u00ading witnesses; (2) ensure that Trace (G,epl) is solved by adding edges \nto epl. The details of the algorithm follow: In some tracing applications, data otlter than witnesses \n(such as addmsscs) are also written to the trace file, Vertices in tbe CFG that generate addresses can \nbe blocked with witnesses so that no address is ever mistakenly read as a witness. It would also be feasible \nin this situation to break dte trace file into two files, one for the witnesses and the other for the \naddresses, m avoid placing more blceking witness=, cost =9 Cost =6 t4 +4  Figure 8. Two placements \nof blocking witrtesses. The dashed vertices (B, I, and H) are call vertices. In the first subgraph, a \nblocking witness is placed on each incoming edge to a call vertex (black dots). This placement is suboptimal \nbecause the witness on edge H +1 is not needed and because a witness must be added to edge B +D to solve \nthe tracing problem (white dot). In the second subgraph, blocking witnesses are placed as far away from \ncatl vertices as possible, resulting in an optimal placement. Definition. Let v be a vertex in CFG G. \nThe blocking edges of v are defined as follows: blockers(G, v) = { P-MO 1there is a path p+xo+  +x. \nwhere p is a predicate, v = x., and for 0< i < n, xi is not a predicate ) The first step of the algorithm \nadds an edge e to (initially empty) epl whenever e is a member of blockers(G, v) and v is a call or EXIT \nvertex. To ensure that epl solves Trace (G,epl), edges are then added to epl so that E epl contains no \ndiamonds or directed cycles. The maximum spanning tree algorithm, modified so that no edge already in \nepl is allowed in the spanning tree, is applied to G. The edges that are not in the spanning tree are \nadded to epl, which guarantees that epl solves Trace (G,epl).3 5. PERFORMANCE This section describes \nseveral experiments that demonstrate that the algorithms presented above significantly reduce the cost \nof profiling and tracing real programs. The modified spanning tme algorithm may not actually be able \nto cxeate a spaming tree of G bause of the edges already in epl. In this case the algoritlnn simply identifies \nthe maximal cost set of edges in Ii -epl that conmins no (undirected) cycle.  5.1. Profilhg Performance \nWe implemented the counter placement algorithm for profiling in QP, which is a basic block profiler similar \nto MIPS s pixie [20]. Q]? can either insert counters in every basic block in a program (slow mode) cmalong \nthe subset of edges identified by our algorithm (quick mode). The algo\u00adrithm uses a heuristic weighting, \nbased on the assumptions that (1) each loop iterates ten times, (2) if a loop is entered N times and \nhas E exit edges then each exit edge gets weight N/E, and (3) predicates are equally likely to take any \nof their non-exit branches (see [1] for details). We used the SPEC benchmark suite to test QP [3]. This \nis a collection of 10 moderately large For@an and C pro\u00adgrams that is widely used to evaluate computer \nsystem per\u00adformance. The progmrns were compiled at a high level of optimization and the timings were \nrun on a DECstation 5000/200 with 96MB of main memory and local disks. Table 1 shows the cost of running \nthe benchm&#38;s with profiling, As can be seen from the SIOW and Quick columns, the placement algorithm \nreduces the overhead of profiling dramatically, from 11-424% to 9-105%. For\u00adtunately, the greatest improvements \noccurred in programs in which the profiling overhead was largest, since these programs had more conditioned \nbranches and more oppor\u00adtunities for optimization. The Feedback column shows that the heuristic weighting \nis good at identifying regions of low execution frequency. The times for pixie are less than the times \nrequired by slow QP because pixie rewrites the program to free 3 registers, which enables it to insert \na code sequence that is abotri half the size of the one used by QP (6 instructions vs. 11 instructions). \nIn fact, the pixie code sequence can be reduced to 5 instructions. The column labeled Quick+ is the projected \ntime for quick QP profiling using this 5 instruction code sequence. Table 2 shows the improvement in \nanother way. It records the number of counter increments for both Slow and Quick profiling. For the Fortran \nprograms, the improvements varied. In programs with large basic blocks that execute few conditional branches \n(where profiling was already inexpensive), improved counter placement did not have much of an effect \non the number of increments or the cost of profiling. The fpppp benchmark produced an interesting result. \nWhile it showed the greatest reduction in counter increments, the overhead for measuring every basic \nblock was quite low at 36?Z0 and the average dynamic basic block size was 101. This implies that large \nbasic blocks dominated the execution of fpppp. Thus, even though many basic blocks of smaller size executed \n(which yielded SPEC slow Quick Feedback Pixie Quick+ Benchmark (sec.) % (sec.) % (sec.) % (sec.) % (sec.) \n% gcc (c) 32.2 222.0 19.5 95.0 16.1 61.0 24.5 145.0 14.3 43.2 espresso (C) 71.5 177.1 45.6 76.7 41.0 \n58.9 52.6 103.9 34.8 34.9 spice 379.9 62.7 320.7 37.3 327.3 40.2 320.8 37.4 273.1 17.0 doduc 197.5 56.6 \n142.6 13.1 136.7 8.4 180.1 42.8 133.6 5.9 nasa7 1,045.9 15.7 1,025.9 13.5 1023.5 13.2 992.4 9.8 959.3 \n6.1 Ii (C) 945.9 218.9 553.6 86.6 498.4 68.0 808.2 172.5 413.4 39.4 eqntott (C) 313.1 423.6 122.5 104.8 \n121.6 103.3 178.7 198.8 88.3 47.7 matrix300 311.5 13.6 308.8 12.6 311.0 13.4 292.4 6.6 290.0 5.7 fpppp \n240.2 36.2 199.7 13.2 198.8 12.7 207.2 17.5 187.0 6.0 tomcatv 179.4 10.7 176.6 8.9 172.9 6.7 176.4 8.8 \n168.7 4.1 Table 1. Cost of profiling. For Slow profiling, QP inserts a counter in each basic block. \nFor Quick profiling, QP inserts a counter along selected edges. The column labeled Feedback shows the \nprofiling overhead when the algorithm used an exact weighting from a previous run with identical input. \nPixie is a MIPS utility that inserts a counter in each basic block. Quick+ is the time that Quick profiling \nwould re\u00adquire if QP used the efficient pixie counter instruction sequence. The columns labeled YO show \nthe additional cost of profiling, with respect to the unprofiled program s execution time. Counter Increments \nDynamic SPEC slow Quick Slowl Feedback Slowi Block Benchmark Quick Feedback Size gcc (c) 27,149,754 \n8,458,003 3.2 5,324,315 5.1 4.6 espresso (C) 91,259,523 33,139,589 2.8 27,247,737 3.3 5.0 spice 308,194,784 \n180,543,666 1.7 172,595,830 1.8 10.6 doduc 130,897,009 45,651,338 2.9 35,920,460 3.6 11.2 nasa7 298,530,617 \n254,628,038 1.2 251,638,412 1.2 30.2 li (C) 1,208,747,235 413,622,801 2.9 289,473,770 4.2 4.1 eqntott \n(C) 465,938,460 114,410,157 4.1 112,562,938 4.1 2.3 matrix300 60,035,631 54,951,383 1.1 54,947,186 1.1 \n46.1 fpppp 25,932,871 6,186>762 4.2 4,098,093 6.3 100.8 tomcatv 35,012,274 27,762,776 1.3 21,254,823 \n1.6 56.3 Table 2. Reduction in counter increments due to orXimized counter ulacement. The column labeled \nSlow is the number of increments in basic blocks. The column labeled Quick is the nu~ber of increments \nalong edges chosen by the placement algorithm guided by the heuris\u00adtic weighting described above. The \ncolumn labeled Feedback records the number of increments using an exact weighting from a previous run \nwith identical input. The last column is the average dynamic basic block size. the reduction in counter \nincrements), they contributed little exact weighings was usually small. to the running time of the program. \nThe FORTRAN pro- The cost of modifying a program to place counters along gram doduc, while it has a dynamic \nblock size of 11 edges was a factor of two times higher than placing instructions, has an abundance of \nshort branches [3] that counters in each basic block, primarily because of the addi\u00ad accounts for its \nreduction in counter increments. The tional work required to compute a program s control-flow decrease \nin run time overhead for doduc was substantial at graph and to determine counter placement. 57%-13~o. \n For programs that frequently executed conditional 5.2. Tracing Performance branches, the improvements \nwere large. For the 4 C pro- The witness placement algorithm was also implemented grams (gee, espresso, \n/i, and eqnrort), the placement algo\u00adin the AE program tracing system [8]. AE originally rithm reduced \nthe number of increments by a factor of 3-4 recorded the outcome of each conditional branch and used \nand the overhead by a factor of 2-4. this record to regenerate a full control-flow trace. One Table \n2 also demonstrates that the heuristic weighting complication is that AE traces both the instruction \nand data algorithm is good. As can be seen from the Feedback references so a trace file contains information \nto column, the difference in cost between the heuristic and Program Old File New File Old/ (bytes) (bytes) \nNew compress 6,026,198 4,691,816 1.3 sgefa 1,717,923 1,550,131 1.1 polyd 19,509,062 16,033,055 1.2 11,314,225 \n10,875,475 1.0 PdP Table 3. Improvement in the AE program tracing system which recorded the outcome \nof every conditional branch. the total size of the recorded information, which includes formation. reconstruct \ndata addresses as well as the witnesses. The combined file requires the changes to the placement algo\u00adrithm \ndescribed in Section 4.2. Table 3 shows the reduction in total file size ( File ), witness trace size \n( Trace ), and execution time that result from switching from the original algorithm of recording each \nconditional ( Old ) to a witness placement ( New ). As with the profiling results, the programs with \nregulm control-flow, sgefa and pdp, do not gain much from the new tracing algorithm. For the programs \nwith more com\u00adplex control-flow, compress and polyd, the new algorithm reduces the number of witnesses \nby a factor of 3 and 2.7 times. 6. RELATED WORK This section describes related work on efficiently profiling \nand tracing programs. Edge-Frequency/Edge-Placement The solution to EFreq(G,epl) has been around for \nquite some time. In the area of network programming, the prob\u00adlem is known as the specialization of the \nsimplex method to the network program [6]. The spanning tree solution is also discussed in [7, 15], among \nother places. Samples considers a refinement of EFreq (G,epl) where the cost function models the fact \nthat a jump may have to be inserted into the profiled program when placing a counter on an edge [17]. \nSarkar describes how to choose profiling points using control dependence and has implemented a profiling \ntool for the PTRAN system [18]. His algorithm finds a minimum size epl that solves EFreq (G,ep/) based \non a variety of rules about control dependence, as opposed to the spanning tree approach. There are several \nother major differences between his work and the work reported here: (1) The algorithm only works for \na subclass of reducible CFGS; (2) The algorithm does not use a weighting to place counters at points \nof lower execution frequent y. As a Old Trace New Trace Old/ Old Run New Run (bytes) (bytes) New (sec.) \n(S12C.) 2,760,522 926,180 3.0 6.6 :5.4 1,298,882 1,131,091 1.2 4.1 4.5 5,523,958 2,047,951 2.7 19.0 \n 15.5 1,496,013 1,057,263 1.4 10.4 9.2 5 from placing witnesses along edges. Old refers to the originat \nNew refers to the improved version of AE, which uses witnesses. both witness and data references. Trace \nrefers to the total size of Old/ New 1.2  0.9 1!2 1.1 version of AE, File refers to the witness in\u00ad \n result, the algorithm may produce a suboptimal solution such as that in case (a) of Figure 3; (3) When \nthe bounds of a DO loop are constants, the algorithm will eliminate the loop iteration counter. Vertex-Frequency/Vertex-Placement \nKnuth and Stevenson exactly characterize when a set of vertices vpl solves V,Freq (G ,vpl) and. show \nhow to com\u00adpute a minimum size vpl that solves VFreq(G,vpO [71. They construct a graph G from CFG G such \nthat vpl solves VFreq(G,vpl) iff epl solves EFreq(G ,epl ), where vpl can be derived easily from epl \n. The authors note that their algorithm can be modified to compute a minimum cost vpl solution to VFreq \n(G,vpl) given a set of measured or guessed vertex frequencies. As this paper shows, if counter placement \nis restricted to vertices, a minimum cost solution to the vertex frequency problem cannot always be found. \nEdge-Frequency/Vertex-Placement Probert discusses the problem of solving EFreq(G,vp/), which is not always \npossible in general [15], Using graph grammars, he characterizes a set of well-delimited pro\u00adgrams for \nwhich EFreq(G,vpl) can always be solved. This class of graphs arises by introducing delimiter vertices \ninto well-structured programs. Probert is also concerned with finding a minimat number of vertex measurement \npoints as opposed to a minimal cost set of measurement points. The Tracing Problem Ramamoorthy, Kim, \nand Chen consider how to instrument a single-procedure program with a minimal number of monitors so that \nthe maversal of any lpath through the pro\u00ad gram may be ascertained after an execution [16]. This is equivalent \nto the tracing problem for single-procedure pro\u00ad grams discussed here. The authors do not give an algo\u00ad \nrithm for reconstructing an execution from a trace or con\u00ad sider how to trace multi-procedure prclgrams. \nThe authors are interested in finding a minimal size solu\u00adtion to Trace (G,epl), an NP-complete problem \n[91. However, a minimum size solution does not necessarily yield a minimum cost solution, as case (a) \nof Figure 3 illus\u00adtrates. 7. SUMMARY AND FUTURE WORK This paper introduced algorithms for efficiently \nprofiling and tracing programs. These algorithms optimize place\u00adment of instrumentation code with respect \nto a weighting of the control-flow graph. The placements for a large class of graphs are optimal, but \nthere exist programs for which the algorithms produce suboptimal results. Many interesting questions \nremain open. First, is there an efficient algorithm to optimally solve the vertex fre\u00adquency by instrumenting \nedges? Second, are there other classes of graphs for which an optimal solution to the edge frequency \nproblem also optimaly solves the vertex fre\u00adquency or tracing problem? Finally, can better weighting \napproximation algorithms be found? The profiling and tracing algorithms have been imple\u00admented in a tool \ncalled QP and the tracing algorithm is part of the AE tracing system [8]. Both tools run on several machines \nand are available from James Lams. ACKNOWLEDGEMENTS We would like to thank Susan Horwitz for her support \nof this work. Gary Schultz and Jonathan Yackel provided valuable advice on network programming. Samuel \nBates, Paul Adams, Phil Pfeiffer, and Peter Sweeney critiqued many descriptions of the work in progress. \nThanks to Guri Sohi and Tony Laundrie, who provided their code for a basic-block profiler that eventually \nbecame QP, and to Mark Hill, who provided the disk space and computing resources for the performance \nmeasurements, Thanks also to Vivek Sarkar for his comments and suggestions. REFERENCES 1. T. Ball and \nJ. R. Larus, Optimally Protiling and Tracing Programs, Technicat Report #1031, University of Wiscon\u00adsin, \nMadison (July 1991). 2. R. F. Cmelik, S. I. Kong, D. R. Ditzel, and E. J. Kelly, An Anatysis of MIPS \nand SPARC Instruction Set Utilization on the SPEC Benchnwks, ASPLOS-W Proceedings (SIGARCH Computer Architecture \nNews) 19(2) pp. 290-302 (April 1991).  3, Systems Performance Evaluation Cooperative, SPEC Newsletter \n(K. h4endoza, editor) 1(1)(1989). 4. J. A. Fisher, J. R. Ellis, J. C. Ruttenberg, and A. Nicolau, Parallel \nProcessing: A Smart Compiler and a Dumb Machine, Proc. of the ACM SIGPLAN 1984 Symposium on Compiler \nConstruction (SIGPLAN Notices) 19(6) pp. 37z17 (June 1984). 5. S. L. Graham, P. B. Kessler, and M. K. \nMcKusick, An Exe\u00adcution Profiler for Modular Programs, Software Practice and Experience 13 pp. 671-685 \n(1983). 6. J. L. Kennington and R. V. Helgason, Algorithms for Net\u00adwork Programming, Wiley -Interscience, \nJohn Wiley and Sons, New York (1980). 7. D. E, Knuth and F. R. Stevenson, Optimal Measurement Points \nfor Program Frequency Counts, BIT 13 pp. 313-322 (1973). 8. J. R. Larus, Abstract Execution: A Technique \nfor Efficiently Tracing Programs, Soflware Practice and Experience 20(12) pp. 1241-1258 (December, 1990). \n 9. S. Maheshwriri, Traversal marker placement problems are NP-complete, Report No. CU-CS-092-76, Dept. \nof Com\u00adputer Science, UniversiV of Colorado, Boulder, CO (1976). 10. S. McFarling, Procedure Merging \nwith Instruction Caches, Proceedings of the SIGPLAN 91 Conference on Program\u00adming Language Design and \nImplementation, (Toronto, June 26-28, 1991), ACM SIGPLANNotices 26(6) pp. 71-91 (June, 1991). 11. B. \nP. Miller and J. D. Choi, A Mechanism for Efficient Debugging of Parallel Programs, Proceedings of the \nACM SIGPLAN 1988 Conference on Programming Language Design and Implementation (SIGPLAN Notices) 23(7] \npp. 135-144 (June 1988). 12. W. G. Morris, CCG: A Prototype Coagulating Code Gen\u00aderator, Proceedings \nof the SIGPLAN 91 Conference on Pro\u00adgramming Language Design and Implementation, (Toronto, June 26-28, \n1991), ACM SIGPLAN Notices 26(6) pp. 45-58 (June, 1991). 13. K. Pettis and R. C. Hanson, Profile Guided \nCode Position\u00ading, Proceedings of the ACM SIGPLAN 90 Conference on Programming Language Design and Implementation \n(SIG-PLAN Notices) 25(6) pp. 16-27 ACM, (June, 1990). 14. S. Pottle, private communication. October \n1991. 15. R. L. Probert, Optimal Insertion of Software Probes in Well-Delimited Pro grams, IEEE Transactions \non Sojtware Engineering SE-8(1) pp. 34-42 (January, 1975). 16. C. V. Rarnamoorthy, K. H. Kim, and W. \nT. Chen, Optimal Placement of Software Monitors Aiding Systematic Testing, IEEE Transactions on Sofiare \nEngineering SE-l(4) pp. 403-410 (December, 1975). 17. A. D. Samples, Profile-Driven Compilation, Ph. \nD. Thesis (Report No. UCB/CSD 91/627), University of California at Berkeley (April 1991). 18. V. Sarkar, \nDetermining Average Program Execution Times and their Variance, Proceedings of the ACM SIGPLAN 89 Conference \non Programing Language Design and Imple\u00adrnetiation (SIGPLAN Notices) 24(7) pp. 298-312 ACM, (June 21-23, \n1989). 19. A. J. Smith, Cache Memories, ACM Computing Surveys 14(3) pp. 473-530 (1982).  20, MIPS \nComputer Systems, Inc., UMIPS-V Reference Manual (pixie and ptistats), MIPS Computer Systems, Sunnyvale, \nCA (1990). 21. R. E. Tarjan, Data Structures and Network Algorithms, Society for Industrial and Applied \nMathematics, Philadel\u00adphia, PA (1983).   \n\t\t\t", "proc_id": "143165", "abstract": "<p>This paper presents algorithms for inserting monitoring code to profile and trace programs. These algorithms greatly reduce the cost of measuring programs. Profiling counts the number of times each basic block in a program executes and has a variety of applications. Instruction traces are the basis for trace-driven simulation and analysis, and are also used in trace-driven debugging.</p><p>The profiling algorithm chooses a placement of counters that is optimized&#8212;and frequently optimal&#8212;with respect to the expected or measured execution frequency of each basic block and branch in the program. The tracing algorithm instruments a program to obtain a subsequence of the basic block trace&#8212;whose length is optimized with respect to the program's execution&#8212;from  which the entire trace can be efficiently regenerated.</p><p>Both algorithms have been implemented and produce a substantial improvement over previous approaches. The profiling algorithm reduces the number of counters by a factor of two and the number of counter increments by up to a factor of four. The tracing algorithm reduces the file size and overhead of an already highly optimized tracing system by 20-40%.</p>", "authors": [{"name": "Thomas Ball", "author_profile_id": "81100472343", "affiliation": "", "person_id": "PP39069287", "email_address": "", "orcid_id": ""}, {"name": "James R. Larus", "author_profile_id": "81100277326", "affiliation": "", "person_id": "P132790", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/143165.143180", "year": "1992", "article_id": "143180", "conference": "POPL", "title": "Optimally profiling and tracing programs", "url": "http://dl.acm.org/citation.cfm?id=143180"}