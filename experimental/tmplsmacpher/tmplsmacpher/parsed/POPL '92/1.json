{"article_publication_date": "02-01-1992", "fulltext": "\n The geometry of optimal lambda reduction Georges Gonthier* Martin Abadit Jean-Jacques L&#38;y* Abstract \nLamping discovered an optimal graph-reduction im\u00adplementation of the A-calculus, Simultaneously, Gi\u00adrard \ninvented the geometry of interaction, a mathe\u00admatical foundation for operational semantics, In this paper, \nwe connect and explain the geometry of in\u00adteraction and Lamping s graphs. The geometry of interaction \nprovides a suitable semantic basis for ex\u00adplaining and improving Lamping s system. On the other hand, \ngraphs similar to Lamping s provide a concrete representation of the geometry of interac\u00adtion, Together, \nthey offer a new understanding of computation, as well as ideas for efficient and correct implementations, \nAcknowledgements We have enjoyed discussions with Pierre-Louis Cu\u00ad rien, Jean-Yves Girard, Yves Lafont, \nand John Lamp\u00ad ing. Gordon Plotkin made useful suggestions on the presentation. Many phrases and attitudes \nin this pa\u00ad per are borrowed from Girard; no criticism is implied. Patter This paper develops for the \nthird time a semantics of computation free from the twin drawbacks of re\u00adductionism (which leads to static \nmodelisation) and subjeciivism (which leads to syntactical abuses, in other terms bureaucracy). Such \na semantics was de\u00adveloped previously by Jean-Yves Girard [Gir89, Gira] and by John Lamping [Lam90]. \nGirard is a logician * INRIA Rocquencourt. t Digital Equipment Corporation, Systems Research Center. \n Permission to copy without fee sfl or part of this material is granted provided that the copies are \nnot made or distributed for direct commercial advantage, the ACM copyright notice and the Litfe of the \npublication and its date appear, and notice is given that copying is by permission of the Association \nfor Computing Machinery. To copy other\u00adwise, or to republish, requires a fee and/or specific permission. \nand Lamping is an autodidactic engineer, It is no surprise that they never read one another-although \nthey were working on the same problem from different perspectives. Girard proposed the program of the \ngeometry of interaction. The geometry of interaction provides an abstract semantics for algorithms, based \non the judi\u00adcious use of C*-algebras. Girard s program has three parts. The first two parts are concerned \nwith defining a model and showing that it is suitably rich; the suc\u00adcess here has been clearly remarkable, \nThe third part is concerned with the possibility of implementing the geometry of interaction with an \nad hoc machine, and it has not yet been developed. In this paper we pursue the implementation part of \nGirard s program. We implement the geometry of in\u00adteraction with mere graph reduction; the graphs used \nare a variant of Lamping s, and they are interaction nets in the sense of Lafout [Laf90]. We feel that \nour incredibly concrete formalism sheds some light on the geometry of interaction. We undertake to explain \nthe geometry of interaction without using any relativity theory, any quantum theory, or for that matter, \nany mathematics. Lamping described a graph-reduction implemen\u00adtation of the A-calculus. The implementation \npro\u00advides a new, fine analysis of computation in the J\u00adcalculus, to the point of being optimal in the \nsense defined in [L&#38;80]. After trying to read Girard s pa\u00adpers on the geometry of interaction, Lamping \ns An Algorithm for Optimal Lambda Calculus Reduction sounds like TV Digest . Nevertheless, it seems fair \nto say that Lamping s algorithm is rather complicated and obscure. (Recently, Kathail proposed another \noptimal algorithm [I{at90]; we consider it in the full paper.) It is our thesis that the geometry of \ninteraction gives the proper understanding of Lamping s sys\u00adtem. This view leads to some considerable \nsimpli\u00adfications, to a semantic basis, and to principled tech\u00ad @ 1992 ACM 089791-453-8/9210001/0015 $1.50 \nniques for correctness proofs. It also helps us in generalizing from the ~-calculus to the proof nets \nof linear logic [Gir87]. (We have dealt only with multiplicative-exponential linear logic so far.) We \nbelieve that research on optimal reductions is of some practical importance. Lamping s work suggests \nsome useful techniques for partial sharing, which po\u00adtentially apply to a wide range of systems, from \ncom\u00adpilers to theorem provers. We hope that our study will further the impact of these techniques and \ncon\u00adtribute some more. The next section introduces some of the main themes of the paper, informally. \nSection 3 describes our graphs and the reduction rules that apply to them; section 4 then presents the \nimplementation of the A-calculus. The rest of the paper is devoted to discussing semantics and the correctness \nof these im\u00adplementations (section 5), optimality (section 6), and directions for future work (section \n7). For the sake of simplicity, we concentrate on the pure A-calculus, only hinting at the more general \ntreatment of linear logic. 2 Overview This section introduces some of the ideas of a graph representation \nfor A-terms and corresponding graph\u00adreduction rules. The system described is based on Lamping s, with \nseveral improvements. Then we dis\u00adcuss a semantics in the geometry of interaction and the delicate problem \nof correctness. 2.1 Combinators for sharing The sharing of common subexpressions is an impor\u00ad tant optimization \nin the implementation of a variety of formal systems, It is typically associated with vari\u00ad ous graph \nrepresentations and graph-reduction mech\u00ad anisms. In a graph, sharing is represented by a fan-in. Some \ntime ago, an optimality criterion for J\u00ad calculus reductions was defined. It was soon recog\u00ad nized that \nsharing of common subexpressions is not sufficient for optimality [Wad71, L&#38;80, Fie90]. Re\u00ad cently, \na generalization of sharing was introduced that does support optimal reductions. The idea is to al\u00ad low \nnot only fan-in but also fan-out. Fan-in nodes and fan-out nodes are drawn v1 I Fan-in nodes and fan-out \nnodes have symmetrical syntactic and semantic descriptions. As the graphs of interest to us are undirected, \nthey are identical, formally; they are all called fan nodes. Fan-out nodes allow partial sharing: terms \ncan share a common subterm with a hole which may be filled in different ways in different versions. For \nex\u00adample, the term (LfiV)(AIIV ) can be represented by the graph N N Here (Al -) is shared by the function \nand the argu\u00adment of the top application; the hole is filled with N for the function and with N for the \nargument. We write @ for application. (Application nodes appear in Lamping s graphs, but, as we shall \nsee shortly, not in ours.) The ~-term represented can be recovered by trav\u00adersing the graph. For this \nread-back to be correct, it is essential to take matching branches of fan-in and fan-out nodes during \nthe traversal. This is why two distinct marks, one grey and one black, label two of the ports of these \nnodes. The graph is traversed so that a path that goes through a grey mark at a fan\u00adin node also goes \nthrough a grey mark at the corre\u00adsponding fan-out node, and similarly for black marks. To make precise \nthis constraint on marks, Lamping introduced the notion of a context. A context records how fan-in nodes \nand fan-out nodes are traversed. In some simple cases a context can be represented by a stack; then going \nthrough a fan-in node pushes the mark traversed, and it is popped at the matching fan\u00adout node, to select \nthe port of exit. Fan nodes do not suffice in implementing partial sharing: one must guarantee that fan-in \nnodes and fan-out nodes are matched properly. For this purpose, Lamping introduced three bracketing constructs, \nof which we keep two (called bracket and croissant). It follows that contexts become more complex and \nstructured; fortunately, it will turn out that very sim\u00ad ple trees suffice for representing contexts \nin our sys\u00adtem. In addition, there are two kinds of unary nodes, root and void. Informally, a root node \nterminates every important dangling edge; for a A-term, these are the edges that correspond to free variables \nand the edge for the result (the value of the term). Although variable names are not a formal part of \nour graph representation, they sometimes appear in root nodes, for the sake of clar\u00adity. Void nodes are \nmere plugs. Thus, for example, the graph represents z, T Y d% x represents ZX, and represents zz in \na more contrived way. Finally, one might expect nodes that correspond to abstraction and to application, \nas in the exam\u00adples above. Certainly these nodes appear in Lamp\u00ading s graphs. Perhaps surprisingly, these \nnodes are not needed. Fan nodes can be used instead of ab\u00adstractions and applications. This is a simplification \nin the syntax of the graphs and in the corresponding reduction rules. It is also a significant simplification \nin their seman\u00adtics. All we have left are nodes that transform con\u00adtexts. Therefore, the semantics of \na graph can be given in terms of context transformations. This is directly in the spirit of the geometry \nof interaction. The geometry of interaction is concerned with oper\u00adations on C*-algebras; our contexts \nprovide a partic\u00adular, concrete C*-algebra. Some of the nodes we inherit from Lamping have indices, as \nin Lamping s system. Indices are natu\u00adral numbers; intuitively, an index says at what depth in the context \nthe node operates. In section 3.3 we describe an alternative to the use of indices; edges ( wires ) are \nreplaced with bundles of wires ( buses ), and then. indices become superfluous, as one can explicitly \ndraw on what wires in the bus an operation should act. The evaluation of ~-expressions is based on graph \nreduction. The notion of graph reduction at play is a particularly benign one. Each sort of node has \nan interaction port. When two nodes are adjacent and their interaction ports are on the same edge, then \na local transformation on the graph happens. For example, fan nodes interact through their unmarked ports; \nthe interaction rule for two fan nodes with the same index is the expected one: Lamping s rules were \noften of this form, and ours all are. This means that our graphs are interaction nets. 2.2 The geometry \nof interaction There is no hope of explaining what is a C*-algebra within this restricted space. There \nis no need for such an explanation either. From our perspective, the essence of the geometry of interaction \nis representing computing devices as context transformers. This represent ation appears in Lamping s \nwork, of course, and we develop it further. The use of C*-algebras comes from a justifiable de\u00adsire to \nprovide the most abstract possible formulation of the geometry of interaction. But we have no im\u00admediate \nneed for C*-algebras, and hence omit dealing with these new b~tes noires of semantics. 2.3 On correctness \nComputer science is a young discipline, but it already shows signs of senility. There is an obsession \nwith cor\u00adrectness which often prevents the practitioners from understanding the finitary dynamics of \ncomputation. in this paper, we yield to this obsession. Wur imple\u00adment ations are all correct. Several \nnotions of correctness are possible. The simplest one is baaed on contexts. Graph reduction is sound \nin that it preserves the context semantics of graphs. It remains to see that the context semantics corresponds \nto the usual notions of the ~-calculus, and in particular that read-back yields appropriate A-terms. \nMore precisely, one would like a read-back proce\u00addure R (a partial function) that maps graphs to J\u00adterms \nwith two properties: e if a graph G reduces to a graph G then R(G) reduces to R(G ); if a graph G! is \nin normal form then R(G ) is in normal form as well. The geometry of interaction provides an easy proof \nthat the graph reductions are correct in the case in which G is an observable, for example if it rep\u00adresents \na boolean. Girard has obtained a result of this sort, and his proof applies in our setting. He has argued \nthat this theorem should be considered sat\u00adisfactory, explaining the reason that it might be the best \npossible: In fact from a purely syntactical viewpoint, the execution makes mistakes , but it is precisely \nbecause of these mistakes that we can free ourselves from the need of a uni\u00ad versal time! Thus, it would \nalmost seem that one cannot expect correct, parallel, higher-order computations. Unfortunately, correctness \nfor observable does not suffice. First, it is very dissatisfying. It is also in\u00adsufficient for optimality \narguments, as these require consideration of intermediate results, and not just of certain normal forms. \nThe solution is found by pursuing Girard s ideol\u00adogy of communication without understanding. Com\u00admunication \nwithout understanding is communication where certain parts of messages are treated only in a generic \nWay, and any iisomorphic~> transmission would do just as well, without confusion. Typing guarantees the \npossibility of communication without understanding. Roughly, the type of a port induces a class of isomorphisms \nthat can be applied to contexts communicated on this port without confusion. Communication without understanding \nalso im\u00adplies that generic parts of messages cannot be created spontaneously. They must be copies of \nparts of previ\u00adously received messages. Given a graph, a context is called accessible if either it contains \nno generic parts or it can be obtained from an accessible context by applying the context transformation \nthat the graph defines and (cut-and-paste of generic parts. The graphs that one obtains by encoding the \nk calculus, or for that matter linear logic, admit a typ\u00ading, (For the pure A-calculus, the typing requires \nre\u00adcursive types, but this hardly matters.) The type system for these formalisms then determines accessi\u00adble \ndomains and a suitable class of isomorphisms; ~\u00adreduction (or cut-elimination) is sound with respect \nto the accessible part of the semantics, up to these isomorphisms.  3 The Ad Hoc Machine In this section \nwe define two graph-reduction for\u00admalisms. The first one is a simplification of Lamp\u00ading s, and relies \non indices. The second one seems more primitive; the use of buses frees us from certain unnecessary, \nbureaucrating reductions. 3.1 Nodes We start by considering undirected graphs built ~ la Lamping. We \nneed only some of his nodes. The nodes are those presented in the introduction: root void croissant bracket \nfan  3.2 Reduction The rules for reduction are particularly simple, since we want not to be ridiculous. \n(To our knowledge, Girard was the first to write on the desire not to be ridiculous [Girb]; we continue \nhis work in this respect too.) In the rules, given in Figure 1, it is assumed that O<i <j. Because of \nthe form of these rules, we are dealing with interaction nets. An immediate consequence is that the system \nis Church-Rosser, as there are no critical pairs. Interaction nets have trivial parallel implementations. \nSome pairs of operators do not have a rule for inter\u00adacting, for example brackets and fans with the same \nindex. When these operators meet face to face, we have a deadlock. The context semantics of operators \nwill make clear that a deadlock arises exactly when i i j i b b + i j-1 + &#38; ~piA 1 I Figure \n1: Reduction incompatible constraints are put on the context in a wire. Garbage-collection rules are \nnatural, and seem ap\u00adpealing for the sake of efficiency. Their function is to eliminate useless parts \nof graphs. For example, we may add: Lamping haa included a number of similar rules in his system. The \nrules are not essential for correctness or for optimality. They are not complete, in that they do not \ncollect all garbage, In particular, they fail to collect certain kinds of cyclic garbage. For this reason \nwe prefer not to include garbage-collection rules in our basic system. In order to achieve optimality, \na strategy needs to be followed. Simple strategies (e.g., leftmost\u00adoutermost) will do. We come back to \nthis point below. 3.3 Decomposing the operators There are some hints that the operators presented above \nare not as primitive as possible, Consider, for example, a row of brackets and croissants. Bringing this \nrow to normal form may take quadratic time, because of uninteresting commutations. It is this sort of \nbureaucratic overhead that we should try to avoid. In this subsection we describe a more explicit graph \nformalism. This system decomposes the operators into more primitive ones, eliminating the need for in\u00addices. \nThe main idea is that we are going to view a wire in the old system as a bus, a bundle of wires Ai 1~ \ni 7 i I%j+l   ---+1 t 1 ~i I j+l Y vi j-l ii A II rules with indices running in parallel; indices \nare not necessary, because operators can act on only a part of the bus. The translation is given below. \n(The translation is presented only informally; a precise definition would require, in particular, the \nnotions of left and right in buses, which are introduced easily for roots and then extended by contiguity.) \nRoot nodes and void nodes are as usual, but their arity increases. (Alternatively, we could simply have \nunary nodes and a metalinguistics way to group them. ) Brackets become ternary nodes. Their role is to \ncombine two wires: old bracket new bracket Using hardware notation, this new bracket can be represented \nas: w}j i Croissants become unary nodes. Their role is to crest a wire ex-nihilo: old croissant new \ncroissant Figure 2: Reduction The most complicated change is for fan nodes. For a bus of width n (n \n= z + j + 1), we are going to use a fan node of arity 3n. old fan new fan As in this picture, one of \nthe levels is marked. This is the level at the depth given by the index. We call this the main level \nof the node. It is at the main level that a context mark is added. The other levels do not modify contexts. \nWe have considered going further, decomposing fan nodes into slices, one for each level. Each slice of \na fan node would propagate on its own, but still depend on information that should come from the slice \nfor the main level. This is a promising direction; we postpone further discussion to the full paper. \n3.4 More on reduction With these more primitive operators, the rules of interaction become clearer. They \nappear in Figure 2, where we draw only special cases, from which the general cases can be deduced by \nvarying the width of buses. With the old rules, a bracket and a croissant with different indices could \nmeet and interact. With the new rules, this is no longer the case, as they simply cross on different \nwires on a bus. The commutation is free. 1 rules with buses We tend to use the two systems of nodes inter\u00adchangeably. \nIt is generally more enlightening to use the system with buses. We use the other system only for compactness \nof notation and in order to relate our work to Lamping s and Girard s. 4 Implementations The graphs \ndescribed above can be used to en\u00adcode a variety of computing formalisms. Here we just demonstrate this \nfor the pure J-calculus. We postpone correctness and optimality considerations to later sections, and \nonly hint at the systematic treatment of linear logic, 4.1 Implementing tile ~-calculus The translation \nof the A-calculus into graphs has two stages. In the first stage, we define incomplete graphs, where \nnot all edges are terminated by nodes. Edges are directed, and those that correspond to vari\u00ad ables labelled \nwith variable names. (We will not draw directions explicitly, but will put result edges up\u00ad wards and \nfree-variable edges downwards. ) The sec\u00ad ond stage simply closes the graph, adding root nodes as appropriate. \nAlso, the direction of edges and the variable names on the edges are removed; variable names are put \non roots. The first stage of translation is defined inductively. A variable is represented with a bus \nof width 3: Ill  Intuitively, this bus carries commands between the occurrence and the value of the \nvariable. In the A calculus, these commands can be construed as call a function, return to a cent inuat \nion , access an argument , and report an argument value. Com\u00admands can contain subcommands, allowing \nfor arbi\u00adtrary complex meanings. Each command pertains to a function call, Because of sharing, commands \ngenerated at a single location in the graph can refer to several actual calls, so each must carry an \naddress identifying the relevant call, This address splits into a base address, shared by all commands \nin an inst ante of a lexical scope, and an offset. Subcommands need only an offset relative to their \nbase commands. Thus, commands are composed of three parts, which are carried by the three wires of the \nbus drawn above. The left wire carries the base address, the middle one the offset, and the right one \nthe actual command, piled on top of its subcommands and their offsets. If G and H represent Al and IV, \nrespectively, then represents GH. Here we have drawn only the case where Al and IV have the variable \nz in common; fan\u00adins are used to combine all references to common vari\u00adables. Intuitively, a command \ncoming from the top is nested as a subcommand of a call command and sent to G: the top fan piles a grey \nmark (the call to\u00adken) on the pair (offset, command) created by the top bracket. The croissant generates \na null offset for the call. When the argument H reports back a command to G, the fan packs it under a \nreport command (black mark). Dually, the fan directs to H a sub\u00adcommand packed under an access command \n(black mark) from G, and directs to the top edge a sub\u00adcommand packed under a (return command (grey mark). \nFinally, commands di~ected to the common variable x are sent out on the same edge, but are given represents \nAx .M. VVe ave drawn only the case where Ax.M has one free variable y; brackets are added to all edges \nfor free variables. different offsets by the fan so that responses from z can be sorted out. If G represents \nikf and x occurs in M then The command handling for the abstraction fan is exactly dual to that for \nthe application fan; only the address management differs. A lexical scope is opened for the kc by pushing \nthe call offset onto the base address for the entire body G. This ensures that all commands in G will \nbe relative to the call instance. Dually, commands generated by the fan simply pop the call offset off \nthe base address when they cross the top bracket in the reverse direction. Upon leav\u00ading the scope through \na free variable y, the base ad\u00address is also restored and the popped offset is added to the command offset \nso no information is lost and responses from y reach their intended recipient. If G represents M and \nx does not occur in M then f- G J Y represents Ax. M. Since the argument is never accessed, the black \nbranch of the fan is effectively dead, and we can sim\u00adply terminate it by a plug. Note that there is \nno attempt to recognize com\u00admon subexpressions in the A-term given for reduction. Note also that this \nrepresentation uses fan-in nodes, but not fan-out nodes. Sharing appears in the course of reduction. \n 4.2 Implementing linear-logic proofs The proof nets of linear logic can also be translated into our \ngraphs, at least for the fragment of linear logic with multiplicative and exponential connective. No \nnew nodes are needed. The main contribution of this translation is the elimination of the fastidious \nboxes of linear logic. We break these boxes in our implementation, allowing their partial sharing. Fan \nnodes represent the multiplicative connective and contractions; croissants represent derelictions; void \nnodes represent weakening; the edge of boxes is indicated by brackets, which can propagate indepen\u00addently. \nOur implementation of the A-calculus puts a box around each abstraction: this box is implemented by the \nbrackets above fan nodes and on free variable edges. 4.3 Types As discussed earlier, types can be attached \nto the ports of the graphs obtained by translation from the A-calculus or linear-logic proof nets. For \nthe pure A\u00adcalculus, this is simple, as it consists in distinguishing free variables from results. This \nis not to say that types can be attached to all edges in the course of reduction. In this sense, the \nvarious logics that serve as type systems for the ~-calculus and for proof nets are not suitable iogics \nfor our graphs. The problem of finding such a logic remains open.  5 Semantics In this section we discuss \nthe semantics of our graphs. First, we describe the graphs as context transformers. This semantics is \nof help in under\u00adstanding the rules of reduction, but it does not suf\u00adfice in proving the soundness of \nour implementation of the A-calculus, for example. A more sophisticated semantics appears later. 5.1 \nRudimentary correctness The first semantics is based cm contexts. Contexts are trees, defined by: * \nCl is a context, It represents a node with no descendants. If a is a context then so are o.a and A.a. \nThese terms represent the trees obtained by taking a node and putting a under it, either to the left \nor to the right. (The notations o and A come from Lamping s work, where they are used instead of our \ngrey and black marks, respectively, ) If a and b are contexts then so is (a, b). This term represents \nthe cons of a and b. We denote a .b the context a where the rightmost Cl is replaced by the context b. \nThis is consistent with the o.a and *.a notations above if we let o denote the tree with only one left \nnode (o = o. D), and similarly for *. The concatenation operator . is clearly associative and D is its \nneutral element. Finally we abbreviate (a, D) by (a), so we have (a).b = (a, b). Let A be the set of \ncontexts. The semantics of the nodes is given by relations on A. All variables repre\u00adsent contexts. Nothing \n(the absence of a context) is denoted by a blank space. (io.b Z ii *.b Z ab (a, b) c1 The semantics is \nextended to graphs, by composi\u00adtion. When the individual wires of a bus section of width k are labeled \nal, . . . . ak we say that the bus section is labeled with the context (al) . . . (ak_l) .a~. Assuming \nthat the roots of a graph are numbered, from 1 to n, the context semantics C(G) of a graph G is a relation \nRi,j between contexts for each pair of conclusions (i, j). The relation Ri,j relates d to d if there \nis a path from conclusion i to conclusion j with a consistent labelling and with d labelling the bus \nat conclusion z and d the bus at conclusion j. It is simple to prove that the reduction rules of sec\u00adtion \n3.4 preserve the context semantics. Good start ! (This property fails for the system that uses indices \ninstead of buses, for rather trivial reasons, not worth discussing here.) Theorem 1 If G -b G then C(G) \n= C(G ). r It One may remark that contexts of left, middle, and right wires are of rather different \nkinds, as already mentioned in section 4.1. The left wire is a stack of offsets, the middle wire is an \noffset, the right wire is a list of pairs (offset, command). Specifically, the left wire always contains \na context (... ((CJI, ~2), C13~n). ~n) and the right wire a list @l. (u2,82). (u3, @3).. .(~n-I, @n \nl).Ck where ai are offsets (arbitrary contexts), Bi are com\u00admands o or k, and n > 0. When n = O, the \ncontext is D . The middle wire contains always an a, the offset corresponding to @l. 5.2 The read[-back \nproblem Intuitively, we would expect to read back a A-term by removing all sharing from the graph that \nrepresents it. In fact, this is how Lamping proves the correctness of his system. The proof is laborious, \nand somewhat ad hoc. A proof based on the context semantics seems more appealing. Unfortunately, the \ncontext semantics does not match the usual semantics exactly. For example, the J-term (Az.yx)z is translated \ninto and then this graph reduces to 23 When we try to recover a A-term from this graph, we notice that \nsome spurious brackets are in the way, right above the fan node that represents the applica\u00adtion. The \ncontext semantics does not justify removing them 5.3 Isomorph.isrns and accessibility, . or communication \nwithout under\u00adstanding We would like to have a principled way to understand and to remedy the errors \nof graph reduction. This would lead to a correct interpretation of graphs, and connect the context semantics \nwith the J-calculus. As discussed in the introduction, we propose to take a semantics coarser than the \ncontext semantics, by taking types into account. From the type of a root we can infer properties of the \ncontext seman\u00adtics at that root, and especially of its effect on the right wire. In the case of our translation \nfor the A\u00adcalculus we have only two (recursive) types, result ~ =!(D ~ D) and variable ~~, from which \nwe can infer the alternating structure of the right wire: each multiplicative corresponds to a fan mark \n(A or o), and each modality to a pair with an offset ((a)). Moreover the offset for a ! modality can \nbe chosen arbitrarily without changing the path. More formally, sa,y a context is even when it has an \neven number of ~ branches on its right spine, and odd otherwise (so Cl is even, (a) .C and o.c are even \nwhen c is, and *.c is even when c is odd). Say a context is input at the top root when it is even, and \noutput when it is odd; dually, a context is input at a variable root when it is odd, and output when \nit is even. Finally, say that an offset a is input in the context c.(a) ,d at root X when c is input \nat X, and dually for outputs. Then it can be shown that: Proposition 1 A consistent path u between two \nroots X1 and X2 of the translation of a A-term does not depend on input offsets; specifically, if there \nis a consistent labelling of u with the bus at Xi la belled (ai).ci, then given any assignment of values \nfor the input offsets in ci there is a corresponding assignment of the output oflsets that yields a consistent \nlabelling for u. This is also true when Xl = Xz if the assign\u00ad ment gives identical values to input oflsets \na) that oc\u00adcur after the same prefix p input at Xi (ci = p.(af). cj fori=l,2). An easy induction also \nshows that the left wire must be invariant (al = az). The environment should handle output offsets just \nas a term treats input offsets, that is, opaquely, as tokens. In particular, it should not be able to \ngener\u00adate those offsets spontaneously to prod the internal structure of the graph. So not all contexts \nshould be used at the start of a path. Specifically, noting that every consistent labelling of a root-to-root \npath has an input context at one end and an output con\u00adtext at the other, no prefix of an input context \nat a root should contain an output offset unless it is also a prefix of an output context at that root. \nThis can be formalized as follows: define E = {O}U (A) .E U o.E, the set of star-free contexts. Now for \ne, e c E, define the operation of shunting e to e by c.o. eQ+c. *.e e Then an access path T in a A-term \ngraph G is a di\u00adrected bus path labeled with contexts, starting at the top root with a star-free label, \nsuch that any two suc\u00adcessive bus edges tland t2 of T are either consistent with the context semantics \nor are linked by a shunt loop: they respectively lead to and from a root of G, are labeled c1, C2 with \nc1 ~ C2 for some star-free contexts e, e . Thus, an access path can be pictured as E3d02d+d#+ d;+ ...~dk \n(1) 12 where the Gi are (simple) paths in G from root Xi to root X;+l that can be consistently labelled \nwith di at Xi and d: at X~+l, with the obvious provisos for d; if Un does not end at a conclusion. Note \nthat all the d~ are input contexts, and all the d; are output contexts. Note also that any edge in an \naccess path in the initial translation is traversed upwards iff the context on the rightmost wire is \nodd. This means that the edge direction which was forgot\u00ad ten in the last translation step can be recovered \nfrom the context semantics. Since the context semantics is preserved by graph reduction, the orientation \ncan also be recovered in all residuals. Now say a path is accessible iff it is the suffix of an access \npath. Special cases are: a labelled edge or a node is accessible iff it is part of an access path, a \ncontext c is accessible at a conclusion X iff a bus edge leading to or from X labelled c is accessible. \nThe accessible semantics C.(M) of a term M is the subset of C (GM) generated by the accessible paths, \nwhere GM is the graph represent ation of M. Furthermore, we show: Proposition 2 C. is compositional: \nan access path in the graph GAZM representing ~x. M only traverses its subgraph Gjw representing M through \naccessible paths, and similarly for GMN and GM, GN. This is proved by structural induction, in conjunc\u00adtion \nwith another important property of access paths: Proposition 3 (access-path shunting) Given an ac\u00adcess \npath as in (l), ending at a conclusion X~+l, either d; E E or there is a unique i such that Xi = Xn+l \nand di ~ d; for some e,e EE. Now if X.+l is the top root, then d~ must be odd so the access path must \nend with a shunt. Since shunt\u00ading cannot change the address on the left wire or the offset on the middle \nwire, this immediately shows that an access path cannot traverse an edge upwards un\u00adless it haa already \ntraversed it downwards with the same context on the left and middle wires. This is important for garbage \ncollection and the read-back procedure. Proposition 3 actually gives an algorithm for read\u00ading out the \nBohm tree of the A-term represented by a graph. For e c E, let le] denote the number of o s on the right \nspine of e. By Proposition 1 an access path does not depend on the choice of the offsets in do or any \nof the ej, so the only real choice initially is Id. 1. Let no be the minimal value of Id. I such that \nthere is an access path starting with do and leading to a root Xl. If there is no such do then the term \ndi\u00adverges, and the Bohm tree is Q. Otherwise nO is the number of ~ s in the head normal form of the term. \nNow by Proposition 3, either Xl is the root for some variable x and d; E E, or do $ for some e,e ~ E. \nIn the first case x is the head variable, above which rn~ = ld~ I applications are nested. In the second \ncase, the head variable is a bound variable with de Bruijn index n: = Iel, above which rn~ = Ie 1 applications \nare nested. To continue reading out the arguments for the applications, simply choose Iel I = ml to select \nthe ar. gument of the (ml + l)st application (counted from the outside in). In the general case, the \nde Bruijn index of a bound head variable is nj + ~~=i+l nj. Now this algorithm does not depend on the \nvalue of input offsets, and only depends on output offsets through its use of Proposition 3. Thus it \nis insensitive to a remapping of offsets that leaves the shunt suffixes invariant, so we will read back \nthe same tree for two terms whose accessible context semantics differ only by such an isomorphism. Now \nit is easy to see that contracting the head redex of a term leaves its seman\u00adtics invariant up to such \nan isomorphism, and that the read-back of a redex-free tree indeed yields back the tree. Conversely, \nif the procedure computes the same tree for two terms, simply matching the steps defines the offset mapping. \nTheorem 2 The geometry of interaction semantics, restm cted to accessible contexts and quotiented by \niso \u00admorphismsl is equivalent to the Bohm tree semantics. It is tempting to consider a much simpler definition \nof isomorphism: a context mapping that preserves the right spine and commutes with the accessible seman\u00adtics. \nWith our translation it fails to yield the Bohm tree because the quotient semantics still conveys scop\u00ading \nand sharing information for the applications in the tree. Interestingly, the standard translation of \nthe A\u00adcalculus in linear logic, based on D = (!D) -o D, does not have this problem because it enforces \nless sharing. We are now ready to consider directly the read\u00adback problem. It is quite easy to read back \na ~-term from its translation: we know that fans on the right\u00admost wires correspond to nodes in the syntax \ntree (application, abstraction, variable), and that edges in the graph are oriented aa in the syntax \ntree, so we get the skeleton of the expression simply by travers\u00ading the graph downwards; furthermore \nwhen we do so we must have the same context on the left wire when we enter an abstraction and when we \nreach its bound variable, and nested A s must have left contexts with different left spine length, so \nthis property is enough to identify binders. Now we have shown that edge orientation is de\u00adfined solely \nfrom the context semantics. We show that we can use the same procedure to read back a A\u00adterm from any \nresidual of the initial graph, Now from Proposition 1 the consistency of a downward leftmost path in \nthe graph does not depend on the contents of the rightmost wire, except perhaps for the number of O S. \nHence we have a very simple read-back pro\u00adcedure R: simply follow all downward paths that are consistent \non all but the rightmost wire, and produce syntax nodes for each rightmost fan encountered, ac\u00adcording \nto the orientation. A variable is bound by the A with the same left context. Theorem 3 For any A-term \nM, R(G~) = M. Moreover, if GM +, G, then G +* G implies R(G) ++ R(G ), and G in normalform implies R(G) \nin normal form. Proof sketch: Obviously reductions other than right\u00admost fan elimination don t change \nthe read-back. For /3 redexes, note that the two downward paths to the variable and from the top of the \napplication will be consistent iff they are part of the same access path in the application subterm, \nthat is, iff they have the same left context, that is, iff the variable was bound by the redex A.  6 \nOn Opti]mality Girard wrote that the third part of his geometry of interaction program should be concerned \nwith the study of efficiency, as long as this remains a math\u00adematical problem. The following discussion \nof opti\u00admality follows his suggestion; clearly much more can be done in this area. 6.1 Read-back and \nlabelling Because we have been able to solve the read-back problem, we are now in a position to consider \nopti\u00admality issues. It is straightforward to establish corre\u00adspondences between a A-term with a labelling \n[L&#38;80] and a suitably labelled graph that represents it. (The graph haa labels on the rightmost wires.) \nWe can then argue about how labels evolve through reduction. The reduction rules are easily extended \nso that la\u00adbels commute with all nodes except rightmost fans, and labels are concatenated when edges \nare, the di\u00adrection of concatenation matching the edge direction. A label caught between two facing rightmost \nfans is copied (with overlining and underlining to match the A-term labelling) when the redex is contracted; \nit is called the redex label. Theorem 4 Durin!~ reduction, no two redexes of rightmost fans have the \nsame label. Therefore, graph reductions are optimal. This means that the rules will never duplicate work, \nbut leaves open the possibility of work on subterms that will turn out to be useless. Adopting a normal\u00adorder \nstrategy suffices to avoid this possibility. Proof sketch: Define the flat labelling of a path to be \nthe concatenation of all labels traversed by the path with the following provisos: the order of sym\u00adbols \nin a composite label on an edge that is traversed backwards is reversed, and overlining and underlin\u00ading \nare removed, reversing the order of symbols un\u00adder each removed underline. It is easy to see that any \nconsistent path between rightmost fans has the same flattened label.ling as any of its ancestors in a \ngraph reduction. Now suppose that during a graph References reduction we have two redexes of rightmost \nfans with the same redex label. Consider the two paths consist\u00ading of the forward edge reduced in each \nredex. They have identical flat labelling, so they must have an\u00adcestors in the translation of the initial \nY.term with that same flat labelling; but in this graph all paths between rightmost fans bear a different \nlabel, so the two ancestor paths must be equal, Now a path be\u00adtween facing fans has a unique residual \nuntil either end fan is deleted, so the two redex paths must be equal, hence the redexes must be equal. \n 6.2 Garbage-collection issues The optimality criteria considered do not say any\u00adthing about garbage \ncollection, which we have delib\u00aderately neglected. In fact, garbage collection with lo\u00adcal rules (as \nin Lamping s paper) destroys optimality, because it cannot collect the cyclic graphs the algo\u00adrithm creates \nwithout first executing these graphs to unravel their structure. However, Proposition 3 allows us to \nreclaim all nodes that are unreachable from the top root in the oriented graph, much as in Kathail s \nalgorithm, This standard collection procedure is complete, in the sense that in a graph with no accessible \nredexes, nodes are reachable from the top root in the oriented graph exactly when there is an access \npath to them. Thus, special garbage-collection rules are not neces\u00adsary. Finer schemes could work by \nrunning the read-back algorithm intelligently so that a common subterm is not traced twice, and then \ncollecting all untraced nodes. Obviously, determining the exact extent of garbage (nodes with no accessible \npath to them) re\u00adquires execution, and is thus undecidable.  7 Extensions This work leaves open a number \nof interesting ques\u00adtions. Foremost is the extension of this formalism to the whole of linear logic, \nincluding additives and quantifiers, and from there to classical logic [Gir91]. We should establish a \nclear relationship between the coherence semantics of linear logic [Gir87] and the geometry of interaction. \nThis should give us some guidance for the remain\u00ading two problems: finding a type system that ab\u00adstracts \nthe behavior on the left wire well enough to extend to arbitrary graphs (with sharing types), and decomposing \nfan nodes so that the synchroniza\u00adtion they impose on the bus wires is relaxed. [Fie90] John Field. On \nlaziness and optimality in lambda interpreters: Tools for specifica\u00adtion and analysis. In Seventeenth \nAnnual ACM Symposium on Principles of Program\u00adming Languages, pages 1 15. ACM, January 1990. [Gira] Jean-Yves \nGirard, II: Deadlock-free Geometry algorithms. of interaction [Girb] Jean-Yves lelism. Girard. Linear \nlogic and paral\u00ad [Gir87] Jean-Yves Computer Girard. Science, Linear logic. Theoretical 50:1-102, 1987. \n[Gir89] Jean-Yves Girard. Geometry of interaction I: Interpretation of system F. In Ferro, Bonotto, Valentini, \nand Zanardo, editors, Logic Colloquium 88, pages 221-260, El\u00adsevier Science Publishers B .V, (North Hol\u00adland), \n1989. [Gir91] Jean-Yves Girard. A new Classical logic. Technical INRIA Report 1443. constructive report, \nJune logic: 1991. [Kat90] Vinod Kathail. Optimal interpreters for lambda-calculus based functional languages. \nPhD thesis, MIT, May 1990. [Laf90] Yves Lafont. Interaction nets. teenth Annual ACM Symposium ples of \nProgramming Languages, 108. ACM, January 1990. In Seven\u00adon Princi\u00adpages 95 [Lam90] John Lamping, An algorithm \nmal lambda calculus reduction. teenth Annual ACM Symposium ples of Programming Languages, 30, ACM, January \n1990, for opti-In Seven\u00adon Princi\u00adpages 16 [L&#38;80] Jean-Jacques L&#38;vy. Optimal reductions in the \nlambda-calculus. In J.P. Seldin and J.R. Hindley, editors, To H. B. Curry: Essays in Combinatory Logic, \nLambda Calculus and Formalism, pages 159 191. Academic Press, 1980. [Wad71] Christopher pragmatic sis, \nOxford, P. Wadsworth. of the lambda 1971. Semantics calculus. PhD and the\u00ad  \n\t\t\t", "proc_id": "143165", "abstract": "<p>Lamping discovered an optimal graph-reduction implementation of the &#955;-calculus. Simultaneously, Girard invented the geometry of interaction, a mathematical foundation for operational semantics. In this paper, we connect and explain the geometry of interaction and Lamping's graphs. The geometry of interaction provides a suitable semantic basis for explaining and improving Lamping's system. On the other hand, graphs similar to Lamping's provide a concrete representation of the geometry of interaction. Together, they offer a new understanding of computation, as well as ideas for efficient and correct implementations.</p>", "authors": [{"name": "Georges Gonthier", "author_profile_id": "81100568047", "affiliation": "", "person_id": "P96170", "email_address": "", "orcid_id": ""}, {"name": "Mart&#237;n Abadi", "author_profile_id": "81100547147", "affiliation": "", "person_id": "PP39047996", "email_address": "", "orcid_id": ""}, {"name": "Jean-Jacques L&#233;vy", "author_profile_id": "81100154846", "affiliation": "", "person_id": "PP31084429", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/143165.143172", "year": "1992", "article_id": "143172", "conference": "POPL", "title": "The geometry of optimal lambda reduction", "url": "http://dl.acm.org/citation.cfm?id=143172"}