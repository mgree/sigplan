{"article_publication_date": "02-01-1992", "fulltext": "\n Pattern-based tree attribution Charles Farnum* Department of Computer Science Wright State University \nDayton, OH 45435 cfarnum(lvalhalla .cs.wright .edu Abstract Attribute grammars have been used for many \nlanguage-oriented tasks, including the formal descrip\u00adtion of semantics and the implementation of compi\u00adlation \ntasks from simple type checking through code generation. Despite their successful use, attribute grammars \nhave some disadvantages, including the monolithic nature of the grammar and the fixed fac\u00adtoring of all \nattribute descriptions by a single set of grammar productions. Attribute pattern sets provide a more \nexpressive attribution system by using pattern matching, instead of grammar productions, to perform case \nanalysis. Attribute pattern sets can be imple\u00admented in terms of attribute grammars in a way that maintains \nthe dependency structure of the attribute system, making it straightforward to convert many of the practical \nresults from attribute grammar theory to similar results for attribute pattern sets. Introduction In \nmany applications dealing with trees, it is necessary to specify some family of functions taking tree \nnodes as arguments, and to evaluate these functions at one or many of the nodes in a given tree. In the \nrealm of program translation, where trees represent partially translated programs, typical instances \ninclude: the specification of scope rules, which compute an environment mapping identifiers to entities \nat each node in the tree,  *Portions of this research were performed at U.C. Berke\u00adley, funded by the \nDefense Advanced Research Projects Agency (DoD), monitored by Space and Naval Warfare Systems Com\u00admand \nunder Contract No. NOO039-88-C-0292. Permission to copy without fee all or part of this material is granted \nprovided that the copies are not made or distributed for direct commercial advantage, the ACM copyright \nnotice sad the title of the publication and its date appear, and notice is given that copying is by permission \nof the Association for Computing Machinery, To copy other\u00adwise, or to republish, requires a fee and/or \nspecific permission. O 1992 ACM 089791453-8/92/0001/021 1 $1.50 211 the specification of a type system, \nand the com\u00ad putation of the type of each expression node, and the specification of a (code function, \nrepresent\u00ading the machine code needed to implement some subtree, and the computation of this value at \nthe root. We can formalize the common aspects of these prob\u00adlems as follows: Let Y be a family of partial \nfunctions {~a : iV~ + Va]a c A} where T is a set of labeled or\u00addered trees, NT is the set of nodes of \nT, and A is a set of attribute names. Tree attribution problems require a suitable method of specifying \nF that is both easy to write and useful for generating efficient programs to compute the values .fa(n). \nIn 1968, Knuth introduced attribute grammars as a practical specification method for many families of \nfunctions F when the trees of interest are derivation trees for some grammar G [1]. An attribute grammar \nextends G with a set of semantic rules that describe how the value off. at a given node can be computed \nin terms of the values of fuuctions in Y at nearby nodes. When applied to a particular derivation tree, \nthe at\u00adtribute grammar specifies a set of equations that define the values of all of the fa. Since Knuth \ns introduction, extensive work has been done in efficiently solving the tree attribution problem using \nattribute grammars as the specification method. There are several practical classes of attribute grammars \nthat can be compiled into efficient tree attributers. Deransart, Jourdan, and Lorho provide a survey \nof attribute grammar work [2]. Although Knuth introduced attribute grammars as a specification technique \nfor language semantics, they have proven useful for many applications within pro\u00adgram compilation, including \ncode generation, analy\u00adsis for optimization purposes, and even tree trans\u00adformation. Unfortunately, attribute \ngrammars have some weaknesses as a specification method. By far the largest problem is that an attribute \ngrammar is monolithic; all semantic rules are intertwined with a single grammar, resulting in a specification \nthat is dif\u00adficult to read and to modify. In this paper we propose a new specification tech\u00adnique, attribute \npattern sets. Attribute pattern sets use semantic rules, as do attribute grammars, tospec\u00adify a set of \nequations defining the values of fa. But rather than using a grammar to associate semantic rules with \nnodes of a derivation tree, attribute pat\u00adtern sets use tree pattern matching to associate the rules \nwith nodes of an arbitrary tree. In doing so, attribute pattern sets gain several advantages: The description \ncan be made modular. Rather than adding semantic rules to a single grammar, attribute pattern sets allow \nthe specifier to group patterns and rules as desired.  The association mechanism (tree patterns instead \nof production rules) can be tailored to each par\u00adticular f., rather than using a fixed grammar for all \nfa.  Q Tree patterns are more general than production rules, both in terms of the case analysis they \npro\u00ad vide and in terms of the nodes that can be con\u00ad sidered nearby in semantic rules. In Section 2, \nwe define attribute pattern sets and give simple examples of their usage, concentrating on understanding \nthe specification method. Section 3 compares attribute pattern sets with attribute gram\u00admars, showing \nthat attribute pattern sets are more general, more easily modified, and more expressive than attribute \ngrammars, by way of example and ar\u00adgument. Section 4 shows how attribute pattern sets can be implemented \nwith attribute grammars when the trees in question are derivation trees, making it straightforward to \nmake use of the extensive work in creating efficient attribute-grammar evaluators while gaining the specification \nadvantages of attribute pat\u00adtern sets. In Section 5 we conclude with a brief look at other alternatives \nto traditional attribute grammars. 2 Definition of attribute pat\u00adtern sets A simple attribute pattern \nset that performs type checking appears in Section 2.2.2, and may prove use\u00adful as a reference while \nreading this section. 2.1 Trees and Tree Patterns Before describing attribute patterns sets in detail, \nwe need a notation for trees and tree patterns. Our trees are labeled and ordered. Each tree node n has \na la\u00adbel / and a finite number of children c1 through ck, and is written as /(cl, . . . . c~). We place \nno restriction on the relationship between the label of a node and its arity, e.g., two different nodes \nmay have the same label but a different number of children. We will of\u00adten use a node n to represent \nthe tree rooted at n; in general, the terms (node and subtree will be used interchangeably. We also use \nthe notion of a (posi\u00adtion in a tree, which can be formalized as a sequence of integers giving a path \nfrom the root node to a given subtree. We will use the traditional notion of a pattern as a tree with \nsome of the leaves replaced by pattern variables. Pattern variables may be typed, that is, re\u00adstricted \nto match a particular subset of trees, or may be used as names for internal nodes. Formally: A syntactic \ntype is a regular set of trees (as defined below). A pattern variable is a pair consisting of a symbol \nv and a syntactic type T, written ?V: r. A pattern is a tree in which pattern variables may be used as \nleaf nodes, nodes may be named, i.e., associated with untyped pattern variable; this is denoted by prefixing \nthe node with a pattern variable and the = sign, and all of the pattern variables, whether used as leaf \nnodes or as names, have distinct sym\u00adbols. When the type of a pattern variable is the set of all trees, \nit is often omitted in the notation and we simply write ?V. Typed internal node names greatly compli\u00adcate \nthe design of pattern matching algorithms, such as is carried out in Section 4, and have not appeared \nto be useful in practice, and so we disallow them. We suspect that similar algorithms to those of Section \n4 could be found that handle typed internal node names correctly. A pattern p, with leaf variables (VI, \n, v~) and node names (v~+l, ,,v[ ) , matches a tree t if there are nodes (nl, . . . . nl) of t such that: \nreplacing each leaf variable vi (1 < i < k) in p with ni yields a tree isomorphic to t, for all 1< i \n< k, n~ is a member of the syntactic type of vi, and for each node name u (k + 1< i < 1) at position \nPi in P, ni is the node at position Pi oft. There can be at most one tuple of nodes (nl, , nk) fulfilling \nthese criteria. If the pattern matches, we use o-(p, t) to denote the set of bindings {(s;, n;)} where \nSi is the symbol of vi. For example, the pattern expr(?x, ?op: blnop, ?y) matches a tree t if t is labeled \nwith expr, has three children, and the second child is in the set binop. Only regzdar tree sets maybe \nused as types. Regu\u00adlar tree sets are those sets recc)gnizable by a finite-state bottom-up tree automaton, \na state machine whose transitions are a function of the label of a node and the states of its children \n[3]. A type, or regular set, is specified by giving a list of patterns: type type-name matches patternl \nor patternz . . . ; defining type-name to be the set of all trees matched by one or more of the patterns. \nFor example, binop might be specified by: type binop matches pluso or minuso or timeso or divideo; The \npatterns listed may have recursive references to the type being defined; for example, type binexp matches \nexpr(?x:binexp, ?y:binop, ?z:binexp) or idento ; defines binexp as the set of all trees where each inter\u00adnal \nnode is labeled expr and has three children, and each leaf is ident ( ) (if it occurs as the root, or \nfirst or third child of an expr node) or a member of binop (if it occurs as the middle child of an expr \nnode). 2.2 Attribute pattern sets An attribute pattern set specifies a function from trees to sets of \nattribute equations and, via the equations, to sets of attribute values. As in attribute grammars, the \nspecification is done in terms of semantic rules. A semantic rule is an equation of the form $aO(sO) \n= 9(.fal(Sl),.fa, (S2), ... ~a. (sk)) where the fai are fixed functions in 7, g is a com\u00adputable function, \nand the si are symbols. A semantic rule can be instantiated with a set of bindings u to form an attribute \nequation by replacing all of the sym\u00adbols si in the rule with their corresponding values in .C1. In our \nexamples, we use the traditional dot-notation for attribute functions: the value f=(n) is written as \nn.a, viewing a as an attribute of the object n. Also in our examples, the function g is represented by \nan arbitrary expression of attribute values. An attribute pattern is a pair (p, r) where p is a tree \npattern, r is a semantic rule, and each symbol Si appearing in r also appears in a pattern variable of \np. We write attribute patterns by writing the tree pattern first, and then indenting the semantic rule \nunderneath, e.g., ?e = expr(?x, pluso ,?y) e.val = x.val + y.val An attribute pattern (p, r) can be applied \nto a tree t yielding a set of equations E, where E is the minimal set of equations satisfying the following: \nFor all nodes n oft w-here p matches n-, the equation e obtained by instantiating r with u(p, n) is in \nE. For example, let u bethetree expr(b( ),plus (),c())andtbethe tree expr(a( ) ,plus ( ) , u). Then applying \nthe attribute pattern above tot yields the following set of equations: t.val = ao. val + u.val u.val \n= bo. val + co. val An attribute pattern set S is a set of attribute pat\u00adterns. S is applied to a tree \nt yielding a set of equa\u00adtions Es,t by taking the union of the sets produced by applying the individual \nattribute patterns in S to t. When several attribute patterns in an attribute pat\u00adtern set share the \nsame pattern p, we usually write the pattern once and then indent all of the semantic rules paired with \nthat pattern underneath it. An attribute pattern set specifies a family of partial functions Z by producing \na set of equations Es,t for a given tree t; the values of the functions in 7 are specified by the solution \nto the equations. 2.2.1 Well-defined and prioritized attribute pattern sets The set f specified by an \narbitrary attril~ute pattern set S is not necessarily well defined, since there may be zero, or multiple, \nsolutions to the set Es,t for one or more trees t. Even when 3 is well defined, it may be difficult to \ncompute via S. Thus, for prac\u00adtical purposes, we impose some additioua.1 conditions on attribute pattern \nsets. We aim at the same solu\u00adtion method employed by typical attribute grammar solvers: ordering the \nequations in a way that permits them to be treated as assignment statements, provid\u00ading a step-by-step \nsolution of each equation by simple substitution of previously determined values. Since the function \ng on the right hand side of an att\u00adribute equation may be difficult or impossible to in\u00advert, solving \nthe equations is simpler if every attribute appears on the left hand side of some equation. We call this \nproperty closure. An attribute pattern set is closed if, for all trees t,for all subtrees n oft, every \nat\u00adtribute value fa(n) appearing on the right hand side of an equation in Es,t also appears on the left \nhand side of some equation. We show how to test an attribute pattern set for the closure property in \nSection 4.3. A second source of difficulty is the possibility of nlul\u00adtiple equations defining the same \nattribute. If, for some tree t, there are two equations in Es,t with the same left side, then S is said \nto be ambiguous. Anl\u00adbiguity does not necessarily imply that the set X is ill-defined, since it is possible \nthat the right hand sides of the equations are also equivalent. But it is inlpos\u00adsible to check whether \nor not an ambiguous attribute pattern set gives a well-defined ~ for all trees, due to the generality \nof the g functions. Thus, ambiguity is undesirable from an inlplenlen\u00adtation point of view. But a strict \nenforcing of this policy would make it very difficult to write practical attribute pattern sets. For \nexample, it is often de\u00adsirable to have some sort of default rule to apply for copying of attribute values \nup and down a tree. In the attribute grammar formalism, it is possible for an implementation to provide \nsome syntax for specifying a default rule, and then insert the default rule into the grammar wherever \nan explicit rule for the attribute is missing. This cannot be done in the attribute pattern set formalism \n doing so would require writing a pat\u00adtern that matched all trees not matched by some other set of patterns \n(those with explicit equations for the attribute), and this is not generally possible. Instead of making \nambiguity illegal, or complicating the pattern language, we take an approach common in pattern-matching \ncircles: we allow ambiguity, and add a disambiguation method. This leads to the no\u00adtion of a prioritized \nattribute pattern set, an attribute pattern set along with a total ordering <P on the se\u00admantic rules. \nIn a prioritized attribute pattern set S, if several equations in Es,t have the same left hand side, \nthe one arising from the rule with higher prior\u00adity is maintained, while the others are discarded. The \nresulting set is used as the defining equations for the functions in Y_. In our examples, we specify \nthe priority function implicitly by the lexical ordering of the semantic rules, with the highest priority \nrules listed first. We generally take the approach that prioritized at\u00adtribute pattern sets are desirable \nfrom a practical point of view, but it is possible to check an attribute pattern set for non-ambiguity \nif that is desired, as shown in Section 4.2. The final problem in treating the set of equations as a \nset of assignment statements is that circular de\u00adpendencies may exist. Detecting whether or not an attribute \npattern set avoids a circular set of equations for all trees is at least as difficult as the correspond\u00ading \nproblem for attribute grammars, which has been shown to require exponential time [4]. We ar~ cur\u00adrently \ninvestigating transferring typical classification schemes for attribute grammars into the attribute pat\u00adtern \nset world; these classes provide for practically use\u00adful attribution styles that can be proven non-circular. \nSection 4.4 discusses one class of non-circular attribute pattern sets that corresponds to the absolutely \nnon\u00adcircular (ANC) class of attribute grammars. Another possible approach is to embrace circular definitions \nand devise a more powerful evaluation strategy, as has been done in some attribute grammar research. \nFinally, when the trees to be attributed are restricted to be derivation trees for some context-free \ngrammar, it is possible to convert the attribute pattern set to an attribute grammar, which can then \nbe tested for circularity. Section 4.5 discusses the conversion algo\u00adrithm. 2.2.2 A simple example The \nfollowing attribute pattern set defines a type at\u00adtribute for binary expressions: ?e=expr(?x, ?b:binop, \n?y) e.type = if (x. type # y. type) then error else if (x. type # integer) and (x. type # float) then \nerror else x. type; ?e=intconsto e type = integer; ?e=f loatconst () e type = f lost; This attribute \npattern set defines the type attribute to have one of three values at binary expressions: integer if \nboth children have type integer, float if both have type float, and error otherwise. Note that the attribute \npattern set is not closed; if the first or last child of an expr node is not matched by any of the three \npatterns, then the use of x. type would be undefined. This could be repaired by use of a pri\u00adoritized \nattribute pattern set and the addition of a default clause: ?any any. type = error This clause matches \nall nodes, but will only apply to nodes that are not matched by the other patterns since the priority \nof the other rules is higher. Alternatively, if the input trees were restricted such that all expr nodes \nwith a binop had either a similar node or an intconst or float const as children, the implemen\u00adtation \ncould efficiently check to see that all possible bindings of x had well defined type attributes. 3 Comparison \nof attribute pat\u00ad tern sets and attribute gram\u00ad mars Mimicking an attribute grammar with an attribute \npattern set is trivial: a production of the form X-> X1X2 ... Xn is replaced with a pattern of the form \n?X = X(?xl: x;, ?X2:X;, . . . . ?Xn: x;), syntactic types X are defined for each grammar sym\u00adbol X, and \ngrammar symbol names are appropriately replaced with variable names in the attribute equa\u00adtions. Attribute \npattern sets share the declarative nature of attribute grammars. As we shall see in section 4.5, attribute \npattern sets can be implemented with at\u00adtribute grammars, and thus, attribute pattern sets can benefit \nfrom the theoretical and practical work that has been done on attribute grammar evaluators. In addition, \nattribute pattern sets solve the problem of the monolithic grammar, and they provide a better case-analysis \nplatform than the grammar itself. 3.1 Attribute pattern sets are modular First and foremost, attribute \npattern sets are triv\u00adially modular. Rather than dealing with a mono\u00adlithic grammar and adding semantic \nrules as the need arises, the writer of an attribute pattern set can add new patterns and/or repeat old \npatterns as required for additional attributes. For example, one group of patterns and associated semantic \nrules may deal with type-checking, a second with identifier bindings, and a third with code generation. \nPatterns and attributes dealing with a small portion of the language (for exam\u00adple, checking that loop \nexit statements are contained within a loop) can be written together, ignoring those portions of the \ngrammar that do not concern them. The problem of the monolithic grammar is, of course, impossible to \ndemonstrate with small exam\u00adples. Some appreciation of the magnitude of the problem can be gained by \nconsidering the size of an attribute grammar for Ada, which performs static\u00adsemantic checking but does \nno code generation: the grammar and semantic rules occupy about 150 pages [5]. Support functions needed \nto keep the attribute grammar to this size require another 250 pages of code. It is desirable to deal \nwith specifications of this size by addition, rather than modification, and to group related rules together, \nrather than spreading them throughout the description, but attribute gram\u00admars do not provide this capability. \n3.2 Attribute pattern sets provide bet\u00adter case analysis Attribute grammars provide a limited amount \nof case analysis via the grammar. For example, when writing semantic rules for the production expro -> \nexprl PLUS expr2 the writer knows that expro is a PLUS node and that exprl and expr2 are expression nodes. \nWhile this case analysis is, in some sense, trivial, it is none the less of practical import, as anyone \nwho has written a seman\u00adtic analyzer by hand is aware; a large portion of the busy work in hand coding \ndeals simply with determin\u00ading what kind of node is being visited, what kind of children it has, and \nassigning names (or referring to children by position rather than names). But this case analysis is limited \nin two important ways. First of all, the case analysis provided by the gram\u00admar is fixed. The semantic \nrule writer is forced to live with the language as divided by the grammar, regard\u00ad less of whether the \ngiven division is appropriate for a given attribute. Consider a simple binary expression grammar: expro \n-> exprl PLUS expr2 expro -> exprl TIMES expr2 expro -> exprl MINUS expr2 expro -> exprl DIVI1)E expr2 \nexpro -> INTEGER-CONST expro -> FLOAT-CONST For code generation purposes, this division may be what \nis desired. But for type-checking, it might have been more convenient to use the following formulation: \nexpro -> exprl binop expr2 binop -> PLUS binop -> TIMES binop -> MINUS binop -> DIVIDE expro -> INTEGER-CONST \nexpro -> FLOAT-CONST allowing identical type-checking rules for the binary operators to be written under \none production instead of being repeated each time. But the grammar wliter must choose one version or \nthe other. Attribute pattern sets do not suffer from a fixed grammar. The attribute pattern set writer \ncan eas\u00adily divide the language up in multiple ways, simply by using different patterns for each attribute. \nWhen writ\u00ading semantic rules for code generation, the following patterns can be used: ?e = expr(?x, pluso, \n?y) ?e = expr(?x, times o,?y) ?e = expr(?x, minus o,?y) ?e = expr(?x, divideo ,?y) and the pattern ?e \n= expr(?x, ?b:bi.nop, ?y) can be used when doing the type-checking. The second limitation on case analysis \nvia produc\u00adtions is the constraint on the depth of the analysis. A production describes the label of \nthe nocle produced and its immediate children, but says nothing about the structure of grandchildren. \nA pattern, on the other hand, can be as complicated as is necessary, and in fact can make use of information \narbitrarily far down in the tree via the syntactic type system. Consider, for example, performing a special-case \ntest on simple increment statements. We wish to com\u00adpile normal assignment statements in one way, but \nincrements in another. An attribute grammar to per\u00adform this task might be written: asgn stmt > IDENT \nGETS expr asgn-stmt.code = if (expr.is-incr and expr.lncr-id = IDENT.name) then gen-incr-code (IDENT.name,expr \n.incr-val) else gen-asgn-code(IDENT .name,expr.code) ; expro -> exprl PLUS expr2 expro.is-i.ncr = exprl.is-ident \nand expr2.is-int; expro.incr-id = exprl.incr-id; expro.incr-val = expr2.incr-val; expr -> IDENT expr.incr-id \n= IDENT.name; expr.is-ident = true; expr -> INT-CONST expr.is-int = true; expr.incr-val = INT-CONST.value; \nNote that assignments to the expr.code attribute have been left out of this grammar (usually in an attribute \ngrammar, the assignments to the code at\u00adtribute would occur alongside all of the other at\u00adtributes under \neach production) and that we assume there is a method for specifying default rules (such as expr.is-int \n= false for most expressions). Even so, the grammar writer is forced to add five extra rules to perform \nthis simple case-analysis. A better solution is to use a prioritized attribute pattern set: ?s=asgn-stmt \n(?lhs,getso , ?e=expr(expr(?id: ident),pluso , expr(?int :int-const) )) s.code = if (lhs.name = id.name) \nthen gen-incr-code (lhs.name,int value) else gen-asgn-code(lhs .name,e.code); ?s=asgn-stmt (?lhs,getso \n,?e) s.code = gen-asgn-code(lhs .name,e. code); In the attribute pattern set version, the special case \nanalysis is performed in one location, in a form that can be locally understood (in the attribute gram\u00admar, \nthe meaning of the is-incr attribute is used in one production, defined in another, and depen\u00addent on \ntwo other attributes defined elsewhere). One can also argue that the pattern is easier to com\u00adprehend \nthan the attributes, particularly if an ab\u00adstract syntax tree is used rather than the parse tree: with \nan abstract syntax tree, the simpler pattern ?s=asgn stmt (?lhs,plus(?id: ident,?int: int-const)) could \nbe used. As can be seen, even from these simple examples, attribute pattern sets have several advantages \noter at\u00adtribute grammarsas a specification method. In the next section, we show how evaluators for an \nattribute pattern set can be constructed using attribute gram\u00admar technology. 4 Checking and implementing \nattribute pattern sets In this section, we examine algorithms that test vari\u00adous properties of attribute \npattern sets and that pro\u00adduce attribute grammars from prioritized attribute pattern sets. The algorithms \nare presented primarily as a feasibility argument attribute pattern sets can be tested for basic safety \nproperties, and can be im\u00adplemented similarly to attribute gralmmars. We view the concept of attribute \npattern sets as the primary contribution of this paper, and intend to continue re\u00adsearch on their efficient \nimplementation. Our algorithms depend heavily on match sets and tree automata, and so we begin by briefly \nreviewing these concepts. 4.1 Match sets and tree autolmata The match set at a tree t for a set of patterns \nP is the set of all patterns and subpatterns in P matching t.A set of patterns Af is a match set of P \nif it is the match set at some tree for P. Let M(P) be the set of all match sets of P. For finite P, \nM(P) is finite, and can be constructed without regard to any particular tree t. A (deterministic, leaf-to-root) \ntree automaton is a function ~ from trees to states such that f(l(c,, . . . . Ck)) = A(g f(c~), . . . \n. f(c~)) for some function A. When Aisfinite, tree autonlata can be efficiently implemented with table \nlookups, Let P be the set of all patterns appearing in an attribute pattern set S. It is possible to \nsimultane\u00adously construct M(P) and a tree-automaton f, with the elements of M(P) as states, such that \nf(t) is the match set at t for P. Our algorithms all rely on this construction. The construction of M(P) \nand j, though pos\u00adsible, is potentially problematic, since the size of M(P) may be exponential in the \nsize of P. Hoff\u00adman and O Donnell suggest a restriction on patterns that ensures a polynomial construction \ntime, and claim that their limitation has not seriously hampered them in their applications [6]. We find \nHoffman and O Donnell s restrictions too limiting, and so for sev\u00aderal years have been constructing automata \nusing a generally-applicable algorithm (due to Chase [7]) in conjunction with various pattern-matching \napplica\u00adtions in compilation [8,9]. We have yet to encounter a practically useful example where the automaton\u00adconstruction \ntime was a significant portion ofour pro\u00adcessing time. 4.2 Testing for ambiguity An attribute pattern \nset S, with patterns P, is am\u00adbiguous if there is some tree t and pair of distinct equations n.a=gl(. \n..) and n.a=g2(. ..) in the set of generated equations E5,t. We can determine whether or not such a t \nexists by examining the match sets M(P) and looking for conflicts between potential def\u00ad initions: Definition \n1 Given an attribute pattern set S, a po\u00adtential definition at a match set M is a tuple (p, s.a, p ) \nwhere pi E ill, pl is a subpaitern of p, s names a sub\u00adpattern of p , and there exists some attribute \npattern (p, r) ~ S where r defines s.a, A realized definition is a ,potential definition with pz p . \n Lemma 1 An attribute pattern set S is ambiguous if and only if there exists a tree tl with subtrees \nt2 and n, and distinct attribute patterns (pl, rl) and (p2, r2) in S defining the same attribute a, such \nthat: PI matches tl binding S:L to n, where rl defines sl. a, and  p2 matches t2 binding SZ to n, where \nr2 defines sz. a.  This lemma follows immediately from the definitions, and is used to prove the following: \nTheorem 1 An attribute pattern set S is ambiguous if and only if there is a match set M with a realized \ndefinition (p2, s2.a, p2) and distinct potential definition (Pi, sl.a, pi), for the same attribute a, \nsuch that S2 and S1 name nodes at corresponding positions of p2 and p;. Proofi Suppose that S is ambiguous, \nand that we therefore have trees and attribute patterns satisfying the conditions of Lemma 1. Condition \n2 of the lemma implies that the match set at t2must have a realized definition (p2, s2.a, p2). Furthermore, \nthe match set at t~ must have some potential definition (P1, S1 .a, pi), since t2 is a subtree of tl, \npl matches tl, and pl binds S1.a to n within tz.Finally, since S1 and S2 are bound to the same node, \nthey must name nodes at corre\u00adsponding positions of p; and p2. For the converse, suppose we have a match \nset M with patterns satisfying the conditions in the theorem, and let t2be a tree with match set M. Since \nt z is matched by p{, and p{ is a subpattern of pl, there must be some tree tlmatched by p with tzas \na subtree. It is easy to show that this tree satisfies the conditions of the lemma, and so S is ambiguous. \n0 We can therefore test for ambiguity by checking each match set for the conditions of Theorem 1. With \nsome care in preprocessing (e.g., computing positions once for each potential clef), this test at each \nmatch set can be done in time proportional to the number of po\u00adtential definitions at the match set. \nWe expect this to be less expensive than the automaton construc\u00adtion; although there may be many potential \ndefini\u00adtions for a given pattern in a match set (one for each attribute), the match set construction \nalgorithm also involves testing a number of potential patterns at each match set. Experience with actual \nattribute pattern sets is needed to test this conjecture. 4.3 Testing for closure Testing for closure \nis not as straightforward as testing for ambiguity. We can define potential and realizecl uses similarly \nto potential and realized definitions, but investigating the combination of uses and clefs at indi\u00advidual \nmatch sets is insufficient to determine closure; a study of paths through the automaton is instead neces\u00adsary. \nThis leads us to a testing algorithm that involves solving a data flow problem on the automaton. Definition \n2 A path in a pattern matching autonLa\u00adton with transition function A is a sequence of match set/integer \npairs ((A&#38;l, cl), . . . . (Af~, c~)) such that each Mi is the Ci th argument in some A transition \nto ?vli+l. Equivalently, a path is a sequence of match set/integer pairs such that there exists a sequence \nof trees (uI, . . . . uk) where each ui is the ~i th child of Ui+l and Mi is the match set at Ui. Given \nan attribute pattern set S, a potential use at a match set M is a tuple (p, s.a, p ) where pi E M, p! \nis a subpattern of p, s names a subpattern of p , and there exists some attribute pattern (p, r) c S \nwhere r uses s.a. A realized use is a potential use with p = p . Lemma 2 An attribute pattern set S \nis noi closed if and only if there is some path ((MI) cl), . . . . (flfk, ck)) fulfilling the following \nconditions: 1. There exists a sequence potential of uses ((p, s.a, pi), . . . . (p, s.a, pk)) such that \neach (p, s.a, pi) is a potential use of Mi, pl is named by S, pk = p, and each pi iS the Ci th child \nofpi+l for i< k, and  2. There is no k < k and sequence of potential def\u00ad  . inataons ((p , s.a, pj), \n., (p , s.a, p~, )) S7LCh that each (p , s.a, pj) is a potential definition of Mij Pi 2S named h S, Pi.) \n= P , and each P: is the Ci th child of pj+l for i < k . Proof: Suppose S is not closed. Then there \nis some tree t,subtree n, and attribute pattern (p, r) satisfy\u00ading the following: p matches t binding \nsome s to n, r uses some attribute s.a, and no attribute pattern defines a for n in t.Let ((ul, c1), \n. . . . (u~,c~)) be the sequence of tree/integer pairs where U1 = n, uk = t, and each ui is the ci th \nchild of Ui+l in t. Let Mi be the match set of Ui. Since (p, r) uses attribute a at n, it is easy to \nshow that ((MI, CI), . . . . (M~, c~)) satisfies condition 1; condition 1 simply traces potential uses \nup through the match sets. There can be no potential definitions satisfying condition 2, since if there \nwere such potential definitions then they would define a at n, contradicting our choice of t, a, and \nn. Conversely, suppose there is a path fulfilling con\u00additions 1 and 2. Let (UI, . . . . Uk) be a sequence \nof subtrees of some tree t = Uk, where each ui is the ci th child of Ui+l and Mi is the match set at \nUi. Con\u00addition 1 ensures that there is a use of attribute a at U1 in Uk, while condition 2 ensures that \nthere is no definition of a at U1 in uh, so S is not closed. 0 We test for closure by identifying match \nsets with potential undefined uses, and propagating these po\u00adtential problems through the automaton until \neach is either safely resolved (a definition is found) or exhibits a path satisfying Lemma 2, as follows. \nDefinition 3 A potential undefined use ai a match set M is a pair (u, D) where u is a potential use at \nM using some attribute a at position p and D is a subset of the potential definitions at M defining a \nat p. We will generate a potential undefined use at a match set that has some potential use of the form \n(p, s.a, p ) where s names p , and where there is no correspond\u00ading realized definition. Such a potential \nundefined use may lead to an actual undefined use if there is some path, leading to a realized use, that \nnever reaches a corresponding realized definition. We propagate po\u00adtential undefined uses along paths \nthat continue to match the pattern p, while updating the set of poten\u00adtial definitions and eliminating \nthe potential undefined use should some definition be realized: Definition 4 Gen(ikf), the set of potential \nundefined uses generated at M, is the set of all potential un\u00addefined uses ((p;, si. ai, p~), Di) where \np: is named by si, Di is maximal (i. e., it contains all of the potential definitions at M defining a \nat p), and Di contains no realized definitions. Preds[M], the predecessors of match set M, is the set \nof all tuples of the form (M , i) where M! is the i th argument of some A-transition to M. F rop~, the \ni ih propagation function at M, is a function from sets of potential undefined uses at pre\u00addecessors \nof M to sets of potential undefined uses at M, defined as follows: a potential undefined use ((p,s.a, \np ), {(pi, sl.a, p~), . . . ,(pk, sharp\\)}) at M is an element of Prop~(U) ifl 1. none of the (Pj, Sj \n.a, p~) are reaiized potential def\u00adinitions, 2, there a s an element ((p, sa,p ), {(pi, sl.a, pj),..., \n(p~, s~.a)pj)}) in U where k <4, pi is the i ill child of pit, p; is the i th child of p; for 1< j < \nk, and 3. for the element in 2, for all k < j < ! either p~. is J not the i th child of its parent or \nits parent is not in M. Theorem 2 Given an attribute pattern set S with pattern matching automaton f \nwith transition func\u00adtion A, let C(M) be defined as the minimai solution to the set of equations C(M) \n= Gen(M) U Prop~( (C(M )), u (fi~,i)cPreds(L~) S is not closed if and only if there is some C(M) with \nan element of the form (u, D) where u is a realized use and D contains no realized definitions, Proof: \nSuppose S is not closed. Let ((MI, cl),..., (Mk, Cfi)) and ((p, s.a, pi), . . . . (p, s.a, ~h)) be a \npath and se\u00adquence of potential uses satisfying the conditions of Lemma 2. Gen(Ml) must contain a potential \nunde\u00adfined use ((p, s.a, pl ), D1 ) since D cannot contain a realized definition of a (else condition \n2 of the lemma would be violated). If this potential undefined use propagates via the Prop,, f functions \nto a potential undefined use ((p, s.a, p), Dk ) then Dk cannot contain a realized definition (else condition \n2 of the lemma would be violated). The only way in which the unde\u00adfined use could not propagate to ((p, \ns.a, p), Dk ) would be if some potential definition were realized along the way, but this would again \nviolate the condition of the lemma. Conversely, suppose there is a C(M) with an el\u00adement of the form \n((p, s.a, p), D) where D contains no realized definitions. There must be some path ((M1,c1), . . . . \n(Mk, c~)) where Gen(Ml) contains an element of the form ((p, s.a, pl), Dl) that propagates via the Prop: \nfunctions to ((p, s.a, p), D) without realizing any potential definitions along the way; this path fulfills \nthe conditions of Lemma 2. 1 The closure test can be implemented using a sim\u00adple worklist algorithm to \ncompute the values C(AJ), Although this could be very expensive (there can be O(rnnd) applications of \nProp, where m is the number of match sets, n the maximum number of predecessors of a match set, and d \nthe maximum depth of a node with a attribute definition in an attribute pattern), we expect in practice \nthat it will be relatively inexpensive if priority-based attribute pattern sets are used. At\u00adtributes \nwith default definitions will never generate potential undefined uses. Attributes that are always defined \nat the root ofan attribute pattern will either never generate apotential undefinedu se, orthe poten\u00adtial \nundefined use will immediately be recognizable as an actual undefined use (since a potential undefined \nuse of the form (u, 0) will adways lead to an actual undefined use). As with the ambiguity test, practical \nexperience is needed to verify our conjecture that the algorithm will be efficient in practice. 4.4 Testing \nfor circudarit~ Testing for circularity is at least as difficult as it is for attribute grammars, and \nmay be exponential even when the automaton can be constructed quickly. We therefore have developed an \nalgorithm that finds a subclass of the non-circular attribute pattern sets. For attribute pattern sets \ndirectly corresponding to at\u00adtribute grammar via the construction described at the start of Section 3, \nthe class contains exactly the set of absolutely non-circular attribute grammars defined by Kennedy and \nWarren [10], and so we call our class the absolutely non-circular (ANC) attribute pattern sets. Definition \n5 Given an attribute pattern set S and tree -t, the node attributes oft are the pairs (n, a) where n \nis a subtree oft and a is an attribute defined at n. Given an attribute pattern set S, the dependency \ngraph for a tree t is the graph. using the node attributes oft as nodes, and with an edge from (nl, al) \nto (nz, az) iff nl. al appears on the right hand side of an equation defining n2.a2 in Es,i. An attribute \npattern set is circular if there is a cycle in the dependency graph for some tree t. Our (non\u00adexact) \ntest for circularity defines dependency graphs on match sets, rather than on trees, and looks for cy\u00adcles \nin the resulting graphs. Definition 6 The unweighed dependency graph G for an attribute pattern set S \nis the minimal graph containing the following nodes and edges: 1. Each potential de$nition (p, s.a, p \n), where p is named by s, is a node of G, 2< Each potential use (p, s.a, p ), where p is named bys,isanode \nofG, 3. There is an edge from a potential use (p, S1 al, pi) to a potentia! definition (p, s2.a2, p~) \nif S1 .al ap\u00adpears on the right hand side of the semantic rule defining s2.a2, and There is an edge fro;m \na potential definition (pi, s~.a, p{) to a potential use (p2, s2.a, pj) if there is a tree t with subtrees \ntl and tz such that pl and p2 match tl and t2, respectively, binding S1 and S2 to the same node. 4. \nWe have defined potential definitions and uses at par\u00adticular match sets M, but we here equate all potential \ndefinitions that have identical components. That is, (p, s.a, p ) is a potential definition only if it \nis a po\u00adtential definition at M for some match set M, thereby assuring certain relationships between \np, s.a, and p , but we identify the potential definition (p, s.a, p ) at Ml and the potential definition \n(p, s.a, p ) at N12\u00b0 as the same potential definition. Lemma 3 If an attribute pattern set S is circular, \nthen there is a cycle in the unweighed dependency graph for S. Proofi Suppose S is circular. Then there \nis some tree t with a cyclical dependency graph. Pick any cycle ((nl, al),.. ., (n~, a~)) in this graph, \nwhere (nl, al) = (n~,a~). For each edge ((ni, a~), (ni+l, ai+l)), there must be some potential use (pi, \nsi .ai, pi ) and potential defini\u00adtion (z4+I, qi+l.ai+l, %+1) leading to the use of (ni, a;) and definition \nof (ni+l, ai+l). It can be confirmed from the definition of the unweighed dependency graph that there \nis a cycle ((p~,s~oa~,pl), (~~,9~.a~,~j), (P2)$2 a21P\\)7(~2! ~2 a2>~4)! ) (p~)sk.a~)pl)) where (pi, \nsl.al, p~) = (p~,sk.ak,pj). 0 The unweighed dependency graph can be easily built from the match sets; \ncondition 4 of Definition 6 is satisfied if there is a match set with a realized defi\u00adnitioniuse (pi,s~ \n.a, pt~ ) and a potential useidefinition (P~ ~sl .a) P~) where Si a and sj a occur in correspond\u00ading \npositions of p~ and p;. Thus, Lemma 3 leads to a straightforward test for circularity, similar to the \nANC test for attribute grammars. The edges from condition 3 correspond to the edges in the depen\u00addency \ngraph DG of Kennedy and Warren. The edges from condition 4 denote connections between defin\u00aditions and \nuses of a single attribute at a given node, and roughly correspond to the notion of IO graphs in Kennedy \nand Warren (Kennedy and Warren copy edges from one dependency graph to another, rather than add links \nbetween them). Unfortunately, this test is not quite as strong as the ANC test. The test conceptually \nmerges all nodes in the tree tthat have the same match set, and this will lead to a false cycle when, \ne.g., a node makes use of an attribute of one of its children and is matched by the same patterns as \nthat child. This happens frequently when dealing with recursive patterns, such as lists, and must be \navoided. We can solve this problem by weighting the edges in the dependency graph by the distance they \npass information up or down the tree, and then insisting on a zero-weight cycle rather than an arbitrary \ncycle: Definition 7 The weighted dependency graph G$or an attribute pattern set S isidentical totheunweighted \ndependency graph for S, with some weights added. ~ is the minimal graph containing the following nodes \nand edges: 1. Each potential definition (p, s.a, p ), where p is named by s, is a node of~, 2. Each \npotential use (p, s.a, p ), where p is named by s, is a node ofg, 3. There is an edge from a potential \nuse (p,s~ al, P{) to a potential definition (p, s2.a2, pi) with weight w if S1 .al appears on the right \nhand side of the semantic rule dejining S2 .az and w is the (signed) difference between the depth of \npi and p; in p, and 4. There is an edge from a potential definition  (PI, sl.a, pj) to a potential \nuse (Pi, s2.a, p;), with weight zero, if there is a tree such that pl and p2 match at subtrees tl and \ntz binding both sl and S2 to the same node. Lemma 4 If an attribute pattern set S is circular, then there \nis a zero-weight cycle in the weighted de\u00adpendency graph for S. Proofi It can be verified that the cycle \nconstructed in Lemma 3 has zero weight. c1 Finding a simple zero-weight cycle (in which no path is repeated) \nin an arbitrary graph is an NP-complete problem, but finding arbitrary zero-weight cycles can be solved \nin time O(n3), where n is the number of nodes in the graph. We define the class ANC for at\u00adtribute pattern \nsets to be the set of attribute pattern sets whose weighted dependency graphs have no zero\u00adweight cycle. \n4.5 Conversion to attribute grammars If the trees to be attributed are derivation trees for a context \nfree grammar, then semantic rules can be added to the grammar to create an evaluator for an attribute \npattern set. Our goal in this section is not to give a detailed recipe for efficient implementation of \nattribute patterns via attribute grammars, but rather to impart an intuition of how the implementation \nof attribute pattern sets can be related to that of at\u00ad tribute grammars. The close relationship provides \nev\u00ad idence that attribute pattern sets can be implemented efficiently, but in our conversion we frequently \nignore efficiency in exchange for ease of exposition. In par\u00ad ticular, we will create attributes with \nabandon. Effi\u00ad ciency considerations are briefly discussed at the end of this section. The main idea \nis to match each grammar pro\u00ad duction against each attribute pattern, and insert un\u00ad der the production \nthe semantic rules for variables matched by nodes in the production. Three main tasks need to be carried \nout: It must be determined, at a given production, whether or not the complete pattern (from which each \nsemantic rule was inserted) matches. This can be done with one set of synthesized attributes, implementing \nthe match-set automaton, and a second set of inherited attributes, passing down information regarding \nwhich patterns matched higher in the tree. Attributes must be added to carry information from the one \nplace to another. A single pattern may be of arbitrary height, but an attribute gram\u00admar can only move \ninformation up or down one level in the tree per rule; thus, a single depen\u00addency in the attribute pattern \nset may result in several copy rules in the attribute grammar. Rule priority must be dealt with. Some \nambigu\u00adities can be resolved at conversion time, but in general, an ambiguity may result in the insertion \nof nested if-then-else expressions in the right hand side of an attribute rule, with the priorities of \nthe rules determining the order of occurrence in the if-then-else. For the remainder of this section, \nS is an attribute pattern set and G is a context free grammar describing the trees we wish to attribute. \nP will be a production of the form N --+ S1S2 . . . S n. We shall ignore terminal symbols; they can be \ntreated as non-terminals with the single production T --+ e where ~ denotes the empty string. We also \nassume that the start symbol does not appear on the right hand side of any production. We produce the \nattribute grammar by adding semantic rules to G as described by paragraphs prefixed with the symbol A \n. For a symbol IV, let @(IV) be the set of patterns or subpatterns of S that can match trees with root \nlabel N. First of all, it is necessary to determine which po\u00adtential definitions are realized. x For \neach production P of G, add the rule  N.m = A(N, S1.m,S2.m,....Sn.m), defining an attribute m for match \nsets. The attribute mdetermines what patterns match in the tree, but this information must be propagated \ndown\u00adwards from the root of a matched pattern to the nodes defined. We do so using attributes with potential \ndef\u00adinitions as names: A For each symbol Si on the right hand side of P, for each potential (but not \nrealized) definition (p, s.a, p ) where p E ~(Si), add the semantic rule S1.(p, s.a, p ) = N.(p, s.a, \np ) if there is a poten\u00adtial definition (p, S.U,p ) where p E #(IV) and p is the i th child of p ; add \nthe semantic rule S~.(P, s.a, p ) = fake otherwise. A For each symbol S i, for each realized definition \n(p, s.a, p) where p G #(Si), add the semantic rule S~.(p, s.a, p) = (p G S~.rn). Secondly, in order to \naccess attribute values that may be multiple levels away in the tree, attributes must be copied around \nthe tree. We copy poten\u00adtial uses up to the root of the pattern governing the use, and then back down \nto the potential definition, using attributes with names based on the potential useidefinition: k For \neach symbol Si on the right hand side of P, for each potential (but not realized) use (p, s.a, p ) where \np E #(Si), add the semantic rule IV.(p, s.a, p ) = Si. (p, s.a, p ) if there is a poten\u00adtial use (p, \ns.a, p ) where p c @(N) and p is the i th child of p . k For each potential use (p, s,a, p ) where p \nE @(IV) and s names p , add the semantic rule IV.(p, s.a, p ) = N.a. k For each symbol Si on the right \nhand side of P, for each potential (but not realized) definition (p, s.a, p ) where p c @(Si), for each \nattribute s .a used by the rule defining s.a, add the se\u00admantic rule Si. (p, s.a, p )s .a = N.(p, s.a, \np )s . a if there is a potential definition (p, s.a, p ) where p ~ 4(N) and p is the i th child of p \n; add the semantic rule S i.(p, s.a, p )s .a = undef oth\u00aderwise. k For each symbol Si, for each realized \ndefinition (p, s.a, p) where p c q!J(Si), for each attribute s .a used by the rule defining s.a, add \nthe semantic rule S~. (p, s.a, p)s .a = S~. (p, s .a , p). This could clearly be done more efficiently \nby only copying values up and down as far as necessary, rather than all the way to the root of the pattern, \nby not copying values when they are within one level of the use, or (by breaching the strict attribute \ngrammar paradigm) by accessing values via the tree when re\u00adquired. Finally, the rules of the attribute \npattern set must be placed in the attribute grammar and applied when appropriate, taking priorities into \naccount. The matching attributes are used to control which rule will be used at a given node. * At each \nproduction P, for each attribute a that may be defined at nodes labeled N, we add a semantic rule of \nthe form N.a = if testl then vail else if testz then valz ... else undef where each testi is a matching \nattribute. For each potential definition (p, s.a, p ) where s names p , let s.a = g(sl.al, . . . . s~.a~) \nbe the rule defining s.a; then N.(p, s.a, p ) is one of the testi s and  N.a = g(N. (p, s.a, p )sl. \nal,. . . . N.(p, s.a, p )s~.a~) is the corresponding vali. The ordering of the tests implements the priority \nscheme; rules with higher pri\u00adority should occur first in the list. This construction will implement \nthe attribute pat\u00adtern set, with priority, using an attribute grammar. There are several places where \nefficiency could be improved. The multitude of top-down matching at\u00adtributes, for example, could be replaced \nby a top-down automaton, Copying of attributes is not necessary if one is willing to extend the power \nof the implement\u00ading machine to access attributes at removed levels of the tree. Nor have we mentioned \nimprovements to the automaton construction that take advantage of the known restrictions on the input \ntree. Aside from the attributes added to perform pattern matching, which can be evaluated in a bottom-up \nfol\u00adlowed by top-down pass, the dependencies in the at\u00adtribute grammar are exactly those present in the \nat\u00adtribute pattern set. Thus, we claim that attribute pat\u00adtern sets can be implemented as efficiently \nas attribute grammars. 5 Comparison with previous work Attribute pattern sets draw heavily on previous \nwork in both pattern matching and attribute grammars, but combine important concepts from both fields \nin a new way. Attempts at solving the problem of the monolithic attribute grammar have been numerous, \nbut none have really attacked the key difficulty: at\u00adtribute grammars are factored by a fixed set of \npro\u00adductions, and this is an inconvenient way to divide the problem. The single exception to this rule \nare the modular attribute grammars of Dueck and Cormack [11], in which semantic rules are associated \nwith pro\u00adduction patterns. These production patterns are com\u00adpared with a grammar, and when a pattern \nmatches a particular production, any associated semantic rules are added to the production. The resulting \nsystem solves the modularity problem, by allowing the de\u00adscription for a given attribute to be localized. \nThe production pattern language is rather weak, however, being keyword oriented rather than structure \noriented; knowledge of the particular grammar being used to describe the syntax is necessary to avoid \nextraneous matches. The reliance on the underlying grammar shows through in the inability to create multi-level \npatterns and in the fixed case-analysis. For example, a pattern can be more general than a given produc\u00adtion \n(by matching several different productions), but it cannot be more specific. Natural Semantics is a well-known \ntechnique for providing semantic definitions using pattern matching [12]. Natural semantics differ from \nattribute pattern sets in two important ways, leading to very different semantic descriptions. First \nof all, the pattern lan\u00adguages are incomparable. Natural Semantics allows a variable name (a symbol, \nin our terminology) to ap\u00adpear twice in a pattern, but does not allow syntacti\u00adcally typed variables. \nThe former is a powerful match\u00ading technique but one that makes it much more diffi\u00adcult to analyze the \npattern sets. Secondly, the seman\u00adtic rules of attribute pattern sets, like attribute gram\u00admars, are \nviewed as algebraic equations, while rules in Natural Semantics are presented as logical formulae. In \naddition to yielding different specification styles, different implementation techniques are also result, \nnamely ordered evaluation of assignment statements for attribute pattern sets w a logic-programming style \nimplementation for Natural Semantics. Acknowledgements This paper, in various forms, has been read by \nmany members of the Piper group at U. C. Berkeley, and I am indebted to them for their helpful comments. \nJohn Boyland and Dain Samples, in particular, have each read at least four different versions of this \npaper, and John has been instrumental in the design of the various languages of Dora [9], from which \nthe concept of attribute pattern sets was distilled. References [1] Donald E. Knuth, Semantics of context \nfree lan\u00ad guages, Mathematics Systems Theory 2 (1968), 127-145. [2] Pierre Deransart, Martin Jourdan \n&#38; Bernard Lorho, Attribute Grammars, Lect. Notes in Comp. Sci. #323, Springer Verlag, Berlin, 1988. \n[3] Ferenc G6cseg &#38; Magnus Steinby, Tree Automata, Akad6mai Kiad6, Budapest, 1984. [4] Mehdi Jazayeri, \nWilliam F. Odgen &#38; William C. Rounds, (The Intrinsically Exponential Com\u00adplexity of the Circularity \nProblem for Attribute Grammars, Communications of the ACM 18 (Dec. 1975), 6769-706. [5] J. Uhl, S. Drossopoulou, \nG. Persch, G. Goos, M. Dausmann, G. Winterstein &#38; W. Kirchgassner, An Attribute Grammar for the Semantic \nAnalysis of Ada, Lect. Notes in Comp. Sci. #139, Springer Ver\u00adlag, Berlin, 1982. [6] Christoph M. Hoffman \n&#38; Michael J. O Donnell, Pattern Matching in Tkees, Journal of the ACM 29 (Jan. 1982), 68-95. [7] \nDavid R. Chase, An Improvement to Bottom\u00adup Tree Pattern Matching, Conference Record of the Fourteenth \nACM Symposium on Principles of Programming Languages, Miinchen, W. Germany (Jan. 1987), 168-177. [8] \nCharles Farnum, A Tree Transformation Facility Using Typed Rewrite Systems, Univ. of Califor\u00adnia, Berkeley, \nTech. Rep. UCB/CSD88/431, July 1988. [9] Charles Farnum, (Pattern-based Languages for Prototyping of \nCompiler Optimizers, Univ. of California, Berkeley, Tech. Rep. UCB/CSD 90/608, Dec. 1990. [10]Ken Kennedy \n&#38; Scott K. Warren, (Automatic Generation of Efficient Evaluators for Attribute Grammars, Conference \nRecord of the Third ACM Symposium on Principles of Programming Lan\u00adguages (Jan. 1976), 32-49. [11]Gerald \nD. P. Dueck &#38; Gordon V. Cormack, (Modular Attribute Grammars, Univ. of Water\u00ad100, Tech. Rep. CS-88-19, \nWaterloo, Canada,, May 1988. [12] G. Kahn, Natural Semantics, Proceedings of the 4th Annual Symposium \non Theoretical Aspects of Computer Science 247 (Feb. 1987), 22-39.  \n\t\t\t", "proc_id": "143165", "abstract": "<p>Attribute grammars have been used for many language-oriented tasks, including the formal description of semantics and the implementation of compilation tasks from simple type checking through code generation. Despite their successful use, attribute grammars have some disadvantages, including the monolithic nature of the grammar and the fixed factoring of all attribute descriptions by a single set of grammar productions. <italic>Attribute pattern sets</italic> provide a more expressive attribution system by using pattern matching, instead of grammar productions, to perform case analysis. Attribute pattern sets can be implemented in terms of attribute grammars in a way that maintains the dependency structure of the attribute system, making it straightforward to convert many of the practical results from attribute grammar theory to similar results for attribute pattern sets.</p>", "authors": [{"name": "Charles Farnum", "author_profile_id": "81100346036", "affiliation": "", "person_id": "PP31075536", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/143165.143209", "year": "1992", "article_id": "143209", "conference": "POPL", "title": "Pattern-based tree attribution", "url": "http://dl.acm.org/citation.cfm?id=143209"}