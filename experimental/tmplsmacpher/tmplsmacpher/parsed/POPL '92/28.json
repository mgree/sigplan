{"article_publication_date": "02-01-1992", "fulltext": "\n OBSERVABLE SEQUENTIALITY AND FULL ABSTRACTION Robert Cartwright Matthias FeHeisen* Department of Computer \nScience Rice University Houston, TX 77251-1892 Abstract One of the major challenges in denotational \nsemantics is the construction of fully abstract models for sequential programming languages. For the \npast fifteen years, re\u00adsearch on this problem has focused on developing mod\u00adels for PCF, an idealized \nfunctional programming lan\u00adguage based on the typed lambda calculus. Unlike most practical languages, \nPCF has no facilities for observ\u00ad ing and exploiting the evaluation order of arguments in procedures. \nSince we believe that such facilities are crucial for understanding the nature of sequential com\u00adputation, \nthis paper focuses on a sequential extension of PCF (called SPCF) that includes two classes of control \noperators: error generators and escape handlers. These new control operators enable us to construct a \nfully ab\u00adstract model for SPCF that interprets higher types as sets of error-sensitive functions instead \nof continuous functions. The error-sensitive functions form a Scott do\u00ad main that is isomorphic to a \ndomain of decision trees. We believe that the same construction will yield fully abstract models for \nfunctional languages with different control operators for observing the order of evaluation. 1 Full \nAbstraction and ~equentiality A denotational semantics for a programming language determines two natural \nequivalence relations on pro\u00ad gram phrases, The first relation, denotational equs ua\u00ad lence, equates \ntwo phrases if and only if they denote the same element in the model. The second relation, observational \nequivalence, equates two phrases if and only if they have the same observable, behavior . In the denot \national framework, observable behavior refers *Both authors were supported in part by NSF grant CCR 89\u00ad17022 \nand Darpa/NSF grant CCR 87-20277. Permission to copy without fee all or part of this matertial is granted \nprovided that the copies are not made or dktributed for dkect commercial advantage, the ACM copyright \nnotice and the title of the publication and its date appear, and notice is given that the copying is \nby permission of the Association for Computing Machinery. To copy other\u00adwise, or to republish, requires \na f= and/or specific permission. @ 1992 ACM 089791-453-81921000110328 $1.50 to the concrete output produced \nby entire programs. Thus, two phrases are observationally equivalent if and only if they can be interchanged \nin an arbitrary program without affecting the output. These two equivalence relations are different in \ngen\u00aderal. Denotational equivalence implies observational equivalence because denot ational models are \ncomposi\u00adt ional. However, the converse rarely holds for conven\u00adtional models of practical programming \nlanguages; some observationally equivalent phrases inevitably have dif\u00adferent meanings. A semantics in \nwhich denotational equivalence and observational equivalence coincide is said to be jully abstract. Observational \nequivalence is the fundamental con\u00adst raint governing program opt imizat ion. Since the users of a program \nare primarily interested in its input-output behavior, a compiler can optimize a program by inter\u00adchanging \nobservation ally equivalent phrases. If a deno\u00adtational semantics is fully abstract, then observational \nequivalence reduces to denotational equivalence, which can be analyzed with traditional mathematical \ntools. Consequently, one of the primary goals of research in de\u00adnotational semantics has been the construction \nof fully abstract models for practical languages. The following example shows why models based on the \nconventional continuous function spaces are typi\u00adcally not fully abstract for sequential languages. Con\u00adsider \nthe following family of procedures pi defined in a sequential, call-by-name functional language L: Pi(f) \n= if ~(fl,false) then Q else if ~(false,Q) then Q else if ~(true,true) then z else Q In this equation, \n!2 denotes any divergent expression and i denotes an arbitrary natural number. It is easy to show by \nan exhaustive case analysis that the procedures pi diverge for all inputs because the only possible inputs \nare sequential procedures. Hence, pi is observationally equivalent to the procedure p defined by p(~) \n= C?. 1we use the term p~ocedure rather than function tO refer to the primitive operators in a functional \nprograrnmi ng language because procedures are not necessarily interpreted as functions in models. On \nthe other hand, the conventional model for the language L includes functions that evaluate their argu\u00adments \nin parallel. A simple example of a parallel func\u00adtion is parallel-and, which returns false if either \ninput is false and returns true if both inputs are true. If we apply the conventional meaning of pi to \nparallel-and, the computation produces the answer i instead of 1 because the divergent sub computations \nare ignored by parallel-and. Consequently, the conventional model for such functional languages fails \nto identify pi and p. Essentially the same example can be constructed in any practical deterministic \nprogramming language where procedures can be passed as parameters [13, 20]. For example, in call-by-value \nlanguages, the procedures pi can be rewritten so that the parameter f takes con\u00adstant procedures as arguments \nand uses these proce\u00addures to simulate call-by-name boolean arguments [20]. Indeed, all commonly used \ndeterministic languages are sequent ial. In informal terms, a language is sequential if it can be implemented \nwithout timeslicing among multi\u00adple threads of control. Practical languages eschew paral\u00adlel operations \nlike parallel-and because they are painful to implement and encourage hideously inefficient pro\u00adgramming. \nEven deterministic languages for paraJlel machines like C* [17] are sequential. 1.1 Summary of Previous \nWork Milner [14] and Plotkin [ltfl were the first researchers to study the full abstraction problem for \nsequential lan\u00ad guages. They focused on constructing fully abstract models for PCF, a call-by-name functional \nlanguage based on the typed A-calculus. The above example shows that the continuous function model for \nPCF is not fully abstract. Milner and Plotkin developed differ\u00ad ent strategies for eliminating the discrepancy \nbetween the continuous function model and the observable be\u00ad havior of PCF. Milner eliminated parallel \nfunctions from the model by constructing a syntactic model in which the ele\u00ad ments are equivalence classes \nof observationally equiv\u00ad alent terms. Although Milner s model is fully abstract, it is not generally \nregarded as a denotational model because it does not identify any mathematical structure in program denotations \nother than their operational se\u00ad mantics. Plotkin extended PCF by adding parallel de\u00ad terministic operations, \neliminating the discrepancy be\u00ad tween the continuous function model and the procedures definable in the \nlanguage. Unfortunately, neither Mil\u00ad ner s nor Plotkin s result showed how to construct fully abstract \ndenotational models for sequential languages. In a later effort to understand the semantics of se\u00ad quential \nlanguages, Berry and Curien [2, 3, 5, 8] con\u00ad structed models for PCF with more restrictive domains of \nprocedure denotations. Berry eliminated many paral\u00ad lel functions from the domain of procedure denotations \nby forcing functions to be stable. This construction eliminated some of the spurious distinctions between \nphrases in the conventional model, but it introduced some new ones.z To address this problem, Berry and \nCurien [3, 4] imposed further restrictions on the space of procedure denotations by interpreting procedures \nas sequential algorithms over concrete domains [12]. A se\u00adquential algorithm is a function plus a strategy \nfor eval\u00aduating its arguments. While this approach eliminates all parallel functions, the resulting model \nis not extensional because it contains different procedure denotations with exactly the same behavior \nunder application. In addi\u00adtion, PCF cannot express all of the observations that characterize sequential \nalgorithms, such as the order of argument evaluation. As a result, the sequential algo\u00adrithm model for \nPCF is not fully abstract. Recently, Mulmuley [15] generalized Milner s work by showing how to construct \na fully abstract model for PCF aa a quotient of a conventional model based on lattices instead of cpos. \nMulmuley defined a retraction on the conventional model that equates all parallel func\u00adtions with the \noverdefined element top (T). However, like Milner s original fully abstract model, Mulmuley s model is \nsyntactic in flavor because his construction relies on the syntactic notion of observational equiva\u00adlence. \nFor more details on the history of the full ab\u00adstraction problem for sequential languages, we refer the \nreader to two extensive surveys [5, 23]. 1.2 Summary of Results Fifteen years after Milner s and Plotkin \ns original work, the fundamental question still remains: Are there fully abstract denotational models \nfor sequential programming languages ? In this paper, we answer the question affirmatively by showing \nhow to construct fully abstract denotational models for an observably sequential functional program\u00adming \nlanguage that is a simple sequential extension of PCF. The construction relies on two closely related \nin\u00adsights: 1. In most practical languages, a programmer can ob\u00adserve the order in which a procedure evaluates \nits arguments by generating run-time errors. Simi\u00adlarly, many of these languages permit programs to determine \nand exploit the evaluation order of subexpressions by using explicit control operators such as exception \nhandlers. 2. Continuous functions can be identified with deci\u00adsion trees if they are constructed by \ncomposing error-sensitive operations. In informal terms, an operation is error-sensitive if it propagates \nany er\u00adrors that it encounters in evaluating its arguments.  2 T&#38; ~bseryation is due to A. Meyer \n(MIT): personal co~u\u00adnication, August 1991 The remainder of this paper is organized as follows. After \npresenting the syntax and informal semantics of PCF in Section 2, we compare PCF to realistic func\u00adtional \nlanguages in Section 3. Unlike practical versions of functional languages, PCF lacks control operators \nfor generating errors and performing non-local exits, which makes it impossible to observe the order \nin which pro\u00adcedures evaluate their arguments. If we extend PCF to include these facilities, then we \ncan construct a fully abstract model by identifying error-sensitive functions with decision trees. We \ndefine such a model in Sec\u00adtion 4 and show that it is extensional. In Section 5, we sketch a proof of \nthe full abstraction theorem. Finally, in Section 6, we show that our extension of PCF is se\u00adquential \nand formulate the notions of error-sensitivity and observable sequentiality. Due to space limitations, \nthis paper only sketches the construction of the model and the proof of the full ab\u00adstraction theorem. \nWe refer the interested reader to an extended version of the paper [7].  2 PCF PCF is a simple functional \nlanguage based on the typed A-calculus with numerals, increment and decrement pro\u00ad cedures on numerals, \nconditionals, and a family of fixed\u00ad point combinators. The collection oft ypes consists of a single \nground type (o), denoting the set of non-negative integers, and procedure types (r + u), denoting sets \nof higher-order procedures, constructed from simpler types ~ and a. The set of types r is formally defined \nby the recursive rule: T ::= 01 (T--+ T). This rule is equivalent to T ::=ol(~+.; .+~+o) for all n, \nn which shows that procedures can be interpreted as maps from n-ary tuples to ground results. The second \nview also emphasizes the fact that all procedures have fixed arity. The set of PCF terms (M, A4 , . . \n.) consists of numer\u00ad als (kn for each n c N), procedural constants (~), typed variables (cc ), abstractions, \nand term juxtapositions: PCF programs are closed PCF terms of ground type. A syntactic context is a term \nwith holes [ ] in place of some subexpressions. The term C[kf, . . . . N] is the result of filling the \nholes of C with M, . . . . N, possibly capturing free variables in M, . . . . N in the process. In models \nof PCF, numerals denote numbers, k abstractions denote call-by-name procedures, juxt appos\u00ad itions denote \nprocedure applications, and the procedural constants add 1, subl, ifO, and Y have their usual mean\u00adings. \nThe procedures addl and subl, respectively, add and subtract 1 from their integer inputs; the latter \ndi\u00adverges on O. The procedure ifO evaluates its first argu\u00adment: if the result is O, it evaluates the \nsecond argument and returns it; otherwise it evaluates the third argu\u00adment and returns it. The Y combinator \ncomputes the fixed points for procedures of appropriate type. In PCF program text, we also use the constant \nQ, which ab\u00adbreviates the term Y(As .x), the prototypical divergent expression. The following equations \ndefine two different versions of the binary addition procedure in PCF: +1 = Y(A+. (AZY. ifO z y (addl \n(+ (subl Z) Y)))) +, = Y(A+ .(kcy. ifO y ~ (addl (+ z (subl Y))))) We will use these examples in subsequent \ndiscussions. To define a denotational model for PCF or any func\u00adtional language L based on the typed \nXcalculus, we must define a family of domains !l~ and a family of meaning functions 87. The domain DT \nconsists of the denotations for closed terms of type r; ~, : L, + DT is the meaning function that maps \nthe set LT of closed terms of type r to their meaning. Figure 1 contains the conventional function model \nof PCF; it interprets each type u --+ T as the set of all continuous functions from type u into type \n~. Given a denotational model M for the language L, we define the notion of observational equivalence \nand full abstraction as follows [14]. Definition 2.1. (Denotation/ Equivalence, Observa\u00adtional Equivalence, \nFull Abstraction) Two closed ex\u00adpressions, Ill and Al , in L are denotationally equivalent in a model \n.&#38;f, written ill =M &#38;f iff ~[kf] = g[lf ]. They are observaiionatly equivalent, written M z M \n, iff for all integer contexts C[ ] such that C[M] and C[M ] are programs, ~[C[M]] = ~[C[M ]]. A model \nM is fully abstract iff M = M implies M EM M for closed M, M . Remark. Observational equivalence only \ndepends on the meanings of complete programs. Hence, it is inde\u00adpendent of the choice of model as long \nas the models agree on the meanings of complete programs. The standard denotational model for PCF is \nnot fully abstract because the domain of continuous functions in\u00ad cludes parallel functions like paralleLand, \nyet PCF can only define sequent ial functions. Given the denotational semantics determined by D and \n~~, we can also define what it means for the lan\u00ad guage L to be sequential. Definition 2.2. (Sequentiality) \nL is sequential iff the following condition holds. Let Ml through kfk be expressions and let C[A41, . \n. . . &#38;fk] be a program such that SICIIW1, . . . , &#38;f~]] = n for some n e N yet Domains: c) = \nNL ~.-b. = [Dr -. D ] Meaning Functions: ~[e] = [e]@ where [kn]cL = kn A z.z = I A*z.M = apply(K, M) \nif x is not free in M = &#38; =f x A*2?. apply(Ml , M2) = appb(appb(S, A*z.MI), A*m.M2) [(it!f,kf,)]~L \n= Cq@y([itfl] CL, [~d CL) [Ax.M]CL = ~ X.[M]cL and, for 1,m, n c N, apptg(f, a) = f(a) addl(m) = m + \n1 addl(l-) = J\u00adl(x) = z subl(m + 1) = m subl(o) = subl(L) = 1 K(x)(y) =z if =m if = J\u00ads(x)(y)(z) = [x(z)] \n(y(z)) ifO(l + l)(m)(n) = n Y(f) = U{ fi(L) Ii G N} Figure 1: The Continuous Function Space Model for \nPCF qc[fl ,.. ., Q]] = ~[fl]. Then there exists a j such of PCF, which requires (sub 1 ko) to diverge, \nit is far that 8[C[ikf~, . . . . j-l, more informative from a programmer s point of view. It Q}~j+I, \n. . .,~~]] = $[0] for all M:. also permits programmers to observe the order of eval\u00aduation in programs \nby conducting simple experiments. To provide PCF with error generators, we add two It is straightforward \nto prove that PCF is sequen\u00adconstants, errorl and error2, of ground type to the lan\u00adtial [16: Activity \nLemma]. guage and force all procedures in the extended language to be error-sensitive. An operation is \nerror-sensitive if it 3 Observing Sequentiality propagates any errors that it encounters in evaluating \nits arguments. In PCF with errors, a programmer can ob-PCF omits many features that are essential in \nprac-serve the evaluation order of subexpressions by exploit\u00adtical languages. One of the most glaring \nomissions is ing the error-sensitivity of all program operations. For the lack of any provision for generating \nrun-time errors any pair of subexpressions, the programmer can replace and performing non-local exits. \nAlthough this design each one by a distinct error value and observe the be\u00adchoice simplifies the definition \nof the language, it has havior of the modified program. If either subexpression thwarted efforts to construct \nfully abstract models for is used in the evaluation of the original program, the PCF and similar sequential \nlanguages. In the following modified program returns the error value corresponding paragraphs, we explain \nwhy the addition of two simple to the subexpression that is evaluated first. As a re\u00adcontrol mechanisms \nto PCF is important from the per\u00ad sult, the programmer can distinguish distinct versions spective of \na language designer and how their presence of {commutative procedures such as the addition pro\u00ad in a \nprogramming language affects the construction of cedures +1 and +r defined in Section 2, The expression \na denot ational model. (+1 errorl errorz) produces an errorl because +1 eval\u00aduates its left argument \nfirst; (+r errorl errorz ) returns error2 because +r evaluates its right argument first. Using errors, \nprogrammers can observe the or\u00ad der of evaluation. The most obvious omission from PCF is a provision \nfor computations to generate errors. Using error handlers, programs can observe the Any practical implementation \nof PCF would signal an order of evaluation. In PCF with errors, the sequen\u00aderror for an application of \nthe procedure subl to k. be-tial behavior of procedures is observable externally by cause the latter \nis an invalid input for the former. Al-the programmer but this information is not accessible though this \nbehavior is inconsistent with the semantics internally within programs. Consequently, a program cannot \ndetermine the order of evaluation among the ar\u00adguments in a procedure application. To express these computations, \nthe program must be able to delimit the dynamic extent of control actions such as generating errors [20]. \nFor this reason, many practical languages include an error handling facility or a non-local control operator. \nThe original version of Scheme [22], for example, cent ained a lexically-scoped catch construct for \nimple\u00ad menting non-local exits from expressions. Hence, the evaluation of the expression (catch e (addl \n(e O))) would return O by popping the control stack back through the lexical binding of e in (catch \ne . ..) af\u00adter encountering the sub-expression (e O). With such a catch construct, it is possible to \nwrite a program that determines the order of evaluation of a procedure s ar\u00adguments, e.g., the procedure \nG = (Af.catch z ($ (x O) (z l))) maps +1 to Oand +r to 1. To add this capability to PCF, we introduce \na family of catch procedures with types (rl ~ . . . Tn ~ o) ~ O. If ~ is a procedure of type (71 ~ . \n. .tn -+ o), then (catch ~) returns either i l if ~ evaluates the ith ar\u00adgument first or k+n if ~ is \na constant procedure with result k. Alternatively, (catch ~) is i 1 if (~~ errorj Q .1. q) i-1 n-i returns \nerrorj for ~ = 1, 2. In PCF, the catch procedure has the same expressive power as Scheme s (downward) \ncatch construct, but the catch procedure has a simpler semantic definition and is better suited to proving \nthe represent ability lemma (see Section 5). We designate our sequential extension of PCF by the name \nSPCF. Definition 3.1. (SPCF) SPCF is PCF with constants errorl and error2 of type o and with catch procedures \nof type (tl ~ . . .tn+o)~o foralltl, . . ..tn. Procedure denotations contain more computa\u00adtional structure \nthan ordinary function graphs. Conventional models for languages like SPGF are writ\u00adten in continuation-passing \nstyle to cope with the be\u00adhavior of control operators. Since this form of model contains parallel functions, \nit is not fully abstract for sequential languages [20]. To construct a fully abstract model for SPCF, \nwe need to develop a new form of model that excludes parallel functions. The informal operational semantics \nof SPCF (particularly the catch operator) suggests that procedure denotations should have more internal \nstructure than function graphs. In particular, they should explicate the order in which ar\u00adguments are \nevaluated. Consider the procedure p = Atozyz. ifo z (y+ 1) (z 2). It has type o ~ (o ~ (o ~ (o ~ o))), \nwhich means we can view it as a procedure mapping quadruples of inte\u00adgers to integers. The procedure \np evaluates its second argument x first, but the subsequent evaluation order depends on the value of \nz. If x is O, p evaluates its third argument y next; otherwise it evaluates its fourth argument .z. To \ncapture this information, we can de\u00adfine the denotation of p as the index 2 paired with a function that \nmaps the value of the second argument to appropriate information, The rest of the denotation can be described \nin the same manner: if the first argument is 0, p maps the third argument g to y + 1; otherwise, it skips \nthat argument and decreases the value of the fourth argument by 2: 1,+1 errorl H errorl errorz M errorz \nll+_J\u00aderrorl w errorl errorz H errors 0-(3, ) 1*2 owl (2, ) L-d\u00aderrorl w errorl errorz H errorz () HL \n1 H (4, ) 1 HJ_ 2 H-O 3H1 ...  ( ... Since p is continuous and error-sensitive, it must map 1 to -1-and \nerrori to errori. If we rotate this object, we can view it as a decision tree: (2, ?) o ... (3, ?) A \nnode represents a query about the ith argument; for clarity, we will henceforth represent the argument \nindex z by the pair (i, ?) in decision trees. The branches below a node are labelecl with the possible \nvalues of the ith argument. The target node for each branch specifies what happens next. If it is a simple \ninteger, 1, or error, p has completed its computation; otherwise, it continues to query its argument(s). \nWe have omitted the branches that map 1 to -1 and error~ to error~ to avoid cluttering decision trees \nwith implied information. Higher-order procedures explore trees sequen\u00adtially. After deciding that procedures \ndenote decision trees, it is natural for us to ask how higher-order pro\u00adcedures process procedural inputs. \nGiven that trees re\u00adsemble LISP S-expressions, we can visualize higher-order procedures as processes \nthat examine decision trees in essentially the same manner as LISP procedures tra\u00adverse S-expressions. \nTo simplify notation, we express queries as patterns that match paths in decision trees. More specifically, \na query is a rooted finite path of nodes and edges in a decision tree terminated by the marker ? . This \nmarker identifies the node that the procedure wants to inspect. The answer produced by the query is the \ninformation stored in the specified node. If this match yields 1 or errori, the result of the entire \nprocess is 1-or I errori. Like a LISP procedure, a higher-order procedure can inspect a node in an input \ntree only after inspecting its predecessors. To illustrate this process, let us examine the behavior \nof the procedure F = Af. (addl (~ Q 02 errorl)), When (the tree representing) F is applied to an argument \ntree f, it knows nothing about the value of !. Since F needs to know how f behaves on certain arguments, \nit asks the question (1, ?) to determine the root off. If the value of f is the procedure p described \nabove, the response to this question is (2, ?), which is the contents of the root of p. Now P knows that \nf first demands information about its second argument. To find out more about f, F must provide the information \nthat f has requested, which is O. This information determines the subtree within f that F wants to inspect. \nThe information is specified by extending the previous response by the edge: Matching this pattern against \np yields the node value (3, ?), which is a query about p s third argument. F passes the value 2 as the \nthird argument to f. Con\u00adsequently, F s next query to f has the form: (2, ?) (3,?) 0 2 <? Matching this \npattern against p yields the leaf value 3, which is a final answer from p. Since the subcomputa\u00adtion \n(~ Q 02 errorl) is complete, F can proceed to add to the result of calling f yielding the final answer \n4. The preceding query-response protocol can be repre\u00adsented by a tree whose nodes are labeled with queries \nand whose arcs are labeled with the possible answers. Figure 2 shows part of the denotation of F, including \nthe path that we just discussed. It also includes paths that describe how F interacts with procedure \narguments that immediately demand the value of their first or fourth ar\u00adgument: in the former case F \nreturns 1; in the latter case, F signals errorl. The other branches in the tree denoting F have been \nomitted. When procedures are represented as trees, it is easy to see that higher order procedures can \nextract apparently intensional information from procedural arguments. For example, the following tree \nrepresents a procedure that maps unary constant procedures to 1, and strict proce\u00addures to O: (1, ?) \no 11 Similarly, the catch procedure extracts information about the evaluation order of its argument. \nHowever, this information is not intensional because distinct trees represent distinct continous functions. \nThe presence of error values in the ground domain combined with the convention that all procedures are \nerror-sensitive makes evaluation information extensional. In Section 4.2, we prove that there is a one-to-one \ncorrespondence be\u00adtween the graphs of observably sequential functions and their tree representations. \nDecision trees simply iden\u00adtify mathematical structure that is present within error\u00adsensitive functions,3 \n4 The Tree Model A model of SPCF has essentially the same form as a model of PCF. It consists of a family \nof Scott domains D and a family of meaning functions &#38;. In our model 3 Berry and Curien [3] proposed \nrepresenting procedures as trees in their work on concrete sequential algorithms. Since their domains \ndo not include error elements, they associate distinct trees with the same function. For example, +1 \nand +r denote distinct concrete sequential algorithms but denote the same func\u00adtion [3:316]. In this \nframework, evaluation information is intew sional. In later work [4, 8], Berry and Curien noted that \nsequen\u00adtial algorithms can distinguish different algorithms for the same function[8:210]. But they did \nnot make a connection between intensional procedures and control operators like catch. Recent discussions \nwith Curien have revealed a surprising re\u00ad lationship between Berry and Cnrien s model for PCF and our \nmodel for SPCF. If we restrict our model to the operators in PCF and project error values onto 1., our \nmodel is isomorphic to theirs [P.L. Curien (ENS): personal communication, May 1991]. (1, Q3) 3 g (% o \n3 ($?) 41 2 <? Figure2: A Fragment of Procedure F of SPCF, the former are domains consisting of the \ndeci\u00adsion trees described in the previous section. Each mean\u00ading function &#38; is a map from closed \nSPCF terms to trees in the appropriate domain. To define these mean\u00ading functions, we rely on extensions \nof the translation and abstraction algorithms, [.] CL and A for PCF (see Figure 1). However, we interpret \nthe combinators pro\u00ad duced by this translation as decision trees; the function apply : D - x w -+ D converts \ndecision trees into functions. In the following subsection, we define our tree do\u00admains. Next, we define \nthe apply functions and prove that our tree representation is extensional: procedural trees are identical \nprecisely when they cannot be distin\u00adguished by apply. In the third and fourth subsection, we assign \ninterpretations to the procedural constants and the combinators associated with SPCF, and prove the basic \nequational properties of the tree model. 4.1 Domains A Scott domain is the ideal completion of a jinifary \nbasis [6, 18, 19]. A finitary basis B is a countable, partially ordered set such that every finite, bounded \nsubset has a least upper bound; the principal ideals corresponding to elements of B are the jinite elements \nof the domain determined by B (the set of ideals over B). By this construct ion, a domain is a consistently \ncomplete, w\u00ad algebraic cpo. In discussing domains, it is convenient to ignore the distinction between \neIements in the finitary basis and corresponding principal ideals. Our definition of the domains for \nprocedure types re\u00ad lies on the notion of legal queries and responses for lower\u00ad type arguments. For \neach domain D , we define a set of queries Q , which higher-type objects can ask about elements of type \nr, and a set of proper responses W to such queries. Since the behavior of error-sensitive func\u00ad tions \non the answers {J-, errorl, errorz } is predetermined, we do not include these answers within the set \nof proper responses that appear in tree representations. The pre\u00adcise definition of !3 - is rather subtle. \nWe start by giving a preliminary definition that cent ains too many elements. Then we refine that definition \nto achieve a one-to-one correspondence between decision trees and observably sequent ial functions. The \ndefinition of the set of domains D for each type T proceeds by induction on the structure of r. For pro\u00adcedure \ndomains, we use the expansion of the type into a map from arbitrary k-tuples to ground types so that \nwe can refer to all possible argument indices. Type ~ = o: Expressions of observable type denote either \na natural number, the diverging computation (1), or an error value: where E = {-L, errorl, error2}. The \napproximation ordering is the usual one, that is, 1 approximates all other elements, and the rest of \nthe elements are mutually incomparable. The only possible query about an argument of type o is the initial \nquery ? since the response completely determines the element. The only proper responses to this query \nare integers. Consequently, we define the set of ground queries and proper responses aa follows: R = \nN. Q = {?} Type T = rl -+ . . . ~ rk ~ o: Finite higher-order objects are finite decision trees. Every \npath within such a tree is finite and all leaves are elements of N~. In addition, only finitely many \nbranches below each non\u00adterminal node are not 1. Thus, we can inductively de\u00adfine the set of finite elements \nof D follows. A finite tree of type ~ is either: 1. aleaf in N~, or Elements : KY(p) = N~ u {(i, g, \nf) I I<i<k, qEQ i(p(i)), f: r c R (q) I+ d E D (PU {(i, T)}), {~ I f(r) #~} is finite} Paths: Queries \n: Q = P(&#38;Z{?}, 0) Legal Q r((i Queries : Q (P) Q (n) G? r((i 9)) q, (r, r ))) = = = = { {?} {q \nGQ r(T) lr6p, fordlr 0 {(i f?,(~,?)) I r e ~r (d} {(i !7, (~, d)) I9 c Q T*(r )} Ep:z@r} ifp=fl ifp#O \n&#38;8pOt18t38 ; R = P(M.N u {(i, q, 1) i i<k, q c Q (p(i))},@) Legal Responses ; R (q) = {r c ~ I \nr = q[?/a] for a G N or T = q[?/(i, p, 1)]} Figure 3: Elements, queries, and responses at T = rl ~ . \n. . ~ r~ ~ o 2. a triple (i, q, ~) consisting of an index i, 1< i < k, a query q of type Ti about the \nith argument, and branching function f that maps proper responses to finite trees. For all but a finite \nset of proper re\u00adsponses, called the proper domain off, the function f must produce the value 1. In pictures, \nwe represent a tree (i, q, f) as a node la\u00adbeled (i, q) with an outgoing edge labeled r for each response \nin the proper domain off; each edge r is at\u00adtached to the subtree f(r). For each type r, we tentatively \ndefine the set of queries ~ and responses W as follows. Queries and responses of type r designate paths \nin trees of type r; they have exactly the same concrete representation as finite trees with two exceptions. \nFirst, the domains of branching functions in queries and responses contain at most one element. Second, \nthe degenerate query is de\u00adnoted by the special marker ? and the final branch\u00ading function in a query \nmust map a response r to ? . Within a path, we denote the branching function that maps the response r \nto path p by the pair (r, p). Sim\u00adilarly, we denote the everywhere undefined branching function (which \nmay occur at the end of a response) by 1. The ? marker at the end of each query identifies the node value \nthat the query is seeking. Replacing the ? marker in a query q with a final answer in N or an intermediate \nanswer (i, q, J-) yields a response to query g. The notation q[?/lV] denotes the response to q ob\u00ad ~~?>> \nwith the tree node ~. Every response r of type T is a finite tree in 13T. Every query q of type r becomes \nan element of D if we replace ? by J-; we define 7f as q[?/L]. For the sake of brevity in notation, we \nabbreviate the triple (i, q, 1) by the pair (i, q). Similarly, in pic\u00adtures, we represent the response \nlabeling each edge by the answer that replaces ? in the corresponding query instead of the entire response. \ntained by replacing Unfortunately, the preliminary definitions of 0 , v, and W given above are too broad \nto constitute an extensional representation for error-sensitive functions. There are three sources for \nthis imprecision. First, the definition of D permits duplicate queries in trees, implying that many different \ntrees represent the same function. Second, the definition of trees does not require a procedure to inspect \nall the predecessors of node N in an argument tree before inspecting N. Finally, the definition of W \ndoes not guarantee that the responses to a query are appropriate. We can solve these three problems by \nmaintaining an environment that accumulates the responses that ap\u00adpear on a path from the root of a procedure \ntree to a given node. We refer to this environment as the tree context of a node. We will use the term \ncontext in place of tree context, unless it is ambiguous. Technically, a context is a relation mapping \nargument indices to re\u00adsponses; we use it as if it were a set-valued function. A context contains the \nknowledge that the procedure has gathered about its arguments at a given point in a computation. More \nprecisely, given the context p of a node N in a procedure P, u p(i) G DTI is the finite approximation \nfor argument z of type ~ known to P at node N during a computation. Given the context of a node N, we \ncan determine the set of queries about each argument that are legal at node N: a query q with index i \nmust extend the approx\u00adimation tree U p(i) for the ith argument by exactly one node, which is identified \nby a ? in the query q. This restriction on queries guarantee&#38; that queries cannot be duplicated. \nIt also guarantees that all the predecessors of a node N in an argument tree are inspected before N \nis inspected. We formalize the set of legal queries by defining a function Q that maps the set of prior \nresponses for a particular index to the legal set of queries; the definition is given in Figure 3. In \nthis definition, the auxiliary function Q maps a legal response r to a set of queries extending the response \nby a branch (r , ?) where a is a legal answer to the query at the end of r. This set is empty if the \nresponse terminates with a final answer rather than a query. Pictorially, we have: 2 Q (i, q) (i, q) \nr ? ! Figure 3 contains the formal definition of Q . The last problem that we must address is the def\u00adinition \nof the legal responses to a query q. But this question is easy: a response q[?/N] to q is legal iff the \nnode N can appear at the point specified by q in the selected argument tree. This test reduces to confirming \nthat the response q[?/N] is a well-formed tree. Since arguments are trees of lower type, this reduction \nis not circular. Based on the preceding analysis, we can now finalize the definition of finite elements \nfor procedure types. We parametrize the definition of the sets D over contexts p and demand that subtrees \nof the shape (i, q, f) E DT sat isf y the following conditions: 2. .f : r E R(q) H dE D (pu{(i, r)}), \nand 3. {r I f(r) #l} is finite.  The inductive definition is summarized in a set of equa\u00adtions in Figure \n3. The set D(p) contains all subtrees appropriate for tree context p. The domain of finite ele\u00adments \nis made up of the subtrees that exits in the empty context. The approximation order on this domain is \nthe ex\u00adpected one. If dl, dz are trees in ~ then ctl ~ dz if dl is a prefix of dz. Definition 4,1. (Approximation) \nLet p be a context, and let d, d be subtrees in D(p). Then, d ~ d 1. ifd=l; or 2. if d = (i, q,f), d \n= (i, q,g) and ~(r) ~ g(r) for all r C R(q).  This finishes the formal definition of the finite ele\u00adments \nof the family of domains llr. It is tedious but straightforward to prove that the functions Q and RT \nare well-defined and that !37 is a finit ary basis. The ideal completion process adds infinite trees \nto the finite elements in each domain D .  4.2 Application The function apply : D +r x D -D7 interprets \ndeci\u00adsion trees aa functions. Given a sub tree of a procedural tree and an (entire) argument tree, it \nproduces a sub\u00adtree for the appropriate context. More specifically, for inputs ~ in DU+7 and z in W , \napply (f, Z) is defined by case analysis on ~: 1. If f is a constant, apply ignores the value of x and \nreturns the value f. 2. If f is a tree of the form (1, q, f ), apply performs a pattern match between \nthe specified query and the argument Z. For proper responses r, apply selects the appropriate branch \nin the branching function, f (r), and continues the process of constructing the output tree. The improper \nanswers errorl, error2, and 1 are mapped to errorl, errorz, and -l_, respec\u00adtively. 3. If f is a tree \nof the form (z + 1, q, f ), appiy con\u00adstructs a new decision tree of type T of the form (i, q, g ) where \ng is constructed by recursively pro\u00adcessing each subt ree f (r) for each response r.  Figure 4 contains \nthe formal definition of the function apply including the definition of the auxiliary function match. \nThe match function compares a query q with an element ~ and returns a response replacing ? in q with \ncontents of the node that matches ? in x. If the matched node is an error value or bottom, match returns \nthe node value instead of a response. It is easy to show that apply and match are well\u00addefined, i.e., \napply only uses match on arguments for which it is defined, and apply returns a subtree of the stipulated \ntype and tree context. The function apply determines an approximable mapping on finite de\u00adcision trees \n[19]. Consequently, we can extend apply to a cent inuous function on arbitrary elements. More importantly, \nwe can prove that the model is order\u00adextensional.4 capply(d, C4pply((l, q, f), app~v((i + 1,9, f), dl \n) dl) dl) = = = d ifd~N~ { :pply(f(T), ~1) where T = rnatch(q, (i, ~,~ fi.C3J3ply( f(7 i), ::: dl ) all)) \nmatch((i, rnatch(?, d) rnatch(?, (i, q, f)) q, (r, 9 )), (i 9) f)) = = = d ifd~N~ (i, q) { :; q (?., \n7. )) 5: whe;e r = match(g , E f(r)) Figure 4: Application in the Tree Model Definition 4.2. ( Order-extensionality) \nLet L be a language conforming to the syntax of the typed lambda calculus with constants. A model M interpreting \nL is order-extensional iff for all ~, g c ii + , apply (f, d) ~ apply (g, d) for all d ~ D implies ~ \n~ g. Theorem 4.3 The Tree model for SPCF is order\u00ad extensional. Proof. Assume apply(.f, d) z apply (g, \nd) for all d E D , but ~ ~ g. Recall that ~ = U{t ] ~ ~~, f finite }, g = I-l{g I g ~gt g finite }. Thus, \nthere exists a finite ~ C ~ such that f Q g. Hence, for all finite g z g, jt is also true that f ~ g \n. By the following lemma, there exists a finite d such that apply( f , d) ~ apply (g , d) for all g ~ \ng. Since appiy(g, d) = U{appiy(g , d) I g ~ g}, we also have apply ( f , d) ~ apply (g, d) by the finiteness \nof apply ( f , d). Since apply is monotonic, appiy ( f, d) ~ apply (g, d), which contradicts our assumption. \ni Thus, the extensionality of arbitrary decision trees reduces to the extensionality of finite decision \ntrees. Lemma 4.4 Let f, g be finite elements in D +a. If for a!l jinite d G DT, appiy(f, d) ~ apply (g, \nd) then f E g. Proof Idea. The proof proceeds by induction on the depth of the tree g. The induction \nstep is a case analysis on the possible differences between corresponding nodes of f and g. The error \nelements in the domain play a crucial role in the proof. If f and g are identical except for one node \nwhere they make different queries about d (the first argument), we can construct an input that places \nerrorl in the position specified by f and errorz in the position specified by g. s 4P.L. Cnrien (ENS) \n~ersonal communication, August 1991] pointed out that the order-extensionality theorem does not hold \nif the model ord y contains one error value. For example, the functions error and (1, ?, Az.error) are \nincomparable, yet for all d, apply((l, ?, Az.error), d) ~ app[y(error, d). On the other hand, while a \nmodel based on a single error value is not order\u00adextensiorml, it is still extensional. We also conjecture \nthat such a model is fully abstract. S. Brookes (CMU) ~ersonal com\u00admunication, October 1991] au~geeted \na modified approximation ordering, in which successive nodes that are behaviorally indis\u00adtinguishable \ncollapse. Under this ordering, the model based on a single error is still order-extensional but at the \ncost of making the ordering ineffective. The extensionality theorem implies that the domain ~ + is isomorphic \nto a domain of functions from El to Do defined as follows. Definition 4.5. (FLn - ) For each ~ in D -u, \nlet fun(f) denote the function &#38; : D .apph(f, z). The domain Fun - is the set {fun(f) I f G D7-U \n} under the pointwise ordering on functions: f ~ g W f($) z g(~) for all $ in D . Corollary 4.6 D + is \nisomorphic to FLnT+ . 4.3 Assigning Meaning to Terms To assign meaning to phrases in SPCF, we translate \nprograms into a sublanguage without A-abstractions but with combinators S, K, 1. The translation is based \non the conventional abstraction algorithm (see Figure 3): .. M .. knlzl SIKlll Ylapply(M, M) I addl I \nsubl I ifO I catch [ error After the conversion, it suffices to interpret the primitive functions and \ncombinators. Figure 5 contains pictorial and formal definitions for the primitive combinators. The definition \nof the other combinators is tedious. We explain the general idea by defining the denotation of K. Recall \nthat, in a typed setting, K is supposed to represent the abstraction h~+  + .h~.(h~ . . .~~+z.~l~s . \n. . ~~+a) Thus, K begins the evaluation process by probing the first argument, Z1. If Xl returns a constant \nanswer, K returns this answer as its own final answer. If Z1 re\u00ad sponds with a query about its ith argument, \nK directs this query to Xi+z, ignoring X2. The answer of xi+z to this query is the information that x \n1 needs to know. Thus, after obtaining a response from ici+2, K probes XI again with a new query that \nextends of xl s response with the additional information provided by xi+2. The next response by x 1 is \nsubjected to the same case anal\u00ad ysis as the first one. We can formalize this process by defining a chain \nof finite approximations that encode the recursi~e process; KO(q)(r) = 1 K~+l(q)(g[?/a]) = a if a E \nN (1, ?) (1, ?) o 0 1 2 3 4... 1 01 2... addl subl (1, ?) (~,?) o 0 k k+l k+2 ... o 1 . (2,?) (q,?) \n(3,?) (3,?) ... catchk kc:Nl k~ N kc N k~ N kkkk ifOO addl = (1,?, {(n, n+ 1) In c N}) subl = (l, ?,{(n+ \nLn)ln c N} U {(0,1)}) ifOO = (1, ?, {(cI, (2, ?, (j : N.j)))} U {(n + 1, (3, ?, (M : N.j))) I n c N}) \ncatch~ = (L?, {(j,.i+ k)l.i~N} U{((j, ?),j-l)ll<j Sk}) Figure 5: Primitive Combinators Kn+l(q)(q[?/(i, \nP)]) = (i+ 2,P, ~~ .(l, d?/~1, f)) This implies that the ,0 axiom for bracket abstractions is valid in \nthis model [1]. where ~ = Kn(q[?/n]) Corollary 4.8 ((/3)) For combinator terms M, M , n = (i, p, (r \n, ?)) (A*z.M)M = M[z -M ]. K is the limit of these approximations: To determine the important equations \nfor catch and error values, we draw on our operational intuition about K = U{(l, ?, K.(?)) In c N} capturing \nthe behavior of control operators with reduc- It is easy to check that ~un( apply (K, ~)) is like f \nex-tion rules [10, 11]. The main idea is to formalize the notion of a program counter for program text, \nthat is, cept that the new element contains a node of the shape a tool that determines which term in \na program must (i+ 1, q) where $ contained a node of the shape (i, q). I and S are defined along the \nsame lines as K. Y can be evaluated next in order to determine the program s answer. We do this by int \nreducing the auxiliary notion of evaluation context: YM = U{apply (M, -L) I n E N}. be defined in the \nusual manner: E ::= [ 1I wpb(?, E) I apply (E, M)  4.4 Properties of the Model I apply (catch, (A-zl, \n. . . . Zn.E)) The combinators K and S satisfy the usual equations. ~ ::= addl Isubl I ifO Lemma 4.7 \nAn evaluation context is a context whose hole is in leftmost-outermost position, that is, the path from \n appZy(K, s,y) = z (K) the root to the hole is such that only strict primitive apply (apply (appig(s, \nz), y), Z) = (s) functions are to the left, including applications of catch apply (apply (z, z), awdy(v, \n~)) to an abstraction. If an evaluation context cent sins an Proof. By induction on n for each approximation \nKn error or bottom value in the hole, it denotes error or and S~. m bottom. 338 Lemma 4.9 For all evaluation \ncontexts E, numbers k, To prove that some term represents a subtree, it is and variables xl through Zn, \nconvenient to rely on an equational characterization of the representability criterion. By extensionality, \ncondi\u00ad E[errorj] = errorj tion (ii) above is equivalent to the constraint that catch (A*zl, . . . . \nzn.E[zj]) = j 1 apply (g[M_J, dl, ..., 4) = apply (p[?/e], dl, ..., 4) catch (A*zl, . . . . xn.k) = \nk+n foralldl,..., dk in the appropriate domains. Since p de\u00adtermines a context pP for the subtree e, \nwe restate this (A*zl,..., zn. %j]) = (j,?, f) condition more succinctly. If the arguments dl, . . . \n. dk satisfy the constraints, d~ ~ U pP (i) for all i, then the Proof. We can show that for an appropriate \nbranching function f by induction on righthand-side of the equation above is equivalent to the structure \nof the context. The rest follows directly. m apply (e, dl, . . . . dk). If an argument di violates the \ncon-The equations for catch, the natural equations for the straints {d; ~ U pP (i) }, then the subtree \ne does not numerical primitives, and /3 completely determine an affect the result of the application. \nConsequently, the operational reduction semantics for SPCF [10, 11]. The SPCF expression M represents \nsubtree e c D (p) iff equations also suffice to show in the representability apply (SIM], dl, . . . . \ndk) = app~y(e, dl, . . ., dk)lemma of the following section that certain terms rep\u00adresent given finite \nelements. for all arguments dl,. . . . dk of appropriate type such that d~ z Up(i). 5 The Full Abstraction \nTheorem We are now ready to prove that all subtrees of type T are representable. Since the term M must \nbe a pro- Plotkin [16] showed that an order-extensional model of cedure of type r, it has the form PCF \nwith parallel operations is fully abstract if the lan\u00adguage can define all finite elements in the model. \nEx-ktl, . . ..xB.B actly the same argument carries over to SPCF. Since we know that the tree model T \nis order-extensional, we can where B is an SPCF expression with free variables prove that T is fully \nabstract by showing that all finite Zl, . . ..$k. The construction of B (and the proof that trees are \ndefinable in SPCF. In this section, we use this M represents e) proceeds by induction on the depth of \nstrategy to prove that T is fully abstract for SPCF. subtrees. The remainder of the proof is a nested \ninduc\u00ad tion argument so our induction hypothesis holds for all Theorem 5.1 (Pull Abstraction of T) 1 \ne and e subtrees of type less than ~ and for all smaller subtrees are closed SPCF expressions, then e \n~7 iff e z e . of type T. In the base case, e is a leaf in N~. It is easy to verify Proof. The proof \nfollows exactly the same outline as that for any leaf e other than J_, the expression M = Plotkin s proof \nof the full abstraction theorem for the Xrl, . . . . ~k .e represents e. For e = ~, the expression continuous \nfunction model of PCF with parallel opera-M= Axl, ..., ~k .Y(Az .x) works similarly. tions [16:240]. \nIt relies on the following lemma. ~ In the inductive case, e is a finite subtree (i, q, f) and p is an \narbitrary tree context such that e E D (p) belowLemma 5.2 If d is a jinite element in D , then there \n- root ofdis a closed SPCF expression M such that $[MIJ = d. . 1 .  ----m Proof Sketch. The proof \nof the lemma proceeds by induction on the depth of the type I /root of e (i 4 L  T= T1-. .. Tk+O, k~o. \nr rmrm+l rm+n Since the induction step decomposes the element d into a root, a set of proper responses, \nand an attached set of subtrees, we need to prove a stronger result than the lemma because subtrees of \nd are not necessarily trees in m> fl ftn+l fm+n fin D . Specifically, we must prove that every finite \nsubtree e of a finite element din II is representable in SPCF. Let the proper domain of the branching \nfunction f be A subtree e is representable iff there is a term M and the set {rI, ..., rm+n } where the \nresponses rl, ..., r~ a query p such that (i) p[?/e] is an element of D and end in pairs (hi, pi), . \n. . . (h~,P~) and the responses (ii) S[M] = p[?/e]. This definition of subtree repre-rm+l, . . . , rm+n \nend in the final answers al, , . . . an, We sentability reduces to tree representability when e is a \nrefer to the former as final responses and to the latter as decision tree and p is empty. query responses. \nEach edge labeled with ri points to a subtree fi whose root node is not bottom. Let fl, . . . . fn denote \nthe subtrees of e corresponding to the responses rl, . . ..n n. By the induction hypothesis, each subtree \nfi is representable by an SPCF expressions Fi. The execution of procedure M = ~xl . . . Xk .B must first \ndetermine the contents of the node Nq identified by q in the value bound to xi. More precisely, M must \ndetermine which, if any, of the responses r;, that the node iVq matches. Given this information, B can \napply Fi (the expression representing the subtree fi) to the arguments xl, . . . . xk. To understand \nthe process of extracting the node Nq from Zi, we need to state some assumptions. Let pg be the tree \ncontext determined by the responses embedded in q. Let the type Ti of xi be al ~ ...q ~ o. Naively, we \nmight construct an expression B that tries to obtain the contents of node N~ by applying Zi to a tuple \nof argument expressions Al, . . . . AZ that encode the infor\u00admation in q about xi s arguments: U pq (i). \nIf N~ is a terminal node, then this naive strategy works. But it fails when N~ is a query node, because \nxi does not return to B until it has gathered enough information from its arguments to produce a final \nanswer. Since Al, . . . . Al only contain the information in p~, xi will not be able in general to gather \nenough information to return a final answer. If xi dominates one of the query responses, say rj, it will \neventually attempt to probe some argument Ah with Pj. When such an event occurs, the naive argu\u00ad ment \nA does not contain the requested information and the query process will diverge. To solve this problem, \nwe need to embed code in A that escapes to B when this information is requested. In SPCF, a program can \nperform non-local exits by applying the catch operator to an appropriate proce\u00ad dure. For our problem, \nwe must define a A-abstraction M of m arguments that requests the jth argument pre\u00ad cisely when xi dominates \nthe query responses Let rj. Yl, ..., y~ be the parameters of M . The key steps in writing the code M \nare 1. to associate each query response rj with the pa\u00adrameter Yj, 2. to embed variable yj in the argument \nAh if rj ends in (h, pj), and 3. to apply xi to these arguments.  Hence, M has the form A*yl, . . ..yziAIAl \n. ..A/ where the parameters yl, . . . . Ym appear free in the ar\u00ad gument expressions Al, . . . . A/. \nThe precise form of the expressions Al, . . . . Al depends on the query q. For the moment, let us assume \nthat we can construct the argu\u00ad ment expressions Al, . . . . Al. The application of catch to the J-abstraction \nM iden\u00ad tifies which proper response rj (if any) that ~i produces for query q. Given the value j, M can \ninvoke the code Fj representingthe sub tree fj by performing a case split. Without loss of generality, \nwe assume that the final an\u00adswers are sorted: al < az < . . . < ati. Then M is: A xy. ..x:. let w = catch \n(A*yl, . . .,y~.ziAl . . .A~) in (ifo w Flzl ...xk ~ifti (sublm-l W)~mXI...Xk (ifO (subl +~ w) Fm+lxl \n. . .zk ~;f~ (subla +m~~ W)Fm+nXI . . .X~ Q)...) )...) The notation (subl~ w) denotes the b-fold application \nofsubl to W. By the preceding argument, we have reduced the task of constructing M to constructing the \nargument expres\u00adsions A1, ..., Al. Let i be an index in the range 1,...,1. The construction of Ai falls \ninto one of two cases. In the first case, no query response rj asks for more infor\u00admation about the ith \nargument. In this case, we let Ai be the code representing the tree U pg (i), which exists by the induction \nhypothesis because the type CTi of Ai is smaller (shallower) than T. In the more interesting case, there \nis some number s of query responses for index z below the root of e. Assume without loss of generality \nthat these query-responses are rl = q[?/(hl, pi)], . . . . r. = q[?/(h~, p~)]. We know that the queries \npl, . . . . ph extend the information in u pg(i). Consequently, we can form the tree di = Upg(i) Up~[?/(t+ \nl,?)] . .. Up~[?/(t+ b.?)] where t denotes the arity of type ui (the type of Ai). By the induction hypothesis, \nwe can represent this finite tree by an expression A; because the type of di is smaller than r. Without \nloss of generality, we can assume that Yl, ..., y. are the variables that are associated with the queries \npl, . . .p$. Thus, we can define the expression Ai as follows: A~=Azl, . . ..zA{zlzztylztyl . ..y$. This \ncompletes the proof sketch. This sketch omits a proof that the term M indeed represents the subtree e, \nbut given the term, this proof can be constructed based on the equations about catch in the previous \nsection. For a more detailed proof, we refer the reader to our technical report [7]. ~ 6 Observable Sequentiaiity \nin PCF It is easy to show that SPCF is sequential. Let CIM1, . . . . Mk] be a program satisfying the \nhypothesis of Definition 2.2, that is, ~{CIM1, . . . . Mk]] = n and qcp, ....Q]] = S[fl]. We must show \nthat there is one argument position j that forces divergence. Since the model satisfies the equation \n/3, we have: C[kfl,..., iwk]= app/y(A*xl . ..zC[zl.l, z~],Ml,,,Mk), ., Mk), Hence, it suffices to consider \nthe denotations of k-ary procedure (A*X, . . .x&#38;. c[zl, . . .,2%]) The possible denotations of such \na procedure are ei\u00adther elements of hJ~ or triples of the form (j,?, ~) for some j< k and some branching \nfunction ~. Clearly, the first case contradicts the hypothesis of Definition 2,2. The second case specifies \nthat the k-ary procedure probes its jth argument first. But this fact implies that C[ ]1 . . . [ ]~ diverges \nif the expression in jth hole diverges regardless of the expressions in the other holes. Hence, the program \nbehaves sequentially. But SPCF satisfies a stronger condition than sequen\u00adtialit y; every procedure propagates \nany errors that are encountered during program evaluation. We formalize this stronger condition, called \nerror-sensitivity as fol\u00adlows. Definition 6.1. (Error-Sensitivity) A language L based on the typed ~-calculus \nis error-sensitive iff there exist two closed expressions El and E2, denot\u00ading distinct and inconsistent \nelements of a flat do\u00admain for the ground type, with the following prop\u00adert y. Let C[kfl, ..., Alk] be \na terminating program such that S[C[A41, . . . . jtf~]] = n for some n g N yet qc[$-1, .,., 0]] = S[!2]. \nThen there exists j such that $[C[I14~, . . . . A4~_l, E;, Mj+l, . . . . M~]] = g[Ei] for all Al{, I</<k. \nTheorem 6.2 SPCF is error-sensitive. Proof. By exactly the same analysis presented in the preceding proof \nof the sequentiality of SPCF, the pro\u00adgram C[. . .] returns errori if the jth argument is error~, regardless \nof the values of the remaining arguments. ~ Error-sensitivity implies sequentiality. Theorem 6.3 If a \nlanguage L is error-sensitive, then it is sequential. Proof. Let CIAfl, . . ., kf~] be a terminating \nprogram such that ~[C[iVfl, . . . . &#38;lk]] = n for some n c N yet t[c[tl, . . . . Q]] = 2[S2]. Since \nL is error-sensitive, there exists j such that S[C[M; , . . ., M;_l, Ei, M;+l, . . ., M;]] = SIEI] and \nqc[f kq,..., M;_l, Ez, M;+l, . . ., Mj]] = S~E2n for all Jf/. By monotonicity, qc[kq, . . . . ~;-l,fl~;+l, \n. . .,W1 F w%]  &#38;[c[M{,!..,M;_l, fLiw;+l, ...,iwi]] g w72]. Since El and Ez denote inconsistent \nground values in a flat domain, which is precisely what sequentiality demands. m The error-sensitivity \nof SPCF implies that the tree model is extensional. The domain of decision trees of type u + r is isomorphic \nto the domain of error\u00adsensitive continuous functions mapping Do into IIr. But error-sensitivity does \nnot make the decision tree model fully abstract. To represent all error-sensitive functions in SPCF, \nwe need some mechanism within the language for determining the evaluation order of programs, We call \nthis property of languages observable sequentiality. Definition 6.4. ( Observable Sequentiality) An error\u00adsensitive \nlanguage L is observably sequential iff it sat\u00adisfies the following property. Let Ml through Mh be closed \nexpressions and let CIM1, . . . . Mk] be a program such that ~[CIMl, ....M~]] = n for some n c N yet \n&#38;[c[Q ,..., Q]] = S[Q]. Then there exists a program context D[ ] such that $[D[kE1 . . . Zk.CIZ1, \n. . . . Ck]]] = $~]. The catch procedures make SPCF observably sequen\u00adtial. Theorem 6.5 SPCF is observably \nsequential. Proof. We have already shown that SPCF is error sen\u00adsitive. The remainder of the proof is \ntrivial: simply set D[ ] = (addl (catch [ ])). E SPCF is not the first observably sequential language \nthat has been studied in the context of the full abstrac\u00adtion problem. In their work on sequential algorithms, \nBerry and Currien defined an observably sequential lan\u00adguage called CDSO [4]. The sequential algorithms \nmodel for CDSO is fully abstract, but it is not extensional or error-sensitive. Obviously, PCF and PPCF \n(PCF with parallel operations) are not observably sequential. We conjecture that our construction of \na fully abstract model carries over to other observably sequential pro\u00adgramming languages. Since practical \nprogramming languages typically con\u00ad tain non-local control operators that permit program evaluation \norder to be observed, our construction of a fully abstract model for SPCF solves the full abstrac\u00adtion \nproblem for a large class of sequential functional languages. However, it does not yield fully abstract \nmodels for sequential languages that include control de\u00adlimiters [9] (such as prompt). The inclusion \nof control delimit ers in a language prevents it from being error\u00adsensitive, because delimiters swallow \nall errors gener\u00adat ed within their dynamic extent. Consequent Iy, there is still an important class \nof sequential functional lan\u00adguages for which the full abstraction problem remains open. Acknowledgements. \nWe thank Rama Kannegati and Dorai Sitaram for helping hone our intuitions about error-sensitivity and \nsequentiality. Discussions with Pierre-Louis Curien clarified the relationship of our work to sequential \nalgorithms and convinced us that we were working in the tradition of the full abstraction literature, \nSteve Brookes pointed out a mistake in our original definition of sequentiality. References 1. BARENDREGT, \nH.P. The Lambda Calculus: Its Syntax and Semantics. Revised Edition. Studies in Logic and the Foundations \nof Mathematics 103. North-Holland, Amsterdam, 1984. 2. BERRY, G. Modiles compldtement ad~qua~s et sta\u00adbles \ndes lambda-calculus type!. Ph.D. dissertation, University Paris VII, 1979. 3. BERRY, G. AND P-L, CURIEN. \nSequential algo\u00ad rithms on concrete data structures. Theor. C omput. Sci. 20, 1982, 265-321. 4. BERRY, \nG. AND P-L. CURIEN. Theory and prac\u00adtice of sequential algorithms: the kernel of the ap\u00adplicative language \ncds. In Algebraic Methods in Se\u00admantics, edited by J. Reynolds and M. Nivat. Cam\u00adbridge University Press. \nLondon, 1985, 35-88. 5. BERRY, G., P-L. CURIEN, AND P.-P. LfwY. Full\u00adabstraction of sequential languages: \nthe state oft he art. In Algebraic Methods in Semantics, edited by J. Reynolds and M. Nivat. Cambridge \nUniversity Press. London, 1985, 89-131. 6. CARTWRXGHT, R, AND A, DEMERS. The topology of program termination. \nIn Proc. Symposium on Logic in Computer Science, 1988, 296-308. 7. CARTWRIGHT, R.S. AND M. FELLEISEN. \nObserv\u00adable sequentiality and full abstraction. Technical Report TR91-167. Rice University Department \nof Computer Science, 1991. 8. CURIEN, P-L. Categorical Combinators, Sequen\u00adtial Algorithms, and Functional \nProgramming. Re\u00adsearch Notes in Theoretical Computer Science. Pi\u00ad man, London. 1986. 9. FELLEISEN, \nM. The theory and practice of first\u00adclass prompts. In Proc, 15th ACM Symposium on  Principles of Programming \nLanguages, 1988, 180\u00ad 190. 10. FELLEISEN, M. AND R. HIEB. The revised report on the syntactic theories \nof sequential control and state. Technical Report 100, Rice University, June 1989. Theor. Comput. SCZ., \n1991, to appear. 11. FELLEISEN, M., D. FRIEDMAN, E. KOHLBECKER, AND B. DUBA. A syntactic theory of sequential \ncontrol. Theor. Comput. Sci. 52(3), 1987, 205\u00ad 237. Preliminary version in: Proc. Symposium on Logic \nin Computer Science, 1986, 131-141. 12. KAHN, G. AND G. PLOTKIN. Structures des donm% concr~tes. INRIA \nReport 336. 1978. 13. MEYER, A. R. AND K. SIEBER. Towards a fully abstract semantics for local variables. \nIn Proc. 15th ACM Symposium on Principles of Program\u00adming Languages, 1988, 191 203. 14. MILNER, R. Fully \nabstract models of typed A\u00adcalculi. Theor. Comput. SCZ. 4, 1977, 1 22. 15. MULMULEY, K. Full Abstraction \nand Semantic Equivalences. Ph.D. dissertation, Carnegie Mel\u00adlon University, 1985. MIT Press, Cambridge, \nMas\u00adsachusetts, 1986. 16. PLOTKIN, G .D. LCF considered as a programming language. Them. Comput. Sci. \n5, 1977, 223-255. 17. ROSE, J.R. AND G.L. STEELE JR. C*: An ex\u00adtended C language for data parallel programming. \nIn Proc. Second International Conference on Su\u00adpercomputing. International Supercomputing Insti\u00adtute, \nInc. (Santa Clara, 1987) Volume II, 2-16. Also available as: Technical Report No. PL87-5, Think\u00ading Machines \nCorporation, 1987. 18. SCOTT, D. S. Domains for denotational semantics. In Proc. International Conference \non Automata, Languages, and Programming, Lecture Notes in Mathematics 140, Springer-Verlag, Berlin, 1982. \n 19. SCOTT, D.S. Lectures on a Mathematical Theory of Computation. Techn. Monograph PRG-19, Ox\u00adford University \nComputing Laboratory, Program\u00adming Research Group, 1981. 20. SITARAM, D. AND M. FELLEISEN. Reasoning \nwith continuations II: Full abstraction for models of con\u00adtrol, In Proc. 1990 ACM Conference on Lisp \nand Functional Programming, 1990, 161-175. 21. STEELE, G. L., JR. Common Lisp The Language. Digital \nPress, 1984. 22. STEELE, G. L., JR. AND G.J. SUSSMAN. The revised report on Scheme, a dialect of Lisp. \nMemo 452, MIT AI-Lab, 1978. 23. STOUGHTON, A. Fully Abstract Models of Pro\u00adgramming Languages. Research \nNotes in Theoret\u00adical Computer Science. Piman, London. 1986.   \n\t\t\t", "proc_id": "143165", "abstract": "<p>One of the major challenges in denotational semantics is the construction of fully abstract models for <italic>sequential</italic> programming languages. For the past fifteen years, research on this problem has focused on developing models for PCF, an idealized functional programming language based on the typed lambda calculus. Unlike most practical languages, PCF has no facilities for <italic>observing</italic> and <italic>exploiting</italic> the evaluation order of arguments in procedures. Since we believe that such facilities are crucial for understanding the nature of sequential computation, this paper focuses on a sequential extension of PCF (called SPCF) that includes two classes of control operators: error generators enable us to construct a fully abstract model for SPCF that  interprets higher types as sets of <italic>error-sensitive</italic> functions instead of <italic>continuous</italic> functions. The error-sensitve functions form a Scott domain that is isomorphic to a domain of decision trees. We believe that the same construction will yield fully abstract models for functional languages with different control operators for observing the order of evaluation.</p>", "authors": [{"name": "Robert Cartwright", "author_profile_id": "81406592800", "affiliation": "", "person_id": "PP39069984", "email_address": "", "orcid_id": ""}, {"name": "Matthias Felleisen", "author_profile_id": "81100323458", "affiliation": "", "person_id": "PP39037684", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/143165.143232", "year": "1992", "article_id": "143232", "conference": "POPL", "title": "Observable sequentiality and full abstraction", "url": "http://dl.acm.org/citation.cfm?id=143232"}