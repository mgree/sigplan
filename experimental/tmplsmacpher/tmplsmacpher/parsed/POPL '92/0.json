{"article_publication_date": "02-01-1992", "fulltext": "\n The essence of functional programming (Invited talk) Philip Wadler, University of Glasgow* Abstract \nThis paper explores the use monads to structure func\u00adtional programs. No prior knowledge of monads or \ncategory theory is required. Monads increase the ease with be modified. They can mimic features such \nas exceptions, state, and also provide effects not easily features. The types of a program occur. The \nfirst section is an extended and non-deterministic choice. The second section de\u00adscribes the relation \nbet ween monads and cent inuation\u00adpassing style. The third section sketches how monads are used in a \ncompiler for Haskell that is written in Haskell. 1 Introduction Shall I be pure or impure? Pure functional \nlanguages, such as Haskell or Mi\u00ad randa, offer the power of lazy evaluation and the sim\u00ad plicity of \nequational reasoning. Impure functional lan\u00ad guages, such as Standard ML or Scheme, offer a tempt\u00ad ing \nspread of features such as state, exception han\u00ad dling, or continuations. One factor that should influence \nmy choice is the ease with which a program can be modified. Pure languages ease change by making manifest \nthe data upon which each operation depends. But, sometimes, a seemingly small change may require a program \nin a pure language to be extensively restructured, when ju\u00ad dicious use of an impure feature may obtain \nthe same *Author s address: Department of Computing Science, UN\u00adversity of Glasgow, Glasgow G 12 8QQ, \nScotland Email: wadlerfldcs .glasgow .ac .uk. Permission to copy without fee all or part of this material \nis granted provided that the copies are not made or distributed for direct commercial advantage, the \nACM copyright notice and the title of the publication and its date appear, and notice is given that copying \nis by permission of the Association for Computing Machinery, To wpy other\u00ad wise, or to republisb, requires \na fee and/or specific permission. @ 1992 ACM 089791453-8/92/0001/0001 $1.50 1 effect by altering a mere \nhandful of lines. Say I write an interpreter in a pure functional lan\u00adguage. To add error handling to \nit, I need to modify the re\u00adsult type to include error values, and at each recursive call to check for \nand handle errors appropriately. Had I used an impure language with exceptions, no such restructuring \nwould be needed. To add an execution count to it, I need to mod\u00adify the the result type to include such \na count, and modify each recursive call to pass around such counts appropriately. Had I used an impure \nlanguage with a global variable that could be incremented, no such restructuring would be needed. To \nadd an output instruction to it, I need to modify the result type to include an output list, and to modify \neach recursive call to pass around this list appropri\u00adately. Had I used an impure language that performed \noutput as a side effect, no such restructuring would <e needed. Or I could use a monad. This paper shows \nhow to use monads to structure an interpreter so that the changes mentioned above are simple to make. \nIn each case, all that is required is to redefine the monad and to make a few local changes. This programming \nstyle regains some of the flexibility provided by various features of impure languages. It also may apply \nwhen there is no corresponding impure feature. The technique applies not just to interpreters, but to \na wide range of functional programs. The GRASP team at Glasgow is constructing a compiler for the functional \nlanguage Haskell. The compiler is itself written in Haskell, and uses monads to good effect. Though this \npaper concentrates on the use of monads in a program tens of lines long, it also sketches our experience \nusing them in a program three orders of magnitude larger. Programming with monads strongly reminiscent \nof continuation-passing style (CPS), and this paper ex\u00adplores the relationship between the two. In a \nsense they are equivalent: CPS arises as a special case of a monad, and any monad may be embedded in \nCIY3 by changing the answer type. But the monadic approach provides additionall insight and allows a \nfiner degree of control. which programs may the effect of impure and continuations; achieved with such \nreflect which example of of monads. A simple interpreter is modified to various extra features: error \nmessages, state, effects the use support output, The concept of a monad comes from category the\u00adory, \nbut this paper assumes no prior knowledge of such arcana. Rather, it is intended as a gentle introduction, \nwith an emphasis on why abstruse theory may be of interest to computing scientists. The examples will \nbe given in Haskell, but no knowl\u00adedge of that is needed either. What the reader will require is a passing \nfamiliarity with the basics of pure and impure functional programming; for general back\u00adground see [BW87, \nPau91]. The languages refered to are Haskell [HPW91], Mirandal [Tur90], Standard ML [MTH90], and Scheme \n[RC86]. Some readers will recognise that the title of this pa\u00adper is a homage to Reynolds [Rey81] and \nthat the use of monads was inspired by Moggi [Mog89a, Mog89b]. Of these matters more will be said in \nthe conclusion. For now, please note that the word essence is used in a technical sense: I wish to argue \nthat the tech\u00adnique described in this paper is helpful, not that it is necessary. The remainder of this \npaper is organised as follows. Section 2 illustrates the use of monads to structure programs by considering \nseveral variations of an inter\u00adpreter. Section 3 explores the relation between mon\u00adads and continuation-passing \nstyle. Section 4 sketches how these ideas have been applied in a compiler for Haskell that is itself \nwritten in Haskell. Section 5 con\u00adcludes.  Interpreting monads This section demonstrates the thesis \nthat monads enhance modularity, by presenting several variations of a simple interpreter for lambda calculus. \nThe interpreter is shown in Figure 1. It is written in Haskell. The notation ( \\name -> expr ) stands \nfor a lambda expression, and name is an infix operator. The type constructor H and functions unitM, bindM, \nand showfl have to do with monads, and are explained below. The interpreter deals with values and terms. \nA value is either Wrong, a number, or a function. The value Wrong indicates an error, such as an unbound \nvariable, an attempt to add non-numbers, or an at\u00adtempt to apply a non-function. A term is either a variable, \na constant, a sum, a lambda expression, or an application. The following will serve as test data. t ermO \n= (App (Lam X (Add (Var x ) (Var x ))) (Add (con 10) (con 11))) 1Miranda is a trademark of Research \nSoftware Limited. In more conventional notation this would be written ((Az. z + z) (10 + 11)). For the \nstandard interpreter, evaluating test t ermO yields the string 42 . The interpreter has been kept small \nfor ease of il\u00adlustration. It can easily been extended to deal with additional values, such as booleans, \npairs, and lists; and additional term forms, such as conditional and fixpoint. 2.1 What is a monad? \nFor our purposes, a monad is a triple (M, unitM, bindM) consisting of a type constructor M and a pair \nof polymorphic functions. unitM ::a ->Ma bindM :: Ma-> (a-> Mb)->Mb These two functions satisfy three \nlaws, which are dis\u00adcussed in Section 2,10. The basic idea in converting a program to monadic form is \nthis: a function of type a -> b is converted to a function of type a -> M b. Thus, in the defini\u00adtion \nof Value, functions have type Value -> M Value rather than Value -> value, and interp has type Term -> \nEnvironment -> M Value rather than type Term -> Environment -> Value. Similarly for the auxiliary functions \nlookup, add, and apply, The identity function has type a -> a. The cor\u00adresponding function in monadic \nform is unitM, which has type a -> M a. It t,akes a value into its corre\u00adsponding represent ation in \nthe monad. Consider the case for constants. interp (Con i) e = unitM (Num i) The expression (Num i) has \ntype Value, so applying unitM to it yields the corresponding M Value, as re\u00ad quired to match the type \nof interp. Two functions k :: a -> b and h :: b -> c may be composed by writing \\a-> let b=ka inhb which \nhas type a -> c. (Here \\name -> expr is a lambda expression. By convention, a will double as a type variable \nand a value variable.) Similarly, two functions in monadic form k :: a -> M b and h :: b -> M c are composed \nby writing (\\a -> k a bindM (\\b -> h b)) which haa type a > M c. (Here name is Haskell not at ion for \nan infix function. The expression a name b is equivalent to name a b.) Thus bindM serves a role similar \nto a let expression. The three monad laws alluded to above simply insure that this form of composition \nis associative, and has unitM as a left and right identity. Consider the case for sums. type Name String \ndata Term Var Con Name Int Add Term Term Lam Name Term App Term Term data Value Wrong Num Int Fun (Value \n-> M Value) type Environment [(Name, Value)] showval showval showval showval Wrong (Num (Fun i) f) Value \n-> String <wrong> showint i <function> int erp interp interp interp interp interp (Var (Con (Add (Lam \n(App x) i) u x t e e v) v) u) e e e Term -> Environment lookup x e unitM (Num i) interp u e bindM interp \nv e bindM1 add a b)) unitM (Fun (\\a -> interp t e bindM interp u e bindM apply f a)) -> (\\a (\\b interp \n(\\f (\\a M Value -> -> v ((x,a):e))) -> -> lookup lookup lookup X x [1 ((y,b):e) Name -> Environment unitM \nWrong if x==y then unitM -> M b Value else lookup x e add Value -> Value -> M Value add add (Num a b \ni) (Num j) uni.tM unitM (Num Wrong (i+j)) apply apply apply (Fun f a k) a Value ka unitM -> Value Wrong \n-> M Value test test t Term -> String showM (interp t [1) Figurel: Interpretation inamonad (call-by-value) \n int erp :: Term -> Environment -> Value interp (Var x) e = lookup x e interp (Con i) e =Numi interp \n(Add u v) e = add (interp u e) (interp v e) interp (Lam x v) e = Fun (\\a -> interp v ((x,a):e)) interp \n(App t u) e = apply (interp t e) (interp u e) Figure 2: Standard interpreter interp (Add u v) e = interp \nu e bindMC (\\a -> interp v e cbindMC (\\b -> add a b)) This can be read as follows: evaluate u; bind \natothe result; evaluate v; bind b to the result; add a to b. The types workout: the calls to interpand \naddyield results of type M Value, and variables a and b have type Value. Application is handled similarly; \nin particular, both the function and its argument are evaluated, so this interpreter is using a call-by-value \nstrategy. An in\u00adterpreter with acall-by-name strategy is discussed in Section 3. Just as the type Value \nrepresents avalue, the type M Value can be thought of as representing a compu\u00adtation. The purpose of \nunitM is to coerce a value into a computation; the purpose of bindM is to evaluate a computation, yielding \na value. Informally, unitM gets us into a monad, and bindM gets us around the monad. How do we get out \nof the monad? In general, such operations require a more ad hoc design. For our purposes, it will suffice \nto provide the following. showM :: H Value -> String This is used in test. By changing the definitions \nof M, unltM, bindM, and showM, and making other small changes, the inter\u00adpreter can be made to exhibit \na wide variety of be\u00adhaviors, as will now be demonstrated. 2.2 Variation zero: Standard interpreter To \nbegin, define the trivial monad. = type Ia a = a bindI ( k =ka showI a showval a unit I a a This is \ncalled the identity monad: I is the iden\u00adtity function on types, unitI is the identity function, bindI \nis postfix application, and showI is equivalent to showval. Substitute monad I for monad M in the interpreter \n(that is, substitute I, unitI, bindI, showI for each occurrence of M, unitM, bindM, showM). Simplify\u00ading \nyields the standard meta-circular interpreter for lambda calculus shown in Figure 2. The other func\u00adtions \nin the interpreter simplify similarly. For this variant of the interpreter, evaluating test termO returns \nthe string 42 , as we would expect. 2.3 Variation one: Error messages To add error messages to the interpreter, \ndefine the following monad. data Ea = Suc a I Err String nnitE a = Suca errorE s = Err s (Sue a) bi.ndE \nk = k a (Err s) bindE k = Err s showE (Sue a) = Success: ++ showval a showE (Err s) = Error: ++ s \nEach function in the interpreter either returns nor\u00admally by yielding a value of the form Suc a, or indicates \nan error by yielding a value of the form Err s where s is an error message. If m :: E a and k :: a -> \nE b then m bindE f k acts as strict post\u00adfix application: if m succeeds then k is applied to the successful \nresult; if m fails then so does the application. The show function displays either the successful result \nor the error message. To modify the interpreter, substitute monad E for monad M, and replace each occurrence \nof unitE Wrong by a suitable call to errorE. The only occurrences are in lookup, add, and apply. lookup \nX [1 = errorE ( unbound variable: ++ x) add ab = errorE ( should be numbers: ++ showval a ++ , 1 \n++ showval b) apply f a = errorE ( should be function: ++ showval f) No other changes are required. \nEvaluating test termO now returns Success: 42 ; and evaluating test (App (Con 1) (Con 2)) returns Error: \nshould be function: l . In an impure language, this modification could be made using exceptions or continuations \nto signal an error,  2.4 Variation two: Error messages with positions Let Position be a type that indicates \na place in the source text (say, a line number). Extend the Term datatype with a constructor that indicates \na location: data Term = . . . I At Position Term with reference values and operations that side-effect \na The parser will produce such terms as suitable. For instance, (At p (Appt (At qu))) indicates that \np is the position of the term (App t u) and that q is the position of the subterm u. Based on E, define \na new monad P that accepts a position to use in reporting errors. type Pa = Position -> Ea unitP a = \n\\p -> unitE a errorP s = \\p -> errorE (showpos p ++ II. ,, ++ s.) m CbindPC k = \\p -> m p bindE (\\x -> \nkxp) showP m = showE (m posO) Here unitp discards the current position, errorp adds it to the error \nmessage, bindP passes the position to the argument and function, and showP passes in an initial position \nposo. In addition, there is a function to change position. resetP :: Position -> P x > P x resetP q m \n= \\p->rnq This discards the position p that is passed in, replacing it with the given position q, To \nmodify the interpreter of the previous section, substitute monad P for monad E and add a case to deal \nwith At terms. interp (At p t) e = resetP p (interp t e)  This resets the position as indicated. No \nother change is required. Without monads, or a similar technique, this mod\u00adification would be far more \ntedious. Each clause of the interpreter would need to be rewritten to accept the current position as \nan additional parameter, and to pass it on as appropriate at each recursive call. In an impure language, \nthis modification is not quite so easy. One method is to use a state variable that cent ains a stack \nof positions. Care must be taken to maintain the state properly: push a position onto the stack on entering \nthe At construct and pop a position off the stack when leaving it. 2.5 Variation three: State To illustrate \nthe manipulation of state, the interpreter is modified to keep count of the number of reductions that \noccur in computing the answer. The same tech\u00adnique could be used to deal with other state-dependent constructs, \nsuch as extending the interpreted language heap. The monad of state transformers is defined as fol\u00adlows. \ntype S a = State -> (a, State) unitS a = \\sO -> (a, sO) m bindS k = \\sO -> let (a, si) = m sO (b,s2) \n=kaSI in (b, s2) A state transformer takes an initial state and returns a value paired with the new \nstate. The unit function returns the given va,lue and propagates the state un\u00adchanged. The bind function \ntakes a state transformer m:: Saand afunction k :: a-> Sb, It passes the initial state to the transformer \nm; this yields a value paired with an intermediate state; function k is applied to the value, yielding \na state transformer (ka :: S b), which is passed the intermediate state; this yields the result paired \nwith the final state. To model execution counts, take the state to be an integer. type State = Int The \nshow function is passed the initial state O and prints the final state as a count. showS m = let (a, \nsl) =mO in Value: ++ showval a ++ ; count: ++ showint si The current count is incremented by the \nfollowing. t ickS ::so tickS = \\s -> ((), S+l)  The value returned is the empty tuple () whose type \nis also written (). The typing oft ickS makes clear that the value returned is not of interest. It is \nanalogous to the use in an impure language of a function with result type (), indicating that the purpose \nof the function lies in a side effect. The interpreter is modified by substituting monad S for monad \nM, and changing the first lines of apply and add. apply (Fun k) a = tickS bindS (\\() ~ k a) add (Num \ni) (Nnm j) = tickS bindS (\\() -> unitS (Num (i+j)))  This counts one tick for each application and addition. \nNo other changes are required. Evaluating test termO now returns Value: 42; Count: 3 , A further modification \nextends the language to al\u00ad low access to the current execution count. First, add a further operation \nto the monad. fetchS :: S State fetchS = \\s -> (s, s) This returns the current count. Second, extend \nthe term data type, and add a new clause to the inter\u00ad preter. data Term = ... I count interp Count e \n= fetchS bindS (\\i -> Num i) Evaluating Count fetches the number of execution steps performed so far, \nand returns it as the value of the term. For example, applying test to (Add (Add (Con 1) (Con 2)) Count) \nreturns Value: 4; Count: 2 , since one addition occurs before Count is evaluated. In an impure language, \nthese modifications could be made using state to contain the count.  2.6 Variation four: Output Next \nwe modify the interpreter to perform output. The state monad seems a natural choice, but it s a poor \none: accumulating the output into the final state means no output will be printed until the comput a\u00adtion \nfinishes. The following design displays output as it occurs; it depends on lazy evaluation. The output \nmonad is defined as follows. type O a = (String, a) = (,, !,, ~) unitO a m bindO k = let (r, a) = m \n(sjb) =k a in (r++s, b) showO (s, a) = output: ++ s ++ Value: ++ showval a Each value k paired with \nthe output produced while computing that value. The unit O function returns the given value and produces \nno output. The bindO function performs an application and concatenates the output produced by the argument \nto the output pro\u00adduced by the application. The showO function prints the output followed by the value. \nThe above functions propagate output but do not generate it; that is the job of the following. Outo :: \nValue -> Out () outO a = (showval a ++ ; , a) This outputs the given value followed by a semicolo~. The \nlanguage is extended with an output operation. Substitute monad O for monad M, and add an a new term \nand corresponding clause. data Term = ... I Out Term interp (Out u) e = lnterp u e bindO (\\a -> out \nO a bindO( (\\() > unitO a)) Evaluating (Out u) causes the value of u to be sent to the output, and returned \nas the value of the term. For example, applying test to (Add (Out (Con 41)) (Out (Con i))) returns Output: \n41; 1; Value: 42 . In an impure language, this modification could be made using output as a side effect. \n2. 7 Variation five: Non-deterministic choice We now modify the interpreter to deal with a non\u00addeterministic \nlanguage that returns a list of possible answers. The monad of lists is defined as follows. type La = \n[a] unitL a = [a] m bindL k = [bla<-m, b<-ka] zeroL = [1 1 plusL m = 1++m showL m = showlist [ showval \na I a <-m ] This is expressed with the usual list comprehension notation. The function showllst takes \na list of strings into a string, with appropriate punctuation. The interpreted language is extended with \ntwo new constructs. Substitute monad L for monad M, and add two new terms and appropriate e clauses. \ndata Term = ... I Fail I Amb Term Term int erp Fail e = zeroL interp (Amb u v) e = int erp u e plusL \n~int erp v e Evaluating Fail returns no value, and evaluating (Amb u v) returns all values returned by \nu or V. For example, applying test to (App (Lam x (Add (Var x ) (Var x ))) (Amb (Con i) (Con 2))) returns \n [2,4] . It is more difficult to see how to make this change in an impure language. Perhaps one might \ncreate some form of coroutine facility.  2.8 Variation six: Propagating state backwards Return now \nto the state example of Section 2.5. Lazy evaluation makes possible a strange variation: the state may \nbe propagated backward. All that is required is to change the definition of bindS. unitS a = \\sO -> (a, \nsO) m bindS k = \\s2 -> let (a, sO) = m SI (b,sl) =kaS2 in (b,sO) This takes the final state as input, \nand returns the initial state as output. As before, the value a is gen\u00aderated bym and passed tok. But \nnow the initial state is passed tok, theintermediate state goes from ktom, and the final state is returned \nby m. The two clauses in the let expression are mutually recursive, so this works only in a lazy language. \nThe Count term defined in Section 2.5 now returns the number of steps to be performed between its eval\u00aduation \nand the end of execution. As before, applying test to (Add (Add (Con 1) (Con 2)) Count) returns value: \n4; Count: 2 , but for a different reason: one addition occurs after the point at which count is evaluated. \nAn unresolvable mutual depen\u00addence, known as a black hole, would arise in the un\u00adfortunate situation \nwhere the number of steps yet to be performed depends on the value returned by Count. In such a case \nthe interpreter would fail to terminate or terminate abnormally. This example may seem contrived, but \nthis monad arises in practice. John Hughes and I discovered it by analysing a text processing algorithm \nthat passes information both from left to right and right to left. To make this change in an impure language \nis left as an exercise for masochistic readers. 2.9 Call-by-name interpreter The interpreter of Figure \n1 is call-by-value, This can be seen immediately from the types. Functions are represented by the type \nValue -> M Value, so the argument to a function is a value, though the result of applying a function \nis a computation. The corresponding call-by-name interpreter is shown in Figure 3. Only the types and \nfunctions that differ from Figure 1 are shown. The type used to repre\u00adsent functions is now M Value -> \nM Value, so the ar\u00adgument to a function is now a computation. Similarly, the environment is changed to \ncontain computations rather than values. The code for interpreting con\u00adstants and addition is unchanged. \nThe code for vari\u00adables and lambda abstraction looks the same but has changed subtly: previously variables \nwere bound to values, now they are bound to computations. (Hence a small change in lookup: a call to \nunit M has van\u00adished.) The code for application does change: now the function is evaluated but not the \nargument. The new interpreter can be modified in the same way as the old one. If modified for execution \ncounts as in Section 2.5, the cost of an argument is counted each time it is evaluated. Hence evaluating \ntest t ermo now returns the string Value: 42; Count: 4 , because the cost of adding 10 to II is counted \ntwice. (Compare this with a count of 3 for the call-by-value version.) If modified for a non-deterministic \nlanguage as in Section 2.7, then a term may return a different value each time it is evaluated. For example, \napplying test to (App (Lsm x (Add (Var x ) (Var x ))) (Amb (Con ~.) (Con 2)))  now returns [2,3,3,41 \n; compare this with [2,41 for the call-by-value version. An advantage of the monadic style is that the \ntypes make clear where effects occur. Thus, one can distin\u00adguish call-by-value from call-by-name simply \nby exam\u00adining the types. If one uses impure features in place of monads, the clues to behaviour are more \nobscure. 2.10 Monad laws For (M, unitM, bindM) to qualify as a monad, the following laws must be satisfied. \nLeft unit: (nnitM a) bindM k = k a Right unit: m CblndM unitM = m Associative: m bindM (\\a -> (k a) \ncbindM h) = (m bindM (\\a -> (k a)) bindM h) These laws guarantee that monadic composition, as discussed \nin Section 2.1, is associative and has a left and right unit. It is easy to verify that the monads described \nin this paper do satisfy these laws. To demonstrate the utility of these laws, let us prove that (Add \nt (Add U V)) and (Add (Add t U) V) always return the same value. Simplify the left term: data type \nint erp interp interp i.nterp interp interp lookup lookup lookup apply apply apply Value Environment \n(Var x) e (Con i) e (Add uv) e (Lamxv) e (Apptu) e X [] x ((y,n):e) (Fun h) m fm Wrong Num Int Fun (M \nValue -> M Value) [(Name, M Value)] :: Term -> Environment -> M Value = lookup x e = unitM (Num i) \n interp u e bindM (\\a -> interp v e bindM( (\\b -> add a b)) unitM (Fun (\\m -> interp v ((x,m):e))) lnterp \nt e cbindM (\\f -> apply f (interp u e)) Name -> Environment -> M Value unitM Wrong if x==y then n else \nlookup x e Value -> M Value > M Value hm unitM Wrong Figure3: Interpretation in amonad (call-by-name) \ninterp (Add t (Add u v)) e unitM (i+j+k), as follows from two uses of the left = interp t e bindM (\\a \n-> unit law and the associativit y of addition; otherwise interp (Add u v) e bindM (\\y -> the result \nisvrong, also by the left unit law. add a y)) The aboveproofis trivial. Without themonadlaws, = interp \nt e bindM (\\a -> it would be impossible. (interp u e blndM (\\b -> As another example, note that foreach \nmonadwe interp v e bindMC (\\c -> can define the following operations, addb c))) bindM (\\y -> mapM :: \n(a->b)->(Ma->Mb) add a y)) = mapM f m = m bindM (\\a -> unitM (f a)) interp t e bindM (\\a -> interp u \ne bindM (\\b ->  j o inM :: M(Ma)->Ma interp v e bindM (\\c -> joimM z = z bindM (\\m -> m) add b c bindM \n(\\y -> add a y)))). For the list monad, mapMis the familiar malfunction, and.joinM concatenates a list \nof lists. Using (.) for Thefirst twosteps are simple unfolding; the third step function composition ((f.g) \nx = f (g x)), one can is justified by the associative law, Similarly, simplify then formulate anumber \noflaws. the right term: mapMid = id interp (Add (Add t u) v) e mapM (f.g) = mapM f . mapM g = interp \nt e bindM (\\a -> interp u e bindM (\\b -> mapM f . unitM = unitM . f interp v e bindM (\\c -> mapM f . \njoinM = joinM . mapM (rnapM f) add a b bindM (\\x -> joinM . unitM = id add x c)))). joinM . mapM unitM \n= id Again, this is two unfold steps andause of the asso-joinM . mapM joinM = joi.nM . joinM ciative \nlaw. It remains to prove that m bindM( k = joinM (mapM k m) add a b bindMc (\\x -> add x c) Theproofofeach \nis a simple consequence ofthe three = add b c bindM (\\y -> add y a). monad laws. This is done by case \nanal ysis. If a, b, c have Often, monads are definednotinterms ofunitMand the forms Num i, Num j, Num \nk then the result is bindM, but rather intermsofunitM, jointM, andmapM [Mac71, LS86, Mog89a, Wad90]. \nThe three monad laws are replaced by the first seven of the eight laws above. If one defines bindM by \nthe eighth law, then the three monad laws follow. Hence the two definitions are equivalent. As described \nin [Wad90], the list comprehension no\u00adtation generalises to an arbitrary monad. That paper gives the \nfollowing translations: [t] = nnitM t [tlx <-u] = mapM (\\x -> t) u [tlx<-u, y<-vl = joinM (mapM (\\x \n-> mapM (\\y -> t) v) u) For the list monad, this yields the usual notion of list comprehension. In the \nnotation of this paper, the translation may be expressed as follows. [t] = unitM t [tlx<-ul = u CbindMC \n(\\x -> unitM t) [tlx<-u, y<-vl = u bindM (\\x -> v bindMC (\\y -> unitM t))  Here the translated terms, \nif not comprehensions, are at least comprehensible. The equivalence of the two translations follows from \nthe monad laws.  3 Continuing monads The purpose of this section is to compare the monadic style advocated \nin Section 2 with continuation-passing style (CPS). Continuation-passing style was first developed for \nuse with denotational semantics [Rey72, P1075]. It provides fine control over the execution order of \na pro\u00adgram, and has become popular as an intermediate lan\u00adguage for compilers [SS76, AJ89]. This paper \nstresses the modularity afforded by CPS, and in this sense has similar goals to the work of Danvy and \nFilinski [DF90], 3.1 CPS interpreter The monad of continuations is defined as follows. type K a = ~a \n-> Answer) -> Answer unitK a =\\c->ca m bindK k = \\c->m(\\a->kac) the final result c a (of type Answer). \nThus, unitK a yields the CPS representation of a. If m :: K a and k ::a -> K b, then m bhlK { k acts \nas follows: bind c to the current continuation, evaluate m, bind the result to a, and apply k to a with \ncontinuation c. Substituting monad K for monad M in the interpreter and simplifying yields an interpreter \nwritten in CPS, as shown in Figure 4. The functions lookup, add, and apply now also take continuations. \nThe line defining Add can be read: Let c be the current continuation, evaluate u, bind a to the result, \nevaluate v, bind b to the result, and add a to b with continuation c. This reading is closely related \nto the monadic read\u00ading given in Section 2.1, and indeed the CPS and monadic versions are quite similar: \nthe CPS version can be derived from the monadic one by simply elid\u00ading each occurrence of bindM , and \nadding bits to the front and end to capture and pass on the continuation c. The second argument to bindM \nhas type a -> (b -> Answer) -> Answer and this is what k ranges over. A continuation has type b -> Answer \n and this is what c ranges over. Both k and c serve similar roles, acting as continuations at different \nlevels. The Answer type may be any type rich enough to represent the final result of a computation. One \nchoice is to take an answer to be a value. type Answer = Value This determines the definition of showK. \nshowK m = showval (m id) Here m :: K Value is passed id :: Value -> Value as a continuation, and the \nresulting Value is converted tp a string. Evaluating test t ermO returns 42 , as before. Other choices \nfor the Answer type will be considered in Section 3.3 3.2 Call with current continuation Having converted \nour interpreter to CPS, it is now straightforward to add the call with current continu\u00adation (callcc) \noperation, found in Scheme [RC86] and Standard ML of New Jersey [DHM91]. The following operation captures \nthe current con\u00adt inuation and passes it into the current expression. In GPS, a value a (of type a) is \nrepresented by a func\u00ad callccK ::((a-> Kb)->Ka)->Ka tion that takes a continuation c (of type a -> Answer) \ncallccK h = ic-> let ka=\\d->ca and applies the continuation to the value, yielding in hkc interp :: \nTerm -> Environment -> (Value -> Answer) -> Answer interp (Var x) e = \\~ -> lookup x e c interp (Con \ni) e = \\c -> ci interp (Add u v) e = \\~ -> interp u e (\\a -> i.nterp v e (\\b > add a b c)) interp (Lam \nx v) e = \\c -> c (Fun (\\a -> interp v ((x,a):e))) interp (App t u) e = \\c -> interp t e (\\f -> interp \nu e (\\a -> apply f a c)) Figure 4: Interpreter in continuation-passing style The argument to callccK \nis a function h, which is Just as unitM converts a value of type a into type passed afunctionk oftype \n(a -> K b). Ifk is called M a, values of type M a can be converted into type K a with argument a, it \nignores its continuation d and as follows. passes atothe captured continuation instead. promot eK :: \nMa->KaToaddcallcc to the interpreted language, add an promoteK m = \\c -> m bindM cappropriate term and \nanew case to the interpreter. Sincere :: Maandc :: a > M Value, the type ofdata Term = . . . ! Callcc \nName Term m cbindM c is M Value, as required. interp (Callcc x v) e For example, to incorporate error \nmessages, take M = callccK to be the monad E defined in Section 2.3. We then (\\k-> interpv ((x, Funk) \n:e)) calculate as follows: This uses callc cKto capture the current continuation errorK :: String -> \nK Value k, and evaluates vwithxbound to afunction that acts errorK s = promot eK ( errorE s) as k. = \n\\c -> (errorE s) bindE c For example, applying testto = \\c -> Error s bindE c = \\c -> Error s (Add (Con \n1) (Callcc k The equalities follow by applying the definitions of (Add (Con2) promot eK, errorE, and \nbindE, respectively, We can (App (Var k ) (Con 4))))) take the last line as the definition of errorK. \nAs we would expect, this simply ignores the continuation andreturns 5 . returns the error as the final \nresult, The last section stressed that monads support mod\u00ad  3.3 Monads and CPS ularity. For example, \nmodifying the monadic inter-Wehave seen that by choosing asuitable monad, the preter to handle errors \nrequires few changes: one only monad interpreter becomes a CPS interpreter. A con\u00ad has to substitute \nmonad E for monad M and introduce verse property is also true: by choosing a suitable calls to errorE \nat appropriate places. CPS supports space of answers, a(lPS interpreter can act as a monad modularity \nin a similar way. For example, modifying interpreter. the CPS interpreter to handle errors is equally \nsimple: Thegeneral trick isasfollows. Toachieve the effects one only has to change the definitions of \nAnswer and of a monad M in CPS, redefine the answer type to test, and introduce calls to errorK at appropriate \ninclude an application of M. places. Execution counts (as in Section 2.5) and output (as type Answer \n= M Value in Section 2.6) may be incorporated into continuation\u00adpassing style similarly. For execution \ncounts, takeThe definition of showK is modified accordingly. Answer = S Value and calculate a continuation \nver\u00adshowK m = showM (m unitM) sion of tickS, Here m of type K Value is passed unitM of type t ickK ::K() \nValue -> M Value as a continuation, and the result\u00ad t ickK = promoteK tickS ing M Value is converted \nto a string by showM. = \\c -> tickS bindS c = \\C > (\\S ->((),s+1)) bindS C = \\c .->\\s -> c () (s+1) \n Thecase ofoutput is similar. In both cases, the mod\u00adifications to the CPS version of the interpreter \nare as simple as those to the monadic version. 3.4 Monads vs. CPS Given the results of the previous \nsection, one may wonder whether there is any real difference between monads and CPS. With monads, one \nwrites III bindM (\\a .-> k a) and with CPS one writes (\\c -> m(\\a -> kac)) and the choice between these \nseems little more than a matter of taste. There is a difference. Each of the monad types we have described \nmay be turned into an abstract data type, and that provides somewhat finer control than CPS. For instance, \nwe have seen that the CPS ana\u00adlogue of the monad type S a is the type (a -> S Value) -> S Value. This \nlatter type contains values such as \\c -> \\s -> (Wrong, c). This provides an error escape: it ignores \nthe current continuation and always returns wrong. The state monad S provides no such escape facility. \nWith mon\u00adads, one can choose whether or not to provide an es\u00adcape facility; CPS provides no such choice. \nWe can recover this facility for CPS by turning con\u00adtinuations into an abstract data type, and providing \nunltK and bindK as operations, but not providing callccK. So CPS can provide the same fine control as \nmonads if CPS is expressed as a monad! Perhaps a more significant difference between mon\u00adads and CPS \nis the change of viewpoint. Monads focus attention on the question of exactly what abstract op\u00aderations \nare required, what laws they satisfy, and how one can combine the features represented by different monads. \n  A Experiencing monads Each phase of the Haskell compiler is associated with a monad. The type inference \nphase uses a monad with an er\u00adror component (similar to E in Section 2.3), a posi\u00adtion component (similar \nto P in Section 2.4), and two state components (similar to S in Section 2.5). The state components are \na name supply, used to generate unique new variable names, and a current substitu\u00adtion, used for unification. \nThe simplification phase uses a monad with a single single state component, which is again a name supply. \nThe code generator phase uses a monad with three state components: a list of the code generated so far, \na table associating variable names with addressing modes, and a second table that caches what is known \nabout the state of the stack at execution time. In each case, the use of a monad greatly simplifies bookkeeping, \nThe type inference would be extremely cluttered if it was necessary to mention explicitly at each step \nhow the current substitution, name supply, and error information are propagated; for a hint of the problems, \nsee [Han87]. The monads used have been altered several times without difficulty. The change to the interpreter \ndescribed in Section 2.4 was based on a similar change made to the compiler. The compiler has just begun \nto generate code, and a full assesment lies in the future. Our early experience supports the claim that \nmonads enhance modularity. 5 Conclusion 5.1 The future This work raises a number of questions for the \nfuture. What are the limits of this technique? It would be desirable to characterise what sort of language \nfea\u00adtures can be captured by monads, and what sort can\u00adnot. Call-by-value and call-by-name translations \nof lambda calculus into a monad are well known; it re\u00admains an open question whether there might be a \ncall\u00adby-need translation that evaluates each argument at most once. Is syntactic support desirable? The \ntechnique given here, while workable, has a certain syntactic clumsi\u00adness. It may be better to provide \nan alternative syn\u00adtax. One possibility is to provide letMa<-rn inka as alternative syntax for m bindM \n(\\a -> k a). Another possibility arises from monad comprehensions [Wad90]. What about eflciency? The \nstyle advocated here makes heavy use of data abstraction and higher-order functions. It remains to be \nseen what impact this has on efficiency, and tlhe GRASP team looks forward to examining the performance \nof our completed Haskell compiler. We are hopeful, since we have placed high priority on making the relevant \nfeatures inexpensive. How does one combine monads? The monads used in the Haskell compiler involve a \ncombination of fea\u00adtures; for instance, the type inference combines state and exceptions. There is no \ngeneral technique for combining two arbitrary monads. However, Sec\u00adtion 3.3 shows how to combine continuations \nwith any other monad; and similar techniques are avail\u00adable for the state, exception, and output monads \n[Mog89a, Mog89b]. One might forma library of stan\u00addard monads with standard ways of combining them. This \nwould be aided by parameterised modules, which are present in Miranda and Standard ML, but absent in \nHaakell. Should certain monads be provided as primitive? Monads may encapsulate impure effects in a pure \nway. For example, when the state is an array, the state monad can safely update the array by overwriting, \nas described in [Wad90]. Kevin Hammond and I have built an interface that allows Haskell programs to \ncall C routines, using monads to sequence the calls and preserve referential transparency. The effect \nis simi\u00adlar to the abstract continuations used in Hope+C [Per87]. How do monads compare to other approaches \nto state ? Several new approaches to state in pure func\u00adtional languages have emerged recently, based \non var\u00adious type disciplines [GH90, SR191, Wad91]. These need to be compared with each other and with \nthe monad approach. Can type inference help ? By examining where mon\u00adads appear in the types of a program, \none determines in effect where impure features are used. In this sense, the use of monads is similar \nto the use of ef\u00adfect systems as advocated by Gifford, Jouvelot, and others, in which a type system infers \nwhere effects oc\u00adcur [GL86, JG91]. An intriguing question is whether a similar form of type inference \ncould apply to a lan\u00adguage based on monads. 5.2 The past Finally, something should be said about the \norigin of these ideas. The notion of monad comes from category theory [Mac71, LS86]. It first arose in \nthe area of homological algebra, but later was recognised (due to the work of Kleisli and of Eilenberg \nand Moore) to have much wider applications. Its importance emerged slowly: in early days, it was not \neven given a proper name, but called simply a standard construction or a triple . The formulation used \nhere is due to Kleisli. Eugenio Moggi proposed that monads provide a useful structuring tool for denotational \nsemantics [Mog89a, Mog89b]. He showed how lambda calculus could be given call-by-value and call-by-name \nseman\u00adtics in an arbitrary monad, and how monads could encapsulate a wide variety of programming language \nfeatures such as state, exception handling, and contin\u00aduations. Independent of Moggi, but at about the \nsame time, Michael Spivey proposed that monads provide a useful structuring tool for exception handling \nin pure func\u00adtional languages, and demonstrated this thesis with an elegant program for term rewriting \n[Spi90]. He showed how monads could treat exceptions (as in Section 2.3) and non-deterministic choice \n(as in Section 2.7) in a common framework, thus capturing precisely a notion that I had groped towards \nyears earlier [Wad85]. Inspired by Moggi and Spivey, I proposed monads as a general technique for structuring \nfunctional pro\u00adgrams. My early proposals were based on a special syntax for monads, that generalised \nlist comprehen\u00adsions [Wad90]. This was unfortunate, in that it led many to think a special syntax was \nneeded. This new presentation is designed to convey that monads can be profitably applied to structure \nprograms today with exist ing languages. A key observation of Moggi s was that values and computations \nshould be assigned different types: the value type a is distinct from the computation type M a. In a \ncall-by-value language, functions take values into computations (as in a -> M b); in a call-by-name lan\u00adguage, \nfunctions take computations into computations (asin Ma-> Mb). John Reynolds made exactly the same point \na decade ago [Rey81]. The essence of Algol, according to Reynolds, is a programming language that distin\u00adguishes \ndata types from phrase types. In his work data types (such as int) play the roles of values, and phrase \ntypes (such as int exp) play the role of com\u00adputations, and the same distinction between call-by\u00advalue \nand call-by-name appears. These ideas form the basis for the design of Forsythe [Rey89a]. But the vital \nunitM and bi.ndM operations do not appear in Reynolds work. This is not the only time that John Reynolds \nhas been a decade ahead of the rest of us. Among other things, he was an early promoter of continuation\u00adpassing \nstyle [Rey72] and the first to apply category theory to language design [Rey80, Rey8 1]. One in\u00adtriguing \naspect of his recent work is the use of inter\u00adsection types [Rey89a, Rey89b, Rey9 1], so perhaps we should \nexpect an upsurge of interest in that topic early in the next millenium. This paper demonstrates that \nmonads provide a helpful structuring technique for functional programs, and that the essence of impure \nfeatures can be cap\u00adtured by the use of monads in a pure functional lan\u00adguage. In Reynolds sense of the \nword, the essence of Stan\u00addard ML is Haskell. Acknowledgements. The work on the HaskelI com\u00adpiler reported \nhere is a joint effort of the GRASP team, whose other members are Cordy Hall, Kevin Ham\u00admond, Will Partain, \nand Simon Peyton Jones. For helpful comments on this work, I m grateful to Don- 1.Z [AJ89] [BW87] [DF90] \n[DHM91] [GH90] [GL86] [Han87] [HPW91] [JG91] [LS86] [Mac71] A. Appel and T. Jim, Continuation-passing, \nclosure-passing style. In 16 th Symposium on Principles of Programming Languages, Austin, Texas; ACM, \nJanuary 1989. R. Bird and P. Wadler, Introduction to Functional Programming. Prentice Hall, 1987. 0. \nDanvy and A. Filinski, Abstracting con\u00adtrol. In Conference on Lisp and Functional Programming, Nice, \nFrance; ACM, June 1990. B. Duba, R. Harper, and D. MacQueen, Typing first-class continuations in ML. \nIn 18 th Symposium on Principles of Program\u00adming Languages, Orlando, Florida; ACM, January 1991. J. Guzm&#38;n \nand P. Hudak, Single-threaded polymorphic lambda calculus. In Sym\u00adposium on Logic in Computer Science, \nPhiladelphia, Pennsylvania; IEEE, June 1990. D. K. Gifford and J. M. Lucassen, Inte\u00adgrating functional \nand imperative program\u00adming. In Conference on Lisp and Func\u00adtional Programming, 28 39, Cambridge, Massachusetts; \nACM, August 1986. P. Hancock, A type checker. Chapter 9 of Simon Peyton Jones, The Implementa\u00adtion of \nFunctional Programming Languages, Prentice Hall, 1987. P. Hudak, S. Peyton Jones and P. Wadler, editors, \nReport on the Programming Lan\u00adguage Haskell: Version 1.1. Technical re\u00adport, Yale University and Glasgow \nUniver\u00adsity, August 1991. P. Jouvelot and D. Gifford, Algebraic re\u00adconstruction of types and effects. \nIn 18 th ACM Symposium on Principles of Program\u00adming Languages, Orlando, Florida, January 1991. J. Lambek \nand P. Scott, Introduction to Higher Order Categorical Logic, Cambridge University Press, 1986. S. Mac \nLane, Categories for the Working Mathematician, Springer-Verlag, 1971. [Mog89a] [Mog89b] [MTH90] [Pau91] \n[Per87] [P1075] [RC86] [Rey72] [Rey80] [Rey81] [Rey89a] [Rey89b] [Rey91] ald Brady, Geoffrey Burn, John \nHughes, David King, John Launchbury, Muffy Thomas, and David Watt.  References E. Moggi, Computational \nlambda-calculus and monads. In Symposium on Logic in Computer Science, Asilomar, California; IEEE, June \n1989. (A longer version is avail\u00adable as a technical report from the Univer\u00adsit y of Edinburgh.) E. Moggi, \nAn abstract view of programming languges. Course notes, University of Edin\u00adburgh. R. Milner, M. Tofte, \nand R. Harper, The definition of Standard ML. MIT Press, 1990. L. C. Paulson, ML for the Working Programmer. \nCambridge University Press, 1991. N. Perry, Hope+C, a continuation ex\u00adtension for Hope+. Imperial College, \nDe\u00adpartment of Computing, Technical report IC/FPR/LANG/2.5 .l/21, November 1987. G. Plotkin, Call-by-name, \ncall-by-value, and the .&#38;calculus. Theoretical Computer Science, 1:125-159, 1975. J. Rees and W. \nClinger (eds.), The revised3 report on the algorithmic language Scheme. ACM SIGPLAN Notices, 21(12) :37 \n79, 1986. J. Reynolds, Definitional interpreters for higher-order programming languages. In 25 th ACM \nNational Conference, 717-740, 1972. J. Reynolds, Using category theory to de\u00adsign implicit conversion \nand generic op\u00aderators. In N. Jones, editor, Semantics-Directed Compiler Generation, 211 258, Berlin; \nLNCS 94, Springer-Verlag, 1980. J. Reynolds, The essence of Algol. In de Bakker and van Vliet, editors, \nAlgorithmic Languages, 345-372, North Holland, 1981. J. Reynolds, Preliminary design of the programming \nlanguage Forsythe. Carnegie Mellon University technical report CMU\u00adCS-88-159, June 1988. J. C. Reynolds, \nSyntactic control of in\u00adterference, part II. In International Collo\u00adquium on Automata, Languages, and \nPro\u00ad gramming, 1989. J. Reynolds, The coherence of languages with intersection types. In International \nConference on Theoretical Aspects of Com\u00ad puter Sofiware, Sendai, Japan, LNCS, Springer Verlag, September \n1991. [Spi90] M. Spivey, A functional theory of excep\u00adtions. Science of Computer Programming, 14(1):25-42, \nJune 1990. [SR191] V. Swarup, U. S. Reddy, and E. Ire\u00adland, Assignments for applicative lan\u00adguages. In \nConference on Functional Pro\u00adgramming Languages and Computer Archi\u00adtecture, Cambridge, Massachusetts; \nLNCS 523, Springer Verlag, August 1991. [SS76] G. L. Steele, Jr. and G. Sussman, Lambda, the ultimate \nimperative. MIT, AI Memo 353, March 1976. [Tur90] D. A. Turner, An overview of Miranda. In D. A. Turner, \neditor, Research Topics in Functional Programming. Addison Wesley, 1990. [Wad85] P. Wadler, How to replace \nfailure by a list of successes. Conference on Func\u00adtional Programming Languages and Com\u00adputer Architecture, \nNancy, France; LNCS 201, Springer-Verlag, September 1985. [Wad90] P. Wadler, Comprehending monads. In \nConference on Lisp and Functional Pro\u00adgramming, Nice, France; ACM, June 1990. [Wad91] Is there a use \nfor linear logic? Confer\u00adence on Partial Evaluation and Semantics-Based Program Manipulation (PEPM), \nNew Haven, Connecticut; ACM, June 1991.  \n\t\t\t", "proc_id": "143165", "abstract": "<p>This paper explores the use monads to structure functionalprograms. No prior knowledge of monads or category theory isrequired.</p><p>Monads increase the ease with which programs may be modified.They can mimic the effect of impure features such as exceptions,state, and continuations; and also provide effects not easilyachieved with such features. The types of a program reflect whicheffects occur.</p><p>The first section is an extended example of the use of monads. Asimple interpreter is modified to support various extra features:error messages, state, output, and non-deterministic choice. Thesecond section describes the relation between monads and thecontinuation-passing style. The third section sketches how monadsare used in a compiler for Haskell that is written in Haskell.</p>", "authors": [{"name": "Philip Wadler", "author_profile_id": "81100173596", "affiliation": "", "person_id": "PP39080765", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/143165.143169", "year": "1992", "article_id": "143169", "conference": "POPL", "title": "The essence of functional programming", "url": "http://dl.acm.org/citation.cfm?id=143169"}